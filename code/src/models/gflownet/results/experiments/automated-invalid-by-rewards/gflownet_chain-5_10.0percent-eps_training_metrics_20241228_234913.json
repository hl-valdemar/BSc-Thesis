{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.1370219588279724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.1370219588279724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.1370219588279724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.1370219588279724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.1370219588279724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13694114685058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.13759124279022217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.1370219588279724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.86007690429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254156907399496,
      "backward_entropy": 0.1370219588279724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.43408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18252917130788168,
      "backward_entropy": 0.13704202175140381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.39598083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00020002684323117137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18251673380533853,
      "backward_entropy": 0.13706226348876954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2663116455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00030006232555024326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250403801600137,
      "backward_entropy": 0.13708219528198243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.5473175048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003980443871114403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824912428855896,
      "backward_entropy": 0.13697702884674073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.58944702148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004968816647306085,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824782689412435,
      "backward_entropy": 0.13773239850997926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.17185974121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005941845593042672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18246511618296304,
      "backward_entropy": 0.13699496984481813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.20826721191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.000690556364133954,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18245174487431845,
      "backward_entropy": 0.13778377771377565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.2186737060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007881388301029801,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18243813514709473,
      "backward_entropy": 0.13701157569885253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.69277954101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008857169887050986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242430686950684,
      "backward_entropy": 0.13701974153518676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.04737854003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009824420558288693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18241041898727417,
      "backward_entropy": 0.13721543550491333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.456787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010784170590341091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823963721593221,
      "backward_entropy": 0.13723371028900147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.60118103027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001172217889688909,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823821465174357,
      "backward_entropy": 0.13789979219436646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.89503479003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012659227941185236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18236780166625977,
      "backward_entropy": 0.13705070018768312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.925048828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013607062865048647,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823532978693644,
      "backward_entropy": 0.13794174194335937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.36534118652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014551648637279868,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233863512674967,
      "backward_entropy": 0.13796211481094361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.82643127441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001550290733575821,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18232365449269614,
      "backward_entropy": 0.13731808662414552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.28741455078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016490812413394451,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18230827649434408,
      "backward_entropy": 0.1380025863647461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.7288055419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017452480969950557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18229277928670248,
      "backward_entropy": 0.13735133409500122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.61720275878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018419253174215555,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18227710326512656,
      "backward_entropy": 0.13804090023040771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.5683135986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019416430732235312,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18226120869318643,
      "backward_entropy": 0.13738365173339845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.32589721679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0020427529234439135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18224485715230307,
      "backward_entropy": 0.13740067481994628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.12709045410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021423809230327606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18222846587498984,
      "backward_entropy": 0.13711814880371093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.62010192871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002243049442768097,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18221201499303183,
      "backward_entropy": 0.13743250370025634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.25784301757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002344312611967325,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18219528595606485,
      "backward_entropy": 0.13813405036926268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.9271697998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0024469622876495123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18217821915944418,
      "backward_entropy": 0.13746421337127684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.98062133789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002549821510910988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18216087420781454,
      "backward_entropy": 0.13748000860214232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.85142517089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002653223928064108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18214346965154013,
      "backward_entropy": 0.13715795278549195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.7697296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027567115612328053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18212576707204184,
      "backward_entropy": 0.13716564178466797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.65426635742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002859337255358696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18210798501968384,
      "backward_entropy": 0.13821814060211182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.35963439941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029591151978820562,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18209117650985718,
      "backward_entropy": 0.13717877864837646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.8015899658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003059530397877097,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18207412958145142,
      "backward_entropy": 0.13755069971084594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.36843872070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003160814754664898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18205698331197104,
      "backward_entropy": 0.1371907949447632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.2261505126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0032602613791823387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1820396383603414,
      "backward_entropy": 0.13719602823257446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.07876586914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0033594020642340183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18202215433120728,
      "backward_entropy": 0.13758594989776612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.18423461914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003459514584392309,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18200449148813883,
      "backward_entropy": 0.13720602989196778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.50973510742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0035602254793047905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18198649088541666,
      "backward_entropy": 0.13760781288146973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.9483642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003660370595753193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18196827173233032,
      "backward_entropy": 0.13721516132354736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.9378204345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0037562339566648006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195017178853354,
      "backward_entropy": 0.13762665987014772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.64610290527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038494563195854425,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18193195263544717,
      "backward_entropy": 0.13834400177001954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.88082885742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003942086361348629,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18191381295522055,
      "backward_entropy": 0.13835335969924928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.4807891845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0040375529788434505,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18189557393391928,
      "backward_entropy": 0.13836276531219482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.3230743408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004130502697080374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18187743425369263,
      "backward_entropy": 0.13722386360168456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.80988311767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004225929267704487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18185869852701822,
      "backward_entropy": 0.13766129016876222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.64222717285156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004317492712289095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818400820096334,
      "backward_entropy": 0.13838815689086914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.08595275878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004408333916217089,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18182136615117392,
      "backward_entropy": 0.13722432851791383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.06332397460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004501180723309517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18180233240127563,
      "backward_entropy": 0.1372239351272583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0464630126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004594708792865276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18178321917851767,
      "backward_entropy": 0.13768181800842286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.46744537353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004687709733843803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18176418542861938,
      "backward_entropy": 0.13768599033355713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1243133544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004775545094162226,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18174533049265543,
      "backward_entropy": 0.13842275142669677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.8513641357422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004863182548433542,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.181726336479187,
      "backward_entropy": 0.1384284257888794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.51051330566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004950451198965311,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18170704444249472,
      "backward_entropy": 0.1372152090072632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.22856903076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005040356889367104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18168745438257852,
      "backward_entropy": 0.13721243143081666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.38284301757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005127036478370428,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18166796366373697,
      "backward_entropy": 0.13844424486160278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.57498168945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0052186474204063416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816477378209432,
      "backward_entropy": 0.1376974105834961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.37037658691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005310957320034504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18162723382314047,
      "backward_entropy": 0.13720202445983887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.92869567871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005401264876127243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18160676956176758,
      "backward_entropy": 0.13719795942306517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.7294464111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005491136573255062,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18158618609110513,
      "backward_entropy": 0.13846378326416015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.87179565429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0055821482092142105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18156540393829346,
      "backward_entropy": 0.13718771934509277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.4188232421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005672664847224951,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18154446283976236,
      "backward_entropy": 0.13847227096557618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.20895385742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0057640718296170235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18152320384979248,
      "backward_entropy": 0.13717570304870605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.13343811035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0058577582240104675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.181501567363739,
      "backward_entropy": 0.13716987371444703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.98793029785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005957179702818394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18147921562194824,
      "backward_entropy": 0.13770315647125245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.549560546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006049113813787699,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1814572016398112,
      "backward_entropy": 0.1384885787963867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.25624084472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006149016786366701,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18143405516942343,
      "backward_entropy": 0.13770177364349365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.15528869628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00624861428514123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18141069014867148,
      "backward_entropy": 0.13770155906677245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.11802673339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006349092349410057,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1813868284225464,
      "backward_entropy": 0.13850100040435792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.7986602783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006450348533689976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813625693321228,
      "backward_entropy": 0.1371350646018982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.3722381591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006548313423991203,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18133838971455893,
      "backward_entropy": 0.13769924640655518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.43040466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006646377965807915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18131397167841592,
      "backward_entropy": 0.13769757747650146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.3900604248047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006747015751898289,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18128913640975952,
      "backward_entropy": 0.13851563930511473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.7296600341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0068499138578772545,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18126380443572998,
      "backward_entropy": 0.138519549369812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.35513305664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006951055023819208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18123859167099,
      "backward_entropy": 0.13710033893585205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.85353088378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007051615044474602,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18121308088302612,
      "backward_entropy": 0.13852646350860595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.6959228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007152925245463848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1811870535214742,
      "backward_entropy": 0.1370815873146057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.97439575195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007255191914737225,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18115870157877603,
      "backward_entropy": 0.13853259086608888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.84521484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007355646230280399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18112977345784506,
      "backward_entropy": 0.13706040382385254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.3316192626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007448939606547356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18110108375549316,
      "backward_entropy": 0.13767369985580444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.28085327148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007544743828475475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18107086420059204,
      "backward_entropy": 0.13766878843307495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.63890075683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007641907315701246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18103965123494467,
      "backward_entropy": 0.1370214581489563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.03614807128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007742659188807011,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18100706736246744,
      "backward_entropy": 0.13854289054870605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.78225708007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007840167731046677,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18097438414891562,
      "backward_entropy": 0.13699496984481813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 288.0182189941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007938929833471775,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18094098567962646,
      "backward_entropy": 0.13854711055755614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.54751586914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008045986294746399,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18090573946634927,
      "backward_entropy": 0.1385500192642212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.89340209960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008150088600814342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18087011575698853,
      "backward_entropy": 0.1376449942588806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.7412109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008253147825598717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18083409468332926,
      "backward_entropy": 0.13694255352020263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.53579711914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008355575613677502,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1807979146639506,
      "backward_entropy": 0.1369282603263855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.05052947998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008461054414510727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18076070149739584,
      "backward_entropy": 0.1369141459465027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.9105224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008561127819120884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18072378635406494,
      "backward_entropy": 0.13762673139572143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.78919982910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008665687404572964,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18068555990854898,
      "backward_entropy": 0.13856244087219238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.63658142089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008770456537604332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18064681688944498,
      "backward_entropy": 0.13761602640151976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.28861236572266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008875698782503605,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18060779571533203,
      "backward_entropy": 0.13856557607650757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.25042724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008975409902632236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1805690328280131,
      "backward_entropy": 0.13682985305786133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6857452392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009071923792362213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18053050835927328,
      "backward_entropy": 0.1375931978225708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.65809631347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009165143594145775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18049192428588867,
      "backward_entropy": 0.13678853511810302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.33738708496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00925950426608324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18045242627461752,
      "backward_entropy": 0.13676568269729614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.57821655273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009348117746412754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804135243097941,
      "backward_entropy": 0.13756089210510253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.42042541503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009434239007532597,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18037440379460654,
      "backward_entropy": 0.13671386241912842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.78990173339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009522596374154091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18033446868260702,
      "backward_entropy": 0.137532639503479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.15890502929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009606235660612583,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18029542764027914,
      "backward_entropy": 0.13856607675552368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.4838104248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009691273793578148,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18025604883829752,
      "backward_entropy": 0.13750007152557372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.67147827148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009777468629181385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18021613359451294,
      "backward_entropy": 0.1366051197052002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.39047241210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009861654601991177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18017605940500894,
      "backward_entropy": 0.13746533393859864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.47777557373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009952514432370663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1801342566808065,
      "backward_entropy": 0.13744971752166749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.12770080566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01003784965723753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1800929307937622,
      "backward_entropy": 0.13652244806289673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.96524810791016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010128643363714218,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18005037307739258,
      "backward_entropy": 0.13856327533721924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.92019653320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01021435298025608,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18000862995783487,
      "backward_entropy": 0.1385626435279846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.9696502685547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010302683338522911,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17996607224146524,
      "backward_entropy": 0.13856220245361328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.14515686035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010396136902272701,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17992218335469565,
      "backward_entropy": 0.13856208324432373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.42245483398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010489839129149914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1798777182896932,
      "backward_entropy": 0.13638806343078613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.46728515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010582215152680874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1798328955968221,
      "backward_entropy": 0.13635969161987305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.701416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010673090815544128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1797874371210734,
      "backward_entropy": 0.13632888793945314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.0802001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010762838646769524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17974152167638144,
      "backward_entropy": 0.13629651069641113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.74667358398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010854385793209076,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1796944538752238,
      "backward_entropy": 0.1372588038444519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.99974060058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010951802134513855,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17964555819829306,
      "backward_entropy": 0.13855843544006347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.9607391357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011051570065319538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17959543069203696,
      "backward_entropy": 0.13620223999023437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.13575744628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011154791340231895,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17954379320144653,
      "backward_entropy": 0.13855838775634766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.5453338623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011257111094892025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17949259281158447,
      "backward_entropy": 0.13719178438186647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.40249633789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011361023411154747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17944071690241495,
      "backward_entropy": 0.13611003160476684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.06600952148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011465257965028286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17938818534215292,
      "backward_entropy": 0.13607797622680665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.72764587402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011569575406610966,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17933479944864908,
      "backward_entropy": 0.1385582447052002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.23818969726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0116737624630332,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17928044001261392,
      "backward_entropy": 0.13855810165405275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.87771606445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011778229847550392,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17922544479370117,
      "backward_entropy": 0.13855804204940797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.47007751464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011885489337146282,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791690985361735,
      "backward_entropy": 0.13594011068344117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.4464874267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0119939548894763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17911183834075928,
      "backward_entropy": 0.13590564727783203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.39402770996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012100708670914173,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17905404170354208,
      "backward_entropy": 0.13855847120285034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.21957397460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012205926701426506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17899572849273682,
      "backward_entropy": 0.1370423913002014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.6688461303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01231284812092781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17893515030543009,
      "backward_entropy": 0.13579398393630981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.26368713378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012414065189659595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17887496948242188,
      "backward_entropy": 0.13700425624847412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.50856018066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012515421956777573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17881319920221964,
      "backward_entropy": 0.1357109546661377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.16775512695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012614556588232517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1787511706352234,
      "backward_entropy": 0.13566713333129882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.71517944335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01271149329841137,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17868868509928384,
      "backward_entropy": 0.138555109500885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.5031280517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012808007188141346,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17862550417582193,
      "backward_entropy": 0.13855395317077637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.12622833251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01290835253894329,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17856033643086752,
      "backward_entropy": 0.13553144931793212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.54971313476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013002244755625725,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17849647998809814,
      "backward_entropy": 0.13686580657958985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.57473754882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013096019625663757,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.178431769212087,
      "backward_entropy": 0.13855109214782715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.5074462890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013196246698498726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1783639391263326,
      "backward_entropy": 0.13539037704467774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.5787353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013301104307174683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17829386393229166,
      "backward_entropy": 0.13678886890411376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.44937133789062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013407344929873943,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17822245756785074,
      "backward_entropy": 0.13855043649673462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.2694549560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013510400429368019,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17815097173055014,
      "backward_entropy": 0.13673936128616332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.23745727539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01361773069947958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17807841300964355,
      "backward_entropy": 0.13520649671554566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6241912841797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013728547841310501,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1780043045679728,
      "backward_entropy": 0.1385498046875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.371826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013834748417139053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17793111006418863,
      "backward_entropy": 0.13666678667068483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.3919219970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0139447171241045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1778557300567627,
      "backward_entropy": 0.13664244413375853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.40260314941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014056680724024773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17777864138285318,
      "backward_entropy": 0.13501087427139283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.69326782226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014165002852678299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17770071824391684,
      "backward_entropy": 0.1349578619003296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.57518005371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014274031855165958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17762102683385214,
      "backward_entropy": 0.13490352630615235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.6237335205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014383967965841293,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1775396466255188,
      "backward_entropy": 0.13484864234924315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.2054901123047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014493338763713837,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17745735247929892,
      "backward_entropy": 0.13854728937149047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.61534118652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014602293260395527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1773742437362671,
      "backward_entropy": 0.13473522663116455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 281.5553894042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014709386974573135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1772907773653666,
      "backward_entropy": 0.13467564582824706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.1828155517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014824088662862778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17720345656077066,
      "backward_entropy": 0.13643007278442382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.6354522705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014938998967409134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17711504300435385,
      "backward_entropy": 0.1345704674720764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.83822631835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015055223368108273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1770247220993042,
      "backward_entropy": 0.13451569080352782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.44574737548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015167271718382835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17693577210108438,
      "backward_entropy": 0.13445541858673096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.8529510498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015272630378603935,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17684815327326456,
      "backward_entropy": 0.1385446548461914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.18905639648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015376506373286247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17676019668579102,
      "backward_entropy": 0.13431744575500487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.37796020507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015475638210773468,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17667225996653238,
      "backward_entropy": 0.1385406255722046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.18473052978516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015576403588056564,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17658241589864096,
      "backward_entropy": 0.13853840827941893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.34071350097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015672199428081512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1764922340710958,
      "backward_entropy": 0.1340814471244812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.46852111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0157715305685997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17639537652333578,
      "backward_entropy": 0.134002423286438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.02197265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015872366726398468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17629408836364746,
      "backward_entropy": 0.133922278881073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.9488983154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015974920243024826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17618932326634726,
      "backward_entropy": 0.13384346961975097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.7203369140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01607871986925602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17608126004536948,
      "backward_entropy": 0.13599019050598143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.84770202636719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016182642430067062,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17597134908040366,
      "backward_entropy": 0.13852477073669434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.79273986816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016277100890874863,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1758656899134318,
      "backward_entropy": 0.1358959436416626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.46998596191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01637096516788006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17575828234354654,
      "backward_entropy": 0.13351120948791503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.57923889160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016465982422232628,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17564880847930908,
      "backward_entropy": 0.1385150671005249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.88035583496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016564296558499336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17553502321243286,
      "backward_entropy": 0.13574130535125734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.15458679199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016661807894706726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17541968822479248,
      "backward_entropy": 0.13568992614746095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.1660385131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01675250008702278,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17530532677968344,
      "backward_entropy": 0.13315865993499756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.96531677246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016838999465107918,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17519181966781616,
      "backward_entropy": 0.13850066661834717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.5491180419922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01692582480609417,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1750763456026713,
      "backward_entropy": 0.1384958028793335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.1273651123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017013046890497208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1749578913052877,
      "backward_entropy": 0.13285892009735106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.8390350341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017100434750318527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17483474810918173,
      "backward_entropy": 0.13276005983352662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.1645736694336,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01719224639236927,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17470641930898032,
      "backward_entropy": 0.138482403755188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.15524291992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0172793660312891,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1745781103769938,
      "backward_entropy": 0.13256211280822755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.7273406982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017365245148539543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.174448033173879,
      "backward_entropy": 0.13245680332183837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.32412719726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017449818551540375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17431604862213135,
      "backward_entropy": 0.1351214051246643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.54601287841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017533618956804276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17418273289998373,
      "backward_entropy": 0.13223484754562378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.13743591308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01761227287352085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17405041058858237,
      "backward_entropy": 0.13211557865142823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.99684143066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017693428322672844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17391419410705566,
      "backward_entropy": 0.13199751377105712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.99871063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017777854576706886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17377281188964844,
      "backward_entropy": 0.1318792223930359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.44911193847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01785854622721672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1736323038736979,
      "backward_entropy": 0.1317551851272583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.52156829833984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017944537103176117,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1734867493311564,
      "backward_entropy": 0.13842880725860596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.66810607910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01802673749625683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17334240674972534,
      "backward_entropy": 0.13151965141296387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.398681640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01810813695192337,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17319637537002563,
      "backward_entropy": 0.13454463481903076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.62840270996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018184542655944824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17305207252502441,
      "backward_entropy": 0.13446252346038817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.37283325195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018264945596456528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1729023059209188,
      "backward_entropy": 0.13438477516174316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.70095825195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018346669152379036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1727487047513326,
      "backward_entropy": 0.13099875450134277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.6359405517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01843174733221531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17258926232655844,
      "backward_entropy": 0.13086968660354614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.1591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01851460337638855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17242980003356934,
      "backward_entropy": 0.1307368516921997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.30862426757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018597206100821495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17226960261662802,
      "backward_entropy": 0.1306053876876831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.24784851074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018683090806007385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17210376262664795,
      "backward_entropy": 0.1304744601249695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.9019317626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01876375637948513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17194066445032755,
      "backward_entropy": 0.13033535480499267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.4198760986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018842462450265884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17177685101826987,
      "backward_entropy": 0.13384407758712769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.76239013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018923744559288025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17160878578821817,
      "backward_entropy": 0.13376448154449463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.72938537597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019003309309482574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17144378026326498,
      "backward_entropy": 0.12989273071289062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.04458618164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019089598208665848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17127148310343424,
      "backward_entropy": 0.12975239753723145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.10203552246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01917767897248268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17109553019205728,
      "backward_entropy": 0.1296106457710266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.8050994873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019263165071606636,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17091999451319376,
      "backward_entropy": 0.13833866119384766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.27859497070312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019347673282027245,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1707431674003601,
      "backward_entropy": 0.1383342146873474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.95787048339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01943398453295231,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1705639362335205,
      "backward_entropy": 0.13324127197265626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.84567260742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019519435241818428,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17038055260976157,
      "backward_entropy": 0.13314975500106813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.42051696777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019608208909630775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1701937715212504,
      "backward_entropy": 0.13306275606155396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.79437255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019696928560733795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17000450690587363,
      "backward_entropy": 0.12866225242614746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.68746948242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019782910123467445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1698157787322998,
      "backward_entropy": 0.1284860849380493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.0745086669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01986643485724926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1696273684501648,
      "backward_entropy": 0.13277139663696289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.003173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019949495792388916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1694383223851522,
      "backward_entropy": 0.12811542749404908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.55477905273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02003464102745056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16924492518107095,
      "backward_entropy": 0.13255126476287843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.64427185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020121753215789795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1690476338068644,
      "backward_entropy": 0.1277317762374878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.83766174316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020205235108733177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16885324319203696,
      "backward_entropy": 0.127528178691864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.1541748046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020286627113819122,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16865913073221842,
      "backward_entropy": 0.13828123807907106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.79051208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020369146019220352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16846235593159994,
      "backward_entropy": 0.12710368633270264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.5362091064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020450564101338387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16826305786768594,
      "backward_entropy": 0.12688014507293702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.6282501220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020534461364150047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16805936892827353,
      "backward_entropy": 0.12665958404541017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.97126388549805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020617417991161346,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16785407066345215,
      "backward_entropy": 0.13168513774871826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.1781463623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02069081738591194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1676574150721232,
      "backward_entropy": 0.12618240118026733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.4566421508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020764725282788277,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16745895147323608,
      "backward_entropy": 0.12593101263046264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.52493286132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020836155861616135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16726195812225342,
      "backward_entropy": 0.1312199592590332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.1034927368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02090967632830143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16706194480260214,
      "backward_entropy": 0.12540297508239745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.04439544677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020977983251214027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16686596473058066,
      "backward_entropy": 0.12512834072113038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.46009826660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02104409784078598,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1666694680849711,
      "backward_entropy": 0.13817191123962402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.95057678222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02111121639609337,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1664700706799825,
      "backward_entropy": 0.1381564736366272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.62107849121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021182460710406303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16626471281051636,
      "backward_entropy": 0.12428022623062134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.33185577392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021254396066069603,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16605693101882935,
      "backward_entropy": 0.1301820993423462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.71810150146484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021323906257748604,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1658499836921692,
      "backward_entropy": 0.1381184935569763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.74429321289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021389838308095932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16564631462097168,
      "backward_entropy": 0.1298081636428833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.20787048339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021455641835927963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1654419203599294,
      "backward_entropy": 0.12309088706970214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.1693878173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021521149203181267,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16523587703704834,
      "backward_entropy": 0.13806586265563964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.94715881347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021589457988739014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16502484679222107,
      "backward_entropy": 0.12921196222305298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.98516845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02166302688419819,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16480525334676108,
      "backward_entropy": 0.1290246844291687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.99365997314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02173582650721073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16458594799041748,
      "backward_entropy": 0.1288299322128296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.7238006591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02180514857172966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1643713116645813,
      "backward_entropy": 0.12862010002136232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.71157836914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021878382191061974,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1641499400138855,
      "backward_entropy": 0.13800194263458251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.63771057128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02195540815591812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16392327348391214,
      "backward_entropy": 0.12091803550720215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.65939331054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022036638110876083,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1636883815129598,
      "backward_entropy": 0.12804150581359863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.5194854736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022120743989944458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16344918807347616,
      "backward_entropy": 0.12784873247146605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.16053771972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02220560796558857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16320671637852988,
      "backward_entropy": 0.12002260684967041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.10816955566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022290071472525597,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1629645029703776,
      "backward_entropy": 0.13798227310180664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.20303344726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022369639948010445,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16272818048795065,
      "backward_entropy": 0.13797496557235717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.99070739746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022447409108281136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16248932480812073,
      "backward_entropy": 0.12699099779129028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.8822479248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022525420412421227,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16224990288416544,
      "backward_entropy": 0.1267589211463928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.4054718017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022606583312153816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620055635770162,
      "backward_entropy": 0.11840188503265381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.99293518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022686272859573364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176252563794455,
      "backward_entropy": 0.126283597946167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.1078338623047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022764738649129868,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16152085860570273,
      "backward_entropy": 0.13794084787368774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.9542694091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0228434931486845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16127785046895346,
      "backward_entropy": 0.12576240301132202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.5288543701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022922515869140625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16103363037109375,
      "backward_entropy": 0.12549080848693847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.76566314697266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023001879453659058,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1607885460058848,
      "backward_entropy": 0.13791351318359374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.2206573486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023078495636582375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16054693857828775,
      "backward_entropy": 0.12492303848266602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.50981140136719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023155709728598595,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16030284762382507,
      "backward_entropy": 0.13788970708847045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.18231964111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023230405524373055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600619157155355,
      "backward_entropy": 0.1155994176864624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.9085693359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023302560672163963,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15982224543889365,
      "backward_entropy": 0.13786046504974364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.67344665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023377178236842155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15957810481389365,
      "backward_entropy": 0.1148223638534546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.39559173583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023457927629351616,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1593224803606669,
      "backward_entropy": 0.1144445300102234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.64315795898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02353423833847046,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15907222032546997,
      "backward_entropy": 0.13783053159713746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6343231201172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023612504824995995,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1588184138139089,
      "backward_entropy": 0.1378226399421692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.31938171386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02369106002151966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15856203436851501,
      "backward_entropy": 0.11325299739837646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.92427825927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023767096921801567,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15830957889556885,
      "backward_entropy": 0.11284607648849487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.65049743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023840967565774918,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15806037187576294,
      "backward_entropy": 0.11242921352386474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.55821228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02391541562974453,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1578083038330078,
      "backward_entropy": 0.12144298553466797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.79914093017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023996243253350258,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1575449506441752,
      "backward_entropy": 0.11159337759017944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.64061737060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02407079003751278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15728829304377237,
      "backward_entropy": 0.12075271606445312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.23918151855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024140426889061928,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.157040665547053,
      "backward_entropy": 0.12036747932434082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.11603546142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024208566173911095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1567955215771993,
      "backward_entropy": 0.1199653148651123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.4296646118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024274997413158417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15655102332433066,
      "backward_entropy": 0.10971863269805908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.88658142089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024341126903891563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1563041607538859,
      "backward_entropy": 0.109226393699646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.27627563476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024410251528024673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1560513973236084,
      "backward_entropy": 0.10873875617980958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.56700134277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02448013611137867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15579402446746826,
      "backward_entropy": 0.10823941230773926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.9285125732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02455567941069603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15552775065104166,
      "backward_entropy": 0.1077608346939087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.23957061767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02463207021355629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15526078144709268,
      "backward_entropy": 0.10728350877761841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.036865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024702880531549454,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15500128269195557,
      "backward_entropy": 0.11717318296432495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.73915100097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024774493649601936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1547393004099528,
      "backward_entropy": 0.11675870418548584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.69064331054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024848949164152145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15447219212849936,
      "backward_entropy": 0.10575737953186035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.62342834472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02492421679198742,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15420405069986978,
      "backward_entropy": 0.11593945026397705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.53206634521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024997152388095856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.153938889503479,
      "backward_entropy": 0.10473310947418213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.07169342041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025069676339626312,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15367468198140463,
      "backward_entropy": 0.11506673097610473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.66605377197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025140253826975822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15341337521870932,
      "backward_entropy": 0.10366506576538086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.52460479736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02521049790084362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15315171082814535,
      "backward_entropy": 0.11414449214935303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.73861694335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025279134511947632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1528928279876709,
      "backward_entropy": 0.10255794525146485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.74720001220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025348791852593422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15262945493062338,
      "backward_entropy": 0.11319558620452881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.75221252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025415416806936264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15237184365590414,
      "backward_entropy": 0.10141205787658691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.1326904296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025480560958385468,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15211792786916098,
      "backward_entropy": 0.13735041618347169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.01527404785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025544563308358192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15186524391174316,
      "backward_entropy": 0.11169686317443847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.5571060180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025605859234929085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15161502361297607,
      "backward_entropy": 0.09959523677825928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.83778381347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025663573294878006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15137330691019693,
      "backward_entropy": 0.09895644783973694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.66033935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025725433602929115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15112577875455221,
      "backward_entropy": 0.11008557081222534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.2052764892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02578812837600708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1508786678314209,
      "backward_entropy": 0.09773739576339721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.96626281738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025854576379060745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15062687794367471,
      "backward_entropy": 0.10904009342193603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.37213897705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025919917970895767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15037755171457926,
      "backward_entropy": 0.10851023197174073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.83460235595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025981156155467033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15013307332992554,
      "backward_entropy": 0.09592041969299317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.51084899902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026042988523840904,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14988428354263306,
      "backward_entropy": 0.10737648010253906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.81495666503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026107046753168106,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14963183800379434,
      "backward_entropy": 0.10681328773498536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.5107879638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02617170847952366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14937866727511087,
      "backward_entropy": 0.10624897480010986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.786407470703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02624017745256424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14912249644597372,
      "backward_entropy": 0.10570271015167236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.80200958251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0263014268130064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14887917041778564,
      "backward_entropy": 0.09275392293930054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.92950439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02636057510972023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1486402153968811,
      "backward_entropy": 0.09209253787994384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.06938934326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026422111317515373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1483942170937856,
      "backward_entropy": 0.0914368212223053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.28268432617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0264833252876997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1481464703877767,
      "backward_entropy": 0.09078572988510132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.84982299804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026548417285084724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14789313077926636,
      "backward_entropy": 0.09014678001403809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.3868522644043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02661708928644657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14763243993123373,
      "backward_entropy": 0.08952898979187011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.80144500732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02667851559817791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14738428592681885,
      "backward_entropy": 0.1015160083770752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.9830780029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02673950418829918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1471373438835144,
      "backward_entropy": 0.1008875846862793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.96180725097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026804184541106224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14688050746917725,
      "backward_entropy": 0.10028353929519654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.6343231201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026866361498832703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1466264327367147,
      "backward_entropy": 0.09965728521347046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.29634857177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02693098783493042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14637056986490884,
      "backward_entropy": 0.08617825508117676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.63735961914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02699482999742031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14611570040384927,
      "backward_entropy": 0.0854838728904724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.34214782714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027062304317951202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14585411548614502,
      "backward_entropy": 0.0978061318397522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.333621978759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027130069211125374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14559268951416016,
      "backward_entropy": 0.08410906791687012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.4911346435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027192410081624985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14534239967664084,
      "backward_entropy": 0.0833885669708252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.93695068359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027256833389401436,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1450857917467753,
      "backward_entropy": 0.13654417991638185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.12583923339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027320312336087227,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14482892553011575,
      "backward_entropy": 0.09526116847991943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.15065002441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027390573173761368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14456325769424438,
      "backward_entropy": 0.08122940063476562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.61097717285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027463888749480247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14429334799448648,
      "backward_entropy": 0.08054367303848267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.87606811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027541508898139,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14401906728744507,
      "backward_entropy": 0.0798780381679535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.23055267333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02762177586555481,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1437439719835917,
      "backward_entropy": 0.07922375202178955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.51181030273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02770131267607212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14347189664840698,
      "backward_entropy": 0.09239735603332519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.107940673828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027783233672380447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14319777488708496,
      "backward_entropy": 0.07790054082870483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.53575134277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027858469635248184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14293701450030008,
      "backward_entropy": 0.07721748352050781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.56968688964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02793351374566555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1426778038342794,
      "backward_entropy": 0.09056282043457031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.45455932617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02801554836332798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14240886767705283,
      "backward_entropy": 0.0758786141872406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.0873031616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028102394193410873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14213291803995767,
      "backward_entropy": 0.07525172233581542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.06660461425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02818642556667328,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1418632666269938,
      "backward_entropy": 0.07460150718688965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.5063247680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028269648551940918,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14159844319025675,
      "backward_entropy": 0.07395379543304444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.26776123046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028351834043860435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14133577545483908,
      "backward_entropy": 0.07329556941986085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.11384201049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028431307524442673,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14107594887415567,
      "backward_entropy": 0.08707733154296875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6983184814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028504373505711555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14082789421081543,
      "backward_entropy": 0.08640853762626648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.54249572753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028580550104379654,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14057745536168417,
      "backward_entropy": 0.08575719594955444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.2933349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028663700446486473,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14031660556793213,
      "backward_entropy": 0.07051670551300049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.7784423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028745874762535095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.140059232711792,
      "backward_entropy": 0.06985007524490357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.3204574584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028824325650930405,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1398106018702189,
      "backward_entropy": 0.08392040729522705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3414764404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028902532532811165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13956656058629355,
      "backward_entropy": 0.06849616765975952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.65766143798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028982823714613914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13931800921758017,
      "backward_entropy": 0.06782075762748718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.1936264038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02906109392642975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1390743851661682,
      "backward_entropy": 0.0819793999195099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.747840881347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029140552505850792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1388319432735443,
      "backward_entropy": 0.06645147204399109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9136199951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029213760048151016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13860042889912924,
      "backward_entropy": 0.08057796359062194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.66263580322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02929021790623665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13836780190467834,
      "backward_entropy": 0.06504894495010376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.43372344970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02936347760260105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13813970486323038,
      "backward_entropy": 0.07913999557495117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.0926284790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02943108044564724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13792089621225992,
      "backward_entropy": 0.06360695362091065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.20230865478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02949926070868969,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13770190874735513,
      "backward_entropy": 0.0628782033920288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.5621109008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029565051198005676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13748645782470703,
      "backward_entropy": 0.06213399171829224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.36212921142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029627852141857147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13727923234303793,
      "backward_entropy": 0.06139440536499023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.51029968261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029691774398088455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13706735769907633,
      "backward_entropy": 0.07526123523712158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.1927719116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029752785339951515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13686259587605795,
      "backward_entropy": 0.05993002653121948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.85486602783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029815517365932465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1366601586341858,
      "backward_entropy": 0.07369648814201354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.41216278076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029875122010707855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13646201292673746,
      "backward_entropy": 0.05848996639251709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.06291198730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029932085424661636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13626807928085327,
      "backward_entropy": 0.05776224136352539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.24066162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029989933595061302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13607627153396606,
      "backward_entropy": 0.05705505609512329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.81407165527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030052442103624344,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587881127993265,
      "backward_entropy": 0.0705469310283661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.94721221923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03011465072631836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567917545636496,
      "backward_entropy": 0.06980308294296264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.3719940185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030176984146237373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13548117876052856,
      "backward_entropy": 0.05498383641242981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.68428039550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030243579298257828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13527822494506836,
      "backward_entropy": 0.054305994510650636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.98612213134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030308296903967857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13507924477259317,
      "backward_entropy": 0.053617656230926514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.52588653564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030371643602848053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13488565882047018,
      "backward_entropy": 0.052935242652893066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.95402526855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03043246641755104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1347007155418396,
      "backward_entropy": 0.06609958410263062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.3704833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030493590980768204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13451293110847473,
      "backward_entropy": 0.05159156322479248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.22148895263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030558910220861435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13431761662165323,
      "backward_entropy": 0.06465548276901245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.04094696044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030625715851783752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13412398099899292,
      "backward_entropy": 0.050298911333084104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.05815887451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030692433938384056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.133934219678243,
      "backward_entropy": 0.04966694712638855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.56542205810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030760321766138077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1337439219156901,
      "backward_entropy": 0.04904297292232514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.89649200439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030830787494778633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13355141878128052,
      "backward_entropy": 0.04844536781311035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.13258361816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030896436423063278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13336690266927084,
      "backward_entropy": 0.06131261587142944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.96112823486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030959514901041985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13318929076194763,
      "backward_entropy": 0.04721236526966095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.67394256591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031020302325487137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13301875193913779,
      "backward_entropy": 0.046599796414375304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.6654052734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03108302876353264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1328466534614563,
      "backward_entropy": 0.04600242972373962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.5880355834961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031146083027124405,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13267412781715393,
      "backward_entropy": 0.058597564697265625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.27706146240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031210608780384064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1324993371963501,
      "backward_entropy": 0.04482824504375458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.49640655517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03127279505133629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.132331113020579,
      "backward_entropy": 0.04424509704113007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.98008728027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03133384883403778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1321634848912557,
      "backward_entropy": 0.043655121326446535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.95320129394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031402673572301865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13198880354563394,
      "backward_entropy": 0.04311403036117554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.77568054199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03146865963935852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13182008266448975,
      "backward_entropy": 0.04256546497344971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.97972106933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03153211250901222,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13165749112764993,
      "backward_entropy": 0.1355525255203247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.93230438232422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03159302845597267,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13149831692377725,
      "backward_entropy": 0.1355298399925232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.33781433105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03165455535054207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13133537769317627,
      "backward_entropy": 0.053502893447875975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.2058334350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03171693533658981,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13117603460947672,
      "backward_entropy": 0.05288715958595276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.81119537353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03178003430366516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13101819157600403,
      "backward_entropy": 0.05228466987609863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.12444305419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03184778615832329,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13085459669431052,
      "backward_entropy": 0.051731276512146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.714908599853516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03191724419593811,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13069222370783487,
      "backward_entropy": 0.13552889823913575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.96004867553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03198207914829254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13053361574808756,
      "backward_entropy": 0.038362860679626465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.22688293457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032043252140283585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13038198153177896,
      "backward_entropy": 0.05003735423088074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.775270462036133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032105233520269394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13022870818773905,
      "backward_entropy": 0.03734640479087829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.80638885498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032161153852939606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13008564710617065,
      "backward_entropy": 0.04885854721069336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.29853057861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0322226919233799,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12993613878885904,
      "backward_entropy": 0.03634429574012756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.89575958251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032281067222356796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12979365388552347,
      "backward_entropy": 0.03585582673549652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.62779998779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03233933448791504,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1296525796254476,
      "backward_entropy": 0.1354546070098877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.73954772949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03239759802818298,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.129513551791509,
      "backward_entropy": 0.046615153551101685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.61817932128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03245561569929123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12937424580256143,
      "backward_entropy": 0.046065494418144226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.00638580322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03251337632536888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12923472126324972,
      "backward_entropy": 0.03394856452941895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.71813201904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032575156539678574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1290909151236216,
      "backward_entropy": 0.04501164257526398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.15899658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03263681009411812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12895075480143228,
      "backward_entropy": 0.0330457478761673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.181941986083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03269932419061661,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12880871693293253,
      "backward_entropy": 0.04401688277721405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.064483642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032757241278886795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12867364287376404,
      "backward_entropy": 0.03216056227684021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.0208854675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03281104564666748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1285451054573059,
      "backward_entropy": 0.03170475363731384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.88702392578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0328625924885273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12842007478078207,
      "backward_entropy": 0.031250154972076415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.38436889648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03291213512420654,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12829488515853882,
      "backward_entropy": 0.04191319346427917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.61865997314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03296928480267525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12815943360328674,
      "backward_entropy": 0.041452229022979736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.54305267333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03302674740552902,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12802771727244058,
      "backward_entropy": 0.040999037027359006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.47281646728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03308851271867752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12789231538772583,
      "backward_entropy": 0.0296052485704422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.83424377441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03314992040395737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12775743007659912,
      "backward_entropy": 0.029216787219047545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.9460220336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03321802616119385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12761564056078592,
      "backward_entropy": 0.0397672027349472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.30433654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03328530490398407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12747633457183838,
      "backward_entropy": 0.028503260016441344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.14599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03335481509566307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12733701864878336,
      "backward_entropy": 0.028164198994636534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.29326629638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03342502936720848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1271995703379313,
      "backward_entropy": 0.03865362405776977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.01984405517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03349311649799347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12706677118937174,
      "backward_entropy": 0.0275028258562088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.69921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0335661955177784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12693198521931967,
      "backward_entropy": 0.027193564176559448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.45344543457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03363935649394989,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12679648399353027,
      "backward_entropy": 0.03760306537151337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.79646301269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03371260687708855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12666128079096475,
      "backward_entropy": 0.026573491096496583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.86030578613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03378744050860405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12652557094891867,
      "backward_entropy": 0.026274266839027404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.58863067626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03386234492063522,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12638971209526062,
      "backward_entropy": 0.025980830192565918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.40391540527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03394128382205963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12625149885813394,
      "backward_entropy": 0.025699681043624877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.01774024963379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034019842743873596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12611446777979532,
      "backward_entropy": 0.025415968894958497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.61253356933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03409161418676376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12598774830500284,
      "backward_entropy": 0.02512410581111908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.570584297180176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03416692093014717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1258597175280253,
      "backward_entropy": 0.024859586358070375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.94994354248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03423412889242172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1257408857345581,
      "backward_entropy": 0.024574443697929382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.087646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03430348262190819,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1256191929181417,
      "backward_entropy": 0.03475566208362579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.53888702392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03437618538737297,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12549569209416708,
      "backward_entropy": 0.024024058878421784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.450836181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034450333565473557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12536881367365518,
      "backward_entropy": 0.03416284620761871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.5760726928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03452076390385628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12524654467900595,
      "backward_entropy": 0.023478642106056213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.91423797607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03459574654698372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1251201033592224,
      "backward_entropy": 0.023218439519405366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.12278366088867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034669507294893265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12499455610911052,
      "backward_entropy": 0.022958822548389435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.90599060058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034739475697278976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12487347920735677,
      "backward_entropy": 0.022689886391162872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.48103332519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03481161221861839,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12475138902664185,
      "backward_entropy": 0.03271420896053314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.47484588623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0348842591047287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12462939818700154,
      "backward_entropy": 0.03243127465248108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.49654006958008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03495866060256958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12450627485911052,
      "backward_entropy": 0.02192818224430084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.45583724975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0350293405354023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12438714504241943,
      "backward_entropy": 0.031869041919708255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.46857452392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035098087042570114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12427080670992534,
      "backward_entropy": 0.021420811116695405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.26956939697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03516784682869911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12415369351704915,
      "backward_entropy": 0.03130392432212829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.23722076416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03523847833275795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12403692801793416,
      "backward_entropy": 0.020943641662597656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.76829528808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03531097620725632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12391763925552368,
      "backward_entropy": 0.020713227987289428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.4866714477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03538414463400841,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12379910548528035,
      "backward_entropy": 0.030551010370254518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.28296661376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03545670211315155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12368269761403401,
      "backward_entropy": 0.020276980102062227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.09293365478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035528723150491714,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12356857458750407,
      "backward_entropy": 0.030077481269836427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.06449508666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03560261428356171,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12345165014266968,
      "backward_entropy": 0.019861145317554472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.72608184814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03567437827587128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1233367919921875,
      "backward_entropy": 0.01965163052082062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.70308685302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03574562072753906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1232233742872874,
      "backward_entropy": 0.019446206092834473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.96839904785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03581605851650238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12310908238093059,
      "backward_entropy": 0.029143068194389343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.70973205566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03589516505599022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12298882007598877,
      "backward_entropy": 0.019050562381744386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.93291473388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03597550839185715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1228669285774231,
      "backward_entropy": 0.028756746649742128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.22797775268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03605440631508827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12274630864461263,
      "backward_entropy": 0.018682119250297547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.90167999267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036129578948020935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12263072530428569,
      "backward_entropy": 0.018499141931533812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.79962921142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036206312477588654,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12251326441764832,
      "backward_entropy": 0.028174248337745667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.72000503540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03628722205758095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12239213784535725,
      "backward_entropy": 0.018152183294296263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.16444778442383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03636133298277855,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12227731943130493,
      "backward_entropy": 0.027806994318962098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.38191223144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03643074631690979,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12216687202453613,
      "backward_entropy": 0.017785878479480745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.44110870361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036506228148937225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12205018599828084,
      "backward_entropy": 0.017612223327159882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.64478302001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036583442240953445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12193264563878377,
      "backward_entropy": 0.017444197833538056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.069698333740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036665868014097214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12180989980697632,
      "backward_entropy": 0.01728353798389435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.14195251464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03674658015370369,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12168838580449422,
      "backward_entropy": 0.026898777484893797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.36570739746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03682730719447136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12156806389490764,
      "backward_entropy": 0.026736554503440858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3214264512062073,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036913082003593445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12144378821055095,
      "backward_entropy": 0.026592439413070677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.13331985473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03698934242129326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1213308572769165,
      "backward_entropy": 0.016663983464241028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.36832809448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03706465661525726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1212167243162791,
      "backward_entropy": 0.01650945544242859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.45118713378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03713665530085564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12110581000645955,
      "backward_entropy": 0.026086178421974183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.76051330566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037211887538433075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12099186579386394,
      "backward_entropy": 0.016207408905029298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.601957321166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037287455052137375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1208771566549937,
      "backward_entropy": 0.016059687733650206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.925601959228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03735719248652458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12076860666275024,
      "backward_entropy": 0.025604599714279176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.05535125732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03742557018995285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12066173553466797,
      "backward_entropy": 0.015765196084976195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.85514068603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03749503940343857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12055408954620361,
      "backward_entropy": 0.015622609853744506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.66087341308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03756691515445709,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12044491370519002,
      "backward_entropy": 0.025151070952415467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.34684371948242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037642136216163635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12033119797706604,
      "backward_entropy": 0.0250214546918869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.10819625854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03771521523594856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12021893262863159,
      "backward_entropy": 0.015231069922447205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.88021850585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03778660297393799,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12010898192723592,
      "backward_entropy": 0.01510210931301117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.61637115478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03785884752869606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11999754110972087,
      "backward_entropy": 0.014975124597549438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.616539001464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037931978702545166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11988540490468343,
      "backward_entropy": 0.01485271006822586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.608970642089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03800339996814728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11977515618006389,
      "backward_entropy": 0.014732630550861358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.299781799316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038071997463703156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11966792742411296,
      "backward_entropy": 0.02423952370882034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.57783317565918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03813932090997696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11956223845481873,
      "backward_entropy": 0.01449233591556549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.973453521728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0382029227912426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1194594403107961,
      "backward_entropy": 0.01437007486820221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.30858612060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03826583921909332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11935723821322124,
      "backward_entropy": 0.014252662658691406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.37693405151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038330577313899994,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1192531685034434,
      "backward_entropy": 0.023733828961849213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.5571403503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03839578479528427,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11914906899134318,
      "backward_entropy": 0.014030390977859497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.81267261505127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038460005074739456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1190451979637146,
      "backward_entropy": 0.013920354843139648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.47423553466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03851836547255516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11894819140434265,
      "backward_entropy": 0.013806530833244323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.89418601989746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038579061627388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11884703238805135,
      "backward_entropy": 0.013701650500297546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.96477127075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0386369526386261,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11874986688296,
      "backward_entropy": 0.013598799705505371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.7773323059082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03869469091296196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11865268150965373,
      "backward_entropy": 0.013496848940849304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.228759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03875255584716797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11855585376421611,
      "backward_entropy": 0.013401660323143005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.50890350341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03881397843360901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11845435698827107,
      "backward_entropy": 0.013309352099895477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.856727600097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038877397775650024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11835002899169922,
      "backward_entropy": 0.022780074179172514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.963512420654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03894132375717163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11824443936347961,
      "backward_entropy": 0.013130323588848114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08321129530668259,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03900081664323807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11814435323079427,
      "backward_entropy": 0.013038623332977294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.83070182800293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039053983986377716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11805246273676555,
      "backward_entropy": 0.012946224212646485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.206329345703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039103925228118896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11796396970748901,
      "backward_entropy": 0.022408781945705412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.36872863769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0391557551920414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11787114540735881,
      "backward_entropy": 0.012767201662063599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.973281860351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03921060636639595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11777567863464355,
      "backward_entropy": 0.012683546543121338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.89972496032715,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03926333785057068,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11768282453219096,
      "backward_entropy": 0.13785476684570314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.09339141845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039314139634370804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11759241422017415,
      "backward_entropy": 0.012523189187049866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.34220886230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03936928138136864,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11749602357546489,
      "backward_entropy": 0.012447860836982728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.25145721435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039430707693099976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11739148696263631,
      "backward_entropy": 0.012377297878265381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.582401275634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03949301317334175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11728543043136597,
      "backward_entropy": 0.021893976628780364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.78097915649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03955233842134476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11718280116717021,
      "backward_entropy": 0.012239950150251389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.735984802246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039611414074897766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11708004275957744,
      "backward_entropy": 0.01216970831155777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.48508071899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0396716371178627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11697594324747722,
      "backward_entropy": 0.02171654552221298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.399906158447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03973162919282913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11687175432840984,
      "backward_entropy": 0.012037692964076996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.231590270996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039792634546756744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11676584680875142,
      "backward_entropy": 0.011974252015352248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.05354690551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0398545041680336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11665838956832886,
      "backward_entropy": 0.011911950260400771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.83809280395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03991717845201492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1165494720141093,
      "backward_entropy": 0.011851264536380768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.6339225769043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03998187556862831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11643776297569275,
      "backward_entropy": 0.011793971806764603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.1558837890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040048301219940186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11632333199183147,
      "backward_entropy": 0.021431492269039155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.420806884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04011976346373558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11620163917541504,
      "backward_entropy": 0.011682942509651184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.7942123413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040189944207668304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11608184377352397,
      "backward_entropy": 0.011629826575517654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.71334457397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04026252031326294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1159582535425822,
      "backward_entropy": 0.011579257249832154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.36524772644043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04033605009317398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11583338181177776,
      "backward_entropy": 0.011530641466379166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.26847267150879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04040563851594925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11571385463078816,
      "backward_entropy": 0.021266590058803558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.88768768310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04047166183590889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11559891700744629,
      "backward_entropy": 0.011431781947612763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.45680618286133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04053569957613945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11548653244972229,
      "backward_entropy": 0.011382387578487396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.648128509521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040599074214696884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11537444591522217,
      "backward_entropy": 0.01133228987455368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.1632194519043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040660709142684937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11526461442311604,
      "backward_entropy": 0.01128230318427086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.414669036865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04072188958525658,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11515521009763081,
      "backward_entropy": 0.011231408268213273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.01092529296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04078155755996704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1150468389193217,
      "backward_entropy": 0.011181961745023727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.71828079223633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04084340110421181,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11493510007858276,
      "backward_entropy": 0.011134400963783264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.55714988708496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0409049354493618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11482371886571248,
      "backward_entropy": 0.01108943223953247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.43857955932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040963687002658844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11471608281135559,
      "backward_entropy": 0.011043740808963776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.75249099731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04102233424782753,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11460810899734497,
      "backward_entropy": 0.02089206576347351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.00741195678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041082099080085754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1144979993502299,
      "backward_entropy": 0.020856741070747375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.60810852050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041144076734781265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11438421408335368,
      "backward_entropy": 0.020824429392814637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.6029052734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04120447486639023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1142723560333252,
      "backward_entropy": 0.010869649052619935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.033056259155273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041266947984695435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11415670315424602,
      "backward_entropy": 0.010827979445457459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.948040008544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0413266122341156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11404528220494588,
      "backward_entropy": 0.010786860436201095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295746803283691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04138372465968132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11393759648005168,
      "backward_entropy": 0.010745911300182343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.563907623291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041436199098825455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11383734146753947,
      "backward_entropy": 0.010705291479825973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.40821075439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04149043187499046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11373382806777954,
      "backward_entropy": 0.010666830837726593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21463394165039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04154622554779053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11362725496292114,
      "backward_entropy": 0.010630247741937637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.917476654052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04159754887223244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11352815230687459,
      "backward_entropy": 0.010594332218170166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.7927131652832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041649527847766876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11342742045720418,
      "backward_entropy": 0.02053113132715225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.53357696533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04170207306742668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11332519849141438,
      "backward_entropy": 0.010523220896720887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.43152618408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041753966361284256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1132236619790395,
      "backward_entropy": 0.010487686842679977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.494441986083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04180530831217766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11312276124954224,
      "backward_entropy": 0.010453315824270249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.17262077331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041858501732349396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1130182147026062,
      "backward_entropy": 0.010420132428407669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.190452575683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0419098399579525,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11291672786076863,
      "backward_entropy": 0.13835378885269164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.024436950683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04196300730109215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11281150579452515,
      "backward_entropy": 0.010356409847736359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.861351013183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04201550781726837,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11270729700724284,
      "backward_entropy": 0.020323076844215394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.5778579711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04207087680697441,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1125975251197815,
      "backward_entropy": 0.010296685993671418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.391815185546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04213113710284233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1124786635239919,
      "backward_entropy": 0.02027255594730377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.78767204284668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04219459742307663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11235358317693074,
      "backward_entropy": 0.010238590091466904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.729799270629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04225404933094978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11223572492599487,
      "backward_entropy": 0.010210799425840378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.022804260253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04230988398194313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11212433377901714,
      "backward_entropy": 0.010184190422296523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.046287536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04236706718802452,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11200992266337077,
      "backward_entropy": 0.010157816857099534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.56329345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04242432117462158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1118950645128886,
      "backward_entropy": 0.01013219654560089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.53000259399414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042478181421756744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11178638537724812,
      "backward_entropy": 0.010107816755771637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.639591217041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04253358021378517,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11167430877685547,
      "backward_entropy": 0.020106734335422517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.50341033935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0425892174243927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11156132817268372,
      "backward_entropy": 0.010059912502765656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.713035583496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04264506697654724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11144761244455974,
      "backward_entropy": 0.020061546564102174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.57906150817871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04270338639616966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1113286813100179,
      "backward_entropy": 0.010013759881258012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.617024898529053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04276049882173538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11121151844660442,
      "backward_entropy": 0.009991974383592606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.54533004760742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042813077569007874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11110305786132812,
      "backward_entropy": 0.00997147113084793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.38534164428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04286729544401169,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11099104086558025,
      "backward_entropy": 0.009951106458902358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.22089385986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042922988533973694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11087546745936076,
      "backward_entropy": 0.009930847585201264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.56124496459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04298000782728195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11075684428215027,
      "backward_entropy": 0.009910796582698823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.438642501831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04303934425115585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11063307523727417,
      "backward_entropy": 0.019909407198429107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.806015014648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04309621453285217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11051412423451741,
      "backward_entropy": 0.009871456027030944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.54368209838867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04315200448036194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11039660374323527,
      "backward_entropy": 0.009853193908929825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.37445068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04320908337831497,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11027608315149943,
      "backward_entropy": 0.009834980964660645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.83475112915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04326732084155083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11015262206395467,
      "backward_entropy": 0.00981685221195221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.69088363647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04332546517252922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11002885301907857,
      "backward_entropy": 0.009798987209796906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.618969917297363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04338352009654045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10990476608276367,
      "backward_entropy": 0.019776855409145356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.693992614746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04343809187412262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10978786150614421,
      "backward_entropy": 0.009765143692493438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.018352508544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04349405691027641,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10966736078262329,
      "backward_entropy": 0.009748953580856323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.27196502685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04354900121688843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10954868793487549,
      "backward_entropy": 0.009733158349990844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.39454174041748,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04360976442694664,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10941685239473979,
      "backward_entropy": 0.1384832501411438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.180931091308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04366676136851311,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10929306348164876,
      "backward_entropy": 0.009700723737478257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.83557891845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04372600093483925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10916370153427124,
      "backward_entropy": 0.00968492329120636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.65607452392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043786123394966125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10903193553288777,
      "backward_entropy": 0.009669284522533416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.316402435302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043847035616636276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10889764626820882,
      "backward_entropy": 0.00965416207909584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.345645904541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04390641301870346,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10876649618148804,
      "backward_entropy": 0.01956307888031006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.14996337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04396774247288704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10863032937049866,
      "backward_entropy": 0.01953746974468231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.947710037231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04403194040060043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.108487069606781,
      "backward_entropy": 0.009609661996364594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.82330894470215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04409424960613251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10834797223409016,
      "backward_entropy": 0.009594982117414474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.40228271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04415487125515938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10821168621381123,
      "backward_entropy": 0.009581561386585235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.254947662353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04421838000416756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10806835691134135,
      "backward_entropy": 0.009567436575889588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.584531784057617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04428337886929512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10792097449302673,
      "backward_entropy": 0.009553125500679016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.491682052612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044345319271087646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1077802578608195,
      "backward_entropy": 0.009540529549121856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.402862548828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04440447315573692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10764588912328084,
      "backward_entropy": 0.009528830647468567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.175437927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044461142271757126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10751678546269734,
      "backward_entropy": 0.009518580138683319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.45203399658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04452105239033699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10737913846969604,
      "backward_entropy": 0.009507541358470917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.5584602355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04458169639110565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1072390874226888,
      "backward_entropy": 0.019275861978530883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.449363708496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044641852378845215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10709961255391438,
      "backward_entropy": 0.019249241054058074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.951017379760742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04470479488372803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1069527268409729,
      "backward_entropy": 0.009473923593759537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.479076385498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044764865189790726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10681246717770894,
      "backward_entropy": 0.009463320672512054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.361114501953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04482341930270195,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10667536656061809,
      "backward_entropy": 0.13852852582931519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.245820999145508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044880617409944534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10654107729593913,
      "backward_entropy": 0.009445305168628692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.19671630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04493653401732445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10640949010848999,
      "backward_entropy": 0.009436847269535064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.01162052154541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044993530958890915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10627439618110657,
      "backward_entropy": 0.019081029295921325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.43351173400879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04504714533686638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.106147567431132,
      "backward_entropy": 0.009423203021287917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.355234146118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04509872570633888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10602561632792155,
      "backward_entropy": 0.009417396038770676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.128562927246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04514852911233902,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1059077779452006,
      "backward_entropy": 0.13853781223297118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.00077819824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04519888386130333,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10578779379526775,
      "backward_entropy": 0.01898189038038254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.752545356750488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04524971917271614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10566617051760356,
      "backward_entropy": 0.009403519332408905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.44641876220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045297812670469284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10555086533228557,
      "backward_entropy": 0.009401685744524001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.29720115661621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04534872993826866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1054275135199229,
      "backward_entropy": 0.009398045390844345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.897871017456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04539894312620163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10530558228492737,
      "backward_entropy": 0.00939384251832962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.823486328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045447442680597305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10518795251846313,
      "backward_entropy": 0.009389641880989074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.49510955810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045494433492422104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10507402817408244,
      "backward_entropy": 0.009386326372623443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.12188148498535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045543283224105835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1049539844195048,
      "backward_entropy": 0.009382414072752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.599716186523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04559268057346344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10483141740163167,
      "backward_entropy": 0.00937715321779251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.698123931884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045640528202056885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10471240679423015,
      "backward_entropy": 0.009373918175697327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.4520320892334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568801447749138,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10459377368291219,
      "backward_entropy": 0.009371353685855866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.87607955932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04573409631848335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1044782002766927,
      "backward_entropy": 0.009370031207799912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.205765724182129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0457831509411335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10435350735982259,
      "backward_entropy": 0.009367046505212783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.305994033813477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04582953080534935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1042362650235494,
      "backward_entropy": 0.009364809840917587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.36023712158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04587564617395401,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10411919156710307,
      "backward_entropy": 0.018587903678417207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.107500076293945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04592473804950714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10399262110392253,
      "backward_entropy": 0.009359585493803025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.00515365600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045973289757966995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10386714339256287,
      "backward_entropy": 0.009356720000505447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.8767147064209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04602240025997162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10373946030934651,
      "backward_entropy": 0.018490438163280488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.69392013549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04607199504971504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10360980033874512,
      "backward_entropy": 0.009349276125431061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.53308868408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04612310230731964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10347491502761841,
      "backward_entropy": 0.009344616532325744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.68898582458496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0461755096912384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10333578785260518,
      "backward_entropy": 0.009338433295488358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.476015090942383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046226054430007935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10320154825846355,
      "backward_entropy": 0.009335501492023468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.531251907348633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04627586528658867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10306914647420247,
      "backward_entropy": 0.009332525730133056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.084932327270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0463239960372448,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10294137398401897,
      "backward_entropy": 0.009330830723047256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.956762313842773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0463726632297039,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10281143585840861,
      "backward_entropy": 0.009328332543373109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.30097007751465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046421825885772705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1026793618996938,
      "backward_entropy": 0.01820205748081207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.65347671508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04646937921643257,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10255179802576701,
      "backward_entropy": 0.009324321150779724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.56401252746582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04652171954512596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10240872701009114,
      "backward_entropy": 0.00932127982378006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.107933044433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046574145555496216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1022648811340332,
      "backward_entropy": 0.009317620098590851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.321770668029785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046627745032310486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10211668411890666,
      "backward_entropy": 0.009314318001270295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.523712158203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04667813330888748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10197853048642476,
      "backward_entropy": 0.009311221539974213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.215926170349121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04672771319746971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10184260209401448,
      "backward_entropy": 0.00930745154619217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.319561004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04677458480000496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1017149289449056,
      "backward_entropy": 0.009306341409683228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.669240951538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04682103917002678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10158803065617879,
      "backward_entropy": 0.009305529296398163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.59796714782715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04686614125967026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10146510601043701,
      "backward_entropy": 0.017866107821464538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.528514862060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046909984201192856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10134543975194295,
      "backward_entropy": 0.009309622645378112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.42521858215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046952687203884125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10122913122177124,
      "backward_entropy": 0.00931335836648941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.932195663452148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046996407210826874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10110886891682942,
      "backward_entropy": 0.017774108052253722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.199766159057617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0470380075275898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10099514325459798,
      "backward_entropy": 0.009322359412908553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.086381912231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04708068072795868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10087730487187703,
      "backward_entropy": 0.00932648703455925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.797398567199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04712435603141785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10075547297795613,
      "backward_entropy": 0.009330061823129654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.121740341186523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04716580733656883,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10064047574996948,
      "backward_entropy": 0.017654168605804443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.752349853515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047206368297338486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10052338242530823,
      "backward_entropy": 0.009339644759893417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.99052619934082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04724811762571335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10039833188056946,
      "backward_entropy": 0.009345129877328873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.925973892211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04728889837861061,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10027456283569336,
      "backward_entropy": 0.009351532906293869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.425289154052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04732872173190117,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10015279054641724,
      "backward_entropy": 0.009356901049613953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.795296669006348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04736978933215141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10002387563387553,
      "backward_entropy": 0.017508317530155183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.207782745361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04740992188453674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09989706675211589,
      "backward_entropy": 0.009367358684539796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.74357223510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047451190650463104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09976429740587871,
      "backward_entropy": 0.009370986372232437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.547542572021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047496575862169266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0996138056119283,
      "backward_entropy": 0.009372998774051667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.84063148498535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04754560813307762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09944803516070048,
      "backward_entropy": 0.0093726247549057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.567007064819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04759488254785538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09928035736083984,
      "backward_entropy": 0.009371452778577805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.57504653930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0476435124874115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09911372264226277,
      "backward_entropy": 0.009373459219932555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.44221305847168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047692425549030304,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09894537925720215,
      "backward_entropy": 0.017247214913368225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.193434715270996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0477416031062603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09877445300420125,
      "backward_entropy": 0.009376388788223267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.213083267211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04778892919421196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09861106673876445,
      "backward_entropy": 0.009377308934926987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.05400276184082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04783763363957405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0984411636988322,
      "backward_entropy": 0.009377223998308181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.9119873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047887567430734634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09826560815175374,
      "backward_entropy": 0.009376388788223267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.677547454833984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047937601804733276,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.09808885057767232,
      "backward_entropy": 0.1385658025741577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.709413528442383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04798974096775055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09790265560150146,
      "backward_entropy": 0.00937342494726181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.704401969909668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04804082587361336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09771998723347981,
      "backward_entropy": 0.009373585879802703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.36102294921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048089899122714996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09754514694213867,
      "backward_entropy": 0.009374605119228363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.859303951263428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048139095306396484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09736933310826619,
      "backward_entropy": 0.009374617785215377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.470741271972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048184607177972794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0972083608309428,
      "backward_entropy": 0.016826897859573364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.982454299926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04822859168052673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09705360730489095,
      "backward_entropy": 0.009383495897054672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.93241500854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048273224383592606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0968950887521108,
      "backward_entropy": 0.009387127310037612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.98594856262207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04832234978675842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0967169205347697,
      "backward_entropy": 0.009388577938079835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.02367401123047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048370592296123505,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.09654196103413899,
      "backward_entropy": 0.13856664896011353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.39458179473877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0484209880232811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09635704755783081,
      "backward_entropy": 0.009391078352928161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.663942337036133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048468492925167084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0961840550104777,
      "backward_entropy": 0.00939490795135498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.199657440185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04851537570357323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09601263205210368,
      "backward_entropy": 0.009401340782642365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.50796890258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04856255277991295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09583922227223714,
      "backward_entropy": 0.00940719097852707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.93290138244629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04861390218138695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09564697742462158,
      "backward_entropy": 0.009411616623401642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.128945350646973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04866499453783035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09545587499936421,
      "backward_entropy": 0.00941375195980072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.134817123413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04871309921145439,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09527740875879924,
      "backward_entropy": 0.009418711811304093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.027942657470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04876029118895531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09510292609532674,
      "backward_entropy": 0.009421995282173157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.926284790039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04880678281188011,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09493064880371094,
      "backward_entropy": 0.00942675694823265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.926804542541504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04885263741016388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0947603980700175,
      "backward_entropy": 0.009432823956012725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878811836242676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04889592155814171,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.094601571559906,
      "backward_entropy": 0.00943945124745369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.45309829711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04893691465258598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09445292750994365,
      "backward_entropy": 0.009447325766086579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.55007553100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048979632556438446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09429558118184407,
      "backward_entropy": 0.00945407897233963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.457202911376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049021996557712555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09413918852806091,
      "backward_entropy": 0.009460552036762238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.037612915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0490640364587307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.093983789285024,
      "backward_entropy": 0.009466709196567535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.57889175415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04910757765173912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09382110834121704,
      "backward_entropy": 0.009469439089298249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.169904708862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04915162920951843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09365535775820415,
      "backward_entropy": 0.00947234034538269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.077816009521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049195218831300735,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0934908390045166,
      "backward_entropy": 0.009476587921380997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.743128776550293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923827201128006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09332869450251262,
      "backward_entropy": 0.009479396045207977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.89078140258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04927992448210716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09317280848821004,
      "backward_entropy": 0.009482241421937942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.182680130004883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049321215599775314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09301839272181193,
      "backward_entropy": 0.009483757615089416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.702228546142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04936409741640091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09285575151443481,
      "backward_entropy": 0.009484189003705979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.18924331665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049406539648771286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09269463022549947,
      "backward_entropy": 0.009484972059726714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.740936279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0494522862136364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09251731634140015,
      "backward_entropy": 0.009483298659324646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.594287872314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04949928820133209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0923326810201009,
      "backward_entropy": 0.009484518319368362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.29306411743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049547139555215836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09214437007904053,
      "backward_entropy": 0.00948210284113884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.194503784179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04959411546587944,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09195927778879802,
      "backward_entropy": 0.015476842224597932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.056120872497559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04964014142751694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09177879492441814,
      "backward_entropy": 0.00948225036263466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.994170188903809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049683619290590286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09160995483398438,
      "backward_entropy": 0.009485695511102676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.83199119567871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049726538360118866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09144329031308492,
      "backward_entropy": 0.009489263594150543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.859585762023926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04977082833647728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09126907587051392,
      "backward_entropy": 0.009493091702461242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.704583168029785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04981352016329765,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09110269943873088,
      "backward_entropy": 0.00949697121977806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.30146598815918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04985576495528221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09093758463859558,
      "backward_entropy": 0.009502314031124115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.643991470336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049900252372026443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09076110521952312,
      "backward_entropy": 0.00950554758310318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03810210898518562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994313046336174,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09059230486551921,
      "backward_entropy": 0.009509606659412384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.46064376831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049981649965047836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09044679005940755,
      "backward_entropy": 0.009511701762676239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.436358451843262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05002465844154358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09027772148450215,
      "backward_entropy": 0.009513786435127259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.807661294937134,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05006621778011322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09011536836624146,
      "backward_entropy": 0.009517434239387512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.306625366210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05010470002889633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08996801575024922,
      "backward_entropy": 0.009524445980787277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.721067428588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05014210566878319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08982595801353455,
      "backward_entropy": 0.00953102856874466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.038728713989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050180286169052124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08967980742454529,
      "backward_entropy": 0.009535209089517594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.195127487182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05022116005420685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08951852718989055,
      "backward_entropy": 0.009541253000497818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.724014282226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05026336386799812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08935036261876424,
      "backward_entropy": 0.009545016288757324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.253673553466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05030766874551773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0891713301340739,
      "backward_entropy": 0.009546643495559693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.61785888671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05035224184393883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08898964524269104,
      "backward_entropy": 0.009551869332790374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.600812911987305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0504004992544651,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08878912528355916,
      "backward_entropy": 0.009556116163730621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.868885040283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05044928565621376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08858583370844524,
      "backward_entropy": 0.00955870896577835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.65880298614502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05049772560596466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08838427066802979,
      "backward_entropy": 0.009561475366353989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.151655197143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05054398998618126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08819425106048584,
      "backward_entropy": 0.00956295132637024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.44673728942871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05059276893734932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08799101909001668,
      "backward_entropy": 0.009563501179218292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.94937801361084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0506429597735405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08778005838394165,
      "backward_entropy": 0.0095647931098938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.20170021057129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05069011449813843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08758387962977092,
      "backward_entropy": 0.009570851176977157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.080408096313477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05073711648583412,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0873876412709554,
      "backward_entropy": 0.009579233080148696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.180862426757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05078382417559624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08719297250111897,
      "backward_entropy": 0.009586228430271149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.105793952941895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05082864686846733,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08700750271479289,
      "backward_entropy": 0.014129367470741273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.712100982666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050871796905994415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08682980140050252,
      "backward_entropy": 0.009608440101146698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.278848648071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05091502517461777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08665162324905396,
      "backward_entropy": 0.009620064496994018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.483642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050957534462213516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08647643526395161,
      "backward_entropy": 0.009632766246795654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.839071273803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05100008472800255,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08630140622456868,
      "backward_entropy": 0.013987460732460022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.00494384765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051040928810834885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08613604307174683,
      "backward_entropy": 0.009648805856704712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.483363628387451,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051081255078315735,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08597253759702046,
      "backward_entropy": 0.00965709164738655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.841054916381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05111927166581154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08582175771395366,
      "backward_entropy": 0.009664442390203476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587905883789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05115692317485809,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08567282557487488,
      "backward_entropy": 0.00967046320438385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.99749755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051193248480558395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08553194999694824,
      "backward_entropy": 0.00967230498790741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.59203815460205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05123106762766838,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08538252115249634,
      "backward_entropy": 0.009673114866018295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.399943351745605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05126858875155449,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08523382743199666,
      "backward_entropy": 0.013623256981372834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.335800170898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051304854452610016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08509231607119243,
      "backward_entropy": 0.009675320982933045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.434931755065918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05134005844593048,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0849563479423523,
      "backward_entropy": 0.013502281904220582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.396282196044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051375992596149445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08481576045354207,
      "backward_entropy": 0.009675828367471695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.310253143310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0514134019613266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08466660976409912,
      "backward_entropy": 0.009675223380327225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.12519645690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051452986896038055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08450494209925334,
      "backward_entropy": 0.009674416482448578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.046236753463745,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051492840051651,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08434147636095683,
      "backward_entropy": 0.009673713892698287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0195555686950684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0515294186770916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0841975212097168,
      "backward_entropy": 0.009669862687587738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.61055564880371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051563162356615067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08406956990559895,
      "backward_entropy": 0.009666245430707932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.905079364776611,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05160175636410713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08391509453455608,
      "backward_entropy": 0.009659095853567123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.694829940795898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05163831636309624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08377066254615784,
      "backward_entropy": 0.009656956791877747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.51794719696045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051674701273441315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08362590273221333,
      "backward_entropy": 0.009658821672201157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.303998947143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051711615175008774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08347787459691365,
      "backward_entropy": 0.009660828113555908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.597293853759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051749613136053085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08332529664039612,
      "backward_entropy": 0.009657377749681473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.380697250366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05178646743297577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08317698041598003,
      "backward_entropy": 0.009659190475940705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.668776035308838,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05182293429970741,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08303076028823853,
      "backward_entropy": 0.012719427049160004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8514044284820557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05185748264193535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08289496103922527,
      "backward_entropy": 0.009665714949369431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8255534172058105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05188919976353645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08277690410614014,
      "backward_entropy": 0.00966491997241974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.568537712097168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05191851779818535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08267282446225484,
      "backward_entropy": 0.0096634641289711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.283858299255371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051946546882390976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08257569869359334,
      "backward_entropy": 0.012477495521306992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.702666282653809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05197424441576004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08247990409533183,
      "backward_entropy": 0.009663093090057372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.631103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05200325697660446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08237553636233012,
      "backward_entropy": 0.009664271771907807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.543274879455566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05203330144286156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08226577440897624,
      "backward_entropy": 0.009662553668022156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04383484274148941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052064381539821625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08214974403381348,
      "backward_entropy": 0.00966101735830307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.040918350219727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05209234729409218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08205174903074901,
      "backward_entropy": 0.00965988039970398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.352105140686035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05212004855275154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08195407191912334,
      "backward_entropy": 0.009662127494812012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.234319686889648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05214650556445122,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08186401923497517,
      "backward_entropy": 0.012044262886047364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.400516510009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05217432975769043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08176547288894653,
      "backward_entropy": 0.00966295599937439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.858177185058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05220508202910423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08164865771929423,
      "backward_entropy": 0.011929512768983842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.810713291168213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05223524570465088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08153463403383891,
      "backward_entropy": 0.009672155231237411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.9071044921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05226483568549156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0814235011736552,
      "backward_entropy": 0.009678908437490464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.273404121398926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05229559540748596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0813042422135671,
      "backward_entropy": 0.009689421951770782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.20219898223877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052326444536447525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08118454615275066,
      "backward_entropy": 0.009698890149593353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.093882083892822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052357472479343414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08106296757857005,
      "backward_entropy": 0.009710145741701126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.106754302978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05238690227270126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08095134298006694,
      "backward_entropy": 0.009718561172485351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.990931510925293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05241980403661728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08081854383150737,
      "backward_entropy": 0.009729470312595367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.875641822814941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05245407298207283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08067806561787923,
      "backward_entropy": 0.009737975895404816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.757807731628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052489664405584335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08052947123845418,
      "backward_entropy": 0.011531399935483933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.334485054016113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052526503801345825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08037284513314565,
      "backward_entropy": 0.009758852422237396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.699075698852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052562180906534195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08022202551364899,
      "backward_entropy": 0.009774452447891236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8350090980529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052597444504499435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08007331689198811,
      "backward_entropy": 0.009790071845054626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.321012496948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0526307076215744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07993685205777486,
      "backward_entropy": 0.009803663194179534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.563066482543945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05266512557864189,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07979450126489003,
      "backward_entropy": 0.011355730146169663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.059143543243408,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052701495587825775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07964060703913371,
      "backward_entropy": 0.00982087180018425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.007297515869141,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05273662507534027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07949323455492656,
      "backward_entropy": 0.00983118861913681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.56452465057373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05277055501937866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07935298482577006,
      "backward_entropy": 0.009841229766607285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.750781059265137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05280487611889839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07921058436234792,
      "backward_entropy": 0.009849732369184494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.83655309677124,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0528404600918293,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07905957599480946,
      "backward_entropy": 0.009861119091510773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.540156364440918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05287488177418709,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07891449332237244,
      "backward_entropy": 0.011124984174966813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2715303897857666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05291033163666725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0787638674179713,
      "backward_entropy": 0.009885595738887787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.329938888549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052942994982004166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07862997551759084,
      "backward_entropy": 0.009895561635494233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.23675537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05297675356268883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.078490416208903,
      "backward_entropy": 0.009900713711977005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.12040901184082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053007885813713074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07836648325125377,
      "backward_entropy": 0.009905654191970825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.858965873718262,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053040314465761185,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07823503017425537,
      "backward_entropy": 0.13854045867919923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.057683944702148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05307309702038765,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0781020075082779,
      "backward_entropy": 0.00990770012140274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1610143184661865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053107742220163345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07795797785123189,
      "backward_entropy": 0.009905906766653061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47691535949707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05313977971673012,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07782857616742452,
      "backward_entropy": 0.009907828271389007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.219540596008301,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05317161604762077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0776996910572052,
      "backward_entropy": 0.009911070764064788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.427922248840332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05320186913013458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07757915059725444,
      "backward_entropy": 0.009917837381362916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.164719104766846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05323275178670883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0774547557036082,
      "backward_entropy": 0.0099239319562912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.176979064941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05326198413968086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07734036445617676,
      "backward_entropy": 0.009929070621728897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.136886119842529,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053290512412786484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07722973823547363,
      "backward_entropy": 0.009935036301612854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.113585472106934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0533183217048645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07712360223134358,
      "backward_entropy": 0.010471072793006898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.053643226623535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053346142172813416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07701776425043742,
      "backward_entropy": 0.009941172599792481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.001556396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053375523537397385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07690260310967763,
      "backward_entropy": 0.010370758920907974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.934478282928467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05340412259101868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07679145534833272,
      "backward_entropy": 0.009946193546056747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.872688293457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053432632237672806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07668085396289825,
      "backward_entropy": 0.009946689009666443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8173136711120605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053461093455553055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07657064994176228,
      "backward_entropy": 0.009945853054523468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.389543533325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053489431738853455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07646162311236064,
      "backward_entropy": 0.009942076355218887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.588972091674805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05352132394909859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07633121311664581,
      "backward_entropy": 0.009940074384212494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8291304111480713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053553689271211624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07619665563106537,
      "backward_entropy": 0.009942051023244858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.668930530548096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05358422175049782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0760732392470042,
      "backward_entropy": 0.009943968057632447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.224016189575195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05361393466591835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07595365246136983,
      "backward_entropy": 0.009965571016073227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.272050857543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05364479124546051,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07582764824231465,
      "backward_entropy": 0.009952370822429658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.531123638153076,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05367613956332207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07569802800814311,
      "backward_entropy": 0.009957622736692429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.669846296310425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053706489503383636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07557410995165507,
      "backward_entropy": 0.009963850677013397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.648968696594238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053735218942165375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07545982797940572,
      "backward_entropy": 0.009970543533563614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.744696617126465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053765878081321716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07533397277196248,
      "backward_entropy": 0.009976398944854737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.115500450134277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05379774048924446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07519996166229248,
      "backward_entropy": 0.009985797107219696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7930657863616943,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05382918193936348,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07506829500198364,
      "backward_entropy": 0.009995123744010926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.262267589569092,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05385816842317581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07495181262493134,
      "backward_entropy": 0.010003720223903657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.206650733947754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053886182606220245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07484209537506104,
      "backward_entropy": 0.010008275508880615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.300684928894043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05391354486346245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07473528385162354,
      "backward_entropy": 0.010015816986560821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7292873859405518,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05394228547811508,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.0746195117632548,
      "backward_entropy": 0.13851640224456788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.450048446655273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05396893620491028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07451577981313069,
      "backward_entropy": 0.010035538673400879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.061039924621582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05399635434150696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07440694669882457,
      "backward_entropy": 0.010047976672649384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6855080127716064,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05402494594454765,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07429193456967671,
      "backward_entropy": 0.010056419670581818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040544603019952774,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054051488637924194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.074188232421875,
      "backward_entropy": 0.009387214481830598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.551562786102295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05407533794641495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07410137852032979,
      "backward_entropy": 0.010078010708093643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.510429382324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05409957468509674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07401104768117268,
      "backward_entropy": 0.010090570151805877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.674226760864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05412403866648674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07391929626464844,
      "backward_entropy": 0.010102176666259765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.415271759033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054150015115737915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07381816705067952,
      "backward_entropy": 0.010112921893596648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1937389373779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05417594686150551,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07371799151102702,
      "backward_entropy": 0.010120496153831482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.882151126861572,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0542006678879261,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07362450162569682,
      "backward_entropy": 0.010129666328430176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.262309551239014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05422612279653549,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07352652152379353,
      "backward_entropy": 0.01013650968670845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.837777137756348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054251596331596375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07342881957689922,
      "backward_entropy": 0.010141637176275253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.152939796447754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054279085248708725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07331856588522594,
      "backward_entropy": 0.010147003829479218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.133550643920898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05430644750595093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07320867975552876,
      "backward_entropy": 0.010153084993362427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0295631885528564,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054334938526153564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07309197386105855,
      "backward_entropy": 0.010158587247133255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4707818031311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05436204746365547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07298211256663005,
      "backward_entropy": 0.010168977081775665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.410656452178955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05438980832695961,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07286720474561055,
      "backward_entropy": 0.010183213651180268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.872089862823486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05441802740097046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0727495551109314,
      "backward_entropy": 0.010197386145591736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.383744716644287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05444614216685295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07263116538524628,
      "backward_entropy": 0.010215389728546142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.209791660308838,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05447329953312874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07251929740111034,
      "backward_entropy": 0.010230174660682679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.728376865386963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05450092628598213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07240425546964009,
      "backward_entropy": 0.010244948416948318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4459713697433472,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452823266386986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0722919503847758,
      "backward_entropy": 0.010256032645702361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.619650363922119,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05455340817570686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07219294706980388,
      "backward_entropy": 0.010265130549669266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.576909065246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05457860231399536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07209344704945882,
      "backward_entropy": 0.010274553298950195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.138408184051514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05460372194647789,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07199454307556152,
      "backward_entropy": 0.010281952470541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3982203006744385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0546283945441246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07189654310544331,
      "backward_entropy": 0.010295164585113526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7416064739227295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054651178419589996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07181043922901154,
      "backward_entropy": 0.010306008160114288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7180898189544678,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05467281863093376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07173182566960652,
      "backward_entropy": 0.010312774777412414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.024078845977783,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05469346418976784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07165976365407307,
      "backward_entropy": 0.010317321866750717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.322028636932373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054713886231184006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0715888241926829,
      "backward_entropy": 0.010321642458438873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032101649791002274,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054734617471694946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07151664793491364,
      "backward_entropy": 0.010323043167591094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6272130012512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05475328862667084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07145685950915019,
      "backward_entropy": 0.010325035452842713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6231062412261963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054771438241004944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07139837741851807,
      "backward_entropy": 0.010331562906503677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8899879455566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05478892847895622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07134386400381725,
      "backward_entropy": 0.010336332023143768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.142979145050049,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05480644851922989,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07128895819187164,
      "backward_entropy": 0.010340313613414764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.566788911819458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0548245795071125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07123076915740967,
      "backward_entropy": 0.01034272015094757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5548768043518066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05484212189912796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07117571433385213,
      "backward_entropy": 0.010345728695392608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.293821811676025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05485905706882477,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07112447420756023,
      "backward_entropy": 0.008257177472114564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9987688064575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05487727001309395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07106521725654602,
      "backward_entropy": 0.01034766510128975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.259986162185669,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05489615723490715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07100069522857666,
      "backward_entropy": 0.010351938009262086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.303716659545898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054913830012083054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07094276944796245,
      "backward_entropy": 0.010358589887619018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4679901599884033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054935574531555176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07086080312728882,
      "backward_entropy": 0.010361922532320022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.235947608947754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05495624616742134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07078595956166585,
      "backward_entropy": 0.010362386703491211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4167721271514893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05497545376420021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07071968913078308,
      "backward_entropy": 0.010363122820854187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.977166652679443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05499405413866043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07065577308336894,
      "backward_entropy": 0.010368512570858001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.748076438903809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055013712495565414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07058559854825337,
      "backward_entropy": 0.010373302549123765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.536708354949951,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05503378063440323,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07051253318786621,
      "backward_entropy": 0.13850353956222533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3506641387939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055053677409887314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0704396516084671,
      "backward_entropy": 0.007923831045627595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022476857528090477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05507277697324753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07037142912546794,
      "backward_entropy": 0.010395480692386628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.756343364715576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05509005859494209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07031363745530446,
      "backward_entropy": 0.010405932366847993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3176677227020264,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055108483880758286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07024876276652019,
      "backward_entropy": 0.010415253788232803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2882378101348877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05512595921754837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.070191890001297,
      "backward_entropy": 0.010415580123662949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.508675575256348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05514279007911682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07013904054959615,
      "backward_entropy": 0.010414762049913406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.478573799133301,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05516029894351959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07008118430773418,
      "backward_entropy": 0.010416796058416366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1332992315292358,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05517837777733803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07001949846744537,
      "backward_entropy": 0.010420086979866027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.135252833366394,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055195193737745285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06996557116508484,
      "backward_entropy": 0.010422433167696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3043251037597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055210698395967484,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06992103656133015,
      "backward_entropy": 0.007633781433105469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.190650463104248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05522623658180237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06987657646338145,
      "backward_entropy": 0.007591334730386734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.410164833068848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05524139106273651,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06983369588851929,
      "backward_entropy": 0.010407066345214844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3688645362854,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05525781586766243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06978317101796468,
      "backward_entropy": 0.01040225476026535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0898081064224243,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05527544766664505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06972457468509674,
      "backward_entropy": 0.010399895906448364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1841013431549072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055291809141635895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06967416405677795,
      "backward_entropy": 0.010395699739456176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.256923675537109,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05530824884772301,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06962263584136963,
      "backward_entropy": 0.010393825173377991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1313629150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055325813591480255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06956454614798228,
      "backward_entropy": 0.01039225161075592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.122706890106201,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055343467742204666,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.0695044348637263,
      "backward_entropy": 0.13846296072006226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.089965581893921,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05536086857318878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06944663325945537,
      "backward_entropy": 0.0103961743414402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.050983190536499,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05537823587656021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06938859820365906,
      "backward_entropy": 0.010397553443908691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0278117656707764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055395033210515976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06933353344599406,
      "backward_entropy": 0.010401052981615066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.024249315261841,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055410776287317276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06928415099779765,
      "backward_entropy": 0.010406975448131562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.992807865142822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05542660877108574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06923408806324005,
      "backward_entropy": 0.010413310676813125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.924501895904541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055443547666072845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06917752822240193,
      "backward_entropy": 0.010417947173118591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.866885185241699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05546262860298157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06910810867945354,
      "backward_entropy": 0.01042354553937912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.834483623504639,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05548359453678131,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06902670363585155,
      "backward_entropy": 0.010429032891988755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9375436305999756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05550568550825119,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06893911957740784,
      "backward_entropy": 0.01043347716331482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9191361665725708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05552671104669571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06885754068692525,
      "backward_entropy": 0.010439708828926086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7914559841156006,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05554676800966263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06878137588500977,
      "backward_entropy": 0.010447600483894348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.689055919647217,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055566832423210144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06870634357134502,
      "backward_entropy": 0.010450892150402069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7910683155059814,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05558741092681885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06862886250019073,
      "backward_entropy": 0.01045035496354103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020095089450478554,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05560753867030144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06855397423108418,
      "backward_entropy": 0.010450723767280578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.462080955505371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055625710636377335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0684903512398402,
      "backward_entropy": 0.010452968627214431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5155930519104,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05564519762992859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06841906905174255,
      "backward_entropy": 0.010455156862735748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5768096446990967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055665284395217896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06834462285041809,
      "backward_entropy": 0.010454979538917542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5393471717834473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05568552017211914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06826859712600708,
      "backward_entropy": 0.01045745685696602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8922860026359558,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570594221353531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06819051007429759,
      "backward_entropy": 0.010464249551296234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.066021919250488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05572488531470299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06812107563018799,
      "backward_entropy": 0.006790518760681152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.29595422744751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055745627731084824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0680402119954427,
      "backward_entropy": 0.010481694340705871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5575573444366455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055766914039850235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06795595586299896,
      "backward_entropy": 0.010492480546236038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8522433638572693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05578767880797386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06787454585234325,
      "backward_entropy": 0.010504620522260666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.171065330505371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05580703541636467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0678004523118337,
      "backward_entropy": 0.010520691424608231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8418980240821838,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05582696571946144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0677231748898824,
      "backward_entropy": 0.010535027831792831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2729971408843994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05584543198347092,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06765480836232503,
      "backward_entropy": 0.010548260062932968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8559675216674805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055864136666059494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06758443514506023,
      "backward_entropy": 0.010562785714864732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.420877695083618,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055884022265672684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06750688950220744,
      "backward_entropy": 0.010577540844678879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8123860955238342,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05590330436825752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06743372480074565,
      "backward_entropy": 0.010587257891893386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5012898445129395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05592112988233566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06736946105957031,
      "backward_entropy": 0.01059524118900299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5710299015045166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05594062805175781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0672954519589742,
      "backward_entropy": 0.010602521151304245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3222739696502686,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055959153920412064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06722715497016907,
      "backward_entropy": 0.010608790069818496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.575412750244141,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05597730726003647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06716091434160869,
      "backward_entropy": 0.010614565014839173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5306638479232788,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05599667504429817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06708660225073497,
      "backward_entropy": 0.010623343288898468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5175360441207886,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05601496621966362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06701956192652385,
      "backward_entropy": 0.010627067089080811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5032985210418701,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05603225156664848,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06695965925852458,
      "backward_entropy": 0.1384805202484131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4830528497695923,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05604863166809082,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06690585613250732,
      "backward_entropy": 0.010619240254163742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.917752504348755,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05606432259082794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06685580809911092,
      "backward_entropy": 0.01061355322599411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.894819974899292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05608039349317551,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0668029934167862,
      "backward_entropy": 0.010609978437423706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5776331424713135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05609673634171486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06674868861834209,
      "backward_entropy": 0.010605954378843308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018771231174468994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056113846600055695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06668936212857564,
      "backward_entropy": 0.010603849589824677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4158202409744263,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05612926930189133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06663973132769267,
      "backward_entropy": 0.010602723062038421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.403891921043396,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05614412575960159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06659300128618877,
      "backward_entropy": 0.010602959245443345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6960904002189636,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05615846812725067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06654893358548482,
      "backward_entropy": 0.01060449779033661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.384529709815979,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05617207661271095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0665074090162913,
      "backward_entropy": 0.010613958537578582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3997802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05618523061275482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06646889448165894,
      "backward_entropy": 0.010621513426303863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7029433250427246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05619948357343674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06642326712608337,
      "backward_entropy": 0.010631626099348068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.355804204940796,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05621420592069626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06637450059254964,
      "backward_entropy": 0.0106419138610363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9987757205963135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05622825771570206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0663306713104248,
      "backward_entropy": 0.010646653175354005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3240821361541748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05624230578541756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06628664334615071,
      "backward_entropy": 0.010651441663503647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.321694016456604,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05625595524907112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06624425450960796,
      "backward_entropy": 0.010658860951662064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2447593212127686,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05626906082034111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06620572010676067,
      "backward_entropy": 0.010662609338760376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2109949588775635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056283071637153625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06616224845250447,
      "backward_entropy": 0.010664009302854539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1875059604644775,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056298043578863144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06611232956250508,
      "backward_entropy": 0.010668458789587021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.527815103530884,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05631374940276146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06605842709541321,
      "backward_entropy": 0.010671450197696686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2630258798599243,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056329697370529175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06600260734558105,
      "backward_entropy": 0.010674699395895004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.862472653388977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0563448928296566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06595202287038167,
      "backward_entropy": 0.010675743967294694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4571192264556885,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05635995790362358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06590142846107483,
      "backward_entropy": 0.010678500682115556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4363315105438232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05637530982494354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06584912538528442,
      "backward_entropy": 0.01068146899342537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6080055236816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056390855461359024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06579620639483134,
      "backward_entropy": 0.01068241149187088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1959868669509888,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056407488882541656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06573684513568878,
      "backward_entropy": 0.010682876408100127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.361070394515991,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05642345920205116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06568034489949544,
      "backward_entropy": 0.010687507688999176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.331970453262329,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0564395971596241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06562283138434093,
      "backward_entropy": 0.00587831661105156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1699587106704712,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05645599216222763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0655629535516103,
      "backward_entropy": 0.010700765252113342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.584476113319397,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05647150054574013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06550942361354828,
      "backward_entropy": 0.010704389214515686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016771314665675163,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056485895067453384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06546224157015483,
      "backward_entropy": 0.010707876086235047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.246932029724121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05649883672595024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0654236872990926,
      "backward_entropy": 0.010710407793521882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.229710817337036,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056512266397476196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06538113951683044,
      "backward_entropy": 0.010715311020612716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6569231748580933,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056526072323322296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06533651053905487,
      "backward_entropy": 0.010720381885766983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1895382404327393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056539878249168396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06529127558072408,
      "backward_entropy": 0.010728514939546584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6290194988250732,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056554004549980164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06524414817492168,
      "backward_entropy": 0.010736014693975449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6852622032165527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05656803026795387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0651973287264506,
      "backward_entropy": 0.010744200646877288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.595504641532898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05658269301056862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06514734029769897,
      "backward_entropy": 0.010749053210020065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.583600640296936,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05659724399447441,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06509713331858318,
      "backward_entropy": 0.010756656527519226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0890069007873535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05661160126328468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06504804889361064,
      "backward_entropy": 0.010763750970363617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5513979196548462,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056626129895448685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06499859193960826,
      "backward_entropy": 0.010768236219882965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.04158878326416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05664048343896866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06494980057080586,
      "backward_entropy": 0.010773226618766785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.030384063720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05665513128042221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06489864985148112,
      "backward_entropy": 0.010780492424964904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5027798414230347,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05667075887322426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06484201550483704,
      "backward_entropy": 0.010785365104675293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5065587759017944,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05668610706925392,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06478661298751831,
      "backward_entropy": 0.010792696475982666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4730204343795776,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056700319051742554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0647378961245219,
      "backward_entropy": 0.010799212753772736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9366358518600464,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05671435222029686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06468998392422994,
      "backward_entropy": 0.010805513709783554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.96894770860672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05672869831323624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06463945905367534,
      "backward_entropy": 0.010814649611711502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3757383823394775,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056742388755083084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06459298233191173,
      "backward_entropy": 0.010821788012981415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.882224202156067,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05675668269395828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06454322735468547,
      "backward_entropy": 0.010827136784791946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3249948024749756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05677115172147751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0644923746585846,
      "backward_entropy": 0.01083213984966278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8418208360671997,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05678616091609001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0644384225209554,
      "backward_entropy": 0.005497661978006363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3702419996261597,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05680125579237938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06438392400741577,
      "backward_entropy": 0.010841478407382966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45783430337905884,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05681600794196129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06433157622814178,
      "backward_entropy": 0.010845059156417846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.457278311252594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05682973563671112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06428450842698415,
      "backward_entropy": 0.010850514471530914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.327072024345398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05684245005249977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06424345076084137,
      "backward_entropy": 0.010854267328977586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6196868419647217,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05685506761074066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06420276562372844,
      "backward_entropy": 0.010858197510242463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.451482057571411,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056868672370910645,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06415695945421855,
      "backward_entropy": 0.13846979141235352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2878820896148682,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056883905082941055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06410252054532369,
      "backward_entropy": 0.010858144611120224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6897430419921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05689871683716774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06405081351598103,
      "backward_entropy": 0.010855305194854736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011696456000208855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056913577020168304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06399863958358765,
      "backward_entropy": 0.01085251122713089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42174550890922546,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056926991790533066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06395428379376729,
      "backward_entropy": 0.010851922631263732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.044156551361084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05693947523832321,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06391485532124837,
      "backward_entropy": 0.010852910578250885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8136129379272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05695252865552902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06387268503506978,
      "backward_entropy": 0.010851674526929856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2055379152297974,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05696507543325424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06383278965950012,
      "backward_entropy": 0.010852422565221786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4087420105934143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05697747319936752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0637938529253006,
      "backward_entropy": 0.010852814465761185,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.287866757567972,
    "avg_log_Z": -0.0562358894571662,
    "success_rate": 1.0,
    "avg_reward": 85.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.03,
      "2": 0.95
    },
    "avg_forward_entropy": 0.0663348218301932,
    "avg_backward_entropy": 0.013068191453814503,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}