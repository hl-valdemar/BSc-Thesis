{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09877477373395648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881646292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.66851806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676601648330688,
      "backward_entropy": 0.09881118365696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.92689514160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13675792515277863,
      "backward_entropy": 0.09877946547099523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.59588623046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0001993658661376685,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674968481063843,
      "backward_entropy": 0.09882997614996773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.48915100097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00029916319181211293,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367412805557251,
      "backward_entropy": 0.09883655820574079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.13771057128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003994579892605543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673260807991028,
      "backward_entropy": 0.09882604224341256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.8699493408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004996804054826498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13672374188899994,
      "backward_entropy": 0.09882969515664237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.44760131835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005997538683004677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367146223783493,
      "backward_entropy": 0.09880123819623675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.79454040527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006997778546065092,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13670530915260315,
      "backward_entropy": 0.09886171988078526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.7564697265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007997112115845084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366957128047943,
      "backward_entropy": 0.0988403388432094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.78338623046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008995771640911698,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13668568432331085,
      "backward_entropy": 0.09887349605560303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.909912109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009999892208725214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13667529821395874,
      "backward_entropy": 0.09881763798849923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.92990112304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011003217659890652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13666470348834991,
      "backward_entropy": 0.09885069302150182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.50302124023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012012047227472067,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366538405418396,
      "backward_entropy": 0.09889028753553118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.46142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013025733642280102,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366431713104248,
      "backward_entropy": 0.09882969515664237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.42111206054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014043296687304974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366329938173294,
      "backward_entropy": 0.09883380787713188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.0563201904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015063963364809752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366226077079773,
      "backward_entropy": 0.09886424882071358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.9550018310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001607145182788372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13661201298236847,
      "backward_entropy": 0.09886750153132848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.37034606933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017084359424188733,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13660120964050293,
      "backward_entropy": 0.09884556702205113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.06658935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018084245966747403,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13659021258354187,
      "backward_entropy": 0.09884927102497645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.65025329589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019062331411987543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13657911121845245,
      "backward_entropy": 0.09887688500540597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.47836303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0020022329408675432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365678906440735,
      "backward_entropy": 0.09887967790876116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.71221923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002094060415402055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13655662536621094,
      "backward_entropy": 0.09888216427394322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.78752899169922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002183516277000308,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13654524087905884,
      "backward_entropy": 0.09893648965018136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.4379119873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002268194453790784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13653387129306793,
      "backward_entropy": 0.09886504922594343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.09130859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00235581211745739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13652212917804718,
      "backward_entropy": 0.09886783361434937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.23175048828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024419324472546577,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13651034235954285,
      "backward_entropy": 0.09894659689494542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.43214416503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025275552179664373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364983171224594,
      "backward_entropy": 0.09889232260840279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.78436279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0026129516772925854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648578524589539,
      "backward_entropy": 0.09889394896371025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.98997497558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002698080614209175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364729255437851,
      "backward_entropy": 0.0988779067993164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.80413818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002784240525215864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364596039056778,
      "backward_entropy": 0.09889747415270124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.61056518554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028725769370794296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364457905292511,
      "backward_entropy": 0.098899245262146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.42503356933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029648190829902887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13643132150173187,
      "backward_entropy": 0.09888509341648646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.1582794189453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003053552471101284,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364165097475052,
      "backward_entropy": 0.09896645375660487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.59068298339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003140117507427931,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364014446735382,
      "backward_entropy": 0.09896882942744664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.829833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00322516355663538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363861858844757,
      "backward_entropy": 0.09889156477791923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.2954864501953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0033127765636891127,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13637052476406097,
      "backward_entropy": 0.09897339344024658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.51358032226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003398563712835312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13635465502738953,
      "backward_entropy": 0.09889561789376396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.46310424804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034867061767727137,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13633832335472107,
      "backward_entropy": 0.09897802557264056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.6072998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003573180176317692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13632182776927948,
      "backward_entropy": 0.09891061271939959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.3531494140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0036606481298804283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13630494475364685,
      "backward_entropy": 0.09891172817775182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.4915008544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037513517308980227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13628745079040527,
      "backward_entropy": 0.0989128862108503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.48129272460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038436229806393385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362694650888443,
      "backward_entropy": 0.09891402721405029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.63731384277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0039334725588560104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13625124096870422,
      "backward_entropy": 0.09890700238091606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.3555908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004022540524601936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13623221218585968,
      "backward_entropy": 0.09890873091561454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.30909729003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0041134352795779705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362125277519226,
      "backward_entropy": 0.09891046796526227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.39534759521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0042059519328176975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13619224727153778,
      "backward_entropy": 0.09891220501491002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.09776306152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00429479731246829,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13617192208766937,
      "backward_entropy": 0.09891377176557269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.88694763183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004383089952170849,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361512839794159,
      "backward_entropy": 0.09899736302239555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.45016479492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004469492472708225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361304521560669,
      "backward_entropy": 0.09891665833336967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.48812866210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004552507307380438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13610947132110596,
      "backward_entropy": 0.09891791003090995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.07782745361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0046311551705002785,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13608857989311218,
      "backward_entropy": 0.09900131395884923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.13095092773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004705975763499737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136067733168602,
      "backward_entropy": 0.09891915321350098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.01788330078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004780234303325415,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13604655861854553,
      "backward_entropy": 0.09900340012141637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.61320495605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004862301051616669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13602423667907715,
      "backward_entropy": 0.0989188381603786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.87704467773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00494030537083745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13600140810012817,
      "backward_entropy": 0.09891862528664726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.84124755859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005017745308578014,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359783262014389,
      "backward_entropy": 0.09900626114436559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.80514526367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005094700027257204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359548419713974,
      "backward_entropy": 0.09891802072525024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.6001205444336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00517124030739069,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13593094050884247,
      "backward_entropy": 0.09892404079437256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.13077545166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005242880899459124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13590729236602783,
      "backward_entropy": 0.09891718626022339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4615936279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005312633700668812,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13588325679302216,
      "backward_entropy": 0.09900915622711182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.5709991455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005382540635764599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585874438285828,
      "backward_entropy": 0.09892489228929792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.76744079589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0054522547870874405,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13583366572856903,
      "backward_entropy": 0.09901031426021031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.57949829101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0055190324783325195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358085572719574,
      "backward_entropy": 0.09891443593161446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.3681640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00559224234893918,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1357821822166443,
      "backward_entropy": 0.09901135308401925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.61961364746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005673978477716446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357542872428894,
      "backward_entropy": 0.0989133630480085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.19415283203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00575642054900527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357259750366211,
      "backward_entropy": 0.09891292027064733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.91177368164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0058396244421601295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13569727540016174,
      "backward_entropy": 0.09891247749328613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.77151489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0059232995845377445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356680989265442,
      "backward_entropy": 0.09891201768602643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.91246032714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006005868315696716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13563863933086395,
      "backward_entropy": 0.09891191550663539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.21229553222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00609052088111639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13560861349105835,
      "backward_entropy": 0.09891188996178764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.81280517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006173513829708099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135578453540802,
      "backward_entropy": 0.09892533506665911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.85144805908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006258581764996052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13554763793945312,
      "backward_entropy": 0.09891133649008614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.11237335205078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006338026840239763,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13551750779151917,
      "backward_entropy": 0.09901549986430577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.80543518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0064153471030294895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13548746705055237,
      "backward_entropy": 0.0989253180367606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.9945831298828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00649507250636816,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13545626401901245,
      "backward_entropy": 0.0990160618509565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.94120025634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006577188614755869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13542383909225464,
      "backward_entropy": 0.09890856061662946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.32748413085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006655273027718067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13539130985736847,
      "backward_entropy": 0.09892502001353673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.21832275390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006737376097589731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13535712659358978,
      "backward_entropy": 0.09890708753040858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.44985961914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006821536459028721,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13532133400440216,
      "backward_entropy": 0.098906295640128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.0961456298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0069042700342834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13528479635715485,
      "backward_entropy": 0.09890530790601458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.1179962158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006993796210736036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13524644076824188,
      "backward_entropy": 0.09892445802688599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.76009368896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007083612959831953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13520753383636475,
      "backward_entropy": 0.09890386036464147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.69329833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007170276716351509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13516853749752045,
      "backward_entropy": 0.0989030088697161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.09467315673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007258296944200993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13512839376926422,
      "backward_entropy": 0.09892387901033674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.9561004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007338789291679859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13508936762809753,
      "backward_entropy": 0.09890082904270717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.43262481689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007421192247420549,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350490152835846,
      "backward_entropy": 0.09892337662833077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.69937133789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007498195394873619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13500936329364777,
      "backward_entropy": 0.09892297642571586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.26925659179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007576266303658485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13496872782707214,
      "backward_entropy": 0.09892254216330391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.088623046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00765543058514595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1349271833896637,
      "backward_entropy": 0.09892208235604423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.55599212646484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007732665631920099,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1348855346441269,
      "backward_entropy": 0.09901865891047887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.47605895996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007807670161128044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13484355807304382,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.69781494140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0078856460750103,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13480021059513092,
      "backward_entropy": 0.0990187440599714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.9805450439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007963266223669052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13475632667541504,
      "backward_entropy": 0.09891959599086217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.57122802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008043734356760979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13471117615699768,
      "backward_entropy": 0.09888456548963274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.08635711669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008125260472297668,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13466514647006989,
      "backward_entropy": 0.09891819953918457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.91224670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008203905075788498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346188485622406,
      "backward_entropy": 0.09887983117784772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.1118621826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008280347101390362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345723420381546,
      "backward_entropy": 0.09887714045388359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.49414825439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008359713479876518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13452444970607758,
      "backward_entropy": 0.09887444972991943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.6118621826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008435217663645744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13447682559490204,
      "backward_entropy": 0.09891464029039655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.41848754882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008513901382684708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13442780077457428,
      "backward_entropy": 0.0989136781011309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.68106842041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008591858670115471,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343781054019928,
      "backward_entropy": 0.09891265630722046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.51033782958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008667715825140476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134328231215477,
      "backward_entropy": 0.09886252880096436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.0137481689453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008742081932723522,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1342782974243164,
      "backward_entropy": 0.09901823316301618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.54042053222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008816970512270927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13422784209251404,
      "backward_entropy": 0.09885604892458234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.86736297607422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008890096098184586,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1341770887374878,
      "backward_entropy": 0.09901799474443708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.95449829101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008961514569818974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13412593305110931,
      "backward_entropy": 0.09890666178294591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.2992706298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009038730524480343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13407279551029205,
      "backward_entropy": 0.09884563514164516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.85592651367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009115707129240036,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13401895761489868,
      "backward_entropy": 0.09901759454182216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.18097686767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009191264398396015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13396506011486053,
      "backward_entropy": 0.09890284708568028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.10738372802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009265423752367496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13391101360321045,
      "backward_entropy": 0.09890145914895195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.57659149169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009333067573606968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1338583379983902,
      "backward_entropy": 0.09889992645808629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.29512786865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009399591945111752,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1338050216436386,
      "backward_entropy": 0.09889833416257586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.2324981689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009465922601521015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13375139236450195,
      "backward_entropy": 0.0988241263798305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.03848266601562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009533473290503025,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13369673490524292,
      "backward_entropy": 0.09901648759841919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.12699127197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009601472876966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13364076614379883,
      "backward_entropy": 0.09889345509665352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.18482971191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009668095968663692,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13358427584171295,
      "backward_entropy": 0.0988917521068028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.60243225097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009735561907291412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13352663815021515,
      "backward_entropy": 0.09880670479365758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.74900817871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009805708192288876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1334674060344696,
      "backward_entropy": 0.09880225999014718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.43975067138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009879885241389275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13340607285499573,
      "backward_entropy": 0.09879803657531738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.84344482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009952644817531109,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13334445655345917,
      "backward_entropy": 0.09888511044638497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.33531188964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010026070289313793,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13328205049037933,
      "backward_entropy": 0.09901470797402519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.280029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010098174214363098,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332194209098816,
      "backward_entropy": 0.09878465107509068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.66708374023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010172553360462189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1331552267074585,
      "backward_entropy": 0.09878007854734148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.31671142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010247472673654556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13309021294116974,
      "backward_entropy": 0.09877546344484602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.764404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010326026007533073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13302303850650787,
      "backward_entropy": 0.09887653589248657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.38217163085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010408352129161358,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13295406103134155,
      "backward_entropy": 0.09901355845587594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8321990966797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010485237464308739,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13288646936416626,
      "backward_entropy": 0.09901332003729683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.36911010742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010564341209828854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13281747698783875,
      "backward_entropy": 0.098871077810015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.18618774414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010653611272573471,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13274413347244263,
      "backward_entropy": 0.09901302201407296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.51638793945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010742279700934887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326705515384674,
      "backward_entropy": 0.09874842848096575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.7608642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010839805006980896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13259321451187134,
      "backward_entropy": 0.09874471596309117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.3214340209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010938492603600025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325153112411499,
      "backward_entropy": 0.09874087572097778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.85491943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011029290966689587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13243898749351501,
      "backward_entropy": 0.09886201790400914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.02583312988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011120243929326534,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1323615312576294,
      "backward_entropy": 0.09885999134608678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.23712158203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01120488066226244,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1322859227657318,
      "backward_entropy": 0.09901257923671178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.7911376953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0112908398732543,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1322091668844223,
      "backward_entropy": 0.0990124259676252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.0889434814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011380646377801895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13212957978248596,
      "backward_entropy": 0.09901230675833565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.10549926757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01147180050611496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13204781711101532,
      "backward_entropy": 0.098709089415414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.96826171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011563211679458618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1319650113582611,
      "backward_entropy": 0.09870310340608869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.58074951171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011653241701424122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318819224834442,
      "backward_entropy": 0.09869686194828578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.5006561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011743785813450813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13179779052734375,
      "backward_entropy": 0.09869054385593959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.0550079345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011834794655442238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13171260058879852,
      "backward_entropy": 0.09868413209915161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.65296936035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011926352977752686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1316264271736145,
      "backward_entropy": 0.09867770331246513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.90994262695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012014883570373058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13154073059558868,
      "backward_entropy": 0.09867097650255476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.34249877929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012105831876397133,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13145308196544647,
      "backward_entropy": 0.09883326292037964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.729736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012193145230412483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1313655525445938,
      "backward_entropy": 0.09865694386618477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.68055725097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012283013202250004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13127614557743073,
      "backward_entropy": 0.09882743869509016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.68964385986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012366941198706627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1311892718076706,
      "backward_entropy": 0.09882423707417079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.26264190673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012448480352759361,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13110247254371643,
      "backward_entropy": 0.09863371508462089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.2540740966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012528011575341225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13101571798324585,
      "backward_entropy": 0.09881730590547834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.33375549316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012607010081410408,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13092781603336334,
      "backward_entropy": 0.09900925840650286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.01910400390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012690708041191101,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13083630800247192,
      "backward_entropy": 0.09860701220376152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.47897338867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012773857451975346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13074412941932678,
      "backward_entropy": 0.09880646637507848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.8833770751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012851318344473839,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13065405189990997,
      "backward_entropy": 0.09880248137882777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.71890258789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012935640290379524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1305595189332962,
      "backward_entropy": 0.09857804434640068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.46641540527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013020995073020458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13046343624591827,
      "backward_entropy": 0.09879503931318011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.7276382446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013109293766319752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13036513328552246,
      "backward_entropy": 0.09855871541159493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.76238250732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013189535588026047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13027019798755646,
      "backward_entropy": 0.09854813984462193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.84429931640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013266216963529587,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1301763653755188,
      "backward_entropy": 0.09900626114436559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.48687744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013342938385903835,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13008135557174683,
      "backward_entropy": 0.09877850328172956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.81784057617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013419433496892452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1299850195646286,
      "backward_entropy": 0.09851341588156563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.88533020019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013494318351149559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12988856434822083,
      "backward_entropy": 0.09850083930151803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.31735229492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013566054403781891,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1297929883003235,
      "backward_entropy": 0.09900390250342232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.68760681152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013640452176332474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12969517707824707,
      "backward_entropy": 0.09875918286187309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.14599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013713058084249496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12959688901901245,
      "backward_entropy": 0.09846067428588867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.34379577636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013788257725536823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12949642539024353,
      "backward_entropy": 0.09874887125832695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.58468627929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013856673613190651,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12939909100532532,
      "backward_entropy": 0.09900108405521937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.87033081054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013922599144279957,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12930232286453247,
      "backward_entropy": 0.09900017295564924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.44517517089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013995038345456123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12920065224170685,
      "backward_entropy": 0.09840157202311925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.9991455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014070248231291771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290968358516693,
      "backward_entropy": 0.09872625555310931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.18828582763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01414808351546526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128991037607193,
      "backward_entropy": 0.09872097628457206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.11360931396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014223810285329819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12888488173484802,
      "backward_entropy": 0.09871539047786168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.31649780273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01429764460772276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.128778338432312,
      "backward_entropy": 0.09899675846099854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.14281463623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014372454956173897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1286708116531372,
      "backward_entropy": 0.09832439252308436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.3904571533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014444164000451565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12856429815292358,
      "backward_entropy": 0.09869688749313354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.03923797607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014522113837301731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284531205892563,
      "backward_entropy": 0.09829081807817731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.83250427246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01459865365177393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1283421516418457,
      "backward_entropy": 0.09827397550855364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.89486694335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014676792547106743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12822851538658142,
      "backward_entropy": 0.0982563751084464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.7481918334961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014755495823919773,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12811410427093506,
      "backward_entropy": 0.098993148122515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.15338134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01483114156872034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12800128757953644,
      "backward_entropy": 0.09866451365607125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.62969970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014914419502019882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12788274884223938,
      "backward_entropy": 0.0986581700188773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.593994140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015003116801381111,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12776035070419312,
      "backward_entropy": 0.09899229662758964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.27532196044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015090885572135448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12763740122318268,
      "backward_entropy": 0.09817043372562953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.46499633789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01516666542738676,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1275213062763214,
      "backward_entropy": 0.09863877296447754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.08668518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015242408029735088,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12740355730056763,
      "backward_entropy": 0.09863099030085973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015314677730202675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12728683650493622,
      "backward_entropy": 0.09862257753099714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.3570556640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015391617082059383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12716643512248993,
      "backward_entropy": 0.0989894185747419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.0434112548828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015471065416932106,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12704390287399292,
      "backward_entropy": 0.09898891619273595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.5482635498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015550533309578896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12692028284072876,
      "backward_entropy": 0.09804158551352364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.32351684570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01563057117164135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12679597735404968,
      "backward_entropy": 0.0980196510042463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.48113250732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01570727676153183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1266734004020691,
      "backward_entropy": 0.09858414105006627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.90609359741211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015782857313752174,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12655101716518402,
      "backward_entropy": 0.09898643834250313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.90218353271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015848476439714432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12643595039844513,
      "backward_entropy": 0.09794691630772182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.19241333007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015910301357507706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12632286548614502,
      "backward_entropy": 0.09855519873755318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.08203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01597794145345688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1262047290802002,
      "backward_entropy": 0.09789425134658813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.82134246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01605079136788845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12608200311660767,
      "backward_entropy": 0.09786920888083321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.07354736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01612221822142601,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12595854699611664,
      "backward_entropy": 0.09784190143857684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.2510757446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016196096315979958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1258316934108734,
      "backward_entropy": 0.0978136658668518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.67086791992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016265515238046646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12570780515670776,
      "backward_entropy": 0.09778370176042829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.09188079833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016336161643266678,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1255820244550705,
      "backward_entropy": 0.09849263940538679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.79397583007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016406184062361717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12545593082904816,
      "backward_entropy": 0.09772150005613055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.61443328857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01647142507135868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12533196806907654,
      "backward_entropy": 0.09768682718276978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.70237731933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01653631590306759,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1252071112394333,
      "backward_entropy": 0.09765163489750453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.03753662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01659650355577469,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.125083789229393,
      "backward_entropy": 0.09844011068344116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.7860107421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016662776470184326,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12495534121990204,
      "backward_entropy": 0.09896649633135114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.8859634399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016730360686779022,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12482467293739319,
      "backward_entropy": 0.09841315235410418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.64678955078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016795191913843155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12469467520713806,
      "backward_entropy": 0.09749812739236015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.17002868652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016863377764821053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12456101179122925,
      "backward_entropy": 0.09838475499834333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.61675262451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016932424157857895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12442515790462494,
      "backward_entropy": 0.0983704583985465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.98829650878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016999008134007454,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12429067492485046,
      "backward_entropy": 0.0989557249205453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.57247924804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017066210508346558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12415355443954468,
      "backward_entropy": 0.0973266874040876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.68936157226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017141971737146378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12400851398706436,
      "backward_entropy": 0.09728314195360456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.62102508544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017216788604855537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12386336177587509,
      "backward_entropy": 0.09723950283867973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.49810791015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017285006120800972,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12372328341007233,
      "backward_entropy": 0.09894784007753644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.06939697265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01735452190041542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12358111888170242,
      "backward_entropy": 0.09714821406773158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.27781677246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0174249317497015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1234368234872818,
      "backward_entropy": 0.09826724869864327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.80355834960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01749643124639988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1232907772064209,
      "backward_entropy": 0.09705374922071185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.83751678466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01757010631263256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12314097583293915,
      "backward_entropy": 0.09700474568775722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.20430755615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017641305923461914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12299355864524841,
      "backward_entropy": 0.09695499283926827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.01774597167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017707347869873047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12284889817237854,
      "backward_entropy": 0.09820212636675153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.93141174316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01777110993862152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12270545959472656,
      "backward_entropy": 0.09684449434280396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.57630920410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01783282496035099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12256298959255219,
      "backward_entropy": 0.09816413266318184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.68902587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017902076244354248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12241336703300476,
      "backward_entropy": 0.09672995976039342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.40850830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01797432452440262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12226035445928574,
      "backward_entropy": 0.09812906810215541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.23782348632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018051140010356903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12210272997617722,
      "backward_entropy": 0.09661950383867536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.97577667236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01812884956598282,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12194459140300751,
      "backward_entropy": 0.09809591088976179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.79353332519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01820148155093193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12179074436426163,
      "backward_entropy": 0.09650788136890956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.28791809082031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018263941630721092,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12164632230997086,
      "backward_entropy": 0.09891370364597865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.43739318847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018324486911296844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12150272727012634,
      "backward_entropy": 0.09637866701398577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.76181030273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018387729302048683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1213570237159729,
      "backward_entropy": 0.09801047188895089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.06995391845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01845460943877697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12120664119720459,
      "backward_entropy": 0.09625052554266793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.15110778808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01851312443614006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12106049060821533,
      "backward_entropy": 0.09617950235094343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.08694458007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018582986667752266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12090258300304413,
      "backward_entropy": 0.09611330713544573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.51030731201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018657254055142403,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12073866277933121,
      "backward_entropy": 0.09792225701468331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.70307159423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018732950091362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12057404220104218,
      "backward_entropy": 0.09598219394683838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.8423843383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018809380009770393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12040817737579346,
      "backward_entropy": 0.09788104466029576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.76004028320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018881944939494133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202438622713089,
      "backward_entropy": 0.09584525653294154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.3161849975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01895677112042904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1200757622718811,
      "backward_entropy": 0.0957714489528111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1449737548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01902845874428749,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11991004645824432,
      "backward_entropy": 0.09569387776511055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.99331665039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01910305954515934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11974118649959564,
      "backward_entropy": 0.09778544732502528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.43206787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01918027736246586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11956949532032013,
      "backward_entropy": 0.09554094076156616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.96378326416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019261308014392853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11939316987991333,
      "backward_entropy": 0.09773833411080497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.45294189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019336795434355736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11922204494476318,
      "backward_entropy": 0.09538234983171735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.10503387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019409222528338432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11905370652675629,
      "backward_entropy": 0.09768484319959368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.66339874267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019476814195513725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11888951808214188,
      "backward_entropy": 0.09520486422947474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.6753921508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019539764150977135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1187286525964737,
      "backward_entropy": 0.0951071126120431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.5385284423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01960284449160099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11856770515441895,
      "backward_entropy": 0.09758839436939784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.05970764160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019669057801365852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11840160191059113,
      "backward_entropy": 0.09490753923143659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.44393157958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019738225266337395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11823150515556335,
      "backward_entropy": 0.09480486597333636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.51663208007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019808556884527206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11805997788906097,
      "backward_entropy": 0.09748986789158412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.95870971679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0198738444596529,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1178922951221466,
      "backward_entropy": 0.09745349202837263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.15885543823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019937388598918915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11772722005844116,
      "backward_entropy": 0.094476546560015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.27651977539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019993184134364128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1175699234008789,
      "backward_entropy": 0.09435599190848214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.50091552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020045798271894455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11741545796394348,
      "backward_entropy": 0.09423065185546875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.4251251220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020094143226742744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1172662228345871,
      "backward_entropy": 0.09728401047842843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.48648834228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020149653777480125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11710937321186066,
      "backward_entropy": 0.09724053314753942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.40261840820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020207742229104042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694939434528351,
      "backward_entropy": 0.09385251998901367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.11033630371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020270220935344696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11678507924079895,
      "backward_entropy": 0.09373000689915248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.32183074951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020324915647506714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11662819981575012,
      "backward_entropy": 0.09359730992998395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.61067199707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02038172446191311,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1164674162864685,
      "backward_entropy": 0.09346092598778862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.22759246826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020431017503142357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1163133829832077,
      "backward_entropy": 0.09700935227530343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.15479278564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020480042323470116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11616023629903793,
      "backward_entropy": 0.09695635523114886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.486351013183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020524591207504272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11601140350103378,
      "backward_entropy": 0.09301258836473737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.20481872558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02056325413286686,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11586865037679672,
      "backward_entropy": 0.09871297223227364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.8254852294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020600028336048126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11572642624378204,
      "backward_entropy": 0.09268088000161308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.48519134521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020643150433897972,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11557711660861969,
      "backward_entropy": 0.09671410492488317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.0858154296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020687205716967583,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11542860418558121,
      "backward_entropy": 0.09867338623319354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.43324279785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020727142691612244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11528367549180984,
      "backward_entropy": 0.09218135050364903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.4352798461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02076735720038414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11513788998126984,
      "backward_entropy": 0.09200670037950788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.54840087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02080569602549076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1149931326508522,
      "backward_entropy": 0.09182519572121757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.69388198852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020840628072619438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11485182493925095,
      "backward_entropy": 0.09163710049220494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.26437377929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020870763808488846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11471611261367798,
      "backward_entropy": 0.09630692005157471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.61060333251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020904596894979477,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11457683145999908,
      "backward_entropy": 0.09623298474720546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.19712829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02093948982656002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1144360825419426,
      "backward_entropy": 0.09105673858097621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.62571716308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02098117768764496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11428818851709366,
      "backward_entropy": 0.09086787700653076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.38095092773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021027138456702232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1141359955072403,
      "backward_entropy": 0.0906811101096017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.6312255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021074967458844185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1139819547533989,
      "backward_entropy": 0.09049289567129952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.08443450927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02112632989883423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11382415890693665,
      "backward_entropy": 0.09030583075114659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.57876586914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021175460889935493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11366982012987137,
      "backward_entropy": 0.09580415487289429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.17611694335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021222306415438652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11351816356182098,
      "backward_entropy": 0.0899146454674857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.50825500488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02127281203866005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11336252093315125,
      "backward_entropy": 0.09565211193902153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.27333068847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021323326975107193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11320837587118149,
      "backward_entropy": 0.0895162650517055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.52371215820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021373439580202103,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11305494606494904,
      "backward_entropy": 0.09549680777958461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.3515396118164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021429434418678284,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11289675533771515,
      "backward_entropy": 0.09845854554857526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.14651489257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021482344716787338,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1127416267991066,
      "backward_entropy": 0.09844868523733956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.19722747802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021536489948630333,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11258519440889359,
      "backward_entropy": 0.09526096923010689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.52103424072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02159016765654087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11243036389350891,
      "backward_entropy": 0.08849605492183141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.67366409301758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021642738953232765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11227583885192871,
      "backward_entropy": 0.08827610526766096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.25277709960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02168922685086727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11212937533855438,
      "backward_entropy": 0.08804733412606376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.29776763916016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021736301481723785,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11198385059833527,
      "backward_entropy": 0.09839204379490443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.40151977539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02178722806274891,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11183439195156097,
      "backward_entropy": 0.09481916257313319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.471435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021845316514372826,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11167728900909424,
      "backward_entropy": 0.09473414931978498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.63959503173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021900147199630737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11152347922325134,
      "backward_entropy": 0.08714213541575841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.10213470458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021957652643322945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11136630177497864,
      "backward_entropy": 0.08690341029848371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.32282257080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022015847265720367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11120820045471191,
      "backward_entropy": 0.08665958472660609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.78077697753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02207307331264019,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11105230450630188,
      "backward_entropy": 0.09436704431261335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.5684051513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02213103137910366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11089570075273514,
      "backward_entropy": 0.08615785837173462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.71522521972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022199368104338646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11072944104671478,
      "backward_entropy": 0.0941824061529977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.3290786743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022269032895565033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11056166887283325,
      "backward_entropy": 0.08567151853016444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.47418212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022334454581141472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1103992611169815,
      "backward_entropy": 0.08541143792016166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.14864730834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022392693907022476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11024671792984009,
      "backward_entropy": 0.08514111382620675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.04251098632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022445939481258392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11009985208511353,
      "backward_entropy": 0.08485868998936244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.37779998779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022500190883874893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10995125770568848,
      "backward_entropy": 0.09366052491324288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.3571319580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022551465779542923,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10980549454689026,
      "backward_entropy": 0.09824493953159877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.85237884521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022608214989304543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10965532064437866,
      "backward_entropy": 0.0839695760181972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.75521850585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022661887109279633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10950849950313568,
      "backward_entropy": 0.0932978902544294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.85615539550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022720403969287872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10935677587985992,
      "backward_entropy": 0.08335374082837786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.11566925048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022780098021030426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10920557379722595,
      "backward_entropy": 0.08304988486426217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.56031799316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022830750793218613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10906215012073517,
      "backward_entropy": 0.0929235305104937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.67797088623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022881099954247475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10891939699649811,
      "backward_entropy": 0.08239878926958356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.26403045654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0229310505092144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10877688229084015,
      "backward_entropy": 0.08206429651805333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.77376556396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02298078127205372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10863529145717621,
      "backward_entropy": 0.08172345161437988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.86573791503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02303394302725792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10848978161811829,
      "backward_entropy": 0.09236158643450056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.32142639160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023095613345503807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10833495110273361,
      "backward_entropy": 0.09222635201045445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.36949157714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02316003479063511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10817978531122208,
      "backward_entropy": 0.08071992227009364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.49221801757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023222947493195534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10802767425775528,
      "backward_entropy": 0.08038389682769775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.03939819335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02328385040163994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10787700861692429,
      "backward_entropy": 0.09802852358136858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.38473510742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023343605920672417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10772906243801117,
      "backward_entropy": 0.09165568011147636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.21772766113281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023402072489261627,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10758309066295624,
      "backward_entropy": 0.09799134731292725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.56258392333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023459386080503464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10743895173072815,
      "backward_entropy": 0.07893701962062291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.85831451416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0235175471752882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10729455947875977,
      "backward_entropy": 0.09117567539215088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.7431411743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0235783439129591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10714830458164215,
      "backward_entropy": 0.07817877190453666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.66667938232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023635635152459145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10700547695159912,
      "backward_entropy": 0.07778459787368774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.606910705566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023695537820458412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10686056315898895,
      "backward_entropy": 0.09788848672594343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.24679565429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023748241364955902,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10672347247600555,
      "backward_entropy": 0.09048637322017125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.12112426757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023804541677236557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10658454895019531,
      "backward_entropy": 0.07656220027378627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.33035278320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02386145107448101,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10644474625587463,
      "backward_entropy": 0.07614386081695557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.75528717041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023917166516184807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10630635917186737,
      "backward_entropy": 0.08993336132594518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.53897094726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023975064978003502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10616406798362732,
      "backward_entropy": 0.07527385439191546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.00221252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02403245121240616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10602548718452454,
      "backward_entropy": 0.07483853612627302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.09218978881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024100491777062416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10587993264198303,
      "backward_entropy": 0.07443502119609288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.96776580810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024160467088222504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10574240237474442,
      "backward_entropy": 0.07400609765733991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.15814971923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024215204641222954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10561059415340424,
      "backward_entropy": 0.08898144108908516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.21475219726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024272998794913292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10547666996717453,
      "backward_entropy": 0.07312017679214478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.56215286254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024331437423825264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10534260421991348,
      "backward_entropy": 0.08858216660363334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.11363220214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024384818971157074,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10521413385868073,
      "backward_entropy": 0.09761070353644234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.51663589477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024439675733447075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10508592426776886,
      "backward_entropy": 0.08815703221729823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.75178527832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02448972314596176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1049623042345047,
      "backward_entropy": 0.08792893375669207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.17212677001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02453910931944847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10483870655298233,
      "backward_entropy": 0.0707992400441851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.10503387451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024590039625763893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10471394658088684,
      "backward_entropy": 0.0703118017741612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.615232467651367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024636585265398026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10459359735250473,
      "backward_entropy": 0.06980548586164202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.26700592041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0246731024235487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10448163747787476,
      "backward_entropy": 0.06927437015942164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.52792358398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02471320331096649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10436967015266418,
      "backward_entropy": 0.06876303468431745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.71284484863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024762384593486786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10425260663032532,
      "backward_entropy": 0.08643318074090141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.58534622192383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024809181690216064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10413695871829987,
      "backward_entropy": 0.06779909133911133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.83033752441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02485254593193531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10402652621269226,
      "backward_entropy": 0.08591784749712263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.09727478027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024893183261156082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10392151027917862,
      "backward_entropy": 0.06680501358849662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.43497085571289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02493422105908394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10381536185741425,
      "backward_entropy": 0.08537071091788155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.47618103027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024971725419163704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10371118783950806,
      "backward_entropy": 0.08508465119770595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.94939422607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025004155933856964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10361015796661377,
      "backward_entropy": 0.06521962370191302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.91221618652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025042327120900154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10350599139928818,
      "backward_entropy": 0.06468946167400905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.12322998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025087887421250343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10339874029159546,
      "backward_entropy": 0.06418868047850472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.755985260009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025127634406089783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10329554229974747,
      "backward_entropy": 0.06366494723728724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.082382202148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025164635851979256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10319618880748749,
      "backward_entropy": 0.0631345340183803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.88542938232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0251931119710207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10310423374176025,
      "backward_entropy": 0.0833398870059422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.28450012207031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025219757109880447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10301409661769867,
      "backward_entropy": 0.06202610901423863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.62769317626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025248460471630096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10292163491249084,
      "backward_entropy": 0.06146816696439471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.26509857177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025275349617004395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10283099114894867,
      "backward_entropy": 0.0823835986001151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.49522399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02530699037015438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10273919999599457,
      "backward_entropy": 0.06036308833530971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.40563201904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025334211066365242,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10264943540096283,
      "backward_entropy": 0.08174589702061244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.22940063476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025363627821207047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10255797207355499,
      "backward_entropy": 0.059223677430834086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.95378494262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025395045056939125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10246523469686508,
      "backward_entropy": 0.05865315028599331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.56763458251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025422241538763046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10237482190132141,
      "backward_entropy": 0.05806503125599453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.53693389892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025455709546804428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10228154808282852,
      "backward_entropy": 0.08041485718318395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.54583740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02549252100288868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10218527168035507,
      "backward_entropy": 0.05692039217267718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.2210922241211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025526879355311394,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10209183394908905,
      "backward_entropy": 0.09639982666288104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.99401092529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025566639378666878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10199470818042755,
      "backward_entropy": 0.055780955723353794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.26858520507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02560168132185936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10190165042877197,
      "backward_entropy": 0.05520319512912205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.551025390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025638727471232414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10180985927581787,
      "backward_entropy": 0.07872676849365234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.50335693359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025676671415567398,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10171663761138916,
      "backward_entropy": 0.07837327889033727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.3080940246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025713855400681496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10162375867366791,
      "backward_entropy": 0.05348047614097595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.370155334472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025748269632458687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.101531982421875,
      "backward_entropy": 0.0776433093207223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.69200134277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02577860653400421,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10144399851560593,
      "backward_entropy": 0.05228431735719953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.93795394897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025807105004787445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10135744512081146,
      "backward_entropy": 0.07686340808868408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.64785766601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025834374129772186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1012738049030304,
      "backward_entropy": 0.051076999732426236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.433380126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02586827054619789,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10118693113327026,
      "backward_entropy": 0.0760848777634757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.838863372802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025898538529872894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10110455751419067,
      "backward_entropy": 0.04992428421974182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.85619354248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02592315711081028,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10102568566799164,
      "backward_entropy": 0.049330677304949076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.4139404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025948742404580116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10094688832759857,
      "backward_entropy": 0.048742473125457764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.53395080566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025975417345762253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10086911171674728,
      "backward_entropy": 0.04816444431032453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.25070571899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02600291185081005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10079140961170197,
      "backward_entropy": 0.07404109409877233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.414207458496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026029260829091072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10071530938148499,
      "backward_entropy": 0.04701547537531171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.75984191894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026052409783005714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10064077377319336,
      "backward_entropy": 0.046430809157235284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.86901092529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026073073968291283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10056944191455841,
      "backward_entropy": 0.04584678156035287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.26885223388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026103073731064796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1004926860332489,
      "backward_entropy": 0.045293573822293966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.88467407226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026130151003599167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1004205197095871,
      "backward_entropy": 0.04474179659570966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.151222229003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02616819366812706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10034219920635223,
      "backward_entropy": 0.04423295600073678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.129920959472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026204390451312065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10026717185974121,
      "backward_entropy": 0.043724077088492255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.63212585449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026238860562443733,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10019426047801971,
      "backward_entropy": 0.07070454529353551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.7969970703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02627578191459179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1001211479306221,
      "backward_entropy": 0.042706234114510674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.901229858398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02631467767059803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10004667937755585,
      "backward_entropy": 0.06989235537392753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.77694320678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02634783275425434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09997743368148804,
      "backward_entropy": 0.04169202276638576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.78120422363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026379495859146118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09990904480218887,
      "backward_entropy": 0.04117433088166373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.26484680175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026407932862639427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09984281659126282,
      "backward_entropy": 0.04064909475190299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.52019500732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026435572654008865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09977754205465317,
      "backward_entropy": 0.06812744055475507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.55130004882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026466501876711845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09971185028553009,
      "backward_entropy": 0.039620748588017056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.628173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02650025673210621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0996449887752533,
      "backward_entropy": 0.039123211588178365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.33499145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026532938703894615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09958058595657349,
      "backward_entropy": 0.038631209305354526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.27729034423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02657235413789749,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09951291978359222,
      "backward_entropy": 0.0381640579019274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.094486236572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026616036891937256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09944453835487366,
      "backward_entropy": 0.03771446006638663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.1289291381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026657817885279655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0993795245885849,
      "backward_entropy": 0.03726323587553842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.36027145385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02670343965291977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09931241720914841,
      "backward_entropy": 0.036821803876331875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.64535903930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026744958013296127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09924919903278351,
      "backward_entropy": 0.03637239762714931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.37474822998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026786455884575844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09918560087680817,
      "backward_entropy": 0.06434547049658638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.94013214111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026828039437532425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09912209212779999,
      "backward_entropy": 0.0639229416847229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.6418228149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026871470734477043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09905677288770676,
      "backward_entropy": 0.03502641831125532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.587657928466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026916667819023132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09899020195007324,
      "backward_entropy": 0.0630933770111629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.67205047607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0269557423889637,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09892682731151581,
      "backward_entropy": 0.06265613436698914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.282875061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027001269161701202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09886227548122406,
      "backward_entropy": 0.03368470711367471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.99098205566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0270445104688406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09879831969738007,
      "backward_entropy": 0.033239662647247314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.36238098144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0270917359739542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09873344749212265,
      "backward_entropy": 0.03281056880950928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.72087097167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02713846229016781,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09866806119680405,
      "backward_entropy": 0.03237802854606083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.10359191894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02718294784426689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09860363602638245,
      "backward_entropy": 0.03194124783788409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.03370666503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027232835069298744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09853452444076538,
      "backward_entropy": 0.06014619980539594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.52125930786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02728399634361267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09846431016921997,
      "backward_entropy": 0.031085316623960222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.47317123413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027334455400705338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09839479625225067,
      "backward_entropy": 0.059328275067465644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.43757629394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027384182438254356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09832508862018585,
      "backward_entropy": 0.030233170304979597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.20697784423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027435224503278732,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09825453907251358,
      "backward_entropy": 0.058507059301648824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.68090057373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027489539235830307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09818337112665176,
      "backward_entropy": 0.02939973132950919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.47203063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027547065168619156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09811356663703918,
      "backward_entropy": 0.057725753102983744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.17741012573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02760346606373787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0980447381734848,
      "backward_entropy": 0.02861381002834865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.85093688964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02765500731766224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09797848016023636,
      "backward_entropy": 0.05691651787076678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.64956283569336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02770237997174263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09791604429483414,
      "backward_entropy": 0.02780298037188394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.652435302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027749961242079735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09785610437393188,
      "backward_entropy": 0.056055345705577304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.48664093017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027793774381279945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09779898822307587,
      "backward_entropy": 0.02702368582998003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.561561584472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027849148958921432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0977359339594841,
      "backward_entropy": 0.05521392822265625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.145263671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027899883687496185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09767480194568634,
      "backward_entropy": 0.02629219421318599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.25373458862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02795576862990856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09760942310094833,
      "backward_entropy": 0.025929642575127736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.9312744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028008846566081047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09754444658756256,
      "backward_entropy": 0.025558050189699446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.5545539855957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02806924097239971,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09747815877199173,
      "backward_entropy": 0.05362206697463989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.996660232543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028126809746026993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0974154993891716,
      "backward_entropy": 0.024873710104397366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.87644958496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028177879750728607,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0973568707704544,
      "backward_entropy": 0.052791403872626166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.66188049316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028230758383870125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09729787707328796,
      "backward_entropy": 0.024172848888805935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.37392807006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02828529290854931,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09723901003599167,
      "backward_entropy": 0.023837061864989146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.99667739868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028335651382803917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0971829891204834,
      "backward_entropy": 0.023495171751294817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.34897994995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028384091332554817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09712757170200348,
      "backward_entropy": 0.02315248761858259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.642486572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028432874009013176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09707339853048325,
      "backward_entropy": 0.022817173174449375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.742332458496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028480013832449913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09702020138502121,
      "backward_entropy": 0.050224708659308295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.46273040771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028523992747068405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09697028249502182,
      "backward_entropy": 0.022148328168051585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.23353385925293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02857065573334694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09691944718360901,
      "backward_entropy": 0.02182468133313315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.54196166992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02861207351088524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0968693196773529,
      "backward_entropy": 0.02149105284895216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.93744659423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028658416122198105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09681805223226547,
      "backward_entropy": 0.021176885281290327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.77690887451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028707221150398254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09676524996757507,
      "backward_entropy": 0.0480766807283674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.025184631347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02875456027686596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09671248495578766,
      "backward_entropy": 0.020562391195978438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.19081115722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02880253456532955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09665979444980621,
      "backward_entropy": 0.04725058589662824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.45913696289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02885306067764759,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09660720080137253,
      "backward_entropy": 0.09445113795144218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.45961570739746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02890765853226185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09655183553695679,
      "backward_entropy": 0.01969029860837119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.39399337768555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028956608846783638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09649848937988281,
      "backward_entropy": 0.04606772746358599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.720367431640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029006054624915123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0964445024728775,
      "backward_entropy": 0.019116410187312534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.41873931884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029054366052150726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09639313071966171,
      "backward_entropy": 0.0188367451940264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.40266036987305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029107224196195602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09634160995483398,
      "backward_entropy": 0.018572524189949036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.28303909301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029158705845475197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09629304707050323,
      "backward_entropy": 0.044509129864828925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.94940948486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029208946973085403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09624681621789932,
      "backward_entropy": 0.018057680555752346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.77482604980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029263325035572052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09619608521461487,
      "backward_entropy": 0.01780873324189867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.16508102416992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029323402792215347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09614244103431702,
      "backward_entropy": 0.01757146418094635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.90998077392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02938505820930004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09608883410692215,
      "backward_entropy": 0.04307413952691214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.96703338623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029446234926581383,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09603461623191833,
      "backward_entropy": 0.04273679426738194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.51835250854492,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029512420296669006,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09597622603178024,
      "backward_entropy": 0.09455553122929164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.30107116699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029579605907201767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09591789543628693,
      "backward_entropy": 0.016684480011463165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.0981674194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029644038528203964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0958615094423294,
      "backward_entropy": 0.01646659416811807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.98088073730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02971317246556282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09580212831497192,
      "backward_entropy": 0.016257081712995256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.6135368347168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02978113293647766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09574189782142639,
      "backward_entropy": 0.04116978815623692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.42115783691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029848312959074974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09568463265895844,
      "backward_entropy": 0.015836405966963087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.96413803100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02991642616689205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09562568366527557,
      "backward_entropy": 0.01563121165548052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.328163146972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0299763735383749,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09556977450847626,
      "backward_entropy": 0.01541619747877121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.330345153808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030034461989998817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09551480412483215,
      "backward_entropy": 0.015202556337629045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.555076599121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030089206993579865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09546445310115814,
      "backward_entropy": 0.014990816158907754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.168745040893555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030139010399580002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09541540592908859,
      "backward_entropy": 0.03920372894832066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.42448425292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030186260119080544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09536753594875336,
      "backward_entropy": 0.014560710106577193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.96033477783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030234916135668755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0953204333782196,
      "backward_entropy": 0.014353965009961809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.10906982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030281193554401398,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09527416527271271,
      "backward_entropy": 0.03817416088921683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.20599365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030329039320349693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09522836655378342,
      "backward_entropy": 0.03784509216036115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.200592041015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030381888151168823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09518131613731384,
      "backward_entropy": 0.0137668177485466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.20737838745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03043390065431595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09513553231954575,
      "backward_entropy": 0.013586916029453278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.91794967651367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030488746240735054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09508851170539856,
      "backward_entropy": 0.03694163475717817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.2985610961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030542632564902306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0950426533818245,
      "backward_entropy": 0.013244730021272386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.20456600189209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03060103952884674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09499617666006088,
      "backward_entropy": 0.01308517690215792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.97435760498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030652811750769615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09495335817337036,
      "backward_entropy": 0.036063245364597867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.23285675048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03070576675236225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09490987658500671,
      "backward_entropy": 0.035770190613610406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.43616485595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030761592090129852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09486499428749084,
      "backward_entropy": 0.012602195143699646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.72019386291504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030821779742836952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0948188304901123,
      "backward_entropy": 0.012456187180110387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.3035774230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030878892168402672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0947747677564621,
      "backward_entropy": 0.012309790721961431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.82394790649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03093676269054413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09472964704036713,
      "backward_entropy": 0.012166478804179601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.24845504760742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030993590131402016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09468550980091095,
      "backward_entropy": 0.012024621878351485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.31867980957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03105301409959793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09464029967784882,
      "backward_entropy": 0.011889132005827767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.84834289550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031116493046283722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09459149092435837,
      "backward_entropy": 0.033898036394800456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.26298522949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031181925907731056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09454168379306793,
      "backward_entropy": 0.03366132293428693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.278499603271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031245656311511993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09449412673711777,
      "backward_entropy": 0.011509431259972709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.23295211791992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03130961209535599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09444735944271088,
      "backward_entropy": 0.033182276146752496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.828712463378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03137551248073578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09439844638109207,
      "backward_entropy": 0.011266329458781652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.69001770019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03143974393606186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09435190260410309,
      "backward_entropy": 0.011147976985999517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.49631690979004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03150248900055885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09430743753910065,
      "backward_entropy": 0.011031056089060647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.422176361083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03156043216586113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09426577389240265,
      "backward_entropy": 0.010911026171275548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.2945556640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03161755949258804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09422538429498672,
      "backward_entropy": 0.031991628663880486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.278038024902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031673967838287354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09418526291847229,
      "backward_entropy": 0.031751117535999844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.62860870361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03172629699110985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09414787590503693,
      "backward_entropy": 0.010560381625379835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.91056442260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031786996871232986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09410512447357178,
      "backward_entropy": 0.010452852717467718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.63541793823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03184669092297554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09406210482120514,
      "backward_entropy": 0.010346646819795881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.81961441040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03190721943974495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0940195620059967,
      "backward_entropy": 0.010244589831147875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.5179443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03196508809924126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09397903084754944,
      "backward_entropy": 0.010141784591334206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.39164352416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03202230483293533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09393821656703949,
      "backward_entropy": 0.030425586870738437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.2286376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032078955322504044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09389685094356537,
      "backward_entropy": 0.030213517802102224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.840118408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03214191272854805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09384963661432266,
      "backward_entropy": 0.009844913014343806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.63570213317871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032205481082201004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09380045533180237,
      "backward_entropy": 0.009752992008413588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.12498474121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03226451203227043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09375317394733429,
      "backward_entropy": 0.009658187627792358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.96664047241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03233128413558006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0937027633190155,
      "backward_entropy": 0.029466541750090464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.17899703979492,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03240000829100609,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09365126490592957,
      "backward_entropy": 0.09591892787388392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.44974899291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032468803226947784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09360025823116302,
      "backward_entropy": 0.029133341142109463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.31964874267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032536011189222336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09354962408542633,
      "backward_entropy": 0.009327557470117296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.16456604003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03260178118944168,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09350045025348663,
      "backward_entropy": 0.028796144894191196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.137693405151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032669615000486374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0934506356716156,
      "backward_entropy": 0.028631054929324558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.33927917480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032732609659433365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09340503811836243,
      "backward_entropy": 0.009091200573103768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.572418212890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03279632329940796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09335874021053314,
      "backward_entropy": 0.02828615265233176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569840431213379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03286236524581909,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09331044554710388,
      "backward_entropy": 0.028123033898217336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.19188690185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03292211517691612,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09326724708080292,
      "backward_entropy": 0.027948826551437378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47880744934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032984621822834015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09322180598974228,
      "backward_entropy": 0.02778428154332297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.56033706665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033041294664144516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09317995607852936,
      "backward_entropy": 0.008716454995529992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.90498733520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033099379390478134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09313760697841644,
      "backward_entropy": 0.008644077394689833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.25592803955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03316207230091095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09309203922748566,
      "backward_entropy": 0.008576525109154838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.28549575805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03322559967637062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09304571151733398,
      "backward_entropy": 0.008511100496564592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.93348693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0332915373146534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09299680590629578,
      "backward_entropy": 0.00844844856432506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.406295776367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03335801884531975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0929475724697113,
      "backward_entropy": 0.008387139865330287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.91702270507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03341999277472496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09290263801813126,
      "backward_entropy": 0.008324843964406423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.71411895751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03348777815699577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09285382926464081,
      "backward_entropy": 0.026587098836898804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.307594299316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033562421798706055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09279975295066833,
      "backward_entropy": 0.008214151220662253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.125844955444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033638373017311096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09274417906999588,
      "backward_entropy": 0.008163150399923325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.082404136657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033710550516843796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09269246459007263,
      "backward_entropy": 0.008111331079687392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.628990173339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03377613425254822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09264584630727768,
      "backward_entropy": 0.008056895009108953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.901321411132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03384556993842125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0925963968038559,
      "backward_entropy": 0.02595800587109157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.585886001586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033910393714904785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0925501212477684,
      "backward_entropy": 0.007952081305640084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.448944091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03397426754236221,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09250514954328537,
      "backward_entropy": 0.00789971011025565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.70916748046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034037359058856964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09245936572551727,
      "backward_entropy": 0.025568947196006775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.63947582244873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03409652039408684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09241621941328049,
      "backward_entropy": 0.007796953299215862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.35151481628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034152209758758545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.092374786734581,
      "backward_entropy": 0.025310218334197998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.720252990722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0342063345015049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09233446419239044,
      "backward_entropy": 0.007694493447031293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.70335388183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03426232561469078,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09229187667369843,
      "backward_entropy": 0.025061613747051785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.738142967224121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03432472422719002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09224486351013184,
      "backward_entropy": 0.024949465479169573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.61028289794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03438178077340126,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09220130741596222,
      "backward_entropy": 0.024835043719836643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.919403076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03444349020719528,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09215458482503891,
      "backward_entropy": 0.0075118642832551685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.24248218536377,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03450312092900276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09210920333862305,
      "backward_entropy": 0.09720302479607719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.72776985168457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03455929458141327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09206648170948029,
      "backward_entropy": 0.0074256860784121925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.81476974487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03461410477757454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0920235738158226,
      "backward_entropy": 0.02439872920513153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.597251892089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03467392176389694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09197632223367691,
      "backward_entropy": 0.024300830704825267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.93740463256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034735098481178284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09192737936973572,
      "backward_entropy": 0.007306233048439026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.941341400146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03479905426502228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09187589585781097,
      "backward_entropy": 0.007269866764545441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.323280334472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03485927730798721,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0918269008398056,
      "backward_entropy": 0.024024767535073415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.04576110839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034917622804641724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09177975356578827,
      "backward_entropy": 0.007197248084204537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.14839744567871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03497734293341637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09173227846622467,
      "backward_entropy": 0.007161830152784075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.090946197509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03503530099987984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09168621897697449,
      "backward_entropy": 0.007126852869987488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.624908447265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03509637340903282,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09163658320903778,
      "backward_entropy": 0.023660408599036082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.74557876586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03515855222940445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09158657491207123,
      "backward_entropy": 0.007061699139220374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.81682586669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035223424434661865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09153512865304947,
      "backward_entropy": 0.007031005940267018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.934593200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035292282700538635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09147903323173523,
      "backward_entropy": 0.007002268518720355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.80653953552246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03536001220345497,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09142392873764038,
      "backward_entropy": 0.0069737764341490606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.68940544128418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035426754504442215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09136958420276642,
      "backward_entropy": 0.006945754268339702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.307422637939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035492558032274246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09131624549627304,
      "backward_entropy": 0.006918043430362429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.75045394897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03555440157651901,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09126685559749603,
      "backward_entropy": 0.023094011204583303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.176101684570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03562051057815552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09121299535036087,
      "backward_entropy": 0.023018055728503635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.25144577026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03568274900317192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09116247296333313,
      "backward_entropy": 0.006837943834917886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.13355255126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035746119916439056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0911104828119278,
      "backward_entropy": 0.006812950330121177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.91519546508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0358135886490345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09105420112609863,
      "backward_entropy": 0.006789360727582659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.944021224975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03588475286960602,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09099386632442474,
      "backward_entropy": 0.022733594690050398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.56903076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035951461642980576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09093818068504333,
      "backward_entropy": 0.006744238414934703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.607664108276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03602027893066406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0908803939819336,
      "backward_entropy": 0.006722338497638702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.467369079589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036087874323129654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0908242017030716,
      "backward_entropy": 0.006700174616915839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.01152038574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03615453466773033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09076859056949615,
      "backward_entropy": 0.006678539195231029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.02511215209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03622331842780113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09071047604084015,
      "backward_entropy": 0.00665732632790293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.56798267364502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03629250079393387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0906522274017334,
      "backward_entropy": 0.00663654665861811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.920448303222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03635748103260994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09059799462556839,
      "backward_entropy": 0.006615629153592246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037342317402362823,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03642786294221878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09053748846054077,
      "backward_entropy": 0.006596182606049946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.76478958129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036490850150585175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0904853492975235,
      "backward_entropy": 0.006576146398271833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.91559600830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036557868123054504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09042763710021973,
      "backward_entropy": 0.02205969606127058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.652377128601074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036626894026994705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09036844968795776,
      "backward_entropy": 0.021996608802250454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.195542335510254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03669019415974617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09031536430120468,
      "backward_entropy": 0.0065205565520695275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.696319580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03675002604722977,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09026545286178589,
      "backward_entropy": 0.021867190088544573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.165586471557617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03680829331278801,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09021644294261932,
      "backward_entropy": 0.006486256207738604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.534812927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036866459995508194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09016752243041992,
      "backward_entropy": 0.006469763815402985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.985857963562012,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03692009672522545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09012347459793091,
      "backward_entropy": 0.006453613085406167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.31539535522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03697124868631363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09008173644542694,
      "backward_entropy": 0.0064383793090071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.756174087524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03702465072274208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09003683924674988,
      "backward_entropy": 0.006424126348325184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.89717483520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037078630179166794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08999036252498627,
      "backward_entropy": 0.006411068141460419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.797063827514648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03713745251297951,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08993864059448242,
      "backward_entropy": 0.006398482514279229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.750839233398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037193164229393005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08989040553569794,
      "backward_entropy": 0.006385740424905505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.017318725585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03724600747227669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08984572440385818,
      "backward_entropy": 0.00637257844209671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.57715606689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0372980460524559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08980119228363037,
      "backward_entropy": 0.006360961922577449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.46280288696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03735216706991196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0897538959980011,
      "backward_entropy": 0.021263637713023593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.32936668395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03740802779793739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08970499038696289,
      "backward_entropy": 0.006338065756218774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026231907308101654,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037465550005435944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08965369313955307,
      "backward_entropy": 0.006326869662318911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.081064224243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03751720115542412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08960939943790436,
      "backward_entropy": 0.006316207881484713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.96082878112793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03757092356681824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08956214785575867,
      "backward_entropy": 0.006305871265275138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.347484588623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0376264788210392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08951269090175629,
      "backward_entropy": 0.021014443465641568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.440876007080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037679336965084076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08946637809276581,
      "backward_entropy": 0.006285914352961949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.248201370239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03773115947842598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08942132443189621,
      "backward_entropy": 0.006276204649891172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.387596130371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03778073191642761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08937864005565643,
      "backward_entropy": 0.006267573684453964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.227380752563477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037831153720617294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08933452516794205,
      "backward_entropy": 0.006259418491806302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.256357192993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03788089007139206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08929102122783661,
      "backward_entropy": 0.006251873182398933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.15816879272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037932801991701126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08924475312232971,
      "backward_entropy": 0.006243996322154999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.006595611572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03798814117908478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08919405192136765,
      "backward_entropy": 0.00623580494097301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.81687927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038045186549425125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08914080262184143,
      "backward_entropy": 0.0062280089727469855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.864198684692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038106661289930344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08908162266016006,
      "backward_entropy": 0.006220492401293346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.61146354675293,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038166094571352005,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08902536332607269,
      "backward_entropy": 0.09844262259347099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.69174575805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03822662681341171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08896772563457489,
      "backward_entropy": 0.006202609943492072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.1928596496582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03828538581728935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08891218900680542,
      "backward_entropy": 0.006193813468728747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.02190017700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038346897810697556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08885262161493301,
      "backward_entropy": 0.006185273506811687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.243711471557617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03841094672679901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08878916501998901,
      "backward_entropy": 0.0061774913753782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.577332496643066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038474321365356445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08872640132904053,
      "backward_entropy": 0.0061701083821909765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.51789855957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038534242659807205,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.088668093085289,
      "backward_entropy": 0.020278032336916243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.466772079467773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03859671577811241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0886053740978241,
      "backward_entropy": 0.006157459957259042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.1815071105957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03865582495927811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0885472223162651,
      "backward_entropy": 0.006152111504759107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.02179718017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038717690855264664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08848445117473602,
      "backward_entropy": 0.006147601774760655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.30061149597168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03877769783139229,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08842427283525467,
      "backward_entropy": 0.006143753549882344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.644212245941162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03883465379476547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08836773782968521,
      "backward_entropy": 0.020087508218629018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.55522155761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03888725861907005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08831733465194702,
      "backward_entropy": 0.020052803414208547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.405426025390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03894323110580444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08826150000095367,
      "backward_entropy": 0.020020195416041782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.648040771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0390021838247776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08820094168186188,
      "backward_entropy": 0.006134384976966041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.071561813354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03905928134918213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08814330399036407,
      "backward_entropy": 0.006131058824913842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.48578453063965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03911636024713516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08808523416519165,
      "backward_entropy": 0.006128105734075818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.41037368774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03917194902896881,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08802913129329681,
      "backward_entropy": 0.006125272384711674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.77105712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039226192981004715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08797472715377808,
      "backward_entropy": 0.019844932215554372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.66510772705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03928064927458763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08791939914226532,
      "backward_entropy": 0.0061199042413915905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.574752807617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933548182249069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08786246180534363,
      "backward_entropy": 0.006118862224476678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.83101463317871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03939041495323181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0878060832619667,
      "backward_entropy": 0.006117434906108039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.377429962158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03944696858525276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08774681389331818,
      "backward_entropy": 0.019713569964681352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.272348403930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039503321051597595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0876874029636383,
      "backward_entropy": 0.006113972514867783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.59799861907959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039559561759233475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0876280665397644,
      "backward_entropy": 0.0061110832861491615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.333370208740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0396130196750164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08757269382476807,
      "backward_entropy": 0.006109013089111873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.204023361206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0396680124104023,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08751465380191803,
      "backward_entropy": 0.019568400723593577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.446855545043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03972449153661728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0874539166688919,
      "backward_entropy": 0.006103522543396268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.95624351501465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039778199046850204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08739709109067917,
      "backward_entropy": 0.006101987191608974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.50792121887207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0398334264755249,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08733762055635452,
      "backward_entropy": 0.00609984142439706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.43842887878418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03988736495375633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08727970719337463,
      "backward_entropy": 0.006098478500332151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.146353721618652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03994001820683479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08722367882728577,
      "backward_entropy": 0.006096879818609783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.207965850830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03998870402574539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08717405796051025,
      "backward_entropy": 0.00609526623572622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031008698046207428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04003534093499184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08712738752365112,
      "backward_entropy": 0.006094471684523991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.18476676940918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040077365934848785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08708785474300385,
      "backward_entropy": 0.0060949330883366725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.179784774780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040119074285030365,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08704943209886551,
      "backward_entropy": 0.019250852721078054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.047845840454102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04016340896487236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08700613677501678,
      "backward_entropy": 0.006091281771659851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.999238967895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040206123143434525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08696556091308594,
      "backward_entropy": 0.006089884255613599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.966913223266602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04024868831038475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08692473918199539,
      "backward_entropy": 0.006088642669575555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.73543930053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04028988629579544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08688561618328094,
      "backward_entropy": 0.019103514296667918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.960901737213135,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04033516347408295,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08683937788009644,
      "backward_entropy": 0.09871288708278111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.671701431274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04037732630968094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08679808676242828,
      "backward_entropy": 0.006088688969612122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.812420845031738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040420811623334885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0867542251944542,
      "backward_entropy": 0.006089261599949428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.254966735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040462709963321686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08671273291110992,
      "backward_entropy": 0.006090242947850909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.582404136657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04050873965024948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0866636335849762,
      "backward_entropy": 0.006091500499418804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.834388732910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040554266422986984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0866151824593544,
      "backward_entropy": 0.006092690995761326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.055856704711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040604833513498306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08655727654695511,
      "backward_entropy": 0.006093396672180721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.721139907836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04065737873315811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08649536967277527,
      "backward_entropy": 0.006095387041568756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.06035614013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04071293771266937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0864284336566925,
      "backward_entropy": 0.006097455642053059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.683778762817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040768347680568695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08636105060577393,
      "backward_entropy": 0.0187745669058391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.147758483886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040825214236974716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0862903892993927,
      "backward_entropy": 0.006101582731519427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.756103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040880534797906876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08622203022241592,
      "backward_entropy": 0.006104776369673865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.61765670776367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0409356988966465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0861537903547287,
      "backward_entropy": 0.00610727710383279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.43446731567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040994882583618164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08607780933380127,
      "backward_entropy": 0.0061097533575126105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.435209274291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04105750098824501,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08599548786878586,
      "backward_entropy": 0.006110891167606626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.03724670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04111919552087784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08591456711292267,
      "backward_entropy": 0.006111481360026768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.575417518615723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04118410497903824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08582739531993866,
      "backward_entropy": 0.006111583007233483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.063589096069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04124392569065094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08574899286031723,
      "backward_entropy": 0.006112690482820783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.486738204956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04130050167441368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08567650616168976,
      "backward_entropy": 0.006114572818790164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.42491626739502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04135795682668686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08560198545455933,
      "backward_entropy": 0.006115183234214783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.916908264160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04141369089484215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08553048968315125,
      "backward_entropy": 0.006115971399205071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.52397918701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04146632179617882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0854654610157013,
      "backward_entropy": 0.018380927188055857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.591615676879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04152151197195053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08539445698261261,
      "backward_entropy": 0.018338861210005625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.856151580810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04157647117972374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08532372862100601,
      "backward_entropy": 0.018297033650534495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.392335891723633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04163249209523201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08525048196315765,
      "backward_entropy": 0.006110465420143945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.661913871765137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04168805480003357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.085177943110466,
      "backward_entropy": 0.006107710834060397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.902363777160645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04174068197607994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08511072397232056,
      "backward_entropy": 0.01816545213971819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.571084976196289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04179197922348976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08504568040370941,
      "backward_entropy": 0.006103719451597759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.277255058288574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04184059053659439,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08498597145080566,
      "backward_entropy": 0.006101004779338837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.478618621826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04188571870326996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08493275940418243,
      "backward_entropy": 0.018032563584191457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.441901206970215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04192902520298958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0848827138543129,
      "backward_entropy": 0.006099740309374673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.40269947052002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04197056218981743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0848357081413269,
      "backward_entropy": 0.0060997360519000465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.69675064086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04201054573059082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08479204028844833,
      "backward_entropy": 0.0061000606843403405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.618257522583008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04205169901251793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08474542200565338,
      "backward_entropy": 0.006099997886589595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.285401344299316,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04209402948617935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0846957117319107,
      "backward_entropy": 0.006100825433220182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.360651016235352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04213489219546318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08464837074279785,
      "backward_entropy": 0.006103450698511941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.570648193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042175520211458206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08460129052400589,
      "backward_entropy": 0.006105759314128331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.379743576049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042219944298267365,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08454563468694687,
      "backward_entropy": 0.017733242894921983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.180331230163574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04226648434996605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08448489010334015,
      "backward_entropy": 0.01770261994429997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.200199127197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04231220483779907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08442586660385132,
      "backward_entropy": 0.0061143987945147926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.041111469268799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04236100614070892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08435985445976257,
      "backward_entropy": 0.006116139569452831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.001995086669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04240616783499718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08430156111717224,
      "backward_entropy": 0.017602997166769847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.931357383728027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0424494706094265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08424697816371918,
      "backward_entropy": 0.006120606192520687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03249697387218475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04249216616153717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08419343084096909,
      "backward_entropy": 0.006122292152472905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.742839813232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04253070801496506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08414851129055023,
      "backward_entropy": 0.00612568376319749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.848989009857178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04257059469819069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08410010486841202,
      "backward_entropy": 0.006129636296204158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.389530181884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04260925576090813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08405366539955139,
      "backward_entropy": 0.01744976852621351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.52541732788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04265149310231209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08399918675422668,
      "backward_entropy": 0.00613875687122345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.739320755004883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04269455745816231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08394324779510498,
      "backward_entropy": 0.006141481654984611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.36688232421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04273589700460434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08389046788215637,
      "backward_entropy": 0.006144761507000242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0300460085272789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04277834668755531,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08383440971374512,
      "backward_entropy": 0.006149306361164365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.828949451446533,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04281675070524216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08378690481185913,
      "backward_entropy": 0.006155923541103091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.72100067138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04285269230604172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08374461531639099,
      "backward_entropy": 0.006163513553994042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.562023639678955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042892612516880035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0836929976940155,
      "backward_entropy": 0.0061701083821909765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.016804695129395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042930968105793,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08364492654800415,
      "backward_entropy": 0.017239320491041456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.67268943786621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04297051578760147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08359380066394806,
      "backward_entropy": 0.006180747279099056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7415645122528076,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04301238805055618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0835370123386383,
      "backward_entropy": 0.006185170795236315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.800596237182617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043051350861787796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08348673582077026,
      "backward_entropy": 0.01715987069266183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.0538911819458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0430912971496582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08343417942523956,
      "backward_entropy": 0.006193103534834725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.651467323303223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04313090443611145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08338224142789841,
      "backward_entropy": 0.006195380219391414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.937320709228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043171580880880356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08332732319831848,
      "backward_entropy": 0.0061977771776063105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.12371063232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043212126940488815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08327202498912811,
      "backward_entropy": 0.01703788765839168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.230759620666504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043254751712083817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08321166783571243,
      "backward_entropy": 0.006204625857727868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.351886749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043295543640851974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08315540850162506,
      "backward_entropy": 0.0062070733734539574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.275761604309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04333720728754997,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08309689164161682,
      "backward_entropy": 0.01694441799606596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.200013160705566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04337964951992035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08303612470626831,
      "backward_entropy": 0.0062110839145524165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.073670387268066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043422698974609375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08297371864318848,
      "backward_entropy": 0.0062120333313941956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.541324615478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04346402734518051,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08291491121053696,
      "backward_entropy": 0.016846763236182078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.935840606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04350490868091583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08285681903362274,
      "backward_entropy": 0.016814383012907847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.889781951904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043549150228500366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08279010653495789,
      "backward_entropy": 0.006219340222222465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.249393463134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04359382390975952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08272179961204529,
      "backward_entropy": 0.006221342299665723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029739907011389732,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04364022612571716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08264901489019394,
      "backward_entropy": 0.0062236737992082325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03411079943180084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04368213936686516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08258698880672455,
      "backward_entropy": 0.006227902003696987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.572101593017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04371980205178261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08253537863492966,
      "backward_entropy": 0.006231922656297684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.87694549560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04375888779759407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08247900754213333,
      "backward_entropy": 0.016639446573598043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.733835697174072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04380016773939133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08241686224937439,
      "backward_entropy": 0.006244767989431109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.033550262451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043839726597070694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08235880732536316,
      "backward_entropy": 0.016592147094862803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.293621063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043878816068172455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08230197429656982,
      "backward_entropy": 0.006254861929586956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.625668525695801,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04391876980662346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08224282413721085,
      "backward_entropy": 0.006258226931095123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.8712739944458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04395716264843941,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08218720555305481,
      "backward_entropy": 0.01650373318365642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.55259895324707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04399530589580536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08213190734386444,
      "backward_entropy": 0.006265253892966679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2754480838775635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044032227247953415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08207884430885315,
      "backward_entropy": 0.006270435239587512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.182161331176758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04406675323843956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08203192055225372,
      "backward_entropy": 0.006276581968579974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.886210441589355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04410383477807045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08197788894176483,
      "backward_entropy": 0.016397849789687564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.816553115844727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044141966849565506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0819208174943924,
      "backward_entropy": 0.00628695370895522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.104345321655273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04418107867240906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08186082541942596,
      "backward_entropy": 0.01634485913174493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512007713317871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04422340169548988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08179222047328949,
      "backward_entropy": 0.006295249930449894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1683919429779053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04426499083638191,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08172538876533508,
      "backward_entropy": 0.006298203021287918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1518614292144775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044303786009550095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08166512846946716,
      "backward_entropy": 0.016261166759899685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35474967956543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044340018182992935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08161120116710663,
      "backward_entropy": 0.006309401243925095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.579221725463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04437609761953354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08155759423971176,
      "backward_entropy": 0.006314626229660851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.252870559692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04441557452082634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08149445801973343,
      "backward_entropy": 0.016185027148042406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.311558723449707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04445456340909004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08143287152051926,
      "backward_entropy": 0.016154535114765167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.25555992126465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04449545592069626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08136619627475739,
      "backward_entropy": 0.006322949060371944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.13605308532715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04453926160931587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0812910795211792,
      "backward_entropy": 0.006323971386466708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.020364761352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04458571597933769,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0812084972858429,
      "backward_entropy": 0.006324756890535355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.953553199768066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04463208094239235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08112610876560211,
      "backward_entropy": 0.016013483916010176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9887049198150635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044677525758743286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08104512095451355,
      "backward_entropy": 0.006326652531112943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.708942413330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04471951350569725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08097364008426666,
      "backward_entropy": 0.006328495485442025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.618046760559082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044763315469026566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08089578151702881,
      "backward_entropy": 0.006332212792975562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.51741886138916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044808439910411835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0808141827583313,
      "backward_entropy": 0.006334794419152396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.659071922302246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04485474154353142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08073000609874725,
      "backward_entropy": 0.00633642024227551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8869588375091553,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04489991441369057,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08064795285463333,
      "backward_entropy": 0.09888832909720284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54295539855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04494176805019379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08057473599910736,
      "backward_entropy": 0.006341931543179921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.672123908996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044982921332120895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08050306141376495,
      "backward_entropy": 0.01576449296304158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.24039077758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045022159814834595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08043667674064636,
      "backward_entropy": 0.006348639194454465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.168540000915527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045061949640512466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08036860078573227,
      "backward_entropy": 0.0063507892191410065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.330821990966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04510227218270302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08029872179031372,
      "backward_entropy": 0.006352580551590238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279794692993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04514192417263985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08023025095462799,
      "backward_entropy": 0.0063542819448879784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.958479881286621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04518088325858116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08016389608383179,
      "backward_entropy": 0.006354887038469315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.454734802246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04522034153342247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08009593188762665,
      "backward_entropy": 0.006354502801384244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.122136116027832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0452582873404026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08003148436546326,
      "backward_entropy": 0.006356380879878998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.106698989868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045295774936676025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07996811717748642,
      "backward_entropy": 0.015488637345177787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.343771934509277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045336417853832245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07989439368247986,
      "backward_entropy": 0.006361402039016996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.958742141723633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045378465205430984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07981669902801514,
      "backward_entropy": 0.006363262023244586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6589808464050293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04541979730129242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07974030077457428,
      "backward_entropy": 0.0063665636948176795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6373651027679443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045458029955625534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07967309653759003,
      "backward_entropy": 0.006369481661490032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.623552083969116,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04549368470907211,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07961300015449524,
      "backward_entropy": 0.006374101553644452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.188730239868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04552692919969559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.079559825360775,
      "backward_entropy": 0.015312341707093375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.723455429077148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04555901885032654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07950998842716217,
      "backward_entropy": 0.015284993818828039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.230878829956055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045591212809085846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07945949584245682,
      "backward_entropy": 0.015257585261549269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.564764976501465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04562459513545036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07940500974655151,
      "backward_entropy": 0.006393975445202419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.595159530639648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04565582051873207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07935629785060883,
      "backward_entropy": 0.015204699976103646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03016456961631775,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568725824356079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07930684834718704,
      "backward_entropy": 0.006405671792370933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.022170543670654,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045715585350990295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07926696538925171,
      "backward_entropy": 0.0064121527331216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.477715492248535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04574326053261757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07922860980033875,
      "backward_entropy": 0.006418516061135701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.443657875061035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045771606266498566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07918739318847656,
      "backward_entropy": 0.006426241248846054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.327920913696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04580041766166687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07914425432682037,
      "backward_entropy": 0.015089407563209534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.259859085083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045831650495529175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07909364253282547,
      "backward_entropy": 0.01506465460572924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.319361209869385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045865051448345184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07903632521629333,
      "backward_entropy": 0.006443416433674949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.693790435791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04589848220348358,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0789782702922821,
      "backward_entropy": 0.015010592128549303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.238502502441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04593292623758316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0789165198802948,
      "backward_entropy": 0.006453303886311395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.184946537017822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04596693813800812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0788564532995224,
      "backward_entropy": 0.006455929151603154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.775854587554932,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04600093513727188,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07879548519849777,
      "backward_entropy": 0.09890206371034894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3889732360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04603353887796402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07873935997486115,
      "backward_entropy": 0.0064630817089762005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.406947135925293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0460638552904129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07869045436382294,
      "backward_entropy": 0.006465337106159755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3597333431243896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046095363795757294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07863723486661911,
      "backward_entropy": 0.014834788228784288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.341996908187866,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04612477123737335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07859069108963013,
      "backward_entropy": 0.006469130516052246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.639142990112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046152498573064804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07854883372783661,
      "backward_entropy": 0.0064736636621611455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.79561996459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04617960751056671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0785086452960968,
      "backward_entropy": 0.006478601800543922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.590698719024658,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04621019586920738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07845716178417206,
      "backward_entropy": 0.006481219615255084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.101126670837402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046239789575338364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07840882241725922,
      "backward_entropy": 0.006483526634318488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.533341407775879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04627055674791336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07835641503334045,
      "backward_entropy": 0.006484936390604291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.234062194824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04630051553249359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07830584794282913,
      "backward_entropy": 0.006488210920776639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.166152954101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04633277282118797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07824742794036865,
      "backward_entropy": 0.0064915258969579425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.666931629180908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04636700823903084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07818219065666199,
      "backward_entropy": 0.006494129342692239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.22343373298645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04640091583132744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0781179741024971,
      "backward_entropy": 0.006496264466217586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.136032104492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04643259197473526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07806051522493362,
      "backward_entropy": 0.006499982305935451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.22042179107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046467266976833344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07799303531646729,
      "backward_entropy": 0.006502387779099601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.949159622192383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04650545492768288,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07791446894407272,
      "backward_entropy": 0.014454627675669534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.162869930267334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04654587060213089,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07782863080501556,
      "backward_entropy": 0.014416703156062536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.144167423248291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04658332094550133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07775232195854187,
      "backward_entropy": 0.006497557141951152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.654057502746582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04661822319030762,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07768374681472778,
      "backward_entropy": 0.014350286551884242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38222599029541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0466558001935482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07760529220104218,
      "backward_entropy": 0.014320453362805503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.171847343444824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04669367894530296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07752595096826553,
      "backward_entropy": 0.01429003051349095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.13848876953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04672985523939133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07745212316513062,
      "backward_entropy": 0.006502858230045864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.155445575714111,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04676462337374687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0773824006319046,
      "backward_entropy": 0.006506741046905518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.113790035247803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04679891839623451,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.077314093708992,
      "backward_entropy": 0.014210599873747145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0813570022583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046832695603370667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07724753022193909,
      "backward_entropy": 0.014182234449045998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023522503674030304,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04686713591217995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07717833667993546,
      "backward_entropy": 0.006514864308493478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9980287551879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04689837992191315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07711932063102722,
      "backward_entropy": 0.014132469892501831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.92406702041626,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046928588300943375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07706338167190552,
      "backward_entropy": 0.0065267373408590046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.788220405578613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046959612518548965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07700486481189728,
      "backward_entropy": 0.006530942661421639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.867711544036865,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04699353128671646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0769355520606041,
      "backward_entropy": 0.014062900628362383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8229146003723145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04702695831656456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07686838507652283,
      "backward_entropy": 0.006537639136825289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.61987590789795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04706006124615669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07680219411849976,
      "backward_entropy": 0.006540949323347637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.546436309814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04709472507238388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07673012465238571,
      "backward_entropy": 0.006543127021619252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.803515911102295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04713081941008568,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07665269076824188,
      "backward_entropy": 0.013953653829438346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.273008346557617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04716535285115242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07658033072948456,
      "backward_entropy": 0.006547628768852779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7441585063934326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04720228537917137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07649914920330048,
      "backward_entropy": 0.006549825093575886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.874005675315857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04723756015300751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07642341405153275,
      "backward_entropy": 0.006553217768669128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8585875034332275,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04727022722363472,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07635703682899475,
      "backward_entropy": 0.09890110152108329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.301319599151611,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04730062931776047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07629850506782532,
      "backward_entropy": 0.006560044629233224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.441046714782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04733182489871979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07623696327209473,
      "backward_entropy": 0.006563212190355573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.407557487487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04736292362213135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0761750340461731,
      "backward_entropy": 0.006567773010049548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.365689277648926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047393713146448135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07611428201198578,
      "backward_entropy": 0.006571211452995028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.636646270751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04742438718676567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07605297118425369,
      "backward_entropy": 0.013724897589002336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7852897644042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0474574901163578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07598376274108887,
      "backward_entropy": 0.006576865379299436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5055716037750244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04748809337615967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07592429220676422,
      "backward_entropy": 0.0065769585115568975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4850854873657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047517746686935425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07586692273616791,
      "backward_entropy": 0.0065797365137508935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.89734411239624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04754636809229851,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07581298798322678,
      "backward_entropy": 0.013610007507460458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4365711212158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047575876116752625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0757555365562439,
      "backward_entropy": 0.006586029061249324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.105653762817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04760439693927765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07570134103298187,
      "backward_entropy": 0.013559060437338693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3930091857910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04763301834464073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07564598321914673,
      "backward_entropy": 0.006595303437539509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6990883350372314,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047660600394010544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07559452950954437,
      "backward_entropy": 0.006600127688476017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.669145584106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047686342149972916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0755498856306076,
      "backward_entropy": 0.006604991321052823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3230831623077393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04771324619650841,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07550059258937836,
      "backward_entropy": 0.006609659641981125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.942714691162109,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047739483416080475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07545292377471924,
      "backward_entropy": 0.013448593871934074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.913816928863525,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04776596277952194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07540369033813477,
      "backward_entropy": 0.0066228945340429035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.118158340454102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047792524099349976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07535453140735626,
      "backward_entropy": 0.006628765059368951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2363688945770264,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04782097041606903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07529817521572113,
      "backward_entropy": 0.006633061383451734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.815486431121826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04784856736660004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07524409890174866,
      "backward_entropy": 0.006639072937624795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.775446891784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04787606745958328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07519052922725677,
      "backward_entropy": 0.0066437966057232446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.469260215759277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047903768718242645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07513520866632462,
      "backward_entropy": 0.013326242566108704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5857855081558228,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04793411120772362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07506975531578064,
      "backward_entropy": 0.006655465811491013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1275973320007324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04796242341399193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07501165568828583,
      "backward_entropy": 0.006661581141608102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.72249698638916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04798969626426697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07495751976966858,
      "backward_entropy": 0.013266259006091527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.139358043670654,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048018813133239746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07489539682865143,
      "backward_entropy": 0.006672653236559459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5456386804580688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048048581928014755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07483107596635818,
      "backward_entropy": 0.013224379292556218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0364410877227783,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048076145350933075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07477614283561707,
      "backward_entropy": 0.006680025053875787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0052924156188965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04810275882482529,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07472416758537292,
      "backward_entropy": 0.013174836124692644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.410390853881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048130281269550323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0746682807803154,
      "backward_entropy": 0.006686072796583176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9690616130828857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04816140606999397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07459768652915955,
      "backward_entropy": 0.00668938724058015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9467504024505615,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04819120839238167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07453201711177826,
      "backward_entropy": 0.006692904446806226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722311019897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048219770193099976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07447119057178497,
      "backward_entropy": 0.006696079990693501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.769402980804443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04825061932206154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07440166920423508,
      "backward_entropy": 0.0066969139235360286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4505256414413452,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04828202724456787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07432909309864044,
      "backward_entropy": 0.006698977202177048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.678016185760498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04831117019057274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07426547259092331,
      "backward_entropy": 0.006701444408723286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025523530319333076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04834089055657387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07419893145561218,
      "backward_entropy": 0.012976378202438354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8045711517333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04836766794323921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07414433360099792,
      "backward_entropy": 0.006706619901316506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.312455177307129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04839364439249039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0740923136472702,
      "backward_entropy": 0.006711305252143315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.770082712173462,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0484221912920475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07402963936328888,
      "backward_entropy": 0.012908956834248133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.463839530944824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048449449241161346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07397270202636719,
      "backward_entropy": 0.006716831986393247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.074487686157227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0484774149954319,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.073912613093853,
      "backward_entropy": 0.006718405655452183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.71537446975708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04850505292415619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0738539844751358,
      "backward_entropy": 0.012828156352043152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6779897212982178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04853421077132225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07378893345594406,
      "backward_entropy": 0.006719178919281278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.337705135345459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04856221377849579,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0737280398607254,
      "backward_entropy": 0.012773397777761732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16763687133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04858843609690666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07367343455553055,
      "backward_entropy": 0.01275133980172021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6086578369140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048617955297231674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07360517233610153,
      "backward_entropy": 0.006727298987763268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5969293117523193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048646479845047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0735396072268486,
      "backward_entropy": 0.012710727751255035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8475444316864014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04867371544241905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07348039001226425,
      "backward_entropy": 0.006737500961337771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.289576768875122,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0487007200717926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0734221413731575,
      "backward_entropy": 0.006741274680410113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.039041042327881,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04872585088014603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07337121665477753,
      "backward_entropy": 0.006745138338633946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.005549907684326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04875192046165466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07331568002700806,
      "backward_entropy": 0.006750008357422692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.96550178527832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048778604716062546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07325777411460876,
      "backward_entropy": 0.0067533089646271294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.369817733764648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0488058365881443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07319788634777069,
      "backward_entropy": 0.006755184382200241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8781561851501465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04883531108498573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07312823832035065,
      "backward_entropy": 0.006756776145526341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8346991539001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04886511713266373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07305702567100525,
      "backward_entropy": 0.006758141730512891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7920379638671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04889516532421112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07298478484153748,
      "backward_entropy": 0.012501087571893419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.74244499206543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048925332725048065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07291238009929657,
      "backward_entropy": 0.006757921406200954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5294957160949707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0489557683467865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07283847033977509,
      "backward_entropy": 0.0067576127392905095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4974184036254883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048985615372657776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07276659458875656,
      "backward_entropy": 0.006757888410772596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.318159580230713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049014873802661896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07269719243049622,
      "backward_entropy": 0.00675820665700095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2975549697875977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049042824655771255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0726330429315567,
      "backward_entropy": 0.012362017163208552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.153416633605957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049069590866565704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07257354259490967,
      "backward_entropy": 0.006760252373559135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.376028299331665,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04909442737698555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07252272963523865,
      "backward_entropy": 0.006761347076722554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3434300422668457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049119189381599426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0724717378616333,
      "backward_entropy": 0.00676284943308149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3282811641693115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04914409667253494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07241880893707275,
      "backward_entropy": 0.012263012783867972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2054319381713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04916864633560181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07236844301223755,
      "backward_entropy": 0.0067688460860933575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1881678104400635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919232428073883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07232140004634857,
      "backward_entropy": 0.00677085667848587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.173621416091919,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04921521246433258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07227776199579239,
      "backward_entropy": 0.006773296211447034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1553969383239746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923729971051216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07223763316869736,
      "backward_entropy": 0.006775139165776116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1967811584472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049258749932050705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07220003008842468,
      "backward_entropy": 0.006777348795107433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1733105182647705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928041622042656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07216109335422516,
      "backward_entropy": 0.006779974060399192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1083054542541504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04930226877331734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07212095707654953,
      "backward_entropy": 0.006782975580011096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0591436624526978,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04932349547743797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07208332419395447,
      "backward_entropy": 0.006786331002201352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.188959121704102,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04934336617588997,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0720515251159668,
      "backward_entropy": 0.09889641829899379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0427509546279907,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049365803599357605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07200836390256882,
      "backward_entropy": 0.006792537868022919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.082705974578857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04938680678606033,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07197117805480957,
      "backward_entropy": 0.011997924319335393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.040416240692139,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049409545958042145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07192603498697281,
      "backward_entropy": 0.006798990070819855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.018009901046753,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04943392053246498,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07187294960021973,
      "backward_entropy": 0.011954606643744878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0043437480926514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04945721849799156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07182516157627106,
      "backward_entropy": 0.006804933505398887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.96120548248291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049479417502880096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07178321480751038,
      "backward_entropy": 0.006803900535617556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9930545091629028,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04950165003538132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07174079120159149,
      "backward_entropy": 0.00680325659258025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9855706691741943,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04952250048518181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0717039406299591,
      "backward_entropy": 0.006804382694619042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.807714939117432,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049542106688022614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0716719850897789,
      "backward_entropy": 0.006807202739374978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9192254543304443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04956350848078728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07163164019584656,
      "backward_entropy": 0.006810204258986882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.849307060241699,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04958440735936165,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07159243524074554,
      "backward_entropy": 0.09889183725629534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8954039812088013,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04960548132658005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07155243307352066,
      "backward_entropy": 0.0068199677126748225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7339603900909424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04962582141160965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.071516253054142,
      "backward_entropy": 0.006823549313204629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7859370708465576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04964713007211685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0714750736951828,
      "backward_entropy": 0.006827472043888909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9323900938034058,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04966846853494644,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07143367826938629,
      "backward_entropy": 0.09889187983104161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7414236068725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968857765197754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07139703631401062,
      "backward_entropy": 0.006836148244994027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021646492183208466,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04970889911055565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07135903835296631,
      "backward_entropy": 0.011663177183696203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.384243488311768,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049727216362953186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07132989913225174,
      "backward_entropy": 0.006847840866872242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.458373069763184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497480146586895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0712895616889,
      "backward_entropy": 0.0068524352141789025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.658848762512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04977016896009445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07124358415603638,
      "backward_entropy": 0.006854239851236343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8905102610588074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04979226365685463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07119768857955933,
      "backward_entropy": 0.00685602320092065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7466951608657837,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04981299117207527,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07115727663040161,
      "backward_entropy": 0.011560659323419844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8765277862548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0498332604765892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07111790776252747,
      "backward_entropy": 0.006865668509687696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8718083500862122,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049852337688207626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07108328491449356,
      "backward_entropy": 0.006873014249971935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8666173815727234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04987025633454323,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07105399668216705,
      "backward_entropy": 0.011516458221844264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.377474784851074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988708347082138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0710296481847763,
      "backward_entropy": 0.006887522659131459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.685124158859253,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04990522190928459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07099825143814087,
      "backward_entropy": 0.006895906691040311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8489015698432922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0499231219291687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07096715271472931,
      "backward_entropy": 0.011480818901743208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8423985838890076,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049939919263124466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07094110548496246,
      "backward_entropy": 0.00691507597054754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.292579174041748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04995575547218323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07091934233903885,
      "backward_entropy": 0.006924135876553399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6435010433197021,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04997275397181511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07089230418205261,
      "backward_entropy": 0.006931618920394352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6343564987182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0499894805252552,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07086611539125443,
      "backward_entropy": 0.006939001381397247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8300347328186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050005875527858734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07084158062934875,
      "backward_entropy": 0.0069452619978359765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.205261707305908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05002477392554283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07080520689487457,
      "backward_entropy": 0.006950193750006812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017809633165597916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05004437640309334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0707661360502243,
      "backward_entropy": 0.00695255132658141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.152491331100464,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05006204918026924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0707356408238411,
      "backward_entropy": 0.006955782217638833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5714364051818848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050080690532922745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07070037722587585,
      "backward_entropy": 0.0069583888564791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.330540418624878,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050098903477191925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07066649198532104,
      "backward_entropy": 0.006961822509765625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3142752647399902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05011742562055588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07063055038452148,
      "backward_entropy": 0.006965972483158112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.051560878753662,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05013614520430565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07059337198734283,
      "backward_entropy": 0.006969745670046125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5225812196731567,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0501558855175972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07054997980594635,
      "backward_entropy": 0.006975139890398298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.256924629211426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05017506703734398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0705089271068573,
      "backward_entropy": 0.006980944957051959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2393651008605957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050194431096315384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07046666741371155,
      "backward_entropy": 0.006987094879150391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7549384236335754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05021391063928604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0704236701130867,
      "backward_entropy": 0.00699307130915778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.205397844314575,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050231993198394775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07038841396570206,
      "backward_entropy": 0.006997370294162205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1879498958587646,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050250228494405746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07035185396671295,
      "backward_entropy": 0.0070006586611270905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4515612125396729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050268590450286865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07031463086605072,
      "backward_entropy": 0.011181641902242388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5742039680480957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05028645694255829,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07027944922447205,
      "backward_entropy": 0.0070055196327822545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7208238244056702,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050305914133787155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07023617625236511,
      "backward_entropy": 0.007008300295897892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.816248893737793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05032415688037872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0701981857419014,
      "backward_entropy": 0.00701213681272098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.490399122238159,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050343211740255356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07015600800514221,
      "backward_entropy": 0.007015645503997803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3933608531951904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05036347359418869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07010884582996368,
      "backward_entropy": 0.007016572036913463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3801383972167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05038295313715935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07006549835205078,
      "backward_entropy": 0.007016864738294056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3971364498138428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05040175840258598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07002520561218262,
      "backward_entropy": 0.011049142905644007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3590400218963623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05042180046439171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06997931003570557,
      "backward_entropy": 0.011024825274944305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.331636428833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0504409596323967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06993842124938965,
      "backward_entropy": 0.0070121240402971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3287804126739502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05046145245432854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.069890595972538,
      "backward_entropy": 0.007009277918509075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01856914907693863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05048124119639397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06984555721282959,
      "backward_entropy": 0.007007783012730735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6606590747833252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05049896612763405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06981059163808823,
      "backward_entropy": 0.007006084280354636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.218170642852783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05051560327410698,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06978043913841248,
      "backward_entropy": 0.010900206863880157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.551544666290283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05053364112973213,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06974390149116516,
      "backward_entropy": 0.01087530595915658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2720524072647095,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05055250599980354,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0697026401758194,
      "backward_entropy": 0.09889239924294609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.886411190032959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05057081580162048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06966359168291092,
      "backward_entropy": 0.0070037756647382465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2503825426101685,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05058911815285683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06962460279464722,
      "backward_entropy": 0.00700375171644347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6286584138870239,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050606876611709595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06958799064159393,
      "backward_entropy": 0.010790708873953139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8346565961837769,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050623469054698944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06955716758966446,
      "backward_entropy": 0.007005411599363599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.423166036605835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05064039304852486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06952369213104248,
      "backward_entropy": 0.01075318775006703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2107770442962646,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05065813660621643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06948620826005936,
      "backward_entropy": 0.007011143224579948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7881687879562378,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05067526549100876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06945183873176575,
      "backward_entropy": 0.007013231515884399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6005101799964905,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05069265514612198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06941556930541992,
      "backward_entropy": 0.007016890815326146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01642078533768654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050709016621112823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06938380002975464,
      "backward_entropy": 0.010689422488212585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.324558734893799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05072370916604996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06936042010784149,
      "backward_entropy": 0.007026474390711103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7344117164611816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05073939636349678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06933186203241348,
      "backward_entropy": 0.007031033613852092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8583500385284424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05075531080365181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06930221617221832,
      "backward_entropy": 0.007034890353679657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2674052715301514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05077255517244339,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06926637142896652,
      "backward_entropy": 0.007036929151841572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2436532974243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050790514796972275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06922668218612671,
      "backward_entropy": 0.010610372892447881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1238133907318115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05080925300717354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0691821426153183,
      "backward_entropy": 0.007043371775320598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.655570387840271,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05082713067531586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06914262473583221,
      "backward_entropy": 0.0070452141974653515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5590183734893799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05084509029984474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06910192966461182,
      "backward_entropy": 0.007048076816967556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0905344486236572,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05086175724864006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06906844675540924,
      "backward_entropy": 0.007049817059721265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.148146867752075,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050877898931503296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06903748214244843,
      "backward_entropy": 0.010525592735835485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1253561973571777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05089466646313667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06900367885828018,
      "backward_entropy": 0.007050688777651105,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.2030323777347802,
    "avg_log_Z": -0.04997882079333067,
    "success_rate": 1.0,
    "avg_reward": 72.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.18,
      "2": 0.78
    },
    "avg_forward_entropy": 0.07083427637815476,
    "avg_backward_entropy": 0.011378024992133891,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}