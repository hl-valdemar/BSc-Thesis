{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1386080265045166,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1386080265045166,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1386080265045166,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1386080265045166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1386080265045166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1386080265045166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1386080265045166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.1383615493774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.2880859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278042475382486,
      "backward_entropy": 0.13862351179122925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.7931365966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277879556020102,
      "backward_entropy": 0.13835883140563965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.36354064941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00020002591190859675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827768087387085,
      "backward_entropy": 0.13835568428039552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.18724060058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0002994484384544194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277456363042197,
      "backward_entropy": 0.13860797882080078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.30223083496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003991658450104296,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277219931284586,
      "backward_entropy": 0.1386258840560913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.34326171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000498477544169873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276941776275635,
      "backward_entropy": 0.13860704898834228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.3143310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000596556521486491,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827666163444519,
      "backward_entropy": 0.13833444118499755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.74867248535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006938098231330514,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276365598042807,
      "backward_entropy": 0.1386263847351074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.9408416748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007915051537565887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276039759318033,
      "backward_entropy": 0.13831979036331177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.54873657226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008906060247682035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275678157806396,
      "backward_entropy": 0.13860275745391845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.73831176757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009865324245765805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275312582651773,
      "backward_entropy": 0.13860135078430175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.70962524414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010820820461958647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274901310602823,
      "backward_entropy": 0.13829505443572998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.4772491455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011773494770750403,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274460236231485,
      "backward_entropy": 0.13828575611114502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.9705810546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012702407548204064,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827401320139567,
      "backward_entropy": 0.13862619400024415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.99026489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013660474214702845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18273540337880453,
      "backward_entropy": 0.1385944366455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.0545654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001462382497265935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827304164568583,
      "backward_entropy": 0.13825690746307373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.10494995117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015581652987748384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18272529045740762,
      "backward_entropy": 0.13859062194824218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.8954620361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016536642797291279,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18271992603937784,
      "backward_entropy": 0.13862571716308594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.1407928466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017497920198366046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18271430333455405,
      "backward_entropy": 0.13822693824768068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.12294006347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018471624935045838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18270848194758096,
      "backward_entropy": 0.13862546682357788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.0960693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019428831292316318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827025612195333,
      "backward_entropy": 0.13858193159103394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.14810180664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002037176163867116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18269654115041098,
      "backward_entropy": 0.13819491863250732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.84927368164062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021320609375834465,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18269034226735434,
      "backward_entropy": 0.138624906539917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.62405395507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022266325540840626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826840043067932,
      "backward_entropy": 0.1385740876197815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.1951446533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00232187332585454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18267742792765299,
      "backward_entropy": 0.13857131004333495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.60377502441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002419350203126669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18267057339350382,
      "backward_entropy": 0.13814985752105713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.3133087158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0025099983904510736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266395727793375,
      "backward_entropy": 0.1381378412246704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.8266143798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002599455649033189,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18265734116236368,
      "backward_entropy": 0.1385621428489685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.67184448242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026879804208874702,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18265060583750406,
      "backward_entropy": 0.13811299800872803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.10214233398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027769713196903467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18264361222585043,
      "backward_entropy": 0.1385548949241638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.93980407714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002866294700652361,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826364000638326,
      "backward_entropy": 0.1380875825881958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.1507568359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029571373015642166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826288104057312,
      "backward_entropy": 0.1385474681854248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.20894622802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003050184575840831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18262086311976114,
      "backward_entropy": 0.1385439157485962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.8675765991211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00313982623629272,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261285622914633,
      "backward_entropy": 0.13862199783325196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.89181518554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032250401563942432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18260486920674643,
      "backward_entropy": 0.13803391456604003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.60923767089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033125279005616903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18259636561075845,
      "backward_entropy": 0.13853135108947753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.89382934570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033993450924754143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18258774280548096,
      "backward_entropy": 0.13852691650390625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.94168090820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003486823523417115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825789213180542,
      "backward_entropy": 0.13852241039276122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.6703338623047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035771143157035112,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182569682598114,
      "backward_entropy": 0.13862004280090331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.97222137451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036672602873295546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825604240099589,
      "backward_entropy": 0.13795857429504393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.7726287841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037540539633482695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18255122502644858,
      "backward_entropy": 0.1385086178779602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.5461654663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003841560101136565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825417478879293,
      "backward_entropy": 0.13792706727981568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.77091217041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0039243074133992195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825325091679891,
      "backward_entropy": 0.13791022300720215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.47164916992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004001379478722811,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18252360820770264,
      "backward_entropy": 0.1386170744895935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3628387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004079214762896299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18251434961954752,
      "backward_entropy": 0.13787367343902587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.88497161865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00415752362459898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825048327445984,
      "backward_entropy": 0.13847841024398805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.81853485107422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004231095779687166,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249539534250894,
      "backward_entropy": 0.13861429691314697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.1097412109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004303019028156996,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18248585859934488,
      "backward_entropy": 0.13861315250396727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.66998291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0043776375241577625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824758251508077,
      "backward_entropy": 0.13845651149749755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.1846160888672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004447322338819504,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18246620893478394,
      "backward_entropy": 0.13861091136932374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2042999267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004523405805230141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824554204940796,
      "backward_entropy": 0.1377525210380554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.71122741699219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0046002608723938465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244429429372153,
      "backward_entropy": 0.13773322105407715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.2349853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004675171338021755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824329694112142,
      "backward_entropy": 0.13771276473999022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.39523315429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004751283209770918,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824211279551188,
      "backward_entropy": 0.13860745429992677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9138946533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004829658195376396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240875005722046,
      "backward_entropy": 0.13841131925582886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.6126708984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0049074627459049225,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239607413609824,
      "backward_entropy": 0.13860594034194945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3893280029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004986108280718327,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238298098246256,
      "backward_entropy": 0.1376287341117859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.09909057617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005067070946097374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18236923217773438,
      "backward_entropy": 0.13760775327682495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.52931213378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005148700904101133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235504627227783,
      "backward_entropy": 0.13838284015655516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3297882080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005230822134763002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18234052260716757,
      "backward_entropy": 0.13756505250930787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.67945861816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0053121899254620075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18232574065526327,
      "backward_entropy": 0.1375425100326538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.40564727783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005392507649958134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18231109778086343,
      "backward_entropy": 0.13836090564727782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.97361755371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005470363423228264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18229657411575317,
      "backward_entropy": 0.13835251331329346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.41554260253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005543084815144539,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822824478149414,
      "backward_entropy": 0.1374685287475586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.4497528076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005611015018075705,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822687784830729,
      "backward_entropy": 0.13859903812408447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2574005126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0056812879629433155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18225435415903726,
      "backward_entropy": 0.13741289377212523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.8736114501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005753148812800646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822395920753479,
      "backward_entropy": 0.13738565444946288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.04658126831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005833514966070652,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822234789530436,
      "backward_entropy": 0.137361741065979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.8833465576172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005905579775571823,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822082201639811,
      "backward_entropy": 0.1385945439338684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0025177001953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005979685112833977,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821918487548828,
      "backward_entropy": 0.13859350681304933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.11000061035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006053694058209658,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18217545747756958,
      "backward_entropy": 0.1385924696922302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.54014587402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0061350055038928986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18215771516164145,
      "backward_entropy": 0.13725543022155762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9250946044922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006219687405973673,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18213927745819092,
      "backward_entropy": 0.13859202861785888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.09376525878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006303180009126663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18212072054545084,
      "backward_entropy": 0.13720667362213135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.0793914794922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006390210706740618,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18210124969482422,
      "backward_entropy": 0.13859212398529053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.1846160888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0064840978011488914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18208046754201254,
      "backward_entropy": 0.13716112375259398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.0262451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006578513886779547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18205906947453818,
      "backward_entropy": 0.1382346749305725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.24314880371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006676089949905872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18203675746917725,
      "backward_entropy": 0.13822940587997437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.4159393310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006770971696823835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18201444546381632,
      "backward_entropy": 0.13709696531295776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.5005645751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006864939350634813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1819918155670166,
      "backward_entropy": 0.13821654319763182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.58025360107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006959307473152876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18196876843770346,
      "backward_entropy": 0.13820960521697997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.69491577148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007050184067338705,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18194578091303507,
      "backward_entropy": 0.13859611749649048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2028045654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007140187546610832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18192269404729208,
      "backward_entropy": 0.1381932020187378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.54244995117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0072295512072741985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818994084993998,
      "backward_entropy": 0.13859599828720093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.57470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007321316748857498,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18187532822291055,
      "backward_entropy": 0.1381752610206604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.08363342285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007411141414195299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18185110886891684,
      "backward_entropy": 0.13693369626998902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.6785888671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007503718603402376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18182583649953207,
      "backward_entropy": 0.1369086265563965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.92962646484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007600033655762672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18179935216903687,
      "backward_entropy": 0.13814828395843506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.28106689453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007692793384194374,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817732254664103,
      "backward_entropy": 0.13859604597091674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.0855255126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0077819423750042915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18174733718236288,
      "backward_entropy": 0.13682804107666016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.09190368652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00787536520510912,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18172009785970053,
      "backward_entropy": 0.13859550952911376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.67591857910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007968323305249214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18169240156809488,
      "backward_entropy": 0.13676931858062744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.561279296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008063184097409248,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18166404962539673,
      "backward_entropy": 0.13673975467681884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.51869201660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008157567121088505,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816351612408956,
      "backward_entropy": 0.13670878410339354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.30728149414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008252494968473911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18160577615102133,
      "backward_entropy": 0.13667745590209962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.16130065917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008351847529411316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815751592318217,
      "backward_entropy": 0.13806010484695436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.65443420410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008447177708148956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1815446416536967,
      "backward_entropy": 0.13661561012268067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.2988739013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008540037088096142,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18151422341664633,
      "backward_entropy": 0.13658181428909302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.4520721435547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008632357232272625,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18148336807886759,
      "backward_entropy": 0.1385929822921753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.20803833007812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008726929314434528,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18145151933034262,
      "backward_entropy": 0.13859250545501708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.82102966308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008826485835015774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18141800165176392,
      "backward_entropy": 0.1364809036254883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.97512817382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008927344344556332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18138372898101807,
      "backward_entropy": 0.13644882440567016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.502685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009031039662659168,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18134820461273193,
      "backward_entropy": 0.13641724586486817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.06263732910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009138495661318302,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18131120999654135,
      "backward_entropy": 0.13638689517974853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.050071716308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009243817999958992,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18127411603927612,
      "backward_entropy": 0.13635427951812745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.19935607910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009338490664958954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18123888969421387,
      "backward_entropy": 0.13793039321899414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.76248168945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009427820332348347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18120439847310385,
      "backward_entropy": 0.13627288341522217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.1445541381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009515071287751198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18117006619771323,
      "backward_entropy": 0.13622899055480958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.29105377197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009597714059054852,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1811363697052002,
      "backward_entropy": 0.13618217706680297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.73739624023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009678094647824764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1811025341351827,
      "backward_entropy": 0.13785024881362914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.36669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009757610969245434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18106842041015625,
      "backward_entropy": 0.13782720565795897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.5061264038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009841825813055038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18103277683258057,
      "backward_entropy": 0.13603537082672118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.08103942871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009922920726239681,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18099759022394815,
      "backward_entropy": 0.13598581552505493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.13792419433594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009998979978263378,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18096295992533365,
      "backward_entropy": 0.13857684135437012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.71437072753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01007478404790163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18092779318491617,
      "backward_entropy": 0.13772945404052733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.45951843261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010153381153941154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1808912754058838,
      "backward_entropy": 0.13770405054092408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.51446533203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010229733772575855,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1808548370997111,
      "backward_entropy": 0.13856859207153321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.34697723388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010303029790520668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1808185577392578,
      "backward_entropy": 0.13764946460723876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.08641052246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010371621698141098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18078307310740152,
      "backward_entropy": 0.1376190423965454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.46969604492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010443978942930698,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1807460387547811,
      "backward_entropy": 0.13558743000030518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.54847717285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01051667146384716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18070924282073975,
      "backward_entropy": 0.1375613808631897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.3953857421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01059694029390812,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18066972494125366,
      "backward_entropy": 0.13855302333831787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.85569763183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010680886916816235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18062863747278848,
      "backward_entropy": 0.13751039505004883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.82288360595703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010762525722384453,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18058747053146362,
      "backward_entropy": 0.1385498046875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.63914489746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0108420979231596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18054604530334473,
      "backward_entropy": 0.13531075716018676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.22825622558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010916211642324924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1805057922999064,
      "backward_entropy": 0.13524975776672363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.727294921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010985856875777245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18046621481577554,
      "backward_entropy": 0.13518441915512086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.10343933105469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011062098667025566,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18042393525441489,
      "backward_entropy": 0.13853858709335326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.60934448242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011133361607789993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18038272857666016,
      "backward_entropy": 0.1373225450515747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.11143493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011204974725842476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18034076690673828,
      "backward_entropy": 0.13728773593902588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.55026245117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011283152736723423,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18029596408208212,
      "backward_entropy": 0.13853132724761963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.37954711914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011362601071596146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18025004863739014,
      "backward_entropy": 0.13722476959228516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.48348999023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011445795185863972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18020214637120566,
      "backward_entropy": 0.13719449043273926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.418212890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011534439399838448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1801496942838033,
      "backward_entropy": 0.13853089809417723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.21878051757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011624847538769245,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1800952355066935,
      "backward_entropy": 0.1385321021080017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.14720153808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011714687570929527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1800400416056315,
      "backward_entropy": 0.13711581230163575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011808701790869236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799823840459188,
      "backward_entropy": 0.1345893144607544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.7900390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01190531812608242,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17992266019185385,
      "backward_entropy": 0.13706595897674562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.52818298339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012004806660115719,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17986053228378296,
      "backward_entropy": 0.13853926658630372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.05050659179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012104480527341366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17979745070139566,
      "backward_entropy": 0.13701956272125243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.4818115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012206274084746838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17973224322001138,
      "backward_entropy": 0.1343842029571533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.85122680664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012308284640312195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1796659231185913,
      "backward_entropy": 0.1369716167449951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.75699615478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012408503331243992,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17959946393966675,
      "backward_entropy": 0.13694343566894532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.2056884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01250363141298294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17953387896219888,
      "backward_entropy": 0.13420969247817993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.19834899902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012597533874213696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17946807543436685,
      "backward_entropy": 0.13687613010406494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.7789306640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012685181573033333,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17940547068913779,
      "backward_entropy": 0.13406617641448976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.3994598388672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012773111462593079,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17934173345565796,
      "backward_entropy": 0.1385465145111084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.42182159423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012860141694545746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17927726109822592,
      "backward_entropy": 0.13675169944763182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.30393981933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012942802160978317,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1792138417561849,
      "backward_entropy": 0.1385424852371216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.56851196289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013025117106735706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791494091351827,
      "backward_entropy": 0.13665647506713868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.1859893798828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013108300976455212,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17908360560735068,
      "backward_entropy": 0.13853728771209717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.12806701660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013196717947721481,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17901472250620523,
      "backward_entropy": 0.13656201362609863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.06382751464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013280024752020836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17894810438156128,
      "backward_entropy": 0.13346928358078003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.29418182373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013360695913434029,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1788814663887024,
      "backward_entropy": 0.13337613344192506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.2289581298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013435968197882175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17881651719411215,
      "backward_entropy": 0.1332765817642212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.11615753173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01351256389170885,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17874932289123535,
      "backward_entropy": 0.13852092027664184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.72956085205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013585853390395641,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17868141333262125,
      "backward_entropy": 0.13307371139526367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.06907653808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013654636219143867,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17861342430114746,
      "backward_entropy": 0.13851040601730347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.5211181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013725445605814457,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17854328950246176,
      "backward_entropy": 0.13285458087921143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.1645965576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013789044693112373,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17847557862599692,
      "backward_entropy": 0.13273658752441406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.92826080322266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013853865675628185,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1784056822458903,
      "backward_entropy": 0.13849135637283325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.45002365112305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013918901793658733,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17833391825358072,
      "backward_entropy": 0.132497239112854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.090576171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013977291993796825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17826481660207114,
      "backward_entropy": 0.13236839771270753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.3562469482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014037784188985825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17819311221440634,
      "backward_entropy": 0.13575707674026488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.45762634277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01410170178860426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1781182885169983,
      "backward_entropy": 0.13211318254470825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.24850463867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014167032204568386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17804094155629477,
      "backward_entropy": 0.13560545444488525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.782958984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014237859286367893,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17795958121617636,
      "backward_entropy": 0.1355327844619751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.40227508544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01431406568735838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17787383000055948,
      "backward_entropy": 0.1317565321922302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.24282836914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014388460665941238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17778817812601724,
      "backward_entropy": 0.13163750171661376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.55646514892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01446323748677969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1777010758717855,
      "backward_entropy": 0.13151631355285645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.5972442626953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01453497912734747,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17761480808258057,
      "backward_entropy": 0.13843984603881837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.8849639892578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014607236720621586,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17752859989802042,
      "backward_entropy": 0.1384357690811157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.68596649169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014684644527733326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1774353782335917,
      "backward_entropy": 0.1311387300491333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.00735473632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014760317280888557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17734299103418985,
      "backward_entropy": 0.13101794719696044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.01127624511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014839466661214828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17724724610646567,
      "backward_entropy": 0.13493443727493287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.35101318359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014913288876414299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1771542231241862,
      "backward_entropy": 0.13485300540924072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.48837280273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014984527602791786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1770616372426351,
      "backward_entropy": 0.134767484664917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.9583969116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015057911165058613,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17696630954742432,
      "backward_entropy": 0.1346818447113037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.62474822998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015126875601708889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17687296867370605,
      "backward_entropy": 0.1345891237258911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2970428466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01518994476646185,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17678304513295492,
      "backward_entropy": 0.13021961450576783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.08460998535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015256030485033989,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17668960491816202,
      "backward_entropy": 0.13006973266601562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.21642303466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015323620289564133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17659356196721396,
      "backward_entropy": 0.12991933822631835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.9051971435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015390531159937382,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17649676402409872,
      "backward_entropy": 0.12976521253585815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.724143981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015462121926248074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1763949195543925,
      "backward_entropy": 0.13408771753311158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.7131805419922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015525213442742825,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17629897594451904,
      "backward_entropy": 0.1383882999420166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.93894958496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01558949425816536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17620086669921875,
      "backward_entropy": 0.13387556076049806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.70203399658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015660598874092102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17609461148579916,
      "backward_entropy": 0.13377869129180908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.65283966064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015728801488876343,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17599030335744223,
      "backward_entropy": 0.13367209434509278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.3312530517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01579439453780651,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1758874257405599,
      "backward_entropy": 0.13355638980865478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.55284881591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01586422137916088,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1757798989613851,
      "backward_entropy": 0.12863373756408691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.65454864501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01593129150569439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17567362387975058,
      "backward_entropy": 0.12845932245254515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.88868713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015997469425201416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1755670110384623,
      "backward_entropy": 0.13318853378295897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.88247680664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016065986827015877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1754567821820577,
      "backward_entropy": 0.13305673599243165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.47305297851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016136949881911278,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17534387111663818,
      "backward_entropy": 0.1329268455505371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.79039001464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016211826354265213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1752264897028605,
      "backward_entropy": 0.13280055522918702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.46528625488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0162897240370512,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17510473728179932,
      "backward_entropy": 0.12758407592773438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.00211334228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01636073924601078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1749891440073649,
      "backward_entropy": 0.13253207206726075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.89302825927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01642698235809803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17487708727518717,
      "backward_entropy": 0.13237953186035156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.3472442626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016493314877152443,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17476199070612589,
      "backward_entropy": 0.1270145893096924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.99217224121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01656867004930973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17463690042495728,
      "backward_entropy": 0.13209125995635987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.56694793701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01664871722459793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17450523376464844,
      "backward_entropy": 0.13195546865463256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.03221893310547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016726797446608543,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17437338829040527,
      "backward_entropy": 0.13830931186676027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.8983154296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016803283244371414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1742412249247233,
      "backward_entropy": 0.13166954517364501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.3053970336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016876764595508575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17411011457443237,
      "backward_entropy": 0.13151695728302001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.7128677368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016947375610470772,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1739800969759623,
      "backward_entropy": 0.12588284015655518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.51063537597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017015237361192703,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17385127147038779,
      "backward_entropy": 0.13120414018630983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.68976593017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017090516164898872,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1737130880355835,
      "backward_entropy": 0.1382852554321289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.26473999023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017161685973405838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1735773285230001,
      "backward_entropy": 0.12524157762527466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.18923950195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017238402739167213,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17343421777089438,
      "backward_entropy": 0.13827790021896363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.64210510253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01731734909117222,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17328637838363647,
      "backward_entropy": 0.13059852123260499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.8708724975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01740000769495964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17313297589619955,
      "backward_entropy": 0.1246175765991211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.77328491210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017480498179793358,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17298062642415366,
      "backward_entropy": 0.12440342903137207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.3350372314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0175637174397707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17282323042551676,
      "backward_entropy": 0.12419195175170898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.64115905761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017650224268436432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17265939712524414,
      "backward_entropy": 0.12399111986160279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.03023529052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017734190449118614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17249751091003418,
      "backward_entropy": 0.12378885746002197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.73106384277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01781570352613926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17233816782633463,
      "backward_entropy": 0.12357280254364014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.51293182373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017902741208672523,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17217121521631876,
      "backward_entropy": 0.12336339950561523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.13783264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01798403076827526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1720123291015625,
      "backward_entropy": 0.123134183883667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.16148376464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018067989498376846,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17184885342915854,
      "backward_entropy": 0.1382793664932251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.5994110107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018155021592974663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17167995373408,
      "backward_entropy": 0.122688889503479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.83905792236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018243109807372093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1715084115664164,
      "backward_entropy": 0.12883936166763305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.9292449951172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018327824771404266,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17133734623591104,
      "backward_entropy": 0.138278067111969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.38289642333984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01841401867568493,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1711617906888326,
      "backward_entropy": 0.1382772445678711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.12964630126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018497565761208534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17098796367645264,
      "backward_entropy": 0.12174203395843505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.60993194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018573779612779617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17082258065541586,
      "backward_entropy": 0.12808499336242676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.85914611816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018643563613295555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17066444953282675,
      "backward_entropy": 0.12785276174545288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.5136260986328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018717771396040916,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17049827178319296,
      "backward_entropy": 0.13824574947357177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.91077423095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018792662769556046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1703288952509562,
      "backward_entropy": 0.1206102728843689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.99476623535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018865713849663734,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17016084988911948,
      "backward_entropy": 0.13822726011276246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.63900756835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01893552392721176,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16999604304631552,
      "backward_entropy": 0.12000954151153564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.3839874267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019005965441465378,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1698286533355713,
      "backward_entropy": 0.13820226192474366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.45167541503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019081177189946175,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16965202490488687,
      "backward_entropy": 0.1381930947303772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.95982360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01915648952126503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16947402556737265,
      "backward_entropy": 0.12618069648742675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.25814819335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019232438877224922,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1692930261294047,
      "backward_entropy": 0.11879465579986573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.006103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019308432936668396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16911041736602783,
      "backward_entropy": 0.12567769289016723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.19284057617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019386406987905502,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.168923020362854,
      "backward_entropy": 0.11817748546600342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.07090759277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01947079412639141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16872443755467734,
      "backward_entropy": 0.11788274049758911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.3577117919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019558027386665344,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16851993401845297,
      "backward_entropy": 0.11759321689605713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.2721710205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01965051144361496,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.168306032816569,
      "backward_entropy": 0.11731529235839844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.23204040527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019744819030165672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16808768113454184,
      "backward_entropy": 0.12447433471679688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.9481430053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019837861880660057,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16787062088648477,
      "backward_entropy": 0.11674911975860595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.0808868408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01992839388549328,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1676554282506307,
      "backward_entropy": 0.12398748397827149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.99226379394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02001841366291046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16743930180867514,
      "backward_entropy": 0.11614279747009278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.92422485351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0201043039560318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16722806294759116,
      "backward_entropy": 0.11581640243530274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.47855377197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020191185176372528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16701348622639975,
      "backward_entropy": 0.11548562049865722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.75210571289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020275840535759926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16680059830347696,
      "backward_entropy": 0.12293041944503784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.9163360595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02036198601126671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16658347845077515,
      "backward_entropy": 0.12265248298645019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.4293670654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020447561517357826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.166365385055542,
      "backward_entropy": 0.12236781120300293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.61373901367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02053418755531311,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16614462931950888,
      "backward_entropy": 0.11410512924194335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.1751708984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020619845017790794,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16592384378115335,
      "backward_entropy": 0.13812811374664308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.0458221435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02070656046271324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16569937268892923,
      "backward_entropy": 0.1214833378791809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.0655746459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020794229581952095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1654714047908783,
      "backward_entropy": 0.11302558183670045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.44683074951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020876295864582062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16525177160898843,
      "backward_entropy": 0.12085846662521363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.01542663574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020953131839632988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16504069169362387,
      "backward_entropy": 0.11224476099014283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.29612731933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021028632298111916,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16483010848363241,
      "backward_entropy": 0.1118402361869812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.02392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021102381870150566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16462039947509766,
      "backward_entropy": 0.11142855882644653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.80455017089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02118038572371006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16440196832021078,
      "backward_entropy": 0.11948777437210083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.59732818603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02126184105873108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16417560974756876,
      "backward_entropy": 0.1191516637802124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.68711853027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021341532468795776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16395107905069986,
      "backward_entropy": 0.11879503726959229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.96841430664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02142215147614479,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16372278332710266,
      "backward_entropy": 0.11844017505645751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.26887512207031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021504798904061317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16348896423975626,
      "backward_entropy": 0.10939396619796753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2392120361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02158558927476406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1632574995358785,
      "backward_entropy": 0.10896579027175904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.5860595703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021670326590538025,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.163016676902771,
      "backward_entropy": 0.13800618648529053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.93734741210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02175319939851761,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16277730464935303,
      "backward_entropy": 0.10811874866485596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.27833557128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021839817985892296,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16252899169921875,
      "backward_entropy": 0.13798937797546387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.8680648803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021927887573838234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16227646668752035,
      "backward_entropy": 0.11624268293380738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.38075256347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022014345973730087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16202543179194132,
      "backward_entropy": 0.10685150623321533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.62439727783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022103825584053993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617666780948639,
      "backward_entropy": 0.11551491022109986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.42356872558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02218942902982235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1615147590637207,
      "backward_entropy": 0.11513499021530152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.35121154785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022279679775238037,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16125316421190897,
      "backward_entropy": 0.13796863555908204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.63555145263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022372381761670113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16098478436470032,
      "backward_entropy": 0.1144022822380066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.4698944091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022462468594312668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16072084506352743,
      "backward_entropy": 0.11401594877243042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.59762573242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022554844617843628,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16045119365056357,
      "backward_entropy": 0.10429233312606812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.80353546142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022645825520157814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16018353899319968,
      "backward_entropy": 0.11321666240692138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.40927124023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02273457683622837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15991934140523276,
      "backward_entropy": 0.11279810667037964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.90323638916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022825583815574646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1596494515736898,
      "backward_entropy": 0.10291147232055664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.43540954589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02291630581021309,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15938041607538858,
      "backward_entropy": 0.10244863033294678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.73445129394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023002319037914276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1591213345527649,
      "backward_entropy": 0.10195924043655395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.06965637207031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02308310754597187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15887252489725748,
      "backward_entropy": 0.11102058887481689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.79917907714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023162350058555603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15862668553988138,
      "backward_entropy": 0.11052922010421753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.91730499267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0232431348413229,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15837623675664267,
      "backward_entropy": 0.13788864612579346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.5167007446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023322787135839462,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.158126433690389,
      "backward_entropy": 0.09987021684646606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.60839080810547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023403184488415718,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15787301460901895,
      "backward_entropy": 0.13785754442214965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.72279357910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02348134107887745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15762374798456827,
      "backward_entropy": 0.10853670835494995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.77947998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02356138825416565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15737062692642212,
      "backward_entropy": 0.10803446769714356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.39556121826172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023643920198082924,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1571118434270223,
      "backward_entropy": 0.13781501054763795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.06571960449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02372675947844982,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15684916575749716,
      "backward_entropy": 0.1070630669593811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.12345123291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023802611976861954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15660491585731506,
      "backward_entropy": 0.10653300285339355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.96138763427734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023876523599028587,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15636611978212991,
      "backward_entropy": 0.13776170015335082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.13958740234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023951653391122818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15612486998240152,
      "backward_entropy": 0.09554201364517212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.7816162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024027299135923386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15588227907816568,
      "backward_entropy": 0.09495694637298584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.59934997558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024099890142679214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15564733743667603,
      "backward_entropy": 0.10429041385650635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.22149658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024166570976376534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15542693932851157,
      "backward_entropy": 0.09371774792671203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.05162048339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024231722578406334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15520862738291422,
      "backward_entropy": 0.0930790901184082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.84163665771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02430005930364132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1549814542134603,
      "backward_entropy": 0.09246859550476075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.50811004638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024367908015847206,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15475621819496155,
      "backward_entropy": 0.09184767007827759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.32861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024437906220555305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15452539920806885,
      "backward_entropy": 0.10129539966583252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.12518310546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02451639622449875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15427401661872864,
      "backward_entropy": 0.13754109144210816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.1300048828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02459401823580265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15402441223462424,
      "backward_entropy": 0.09007866382598877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.05691909790039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024667736142873764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15378403663635254,
      "backward_entropy": 0.08947530388832092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.45973205566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0247343722730875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15356099605560303,
      "backward_entropy": 0.13748172521591187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.65901184082031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02480253390967846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15333354473114014,
      "backward_entropy": 0.08820474743843079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.56725311279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02486737258732319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15311433871587118,
      "backward_entropy": 0.09775716066360474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.72942352294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024931225925683975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15289698044459024,
      "backward_entropy": 0.08690493702888488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.1610336303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02499755099415779,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15267068147659302,
      "backward_entropy": 0.08627615571022033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.5836181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02506435103714466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1524431308110555,
      "backward_entropy": 0.08565491437911987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.464599609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02513376995921135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15221007664998373,
      "backward_entropy": 0.08505120277404785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.77806854248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025208445265889168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15196426709493002,
      "backward_entropy": 0.09474126696586609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.11354064941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025280825793743134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15172417958577475,
      "backward_entropy": 0.09415255784988404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.5413818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025355303660035133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1514787475268046,
      "backward_entropy": 0.08328043222427368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.20240020751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02543281763792038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15122594436009726,
      "backward_entropy": 0.08269857764244079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.85974884033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025511732324957848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15096976359685263,
      "backward_entropy": 0.08212158679962159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.45404815673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02559150941669941,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1507116953531901,
      "backward_entropy": 0.08154162168502807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.75686645507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025672689080238342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15045017004013062,
      "backward_entropy": 0.08097069263458252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.9241943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025759512558579445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15017553170522055,
      "backward_entropy": 0.08042194843292236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.02345275878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025846630334854126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14990154902140299,
      "backward_entropy": 0.09024089574813843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.4820327758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0259347353130579,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14962458610534668,
      "backward_entropy": 0.07931733131408691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.75336456298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02601797692477703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14936005075772604,
      "backward_entropy": 0.07874019145965576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.42151641845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026099035516381264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14910159508387247,
      "backward_entropy": 0.07815617322921753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.45455169677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026177730411291122,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14884962638219199,
      "backward_entropy": 0.07756060361862183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.21026611328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026256071403622627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1485990285873413,
      "backward_entropy": 0.08730751872062684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.99884796142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026337800547480583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14833909273147583,
      "backward_entropy": 0.07639883756637574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.81850814819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026417145505547523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14808552463849387,
      "backward_entropy": 0.0861614465713501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.40918731689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02649124525487423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14784570535024008,
      "backward_entropy": 0.07521510720252991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.94325256347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02656467631459236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14760818084081015,
      "backward_entropy": 0.07459697723388672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.04716491699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026639485731720924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14736793438593546,
      "backward_entropy": 0.08429402112960815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.24180603027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02671288698911667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14713109532992044,
      "backward_entropy": 0.07337470054626465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.54930877685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026783060282468796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14690272013346353,
      "backward_entropy": 0.07275106906890869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.209228515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026851903647184372,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14667721589406332,
      "backward_entropy": 0.07212246656417846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.14305114746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026920907199382782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14645293354988098,
      "backward_entropy": 0.08168181180953979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.87002563476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026994628831744194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14621669054031372,
      "backward_entropy": 0.07090877294540406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.82881164550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027071546763181686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1459723711013794,
      "backward_entropy": 0.08046886920928956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.96826934814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02714717388153076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1457319657007853,
      "backward_entropy": 0.0798689603805542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.1204605102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02722032740712166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1454984744389852,
      "backward_entropy": 0.07927142381668091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.0894546508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02728998102247715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14527520537376404,
      "backward_entropy": 0.06860311627388001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.12339782714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02736045978963375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14505016803741455,
      "backward_entropy": 0.07800478935241699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.0421905517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027434973046183586,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14481496810913086,
      "backward_entropy": 0.13715070486068726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.61289978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027512485161423683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14457309246063232,
      "backward_entropy": 0.07679333090782166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.65797424316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02758897840976715,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14433459440867105,
      "backward_entropy": 0.13715591430664062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.36793518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027667202055454254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14409341414769491,
      "backward_entropy": 0.06577157974243164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.726806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027744825929403305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14385398228963217,
      "backward_entropy": 0.0750077247619629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.92921447753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027819504961371422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14362293481826782,
      "backward_entropy": 0.06464627981185914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.21031951904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027894625440239906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14339017868041992,
      "backward_entropy": 0.0737783133983612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.26387023925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027969295158982277,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14316030343373617,
      "backward_entropy": 0.06351323127746582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.9023323059082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028042033314704895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14293662707010904,
      "backward_entropy": 0.07252317667007446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.60428619384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028109749779105186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14272823929786682,
      "backward_entropy": 0.07186605930328369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.10713958740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028176279738545418,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14252410332361856,
      "backward_entropy": 0.06176238059997559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.34534454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028244176879525185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1423151691754659,
      "backward_entropy": 0.07054561376571655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.506103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028314633294939995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14209999640782675,
      "backward_entropy": 0.06991184949874878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.93553924560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02838718891143799,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14187770088513693,
      "backward_entropy": 0.06005728840827942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.37234497070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028457283973693848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14165717363357544,
      "backward_entropy": 0.05949859619140625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.63823699951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028533658012747765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14141910274823508,
      "backward_entropy": 0.05898216366767883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.39982604980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028608759865164757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14118421077728271,
      "backward_entropy": 0.06746790409088135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.69789123535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02868511714041233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14094690481821695,
      "backward_entropy": 0.057931655645370485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.60895538330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028758693486452103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14071853955586752,
      "backward_entropy": 0.057370728254318236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.3273162841797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028828918933868408,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14050151904424033,
      "backward_entropy": 0.13703644275665283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.56663513183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028902681544423103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14027359088261923,
      "backward_entropy": 0.056239640712738036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.51560974121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028977908194065094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14004125197728476,
      "backward_entropy": 0.055690884590148926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.97776794433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029050802811980247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1398160457611084,
      "backward_entropy": 0.05514854788780212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.01165771484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029123330488801003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13959225018819174,
      "backward_entropy": 0.0545914888381958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.3282012939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029194695875048637,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13937222957611084,
      "backward_entropy": 0.062269175052642824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.03382873535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029272165149450302,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1391355593999227,
      "backward_entropy": 0.05351775288581848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.45905303955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0293484628200531,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13890414436658224,
      "backward_entropy": 0.0530091404914856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.927982330322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029421985149383545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13868163029352823,
      "backward_entropy": 0.05250023603439331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.12224197387695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029491282999515533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13847281535466513,
      "backward_entropy": 0.05983819365501404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.96522521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029556574299931526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1382769544919332,
      "backward_entropy": 0.05920354127883911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.23850631713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029624128714203835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13807629545529684,
      "backward_entropy": 0.05856212377548218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.77149200439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029686369001865387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13789389530817667,
      "backward_entropy": 0.05790534019470215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.14092254638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029747359454631805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13771589597066244,
      "backward_entropy": 0.04986850619316101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.2227668762207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02981201373040676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13752524058024088,
      "backward_entropy": 0.056642889976501465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.70287322998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029873479157686234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13734511534372965,
      "backward_entropy": 0.05602524876594543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.4715576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02993164211511612,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13717631498972574,
      "backward_entropy": 0.05538938045501709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.1434326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02999771013855934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13698532183965048,
      "backward_entropy": 0.04791578054428101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.95661163330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03006528504192829,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13679193456967673,
      "backward_entropy": 0.054251575469970705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.4867172241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03013722412288189,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13658930857976279,
      "backward_entropy": 0.04705171287059784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.32060241699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0302103403955698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1363853613535563,
      "backward_entropy": 0.05316444039344788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.25288391113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03028557449579239,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361773411432902,
      "backward_entropy": 0.04623458981513977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.6717529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030363399535417557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13596307237943014,
      "backward_entropy": 0.04585032761096954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.933067321777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030435767024755478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135768194993337,
      "backward_entropy": 0.045425894856452945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.57807159423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030503561720252037,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355884869893392,
      "backward_entropy": 0.04500762820243835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.76239013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030567627400159836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13542125622431436,
      "backward_entropy": 0.05041596293449402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.19444274902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030632510781288147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13525239626566568,
      "backward_entropy": 0.0498607337474823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.385501861572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03069942072033882,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13507882754007974,
      "backward_entropy": 0.043768268823623654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.973880767822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030761713162064552,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13492214679718018,
      "backward_entropy": 0.043367981910705566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.91539001464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0308227576315403,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1347696582476298,
      "backward_entropy": 0.043002575635910034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.7626724243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030889475718140602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13460000356038412,
      "backward_entropy": 0.04266718327999115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.63414764404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030957886949181557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1344257394472758,
      "backward_entropy": 0.04234198927879333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.72810363769531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031026123091578484,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13425352176030478,
      "backward_entropy": 0.13686878681182862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.48508834838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031093992292881012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13408464193344116,
      "backward_entropy": 0.04167637228965759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.67700958251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03115924820303917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13392460346221924,
      "backward_entropy": 0.04134256839752197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.3375473022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03122744895517826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13375665744145712,
      "backward_entropy": 0.04100581407546997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.81803131103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03130090981721878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1335736612478892,
      "backward_entropy": 0.04070373773574829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.869384765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03137378394603729,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13339571158091226,
      "backward_entropy": 0.040398383140563966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.82768249511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03145146369934082,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13320602973302206,
      "backward_entropy": 0.04012255370616913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.76172637939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03153177723288536,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13301004966100058,
      "backward_entropy": 0.03986680805683136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.0953369140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03160892054438591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13282539447148642,
      "backward_entropy": 0.04322198629379272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.7051773071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03168809786438942,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13263648748397827,
      "backward_entropy": 0.03930758833885193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.70030975341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031766410917043686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13245147466659546,
      "backward_entropy": 0.04235277771949768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.21034240722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03184756636619568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13225950797398886,
      "backward_entropy": 0.04194478392601013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.36326599121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03192644566297531,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.132075568040212,
      "backward_entropy": 0.038526153564453124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.84913635253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03200935199856758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13188276688257852,
      "backward_entropy": 0.038299405574798585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.08467102050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03209253028035164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1316910982131958,
      "backward_entropy": 0.03807179033756256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.23812103271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03217395022511482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13150492310523987,
      "backward_entropy": 0.04043552875518799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.67865753173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032257262617349625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13131506244341531,
      "backward_entropy": 0.040078085660934445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.5672149658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032339151948690414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13113073507944742,
      "backward_entropy": 0.03743182420730591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.50250244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03242764249444008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13093135754267374,
      "backward_entropy": 0.03935360312461853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.66604995727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032510507851839066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13074852029482523,
      "backward_entropy": 0.037026727199554445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.20689868927002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032590243965387344,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13057517011960348,
      "backward_entropy": 0.03684536218643188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.29838180541992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032662078738212585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.130426824092865,
      "backward_entropy": 0.038312166929244995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.3988037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03273099288344383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13028812408447266,
      "backward_entropy": 0.036460784077644345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.03763961791992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03279706463217735,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13015909989674887,
      "backward_entropy": 0.036253640055656434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.91056060791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032861970365047455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13003197312355042,
      "backward_entropy": 0.036080628633499146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.27690505981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032927848398685455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12990053494771323,
      "backward_entropy": 0.03689710795879364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.01789093017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03299100324511528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12977810700734457,
      "backward_entropy": 0.036536940932273866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.9671859741211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03305487707257271,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1296538015206655,
      "backward_entropy": 0.03616965711116791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.7129898071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033121321350336075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1295220156510671,
      "backward_entropy": 0.035354888439178465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.61055755615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0331893227994442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12938825289408365,
      "backward_entropy": 0.03519603610038757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.75464630126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03325950354337692,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12924857934316,
      "backward_entropy": 0.035039883852005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.02790832519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03332852944731712,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12911373376846313,
      "backward_entropy": 0.034878626465797424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.43463897705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03339798375964165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1289791762828827,
      "backward_entropy": 0.03448242843151093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.7201156616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033465247601270676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12885181109110513,
      "backward_entropy": 0.03451457619667053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.42676544189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03353124111890793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12872904539108276,
      "backward_entropy": 0.03430433869361878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.123931884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03359442576766014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1286151111125946,
      "backward_entropy": 0.034079349040985106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.19024658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033655330538749695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12850942214330038,
      "backward_entropy": 0.032946744561195375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.52764892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03371397405862808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12841097513834634,
      "backward_entropy": 0.03254342675209045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.23969268798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03377541899681091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12830489873886108,
      "backward_entropy": 0.03338916599750519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.3826675415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03384128957986832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12818507353464761,
      "backward_entropy": 0.031772443652153017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.95171356201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033913690596818924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12804633378982544,
      "backward_entropy": 0.03145076334476471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.91669845581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03398754447698593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1279046634833018,
      "backward_entropy": 0.03287903070449829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.97502899169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03405749052762985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12777684132258096,
      "backward_entropy": 0.03078969717025757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.79061126708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03413475677371025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1276311973730723,
      "backward_entropy": 0.03255296945571899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.603614807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03421531617641449,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12747728824615479,
      "backward_entropy": 0.03243850767612457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.42236328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03429277986288071,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12733386953671774,
      "backward_entropy": 0.13739821910858155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.21250915527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034371890127658844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12718639771143594,
      "backward_entropy": 0.032157710194587706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.6257209777832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03445248678326607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1270358363787333,
      "backward_entropy": 0.032040998339653015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.63253402709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03452782332897186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.126900980869929,
      "backward_entropy": 0.031907692551612854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.85619354248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034601081162691116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12677296996116638,
      "backward_entropy": 0.03175626397132873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.85887908935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0346774160861969,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1266371707121531,
      "backward_entropy": 0.02841465175151825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.88224792480469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03475501760840416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1264988581339518,
      "backward_entropy": 0.03151420056819916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.549354553222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034834735095500946,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12635532021522522,
      "backward_entropy": 0.031442418694496155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.396873474121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03491264581680298,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12621861696243286,
      "backward_entropy": 0.03136568665504456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.3933219909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03498893976211548,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1260866622130076,
      "backward_entropy": 0.03128495812416077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.2426643371582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03506356477737427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12595989306767783,
      "backward_entropy": 0.031194406747817992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.41523742675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03513669595122337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12583743532498678,
      "backward_entropy": 0.02692475914955139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.8501205444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03521057218313217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12571208675702414,
      "backward_entropy": 0.02668306529521942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.5048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03528868034482002,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12557576100031534,
      "backward_entropy": 0.026441025733947753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.660343170166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03536541387438774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12544482946395874,
      "backward_entropy": 0.030846735835075377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.62748718261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03543795272707939,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12532713015874228,
      "backward_entropy": 0.030722108483314515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.24016571044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0355122908949852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12520545721054077,
      "backward_entropy": 0.025664284825325012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.762123107910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035591695457696915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12507073084513345,
      "backward_entropy": 0.030506494641304015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.629459381103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03566984832286835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12493993838628133,
      "backward_entropy": 0.030424952507019043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.064937591552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035743843764066696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12482106685638428,
      "backward_entropy": 0.024961143732070923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.81749725341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0358155183494091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12470880150794983,
      "backward_entropy": 0.024738582968711852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.26036834716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03588533028960228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12460185090700786,
      "backward_entropy": 0.030218669772148134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.98512268066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.035957466810941696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12448885043462117,
      "backward_entropy": 0.13773465156555176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.17510223388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03603701293468475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12435702482859294,
      "backward_entropy": 0.030102720856666564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5273326635360718,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036116939038038254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12422452370325725,
      "backward_entropy": 0.023922812938690186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.72570037841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036189004778862,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12411436438560486,
      "backward_entropy": 0.03003745377063751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.774234771728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03625625744462013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12401934464772542,
      "backward_entropy": 0.023538890480995178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.45577239990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03632071614265442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12393223245938619,
      "backward_entropy": 0.023340064287185668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.46856689453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0363912470638752,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12382500370343526,
      "backward_entropy": 0.02989141047000885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.75508499145508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03646286204457283,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12371575832366943,
      "backward_entropy": 0.029866704344749452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.25706100463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036530833691358566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1236189603805542,
      "backward_entropy": 0.022808347642421723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.56108856201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03659811615943909,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.123524010181427,
      "backward_entropy": 0.029790455102920534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.63047409057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03666574880480766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12342868248621623,
      "backward_entropy": 0.029720830917358398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.492958068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036733388900756836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12333313624064128,
      "backward_entropy": 0.02966221570968628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.88773345947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036801040172576904,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12323745091756184,
      "backward_entropy": 0.02961350977420807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.87565994262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036874234676361084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12312724192937215,
      "backward_entropy": 0.029571962356567384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.66228485107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03694753348827362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12301594018936157,
      "backward_entropy": 0.029558837413787842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.90614318847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03702219948172569,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12290194630622864,
      "backward_entropy": 0.029526075720787047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.136764526367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03709915652871132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12278218070665996,
      "backward_entropy": 0.029509681463241576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.84273147583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037170182913541794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12267924348513286,
      "backward_entropy": 0.029472774267196654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.22491455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037239089608192444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1225833793481191,
      "backward_entropy": 0.029431074857711792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.17841339111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037306416779756546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12249259154001872,
      "backward_entropy": 0.029353785514831542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.26903533935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03737540915608406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12239495913187663,
      "backward_entropy": 0.020661452412605287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.58533477783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037441760301589966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12230509519577026,
      "backward_entropy": 0.020494312047958374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.79422760009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037506066262722015,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12222192684809367,
      "backward_entropy": 0.029203417897224426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.93148803710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03757214918732643,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12213343381881714,
      "backward_entropy": 0.02916017174720764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.41666412353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037639204412698746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12204190095265706,
      "backward_entropy": 0.029107925295829774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.330223083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03771384432911873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12193024158477783,
      "backward_entropy": 0.02908291816711426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.850074768066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037784259766340256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12183090051015218,
      "backward_entropy": 0.029041802883148192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.4929084777832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0378517210483551,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12173990408579509,
      "backward_entropy": 0.029011374711990355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.571746826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037917908281087875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12165186802546184,
      "backward_entropy": 0.0289897084236145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.44332122802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03798253461718559,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12156864007314046,
      "backward_entropy": 0.019215434789657593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.30536651611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03804934024810791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12147873640060425,
      "backward_entropy": 0.028960418701171876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.34906005859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0381186380982399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12138195832570393,
      "backward_entropy": 0.01894725561141968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.63077926635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03818248584866524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12130204836527507,
      "backward_entropy": 0.028906810283660888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.555035591125488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038246605545282364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12122085690498352,
      "backward_entropy": 0.018637758493423463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.0090103149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03830463066697121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12115814288457234,
      "backward_entropy": 0.01847078800201416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.1795711517334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03836468607187271,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1210893193880717,
      "backward_entropy": 0.028752812743186952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.62079620361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038420043885707855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1210356851418813,
      "backward_entropy": 0.018123248219490053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.33938217163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038477927446365356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12097368637720744,
      "backward_entropy": 0.017949576675891876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.15375518798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038535770028829575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12091060479482015,
      "backward_entropy": 0.028542399406433105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.8379020690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03859631344676018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12083921829859416,
      "backward_entropy": 0.0176499679684639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.25221252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038659702986478806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1207599143187205,
      "backward_entropy": 0.01752733439207077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.172802925109863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038726598024368286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12067023913065593,
      "backward_entropy": 0.02851642370223999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.177881240844727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03878743201494217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1205987532933553,
      "backward_entropy": 0.017290078103542328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2198683023452759,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0388450101017952,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12053662538528442,
      "backward_entropy": 0.0285119891166687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.46487808227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038897525519132614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12048908074696858,
      "backward_entropy": 0.02854638695716858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.23391342163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038946591317653656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12045284112294515,
      "backward_entropy": 0.016959357261657714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.6822395324707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0389946885406971,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.120420237382253,
      "backward_entropy": 0.028518712520599364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.72932052612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03904314711689949,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12038515011469524,
      "backward_entropy": 0.028482002019882203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.49793243408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039095688611269,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1203362246354421,
      "backward_entropy": 0.028476837277412414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.82366943359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03914816677570343,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12028950452804565,
      "backward_entropy": 0.01644112765789032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.462324142456055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03920528292655945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12022912502288818,
      "backward_entropy": 0.028485214710235594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.517459869384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03926233947277069,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12016671895980835,
      "backward_entropy": 0.02855214774608612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.1106071472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039319850504398346,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12010342876116435,
      "backward_entropy": 0.028594699501991273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.48828887939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039380330592393875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1200310190518697,
      "backward_entropy": 0.028651806712150573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.08063888549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039445385336875916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11994558572769165,
      "backward_entropy": 0.016019798815250397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.78692626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03950696811079979,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11987119913101196,
      "backward_entropy": 0.02870071530342102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.57569122314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0395737923681736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11978109677632649,
      "backward_entropy": 0.01582220643758774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.454486846923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0396408848464489,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11968982219696045,
      "backward_entropy": 0.028748899698257446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.35333251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03970395028591156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11961042881011963,
      "backward_entropy": 0.028776082396507262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.50578498840332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039770159870386124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11952169736226399,
      "backward_entropy": 0.015551219880580901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.163326263427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0398331955075264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11944352587064107,
      "backward_entropy": 0.028801220655441283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.76040267944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03989648073911667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11936407287915547,
      "backward_entropy": 0.028798815608024598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.95502471923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03996078297495842,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11928025881449382,
      "backward_entropy": 0.028817692399024965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.085933685302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0400250144302845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11919666330019633,
      "backward_entropy": 0.028823184967041015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.54131317138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040087439119815826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11912041902542114,
      "backward_entropy": 0.02880597412586212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.430060386657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040152087807655334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11903640627861023,
      "backward_entropy": 0.014917941391468048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.77113914489746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04021083936095238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11897225181261699,
      "backward_entropy": 0.01478264033794403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.509857177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040267594158649445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11891409754753113,
      "backward_entropy": 0.028642189502716065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.66799926757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04032371565699577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1188571850458781,
      "backward_entropy": 0.014521832764148711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.760183334350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04038311541080475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11878776550292969,
      "backward_entropy": 0.014385873079299926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.188138008117676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040439702570438385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11872840921084087,
      "backward_entropy": 0.028424572944641114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.25153160095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040491461753845215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11868512630462646,
      "backward_entropy": 0.028336340188980104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.09708023071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040542371571063995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11864342292149861,
      "backward_entropy": 0.0282734215259552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.993921279907227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040596555918455124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11859015623728435,
      "backward_entropy": 0.013835065066814423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.080020904541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040650058537721634,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11853952209154765,
      "backward_entropy": 0.0282186359167099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.5251579284668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040702372789382935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11849254369735718,
      "backward_entropy": 0.028217363357543945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.382308959960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04075516015291214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11844376722971599,
      "backward_entropy": 0.02822980284690857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.752836227416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04080549255013466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11840232213338216,
      "backward_entropy": 0.028250232338905334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.097169876098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040852464735507965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11837149659792583,
      "backward_entropy": 0.02828657627105713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.387296676635742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040897760540246964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11834622422854106,
      "backward_entropy": 0.013277661800384522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.867709159851074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0409407876431942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11832821369171143,
      "backward_entropy": 0.013176190853118896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.55658531188965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04098042845726013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11832148830095927,
      "backward_entropy": 0.028261137008666993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.81057357788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04102049022912979,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11831279595692952,
      "backward_entropy": 0.02826581001281738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.17814254760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041064973920583725,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11828932166099548,
      "backward_entropy": 0.02828338146209717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.654991149902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041112471371889114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11825624108314514,
      "backward_entropy": 0.028329938650131226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.2911491394043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04116326943039894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11821115016937256,
      "backward_entropy": 0.028373944759368896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.74799728393555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041217971593141556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11815343300501506,
      "backward_entropy": 0.012685056030750274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.51870346069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0412750318646431,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11808700362841289,
      "backward_entropy": 0.02855261564254761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.681392669677734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0413319393992424,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11802107095718384,
      "backward_entropy": 0.13835612535476685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.121706008911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04139022156596184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1179505983988444,
      "backward_entropy": 0.028756511211395264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.69225311279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041446503251791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1178867518901825,
      "backward_entropy": 0.028842446208000184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.64020538330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04150554537773132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11781380573908488,
      "backward_entropy": 0.012454713135957718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.285343170166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04156893864274025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11772620677947998,
      "backward_entropy": 0.02903316617012024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.84307098388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04163472354412079,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11763046185175578,
      "backward_entropy": 0.029157677292823793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.504013061523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04170168563723564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11752964059511821,
      "backward_entropy": 0.029311364889144896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.53116226196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04176459461450577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1174417535463969,
      "backward_entropy": 0.02945522964000702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.573976516723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04182536527514458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1173607309659322,
      "backward_entropy": 0.029591962695121765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.627498626708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04188194125890732,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11729434132575989,
      "backward_entropy": 0.01224832609295845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.42072296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04193929210305214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11722499132156372,
      "backward_entropy": 0.01218581572175026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.17827033996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0419992096722126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11714720726013184,
      "backward_entropy": 0.029825511574745178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.132043838500977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04205593466758728,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11707963546117146,
      "backward_entropy": 0.02989833652973175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.90665817260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0421111136674881,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1170162558555603,
      "backward_entropy": 0.029974350333213808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.4759750366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04217056185007095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11693814396858215,
      "backward_entropy": 0.03005836606025696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.6046257019043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04223943501710892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11682961384455363,
      "backward_entropy": 0.030150982737541198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.00657844543457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04231080785393715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11671237150828044,
      "backward_entropy": 0.030230098962783815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.908658981323242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042378250509500504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11660897731781006,
      "backward_entropy": 0.030270910263061522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.51749038696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042441368103027344,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11652016639709473,
      "backward_entropy": 0.03030184209346771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.251068115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04250263422727585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11643620332082112,
      "backward_entropy": 0.030351263284683228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.688514709472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0425635501742363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11635146538416545,
      "backward_entropy": 0.03041403591632843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.110870361328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042627375572919846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11625631650288899,
      "backward_entropy": 0.03045554757118225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.606739044189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04269023239612579,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11616598566373189,
      "backward_entropy": 0.030498862266540527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.80718994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04274922236800194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11608866850535075,
      "backward_entropy": 0.030531799793243407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.73532485961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04280815273523331,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11601155996322632,
      "backward_entropy": 0.030525630712509154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.348222732543945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0428667813539505,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11593419313430786,
      "backward_entropy": 0.03053053021430969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.632171630859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042922329157590866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11586641271909077,
      "backward_entropy": 0.030545783042907716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.2210578918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042981237173080444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11578366160392761,
      "backward_entropy": 0.030595767498016357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.294937133789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04304027929902077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11570133765538533,
      "backward_entropy": 0.03061709403991699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.75809860229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043095678091049194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11563263336817424,
      "backward_entropy": 0.01091473624110222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.15957260131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04315243661403656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11555862426757812,
      "backward_entropy": 0.03064209520816803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.551477432250977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04321172460913658,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11547489960988362,
      "backward_entropy": 0.030662089586257935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.839509963989258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043269019573926926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11539828777313232,
      "backward_entropy": 0.030677753686904907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.81021499633789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04332391172647476,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11532960335413615,
      "backward_entropy": 0.030722135305404664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.60983657836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04337873309850693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1152603526910146,
      "backward_entropy": 0.01057155877351761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.5647087097168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043435923755168915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11518216133117676,
      "backward_entropy": 0.0307941734790802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.07607650756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043492987751960754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11510344346364339,
      "backward_entropy": 0.030833113193511962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.96480178833008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04354862868785858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11502896745999654,
      "backward_entropy": 0.030885684490203857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.2115364074707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043607402592897415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11494219303131104,
      "backward_entropy": 0.030960607528686523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.61220169067383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0436660535633564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11485538880030315,
      "backward_entropy": 0.031046366691589354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.62163162231445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04372768476605415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1147563358147939,
      "backward_entropy": 0.03115711808204651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.163841247558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043791137635707855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11464923620223999,
      "backward_entropy": 0.010224576294422149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.27845001220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04385509714484215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11454004049301147,
      "backward_entropy": 0.03134318888187408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.44552993774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043920621275901794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11442478497823079,
      "backward_entropy": 0.03142048120498657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.295059204101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043984007090330124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11431623498598735,
      "backward_entropy": 0.03151040971279144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.730587005615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044043656438589096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11422152320543925,
      "backward_entropy": 0.010059632360935211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.76213836669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044103480875492096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11412689089775085,
      "backward_entropy": 0.010007452964782716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.94529151916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044168148189783096,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11401337385177612,
      "backward_entropy": 0.0317035049200058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.277889251708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04422978684306145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11390966176986694,
      "backward_entropy": 0.031794381141662595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.957115173339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044289927929639816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11381230751673381,
      "backward_entropy": 0.009866239130496978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.81654739379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04435117170214653,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11370853583017985,
      "backward_entropy": 0.03191419243812561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.857070922851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044413402676582336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11359925071398418,
      "backward_entropy": 0.03199329376220703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.45236587524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044473279267549515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11349867781003316,
      "backward_entropy": 0.03205983340740204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.583663940429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04453570395708084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11338650186856587,
      "backward_entropy": 0.032146918773651126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.35648727416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044596243649721146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11328096191088359,
      "backward_entropy": 0.032245615124702455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.3482551574707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044657304883003235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11317325631777446,
      "backward_entropy": 0.0323330283164978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.587858200073242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04471755027770996,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11306830247243245,
      "backward_entropy": 0.032416689395904544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.62631607055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04477432370185852,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11297736565272014,
      "backward_entropy": 0.03249185085296631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.15230941772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04483390599489212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.112872580687205,
      "backward_entropy": 0.009498704224824905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.079267501831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04489213600754738,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11277480920155843,
      "backward_entropy": 0.0326382040977478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.010921478271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04494886100292206,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11268256107966106,
      "backward_entropy": 0.03270339667797088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.039730072021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045008983463048935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11257624626159668,
      "backward_entropy": 0.009350039809942246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62437629699707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04507121443748474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11246030529340108,
      "backward_entropy": 0.03280051946640015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.17919158935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04512815549969673,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11236612995465596,
      "backward_entropy": 0.0328380286693573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.97685623168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04518558830022812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11227012674013774,
      "backward_entropy": 0.032859164476394656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527411460876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04524379223585129,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11216935515403748,
      "backward_entropy": 0.03287985920906067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.707366943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04529711604118347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.112088938554128,
      "backward_entropy": 0.03288694024085999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.90196418762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04535161703824997,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11200147867202759,
      "backward_entropy": 0.03289685845375061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.837141036987305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045406561344861984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11191040277481079,
      "backward_entropy": 0.032936984300613405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.76022720336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04545888304710388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11182911197344463,
      "backward_entropy": 0.03298643231391907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.73465919494629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045516565442085266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11172458529472351,
      "backward_entropy": 0.033031636476516725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.98360061645508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045573554933071136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11162273089090984,
      "backward_entropy": 0.03306353986263275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.90325927734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04563165828585625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11151523391405742,
      "backward_entropy": 0.033108252286911014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.24666690826416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04569043591618538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11140403151512146,
      "backward_entropy": 0.03314785659313202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.631587982177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04574446380138397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11131373047828674,
      "backward_entropy": 0.033178940415382385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.5262336730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04579956457018852,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11121879021326701,
      "backward_entropy": 0.033206358551979065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.22307205200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04585547000169754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11112002531687419,
      "backward_entropy": 0.008529652655124665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.457618713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045913051813840866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11101143558820088,
      "backward_entropy": 0.008484219014644623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.709474563598633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045972902327775955,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11089220643043518,
      "backward_entropy": 0.03333598673343659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.650415420532227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0460326112806797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11077183485031128,
      "backward_entropy": 0.008407416939735412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.74371337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046091869473457336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11065258582433064,
      "backward_entropy": 0.033519917726516725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.27205467224121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04615195468068123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11052889625231425,
      "backward_entropy": 0.008345875889062881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.926069259643555,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04621012508869171,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1104130744934082,
      "backward_entropy": 0.13861334323883057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.30215072631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04626595228910446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11030555764834087,
      "backward_entropy": 0.033850207924842834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.798691749572754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04631916806101799,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11021130283673604,
      "backward_entropy": 0.03392315208911896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.878042221069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0463687963783741,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11013249556223552,
      "backward_entropy": 0.034012827277183535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.027162551879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046416278928518295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11006263891855876,
      "backward_entropy": 0.03410761952400208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.932029724121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04646384343504906,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10999264319737752,
      "backward_entropy": 0.034176313877105714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.797896385192871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0465158112347126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10990184545516968,
      "backward_entropy": 0.03424666225910187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.732542037963867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046563681215047836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10982948541641235,
      "backward_entropy": 0.008063344657421112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.50869369506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04660925641655922,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10976707935333252,
      "backward_entropy": 0.034366142749786374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.391014099121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04665694758296013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10969435175259908,
      "backward_entropy": 0.034434950351715087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.582242965698242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04670746251940727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10960658391316731,
      "backward_entropy": 0.03449388146400452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.3515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04675619304180145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10952828327814738,
      "backward_entropy": 0.007883218675851822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.380300521850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046804241836071014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10945175091425578,
      "backward_entropy": 0.007836297899484635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.332475662231445,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04685106500983238,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10938012599945068,
      "backward_entropy": 0.13862016201019287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.474544048309326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04689663276076317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10931389530499776,
      "backward_entropy": 0.03461205363273621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.1495361328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046939365565776825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10925928751627605,
      "backward_entropy": 0.034648087620735166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.80816078186035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04698800668120384,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10917669534683228,
      "backward_entropy": 0.034672397375106814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.670597076416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04703705385327339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10909062623977661,
      "backward_entropy": 0.007583226263523102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.411773204803467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04709195718169212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10897612571716309,
      "backward_entropy": 0.03476270437240601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.37696075439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04714280366897583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10888026158014934,
      "backward_entropy": 0.03482941687107086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.190914154052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04719855263829231,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.108760933081309,
      "backward_entropy": 0.007461759448051453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.254701614379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047254450619220734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10864190260569255,
      "backward_entropy": 0.034884470701217654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.4079475402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04731015861034393,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10852303107579549,
      "backward_entropy": 0.034910768270492554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.93118953704834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0473681204020977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10839266578356425,
      "backward_entropy": 0.007319826632738113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.497100830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04742249846458435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10827969511349995,
      "backward_entropy": 0.007272499054670334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.96011734008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04747803509235382,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10815962155659993,
      "backward_entropy": 0.0350128710269928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.7042350769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04753236472606659,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10804631312688191,
      "backward_entropy": 0.03500909507274628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.639671325683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04758935421705246,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1079188088575999,
      "backward_entropy": 0.03503096103668213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.574475288391113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04764799028635025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10778303941090901,
      "backward_entropy": 0.035039663314819336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.897769927978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04770342633128166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10766197244326274,
      "backward_entropy": 0.035060399770736696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6736652255058289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04775916039943695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1075383722782135,
      "backward_entropy": 0.03505508601665497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.809940338134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04780927672982216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10744237899780273,
      "backward_entropy": 0.006928396970033645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.049819946289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0478636659681797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10732708374659221,
      "backward_entropy": 0.035019528865814206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.642576217651367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047917839139699936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1072118878364563,
      "backward_entropy": 0.03500592112541199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.524089813232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047970328480005264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10710341731707256,
      "backward_entropy": 0.03499959707260132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.409345626831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0480215959250927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10699965556462605,
      "backward_entropy": 0.035011577606201175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.93531608581543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048072054982185364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10689825812975566,
      "backward_entropy": 0.03505504131317139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.684234619140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048123445361852646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10679222146670024,
      "backward_entropy": 0.03507845997810364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.48253059387207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04817667603492737,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10667457183202107,
      "backward_entropy": 0.035141998529434205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.5562744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04822922125458717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10656074682871501,
      "backward_entropy": 0.03518078327178955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.18332290649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048282328993082047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10644224286079407,
      "backward_entropy": 0.035196664929389956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.835601806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048335473984479904,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10632169246673584,
      "backward_entropy": 0.0352360725402832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.734090805053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04838613048195839,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10621313254038493,
      "backward_entropy": 0.03529607653617859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.796127319335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04843497276306152,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10611178477605183,
      "backward_entropy": 0.03539634346961975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.838376998901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048483073711395264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10601284106572469,
      "backward_entropy": 0.03551247417926788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.731210708618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04853286221623421,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10590463876724243,
      "backward_entropy": 0.035634884238243104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.57047653198242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04858255013823509,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1057967742284139,
      "backward_entropy": 0.03574007749557495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.575255393981934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048635199666023254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10567222038904826,
      "backward_entropy": 0.006319716572761536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.490983963012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048684947192668915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10556275645891826,
      "backward_entropy": 0.03596559762954712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.363784790039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04873235523700714,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10546488563219707,
      "backward_entropy": 0.036069512367248535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.577567458152771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0487789660692215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10537028312683105,
      "backward_entropy": 0.036179208755493165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49055078625679016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048821039497852325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10529929399490356,
      "backward_entropy": 0.036290699243545534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.01680564880371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048859722912311554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10524432857831319,
      "backward_entropy": 0.036445409059524536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.30735397338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04889990761876106,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10517994562784831,
      "backward_entropy": 0.036614221334457395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.185572624206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04894672706723213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10508152842521667,
      "backward_entropy": 0.03674028813838959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.990076065063477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04899172857403755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1049915353457133,
      "backward_entropy": 0.036878162622451784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.07631778717041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04903597757220268,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10490453243255615,
      "backward_entropy": 0.03700573146343231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.79118537902832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04907878488302231,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10482410589853923,
      "backward_entropy": 0.037154284119606015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.326841354370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049121592193841934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10474225878715515,
      "backward_entropy": 0.037325266003608706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.500349044799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049166034907102585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10465153058369954,
      "backward_entropy": 0.03746269941329956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.965214729309082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04921063780784607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10456015666325887,
      "backward_entropy": 0.006064721196889877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.291427612304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049253176897764206,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10447935263315837,
      "backward_entropy": 0.0376606285572052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.56564712524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04929632321000099,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10439437627792358,
      "backward_entropy": 0.03774701952934265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.37297439575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04933857545256615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10431414842605591,
      "backward_entropy": 0.005979451537132263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.622928619384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049384184181690216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10421456893285115,
      "backward_entropy": 0.03789093196392059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.71944808959961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04943150654435158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1041049063205719,
      "backward_entropy": 0.005923007801175118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.679800987243652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04948267713189125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10397403438886006,
      "backward_entropy": 0.03804531395435333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.154272079467773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049531109631061554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10385780533154805,
      "backward_entropy": 0.03811091184616089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.637699127197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049578502774238586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10374627510706584,
      "backward_entropy": 0.03817934095859528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.097930908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049628812819719315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10361756881078084,
      "backward_entropy": 0.03826065957546234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.90733528137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04968208819627762,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10347327589988708,
      "backward_entropy": 0.03830188810825348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.28675651550293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049733955413103104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10333447655042012,
      "backward_entropy": 0.005748767033219337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.81484031677246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04978569597005844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10319564739863078,
      "backward_entropy": 0.0057203337550163266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.656827926635742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04983563721179962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1030674676100413,
      "backward_entropy": 0.005688288807868957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.398706436157227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0498846173286438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10294248660405476,
      "backward_entropy": 0.03853197693824768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.881196975708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049934618175029755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10281091928482056,
      "backward_entropy": 0.03858644366264343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.46144676208496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0499846488237381,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10267842809359233,
      "backward_entropy": 0.0386467695236206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.060518264770508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05003342777490616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10255177815755208,
      "backward_entropy": 0.03871139883995056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.819316387176514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500800646841526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1024358868598938,
      "backward_entropy": 0.005550494045019149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.06568908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05012283846735954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10234262545903523,
      "backward_entropy": 0.03884271085262299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.8346004486084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050168342888355255,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10223332047462463,
      "backward_entropy": 0.038879495859146115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.703733444213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05021708086133003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.102103590965271,
      "backward_entropy": 0.03894939124584198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.832196235656738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05026858299970627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1019565761089325,
      "backward_entropy": 0.03904257118701935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.751187324523926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050317518413066864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10182303190231323,
      "backward_entropy": 0.03914147317409515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.22591781616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05036439746618271,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10169986883799235,
      "backward_entropy": 0.03926077783107758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.012985229492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050412148237228394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10157221555709839,
      "backward_entropy": 0.03934289216995239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.820632934570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05046145245432854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10143426060676575,
      "backward_entropy": 0.005358633399009704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.75327491760254,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05051075667142868,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.101295272509257,
      "backward_entropy": 0.13862709999084472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.565363883972168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05055979639291763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10115790367126465,
      "backward_entropy": 0.039618569612503055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.54532241821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05060621351003647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10103541612625122,
      "backward_entropy": 0.039686155319213864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.471187591552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05065276101231575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10091134905815125,
      "backward_entropy": 0.03975157737731934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.334257125854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050702765583992004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10076665878295898,
      "backward_entropy": 0.005236580595374107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3931498527526855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050752658396959305,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10062141219774882,
      "backward_entropy": 0.0398652970790863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.1396427154541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05079884082078934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10049741466840108,
      "backward_entropy": 0.03993363976478577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.045682907104492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050845272839069366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10037001967430115,
      "backward_entropy": 0.005161219090223312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.77338981628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05089192092418671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1002403696378072,
      "backward_entropy": 0.040085282921791074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.48905563354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05094058811664581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10009891788164775,
      "backward_entropy": 0.005110166966915131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.968748092651367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05099216476082802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09994130333264668,
      "backward_entropy": 0.040144890546798706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.703075408935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05104181170463562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09979551037152608,
      "backward_entropy": 0.04014282822608948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.98231315612793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051090821623802185,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09965376059214275,
      "backward_entropy": 0.04012587070465088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.18133544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05113743618130684,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09952513376871745,
      "backward_entropy": 0.04012878835201263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.5938138961792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05118556320667267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09938268860181172,
      "backward_entropy": 0.04016250967979431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.22300148010254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051232729107141495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09924573699633281,
      "backward_entropy": 0.040221214294433594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.134134769439697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05128024145960808,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09910544753074646,
      "backward_entropy": 0.04030313491821289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.99618148803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0513240247964859,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09898788730303447,
      "backward_entropy": 0.04036715924739838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.017711639404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051368847489356995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09886130690574646,
      "backward_entropy": 0.040477678179740906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.82088851928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05141359567642212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0987352728843689,
      "backward_entropy": 0.04056288599967957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.609188079833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051461394876241684,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09859168529510498,
      "backward_entropy": 0.040603500604629514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.120549201965332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051512300968170166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09842913349469502,
      "backward_entropy": 0.040630707144737245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.017263412475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05156166851520538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09827507535616557,
      "backward_entropy": 0.04066342115402222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.567476272583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05160989612340927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09812622268994649,
      "backward_entropy": 0.0407214879989624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.939212799072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05165994539856911,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09796589612960815,
      "backward_entropy": 0.004699746891856193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.775486946105957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05171030014753342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09780286749204,
      "backward_entropy": 0.040783822536468506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.753226280212402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051759518682956696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09764516353607178,
      "backward_entropy": 0.04083674550056458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.238126754760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0518072135746479,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0974965790907542,
      "backward_entropy": 0.04088701605796814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.811516761779785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05185258388519287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09736177325248718,
      "backward_entropy": 0.040947568416595456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.788071155548096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05189454182982445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09724847475687663,
      "backward_entropy": 0.04100227355957031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.228208541870117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051933422684669495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09715376297632854,
      "backward_entropy": 0.04105175137519836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.76620101928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051973793655633926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09704941511154175,
      "backward_entropy": 0.00451735220849514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.344344139099121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052014563232660294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09694188833236694,
      "backward_entropy": 0.041106191277503965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.58634376525879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0520547516644001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0968368649482727,
      "backward_entropy": 0.041143101453781125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95781421661377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05209546908736229,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09672735134760539,
      "backward_entropy": 0.004434843733906746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.627099514007568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052134301513433456,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09662912289301555,
      "backward_entropy": 0.041220998764038085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.100325584411621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05217061936855316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09654571612675984,
      "backward_entropy": 0.041276201605796814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.032270431518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05220678821206093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09646238883336385,
      "backward_entropy": 0.004358921572566033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.399213790893555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0522429384291172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09637810786565144,
      "backward_entropy": 0.04140539467334747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770242691040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05228117108345032,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09627966086069743,
      "backward_entropy": 0.004315038025379181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730931282043457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05231763795018196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09619249900182088,
      "backward_entropy": 0.04153066575527191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.941057205200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05235251411795616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09611564874649048,
      "backward_entropy": 0.04156901836395264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.274700164794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05238877236843109,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0960281491279602,
      "backward_entropy": 0.04163671731948852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.459299087524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05242951959371567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09591065843900044,
      "backward_entropy": 0.04172694683074951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.740678787231445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052467554807662964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09580995639165242,
      "backward_entropy": 0.041830521821975705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.804393768310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05250627174973488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09570271770159404,
      "backward_entropy": 0.0419314444065094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.506054878234863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052547913044691086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09557612737019856,
      "backward_entropy": 0.04203683137893677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.476761817932129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05258893594145775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09545297423998515,
      "backward_entropy": 0.04214876592159271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.371254920959473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05262903869152069,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09533586104710896,
      "backward_entropy": 0.04224269688129425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.372844696044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052668776363134384,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09521959225336711,
      "backward_entropy": 0.04235433340072632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.209131240844727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05271069332957268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09509009122848511,
      "backward_entropy": 0.004104846343398094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.08136558532715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05275411158800125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09494934479395549,
      "backward_entropy": 0.04250545799732208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.069225311279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052799660712480545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0947944422562917,
      "backward_entropy": 0.042581173777580264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.256369113922119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0528450608253479,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09464000662167867,
      "backward_entropy": 0.042654895782470705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.288755893707275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05288700386881828,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0945075551668803,
      "backward_entropy": 0.042723584175109866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.708148956298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05292525142431259,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09440069397290547,
      "backward_entropy": 0.042742574214935304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.5416259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052964843809604645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09428491195042928,
      "backward_entropy": 0.042744877934455874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.446395874023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053006332367658615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09415429830551147,
      "backward_entropy": 0.04278681874275207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.536199569702148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05304940417408943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09401192267735799,
      "backward_entropy": 0.042850473523139955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.658430099487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05309275910258293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09386651714642842,
      "backward_entropy": 0.04292866289615631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824746131896973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05313534289598465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09372501571973164,
      "backward_entropy": 0.043024659156799316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.280881881713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05317620933055878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09359367688496907,
      "backward_entropy": 0.0038843952119350434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.011904716491699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05321754142642021,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09345821539560954,
      "backward_entropy": 0.043261343240737916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.585824966430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05325624719262123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0933389663696289,
      "backward_entropy": 0.043403834104537964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.360737800598145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05329716578125954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0932055115699768,
      "backward_entropy": 0.04350650012493133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.948969841003418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05333738401532173,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09307581186294556,
      "backward_entropy": 0.04361390471458435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.191686630249023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05337819457054138,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09294087688128154,
      "backward_entropy": 0.04373771548271179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.152079582214355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053421296179294586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09278994798660278,
      "backward_entropy": 0.04385107159614563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.099885940551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05346367135643959,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09264238675435384,
      "backward_entropy": 0.043984249234199524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.848170757293701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05350526422262192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09249878923098247,
      "backward_entropy": 0.044126132130622865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.286251068115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05354425683617592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09237140417098999,
      "backward_entropy": 0.04429199099540711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.929230690002441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05358652397990227,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09222232302029927,
      "backward_entropy": 0.044416165351867674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8550612926483154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0536278635263443,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09207889437675476,
      "backward_entropy": 0.04453894197940826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.298812866210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053665921092033386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09195829431215923,
      "backward_entropy": 0.0037408951669931413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7790279388427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05370466411113739,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09183133641878764,
      "backward_entropy": 0.04474366307258606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.211262702941895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05374070629477501,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09172226985295613,
      "backward_entropy": 0.04485475718975067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.031057357788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053777050226926804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09161148468653361,
      "backward_entropy": 0.003697715699672699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.891061782836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053815849125385284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0914837916692098,
      "backward_entropy": 0.04499965608119964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7100930213928223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05385706573724747,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09133857488632202,
      "backward_entropy": 0.045060598850250246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.277379989624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05389520898461342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09121417999267578,
      "backward_entropy": 0.04511613845825195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6687450408935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05393460765480995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09108105301856995,
      "backward_entropy": 0.04515466094017029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9647722244262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05397111177444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09096723794937134,
      "backward_entropy": 0.00360114686191082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.354784965515137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0540064238011837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09085963169733684,
      "backward_entropy": 0.003583550453186035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.572389602661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05404086410999298,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09075926740964253,
      "backward_entropy": 0.04529196619987488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.134004592895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05407603457570076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09065272410710652,
      "backward_entropy": 0.0035413846373558043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.705623626708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054113686084747314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09052908420562744,
      "backward_entropy": 0.04534582495689392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.389631271362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05415281653404236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09039407968521118,
      "backward_entropy": 0.045371454954147336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.034842491149902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05419175699353218,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0902607540289561,
      "backward_entropy": 0.045366698503494264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.986464500427246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05422978103160858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09013325969378154,
      "backward_entropy": 0.045357358455657956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.55275535583496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05426686629652977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0900125006834666,
      "backward_entropy": 0.045333123207092284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.60068941116333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05430620163679123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0898763636747996,
      "backward_entropy": 0.0453008770942688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.337461471557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05434427037835121,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08974642554918925,
      "backward_entropy": 0.04532522261142731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.88342571258545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0543842539191246,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08960220217704773,
      "backward_entropy": 0.04532188773155212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.95766544342041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05442426726222038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08945857485135396,
      "backward_entropy": 0.04531850516796112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.478347301483154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05446503683924675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08930959304173787,
      "backward_entropy": 0.045295292139053346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.668004035949707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05450396239757538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08917246262232463,
      "backward_entropy": 0.04529767632484436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.38006067276001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05454269051551819,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08903703093528748,
      "backward_entropy": 0.0452819287776947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.668529510498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05457999184727669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08890976508458455,
      "backward_entropy": 0.04530749022960663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.33015251159668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05462026968598366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08876202503840129,
      "backward_entropy": 0.04531027376651764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.297233581542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05466000735759735,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.088616281747818,
      "backward_entropy": 0.04535473585128784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.21315336227417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05469892919063568,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08847581346829732,
      "backward_entropy": 0.0454096257686615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.220096111297607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05473649874329567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08834298451741536,
      "backward_entropy": 0.04550393521785736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.067063331604004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054772309958934784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08822232484817505,
      "backward_entropy": 0.0455892413854599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.039518356323242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05480941757559776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08809234698613484,
      "backward_entropy": 0.04566029012203217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.083630084991455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05484636127948761,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08796154459317525,
      "backward_entropy": 0.04577413201332092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.810856819152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054881900548934937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08783989151318868,
      "backward_entropy": 0.0031247489154338838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.82785701751709,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05491861701011658,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08771018187204997,
      "backward_entropy": 0.13862885236740113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8427152633667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05495545640587807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08757941921552022,
      "backward_entropy": 0.046088886260986325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.648452758789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05499190092086792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08745008707046509,
      "backward_entropy": 0.0030875932425260544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.772587776184082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05502888932824135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08731567859649658,
      "backward_entropy": 0.04631896018981933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.183982849121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05506502464413643,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08718753854433696,
      "backward_entropy": 0.046427929401397706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.042106866836548,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05510321632027626,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08704480528831482,
      "backward_entropy": 0.046515700221061704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.583441734313965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05513869598507881,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08692073822021484,
      "backward_entropy": 0.04660716652870178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.096550941467285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05517375096678734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08679866790771484,
      "backward_entropy": 0.04671124517917633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.498090744018555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055210016667842865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08666799465815227,
      "backward_entropy": 0.04679685831069946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6884870529174805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055245548486709595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0865425964196523,
      "backward_entropy": 0.0030023179948329925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.376960754394531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05527971684932709,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.0864254633585612,
      "backward_entropy": 0.13862502574920654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.327714920043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05531355366110802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08630959192911784,
      "backward_entropy": 0.04707924127578735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.989028930664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055347077548503876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08619516094525655,
      "backward_entropy": 0.002968473732471466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.588652610778809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05538100004196167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08607776959737141,
      "backward_entropy": 0.047289276123046876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9305050373077393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05541626736521721,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08595032493273418,
      "backward_entropy": 0.04737427830696106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.06759262084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055448539555072784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0858458677927653,
      "backward_entropy": 0.04741332828998566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.060541152954102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05548318848013878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08572366833686829,
      "backward_entropy": 0.047444486618041994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03873062133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05551760643720627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08560175697008769,
      "backward_entropy": 0.0028959959745407104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.405397891998291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05555150285363197,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08548219998677571,
      "backward_entropy": 0.04758021831512451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.33559513092041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055583931505680084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08537290493647258,
      "backward_entropy": 0.047650814056396484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.459546089172363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055615440011024475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08526843786239624,
      "backward_entropy": 0.04775517880916595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849860191345215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05564757063984871,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08515910307566325,
      "backward_entropy": 0.047852742671966556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.280009746551514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05567937344312668,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08505149682362874,
      "backward_entropy": 0.04794711768627167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.221691608428955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05570988729596138,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08495330810546875,
      "backward_entropy": 0.04803226590156555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.24949312210083,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05573954060673714,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08486000696818034,
      "backward_entropy": 0.13861938714981079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.193043231964111,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05576780438423157,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08477772275606792,
      "backward_entropy": 0.048199978470802304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.116119384765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05579511821269989,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08470176657040913,
      "backward_entropy": 0.04826028048992157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.98572063446045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05582341551780701,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08461817105611165,
      "backward_entropy": 0.04831722378730774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.673255681991577,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055854432284832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08451428016026814,
      "backward_entropy": 0.04837082624435425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.357983589172363,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055883146822452545,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08442758520444234,
      "backward_entropy": 0.1386198878288269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.887483596801758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05591384693980217,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0843244989713033,
      "backward_entropy": 0.04847431480884552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.8362398147583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05594516545534134,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08421645561854045,
      "backward_entropy": 0.048533910512924196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.371774196624756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05597693473100662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0841047465801239,
      "backward_entropy": 0.048581814765930174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.378758430480957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056008338928222656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08399500449498494,
      "backward_entropy": 0.04863275289535522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.924777507781982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05603882297873497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08389292160669963,
      "backward_entropy": 0.048633080720901486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.973726272583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05606810748577118,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0837993323802948,
      "backward_entropy": 0.04863874316215515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.880858898162842,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056098587810993195,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08369807402292888,
      "backward_entropy": 0.13862440586090088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5443835258483887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056127678602933884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08360724647839864,
      "backward_entropy": 0.04857574105262756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.051450729370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05615448206663132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08353439966837566,
      "backward_entropy": 0.04852326214313507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.3515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056183766573667526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08344103892644246,
      "backward_entropy": 0.04846531450748444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.55100154876709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056213874369859695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08334132035573323,
      "backward_entropy": 0.048430216312408444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.014546871185303,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05624585226178169,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08322592576344807,
      "backward_entropy": 0.04843321442604065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.689936637878418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05627687647938728,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08311851819356282,
      "backward_entropy": 0.04839728474617004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.633293151855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05630658194422722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08302101492881775,
      "backward_entropy": 0.048364341259002686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3830199241638184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05633547902107239,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08292774359385173,
      "backward_entropy": 0.04836995005607605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.59122371673584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0563628114759922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08284443616867065,
      "backward_entropy": 0.002458382211625576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.558994770050049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05638938397169113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08276599645614624,
      "backward_entropy": 0.04847625494003296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.508841037750244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05641535669565201,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08269086976846059,
      "backward_entropy": 0.0485581248998642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.702375888824463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056441158056259155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08261542518933614,
      "backward_entropy": 0.048692870140075686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.309333562850952,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056466978043317795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08253985643386841,
      "backward_entropy": 0.048809653520584105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.499748229980469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056491605937480927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0824718177318573,
      "backward_entropy": 0.04896084666252136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.844842910766602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056515246629714966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08241194486618042,
      "backward_entropy": 0.04906858801841736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.824304580688477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05654129013419151,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.082332710425059,
      "backward_entropy": 0.0492013156414032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4137420654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0565689392387867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0822417289018631,
      "backward_entropy": 0.049305456876754764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2823739051818848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056595463305711746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08215926587581635,
      "backward_entropy": 0.04938811659812927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.623953819274902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056620143353939056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08209048708279927,
      "backward_entropy": 0.002365126088261604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.31371545791626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05664680525660515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08200597763061523,
      "backward_entropy": 0.04953545928001404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438033103942871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05667278543114662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08192520340283711,
      "backward_entropy": 0.04962852299213409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15127824246883392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056699689477682114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0818369189898173,
      "backward_entropy": 0.04972124099731445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.198188304901123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05672415345907211,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08176634709040324,
      "backward_entropy": 0.04983124434947968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.23126745223999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056747227907180786,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08170549074808757,
      "backward_entropy": 0.049950307607650755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2037248611450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05676977336406708,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08164804180463155,
      "backward_entropy": 0.050060755014419554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.233823776245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056791920214891434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0815928081671397,
      "backward_entropy": 0.002301204949617386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.197413444519043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05681515112519264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08152969678243001,
      "backward_entropy": 0.05025399327278137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.115986824035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056839264929294586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08146032691001892,
      "backward_entropy": 0.05030621290206909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1207950115203857,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05686469003558159,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08137977619965871,
      "backward_entropy": 0.13862229585647584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.008964538574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05688869208097458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08130884667237599,
      "backward_entropy": 0.050471580028533934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14332997798919678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056915175169706345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08121935526529948,
      "backward_entropy": 0.05053101778030396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.78979206085205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05693914741277695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08114824692408244,
      "backward_entropy": 0.05060132145881653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.018097877502441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05696689710021019,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08104781309763591,
      "backward_entropy": 0.05069082975387573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.870471000671387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05699368938803673,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08095394571622212,
      "backward_entropy": 0.050786787271499635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.478276252746582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05702095851302147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08085670073827107,
      "backward_entropy": 0.05085388422012329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8420538902282715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057051993906497955,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08073189357916515,
      "backward_entropy": 0.05089070796966553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.683132171630859,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05708252266049385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08061045904954274,
      "backward_entropy": 0.05093064308166504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.774631023406982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057113464921712875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08048556248346965,
      "backward_entropy": 0.0021787591278553007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13073140382766724,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057143643498420715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08036650220553081,
      "backward_entropy": 0.05100106000900269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35853099822998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057171016931533813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08026744922002156,
      "backward_entropy": 0.05104774236679077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.298735618591309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05720004066824913,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08015526831150055,
      "backward_entropy": 0.05111299157142639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.887077331542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05723045393824577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08003185192743938,
      "backward_entropy": 0.05118405818939209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.94554615020752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05726349353790283,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07988941172758739,
      "backward_entropy": 0.05123565196990967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.880578994750977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05729851499199867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07973118126392365,
      "backward_entropy": 0.05131550431251526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.213187217712402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057334885001182556,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07956352333227794,
      "backward_entropy": 0.05137816071510315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.963892936706543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05737115442752838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07939579586187999,
      "backward_entropy": 0.05145931839942932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.593801736831665,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05741089954972267,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07920343677202861,
      "backward_entropy": 0.13862209320068358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.022392749786377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057448647916316986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07902505993843079,
      "backward_entropy": 0.05158548355102539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.546614408493042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05748593807220459,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07885013024012248,
      "backward_entropy": 0.05166448354721069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.907672882080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05752119421958923,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07869025568167369,
      "backward_entropy": 0.051741892099380495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.491802930831909,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05755603313446045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07853399713834126,
      "backward_entropy": 0.05180126428604126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.112217903137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057588979601860046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07839176058769226,
      "backward_entropy": 0.051854103803634644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.448076009750366,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05762112885713577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07825489342212677,
      "backward_entropy": 0.05191556215286255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.186782836914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05765146389603615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07813198367754619,
      "backward_entropy": 0.05195585489273071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.770967721939087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05768521875143051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07798323531945546,
      "backward_entropy": 0.05200759768486023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.950921058654785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057716239243745804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07785515983899434,
      "backward_entropy": 0.05204249620437622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.310222864151001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057746533304452896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07773230969905853,
      "backward_entropy": 0.05207449197769165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.995032787322998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05777550861239433,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07761859397093455,
      "backward_entropy": 0.05211683511734009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11475732177495956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057805921882390976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.077492689092954,
      "backward_entropy": 0.052198398113250735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2413954734802246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057833608239889145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07738604148228963,
      "backward_entropy": 0.05230224132537842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.21858286857605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057860128581523895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07728795210520427,
      "backward_entropy": 0.0019772829487919807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.703968048095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057885583490133286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07719749212265015,
      "backward_entropy": 0.05248470306396484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6994500160217285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05791114270687103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07710508505503337,
      "backward_entropy": 0.0525968611240387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.632226467132568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05793644115328789,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07701448599497478,
      "backward_entropy": 0.052695244550704956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.621359825134277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05796191841363907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07692092657089233,
      "backward_entropy": 0.0019526544958353043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.096101760864258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057987287640571594,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07682763536771138,
      "backward_entropy": 0.05295648574829102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0754287242889404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05801182612776756,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07673987746238708,
      "backward_entropy": 0.05309155583381653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.544287204742432,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058035604655742645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07665714124838512,
      "backward_entropy": 0.05322825908660889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878927230834961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05805923789739609,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0765756368637085,
      "backward_entropy": 0.053344881534576415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.951663017272949,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05808520317077637,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07647609213987987,
      "backward_entropy": 0.053464877605438235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5558722019195557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05811132863163948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07637638350327809,
      "backward_entropy": 0.0019207650795578957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.121838569641113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05813569948077202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07628907263278961,
      "backward_entropy": 0.053617841005325316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.556221842765808,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05816298723220825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07617983222007751,
      "backward_entropy": 0.05369709730148316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.537627935409546,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058188144117593765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07608676950136821,
      "backward_entropy": 0.0537528395652771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.348258018493652,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05821146070957184,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07600729664166768,
      "backward_entropy": 0.1386094570159912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2521467208862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0582379586994648,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0759039322535197,
      "backward_entropy": 0.001878146640956402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.277902603149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05826437845826149,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07580071687698364,
      "backward_entropy": 0.05383340716361999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.960365295410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058290060609579086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07570411264896393,
      "backward_entropy": 0.05383670926094055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23923110961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05831671506166458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07560048500696818,
      "backward_entropy": 0.05382491946220398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.454268455505371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05834517255425453,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07548326253890991,
      "backward_entropy": 0.05382283926010132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.10113525390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058374110609292984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0753609836101532,
      "backward_entropy": 0.053864198923110965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7728583812713623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058402448892593384,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07524282236893971,
      "backward_entropy": 0.05391318202018738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.060773849487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05842922255396843,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07513698935508728,
      "backward_entropy": 0.05393634438514709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0132527351379395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05845526605844498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07503712177276611,
      "backward_entropy": 0.053932422399520875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.262845039367676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05848081409931183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07494087020556132,
      "backward_entropy": 0.053921359777450564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3704324960708618,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05850667133927345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07484191656112671,
      "backward_entropy": 0.053911954164505005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6559271812438965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058530934154987335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07475350300470988,
      "backward_entropy": 0.053932422399520875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8815739154815674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058554112911224365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07467318574587505,
      "backward_entropy": 0.0017584670335054398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.596426248550415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05857714265584946,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07459350923697154,
      "backward_entropy": 0.05395274162292481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.604159116744995,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05859944969415665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07451831797758739,
      "backward_entropy": 0.0539814829826355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.268959999084473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05862077698111534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07445092499256134,
      "backward_entropy": 0.05399126410484314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.553417205810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05864338204264641,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07437395056088765,
      "backward_entropy": 0.05398920774459839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1770524978637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058665141463279724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07430288195610046,
      "backward_entropy": 0.053986257314682005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.104877471923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058688122779130936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07422277331352234,
      "backward_entropy": 0.053977441787719724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.884650230407715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05871251970529556,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07413147886594136,
      "backward_entropy": 0.05399447679519653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.850095272064209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05873720347881317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07403838634490967,
      "backward_entropy": 0.054005444049835205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.977866172790527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05876205861568451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07394450902938843,
      "backward_entropy": 0.05400303602218628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.907403469085693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05878779664635658,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07384455700715382,
      "backward_entropy": 0.053993260860443114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.546143054962158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058814555406570435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07373657325903575,
      "backward_entropy": 0.05400373935699463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2631556987762451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058840926736593246,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07363093892733256,
      "backward_entropy": 0.05403934121131897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.623745441436768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058865178376436234,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07354165116945903,
      "backward_entropy": 0.05404940843582153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.589773654937744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05888984352350235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07344856361548106,
      "backward_entropy": 0.054068857431411745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2260419130325317,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05891479179263115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0733531912167867,
      "backward_entropy": 0.05409247875213623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.622885227203369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05893784016370773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07327179114023845,
      "backward_entropy": 0.054106134176254275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.395728826522827,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05896187201142311,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07318323850631714,
      "backward_entropy": 0.054114365577697755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2009555101394653,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05898536369204521,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07309890786806743,
      "backward_entropy": 0.054108619689941406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08245294541120529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05900702252984047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07302833596865337,
      "backward_entropy": 0.054090529680252075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.369805335998535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05902687460184097,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07296994825204213,
      "backward_entropy": 0.054111868143081665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.347395896911621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059047453105449677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07290541628996532,
      "backward_entropy": 0.054142159223556516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3621931076049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05906852334737778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07283771534760793,
      "backward_entropy": 0.05416010618209839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1937544345855713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05909073352813721,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07276162505149841,
      "backward_entropy": 0.001538982428610325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1839888095855713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05911194905638695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07269374032815297,
      "backward_entropy": 0.054168856143951415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.177840709686279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059133343398571014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07262282570203145,
      "backward_entropy": 0.05420523285865784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1283481121063232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0591556578874588,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07254334290822347,
      "backward_entropy": 0.05429008007049561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1148927211761475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05917809531092644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07246209184328715,
      "backward_entropy": 0.05441206693649292,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.285268248319626,
    "avg_log_Z": -0.05791285835206508,
    "success_rate": 1.0,
    "avg_reward": 16.9,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.88,
      "2": 0.09
    },
    "avg_forward_entropy": 0.07721320902307828,
    "avg_backward_entropy": 0.050553586870431905,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}