{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854225873947143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.72738647460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274100621541342,
      "backward_entropy": 0.13854169845581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.02049255371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18272989988327026,
      "backward_entropy": 0.13854670524597168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6759796142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0001999776141019538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18271867434183756,
      "backward_entropy": 0.13862857818603516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3671417236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00029938912484794855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182707150777181,
      "backward_entropy": 0.1385481834411621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.33802795410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003993393911514431,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18269534905751547,
      "backward_entropy": 0.13856079578399658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.8106689453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004996281932108104,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826832890510559,
      "backward_entropy": 0.1385651111602783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.87635803222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006006038165651262,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826711098353068,
      "backward_entropy": 0.13856924772262574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.9469451904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007015097653493285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18265875180562338,
      "backward_entropy": 0.13862541913986207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.5244903564453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008010640740394592,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182646115620931,
      "backward_entropy": 0.13857700824737548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.4886474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0009020398720167577,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826331615447998,
      "backward_entropy": 0.13858070373535156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.7664794921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010034772567451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18262000878651938,
      "backward_entropy": 0.13862228393554688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.02195739746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001101700239814818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826067566871643,
      "backward_entropy": 0.1386210560798645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.2982177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001201006816700101,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18259330590566,
      "backward_entropy": 0.13856481313705443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.6708984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013002686901018023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257967631022134,
      "backward_entropy": 0.13861820697784424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.23974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013994090259075165,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256582816441855,
      "backward_entropy": 0.138616681098938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.3721160888672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001498541096225381,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18255184094111124,
      "backward_entropy": 0.13859937191009522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.82044982910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0015995888970792294,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18253767490386963,
      "backward_entropy": 0.13860200643539428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.10458374023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017026950372382998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18252313137054443,
      "backward_entropy": 0.1386112689971924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.7954864501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018068213248625398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250838915506998,
      "backward_entropy": 0.13857414722442626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.83547973632812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019108791602775455,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249364693959555,
      "backward_entropy": 0.13860913515090942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3292236328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0020156623795628548,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18247846762339273,
      "backward_entropy": 0.13860478401184081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.63070678710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021203095093369484,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18246306975682577,
      "backward_entropy": 0.13861312866210937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.5260009765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0022238134406507015,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18244757254918417,
      "backward_entropy": 0.13861491680145263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.9713592529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023283378686755896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824317773183187,
      "backward_entropy": 0.1385812997817993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.9413299560547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024315891787409782,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18241578340530396,
      "backward_entropy": 0.13861809968948363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.20374298095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025337247643619776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239963054656982,
      "backward_entropy": 0.13858375549316407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.43544006347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002631920389831066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238325913747153,
      "backward_entropy": 0.1385891079902649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.89988708496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002732764231041074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18236643075942993,
      "backward_entropy": 0.1385857105255127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.20401000976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002833752892911434,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18234926462173462,
      "backward_entropy": 0.13858327865600586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.5898895263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002937933197245002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233164151509604,
      "backward_entropy": 0.13858020305633545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.55892944335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0030405246652662754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18231377998987833,
      "backward_entropy": 0.13858822584152222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.00257873535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0031417107675224543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18229568004608154,
      "backward_entropy": 0.13858890533447266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.73204040527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003244043793529272,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18227740128835043,
      "backward_entropy": 0.13862595558166504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.16189575195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0033462154679000378,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822588046391805,
      "backward_entropy": 0.13856754302978516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.6393585205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034504628274589777,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18223985036214194,
      "backward_entropy": 0.13856422901153564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.04063415527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035532175097614527,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18222177028656006,
      "backward_entropy": 0.13862745761871337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.8056640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003656077664345503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18220365047454834,
      "backward_entropy": 0.1385919451713562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.968505859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003758838865906,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18218592802683511,
      "backward_entropy": 0.13862816095352173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.7443389892578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038612247444689274,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18216808636983237,
      "backward_entropy": 0.1386284351348877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.9407196044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003963560797274113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18215004603068033,
      "backward_entropy": 0.13854658603668213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.5065460205078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004067995585501194,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18213156859079996,
      "backward_entropy": 0.13862886428833007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.62673950195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004174315836280584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18211271365483603,
      "backward_entropy": 0.1385936975479126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.806640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004277334548532963,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18209381898244223,
      "backward_entropy": 0.138629150390625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.38233947753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0043776067905128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18207550048828125,
      "backward_entropy": 0.13859398365020753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.35594177246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0044788578525185585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18205666542053223,
      "backward_entropy": 0.13852890729904174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.5150604248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004578794818371534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820377310117086,
      "backward_entropy": 0.13852534294128419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.29013061523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004680956713855267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18201824029286703,
      "backward_entropy": 0.13859384059906005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.2645721435547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004782787524163723,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18199803431828818,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.25721740722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004885863978415728,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18197770913441977,
      "backward_entropy": 0.13851478099822997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.42088317871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004986205138266087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195740381876627,
      "backward_entropy": 0.1385110378265381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.97488403320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005085481330752373,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18193701903025308,
      "backward_entropy": 0.13850717544555663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.1027374267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005185043904930353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18191631635030112,
      "backward_entropy": 0.13850319385528564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.27418518066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0052871787920594215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818950374921163,
      "backward_entropy": 0.13859257698059083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.6431884765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005391732323914766,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18187270561854044,
      "backward_entropy": 0.13862936496734618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.23876953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005495211575180292,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818497578303019,
      "backward_entropy": 0.13849120140075682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.25331115722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005598337855190039,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18182635307312012,
      "backward_entropy": 0.13859152793884277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.05461883544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005698301363736391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18180272976557413,
      "backward_entropy": 0.13859100341796876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.48680114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005793960299342871,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18177900711695352,
      "backward_entropy": 0.1384793758392334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.72610473632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005891175474971533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18175458908081055,
      "backward_entropy": 0.1385895848274231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.80467224121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005987150128930807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18172975381215414,
      "backward_entropy": 0.13847169876098633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.51339721679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006084556691348553,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817042032877604,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.09619140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006181556265801191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1816788911819458,
      "backward_entropy": 0.1385869264602661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.59593200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006281379144638777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18165282408396402,
      "backward_entropy": 0.13858604431152344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.77719116210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006379661150276661,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18162639935811362,
      "backward_entropy": 0.13862912654876708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.8911895751953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006476784590631723,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18159975608189902,
      "backward_entropy": 0.13862912654876708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1038360595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006574274506419897,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18157277504603067,
      "backward_entropy": 0.13844695091247558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.69908142089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006670583970844746,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18154547611872354,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.99819946289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006773431785404682,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18151692549387613,
      "backward_entropy": 0.13843820095062256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.9307098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006876156199723482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18148825565973917,
      "backward_entropy": 0.138579797744751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.70594787597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006982243154197931,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18145869175593057,
      "backward_entropy": 0.1384289264678955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.89265441894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00708760367706418,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18142886956532797,
      "backward_entropy": 0.1384241223335266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.75448608398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007188176270574331,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18139932552973428,
      "backward_entropy": 0.13841915130615234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.86082458496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007289967034012079,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18136926492055258,
      "backward_entropy": 0.13857539892196655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.43533325195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007389989215880632,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1813389261563619,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.50515747070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007488538511097431,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813084085782369,
      "backward_entropy": 0.13857297897338866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.42018127441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007584550883620977,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18127799034118652,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.44137573242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007674929685890675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18124775091807047,
      "backward_entropy": 0.1385704517364502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.06752014160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007766297087073326,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18121697505315146,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.5983428955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007859529927372932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1811850666999817,
      "backward_entropy": 0.13838040828704834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0057830810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007951351813971996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1811522642771403,
      "backward_entropy": 0.13856641054153443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.48497009277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00804236438125372,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18111894528071085,
      "backward_entropy": 0.138629150390625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 271.13623046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008131287060678005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810853878657023,
      "backward_entropy": 0.1385632038116455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.98571014404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00822879932820797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810497840245565,
      "backward_entropy": 0.13856146335601807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.85813903808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008319280110299587,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18101499478022257,
      "backward_entropy": 0.13862919807434082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.4564666748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008409036323428154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18097972869873047,
      "backward_entropy": 0.13855787515640258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.2611541748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00850230734795332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1809433102607727,
      "backward_entropy": 0.13855597972869874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.74186325073242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008599829860031605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1809054215749105,
      "backward_entropy": 0.13833742141723632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.61856079101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008687105029821396,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18086894353230795,
      "backward_entropy": 0.13833162784576417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.895751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00877573061734438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18083218733469644,
      "backward_entropy": 0.13832533359527588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.88987731933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008864914998412132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18079457680384317,
      "backward_entropy": 0.13831937313079834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.00814819335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008949397131800652,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18075756231943765,
      "backward_entropy": 0.1383128881454468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.11062622070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009038290940225124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18071947495142618,
      "backward_entropy": 0.13854379653930665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.0208740234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00912521593272686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18068118890126547,
      "backward_entropy": 0.13829890489578248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.4266357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009208854287862778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18064284324645996,
      "backward_entropy": 0.13853967189788818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.42133331298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009290959686040878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1806041200955709,
      "backward_entropy": 0.13853731155395507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.4543228149414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009370741434395313,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1805657148361206,
      "backward_entropy": 0.13862929344177247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.87232971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009444915689527988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18052802483240762,
      "backward_entropy": 0.13853267431259156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.06590270996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009522054344415665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18048971891403198,
      "backward_entropy": 0.13826191425323486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.0127716064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009602080099284649,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18045089642206827,
      "backward_entropy": 0.13852860927581787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0183868408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009687058627605438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18041054407755533,
      "backward_entropy": 0.1385267734527588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.5026397705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009771696291863918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18036921819051108,
      "backward_entropy": 0.1382347583770752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.717529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009859458543360233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1803267995516459,
      "backward_entropy": 0.13822565078735352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.5555419921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009942307136952877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1802846590677897,
      "backward_entropy": 0.1385200262069702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.23739624023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010028158314526081,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18024102846781412,
      "backward_entropy": 0.1382077693939209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.2741241455078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010113484226167202,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18019640445709229,
      "backward_entropy": 0.13862919807434082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.01832580566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010197392664849758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18015160163243613,
      "backward_entropy": 0.13851158618927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.20521545410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010282854549586773,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18010574579238892,
      "backward_entropy": 0.13862922191619872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.4024200439453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010368432849645615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1800593932469686,
      "backward_entropy": 0.13862924575805663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.36799621582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010454353876411915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1800127625465393,
      "backward_entropy": 0.1385028839111328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.20913696289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010535912588238716,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799667477607727,
      "backward_entropy": 0.1381550908088684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.43861389160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010620707646012306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17991910378138223,
      "backward_entropy": 0.13814539909362794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.40425109863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010702486149966717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17987140019734701,
      "backward_entropy": 0.13849420547485353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.23265838623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010781555436551571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17982361714045206,
      "backward_entropy": 0.13849092721939088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.69363403320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010858552530407906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17977599302927652,
      "backward_entropy": 0.13848774433135985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.82264709472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010934808291494846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17972769339879355,
      "backward_entropy": 0.1384843111038208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.90664672851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011015298776328564,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17967788378397623,
      "backward_entropy": 0.13862909078598024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.99755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01109923142939806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17962624629338583,
      "backward_entropy": 0.13808399438858032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.85430145263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01118529587984085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17957385381062826,
      "backward_entropy": 0.13847439289093016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.6567840576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011266760528087616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1795219381650289,
      "backward_entropy": 0.1380609393119812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.0299072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01135040633380413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17946787675221762,
      "backward_entropy": 0.1384677529335022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.30970764160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011434351094067097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17941192785898843,
      "backward_entropy": 0.1384643316268921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.5588836669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011520004831254482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17935403188069662,
      "backward_entropy": 0.13802502155303956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.00428771972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011605881154537201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17929498354593912,
      "backward_entropy": 0.13845691680908204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.46226501464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011688681319355965,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17923561731974283,
      "backward_entropy": 0.13862895965576172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.33433532714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011774761602282524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1791739265124003,
      "backward_entropy": 0.13798877000808715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.50711822509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011865276843309402,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1791097323099772,
      "backward_entropy": 0.13797723054885863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.98196411132812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011952369473874569,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17904549837112427,
      "backward_entropy": 0.13862898349761962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.92457580566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012040873058140278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1789795160293579,
      "backward_entropy": 0.137954044342041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.49278259277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012130645103752613,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17891196409861246,
      "backward_entropy": 0.13794267177581787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.2721405029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01222167070955038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17884298165639242,
      "backward_entropy": 0.13842471837997436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.0594482421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012312041595578194,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1787728468577067,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.9434814453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012400017119944096,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17870187759399414,
      "backward_entropy": 0.13790949583053588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.8994598388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01248957123607397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17862985531489053,
      "backward_entropy": 0.13789811134338378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.7562026977539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01258290559053421,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1785548528035482,
      "backward_entropy": 0.13862926959991456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.23590850830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012670444324612617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17848026752471924,
      "backward_entropy": 0.1378784418106079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.05513000488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012751969508826733,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1784075895945231,
      "backward_entropy": 0.13786711692810058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.40025329589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012827454134821892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17833582560221353,
      "backward_entropy": 0.1378560781478882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.61216735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012904379516839981,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.178262988726298,
      "backward_entropy": 0.13837084770202637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.75636291503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012979384511709213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17819021145502725,
      "backward_entropy": 0.13836394548416137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.71327209472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013058827258646488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1781148910522461,
      "backward_entropy": 0.13781429529190065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.9189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013138854876160622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17803790171941122,
      "backward_entropy": 0.13835036754608154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.70787048339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013219654560089111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1779596209526062,
      "backward_entropy": 0.1383434295654297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.74612426757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013302741572260857,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17787947257359824,
      "backward_entropy": 0.13776881694793702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.90737915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013387531973421574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17779703934987387,
      "backward_entropy": 0.13832955360412597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.11575317382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013473210856318474,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17771434783935547,
      "backward_entropy": 0.1386293888092041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.4457550048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013559925369918346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17763161659240723,
      "backward_entropy": 0.13831976652145386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.47605895996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01364833489060402,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17754693826039633,
      "backward_entropy": 0.13862929344177247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.7715606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013737916946411133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17745989561080933,
      "backward_entropy": 0.13766770362854003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.53164672851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013828436844050884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17737040917078653,
      "backward_entropy": 0.1383045196533203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.83981323242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013917443342506886,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17728106180826822,
      "backward_entropy": 0.138629150390625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.9415283203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014004976488649845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17719151576360068,
      "backward_entropy": 0.13829302787780762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.8173065185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01409267820417881,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17710081736246744,
      "backward_entropy": 0.13758357763290405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.08705139160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014178691431879997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17700976133346558,
      "backward_entropy": 0.13827955722808838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.83912658691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014265279285609722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17691832780838013,
      "backward_entropy": 0.13827295303344728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.1897430419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014351798221468925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17682578166325888,
      "backward_entropy": 0.13751709461212158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.13211059570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014437240548431873,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17673379182815552,
      "backward_entropy": 0.13862893581390381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.31695556640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014521722681820393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17664156357447305,
      "backward_entropy": 0.1382528066635132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.10800170898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014603712595999241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17654975255330405,
      "backward_entropy": 0.13744041919708253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.68052673339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014691133983433247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17645404736200967,
      "backward_entropy": 0.1386286973953247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.21400451660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014777161180973053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1763577659924825,
      "backward_entropy": 0.1382349967956543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.45471954345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014868411235511303,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17625804742177328,
      "backward_entropy": 0.13735463619232177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.11471557617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01495447289198637,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1761593222618103,
      "backward_entropy": 0.1382238507270813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.18772888183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01504361443221569,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1760570208231608,
      "backward_entropy": 0.13821650743484498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.2900848388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015138380229473114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17594953378041586,
      "backward_entropy": 0.1372752904891968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.25267791748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015231345780193806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1758426030476888,
      "backward_entropy": 0.13819916248321534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.4277572631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015318947844207287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17573702335357666,
      "backward_entropy": 0.13819003105163574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.56033325195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015400414355099201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17563347021738687,
      "backward_entropy": 0.13818106651306153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.6387939453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015484318137168884,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17552655935287476,
      "backward_entropy": 0.13862844705581664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.76295471191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015566141344606876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1754205028216044,
      "backward_entropy": 0.13713152408599855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.0407257080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01565026119351387,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17531128724416098,
      "backward_entropy": 0.13709790706634523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.27450561523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015736324712634087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17519895235697427,
      "backward_entropy": 0.1370655655860901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.92005920410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015821019187569618,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1750856637954712,
      "backward_entropy": 0.13703396320343017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.07716369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015904249623417854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17497098445892334,
      "backward_entropy": 0.13812841176986695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.78456115722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01598827913403511,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1748547156651815,
      "backward_entropy": 0.13811805248260497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.45320129394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01606938987970352,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1747382084528605,
      "backward_entropy": 0.13694236278533936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.2100372314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016144517809152603,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1746234893798828,
      "backward_entropy": 0.13691327571868897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.47676849365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016221176832914352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17450648546218872,
      "backward_entropy": 0.13808059692382812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.061767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016296396031975746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17439019680023193,
      "backward_entropy": 0.13806960582733155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.77347564697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016373157501220703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17427146434783936,
      "backward_entropy": 0.1368090271949768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.59431457519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016447992995381355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17415253321329752,
      "backward_entropy": 0.13804757595062256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.06055450439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016521835699677467,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1740345557530721,
      "backward_entropy": 0.13672807216644287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.05184936523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016592370346188545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17391717433929443,
      "backward_entropy": 0.1380287528038025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.46041870117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01666637696325779,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1737953027089437,
      "backward_entropy": 0.13801789283752441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.30511474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016740312799811363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17367170254389444,
      "backward_entropy": 0.13660247325897218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.06138610839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016810446977615356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1735480229059855,
      "backward_entropy": 0.13799129724502562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.8847198486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016885528340935707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17341852188110352,
      "backward_entropy": 0.13653078079223632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.86009216308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016971169039607048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17327916622161865,
      "backward_entropy": 0.1379591703414917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.40318298339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017060086131095886,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1731353998184204,
      "backward_entropy": 0.13646754026412963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.0242919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017152048647403717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17298760016759238,
      "backward_entropy": 0.13792396783828736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.88278198242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01723758690059185,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1728442907333374,
      "backward_entropy": 0.1363988399505615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.3822021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017322232946753502,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17270106077194214,
      "backward_entropy": 0.13635594844818116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.8140869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017403695732355118,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17255763212839761,
      "backward_entropy": 0.13631685972213745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.97459411621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017483968287706375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1724126935005188,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.12835693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017557386308908463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17227325836817423,
      "backward_entropy": 0.13783800601959229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.71729278564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017629116773605347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17213348547617593,
      "backward_entropy": 0.1361960530281067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.64813995361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017696423456072807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1719969908396403,
      "backward_entropy": 0.13780324459075927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.2365951538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017762787640094757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17185984055201212,
      "backward_entropy": 0.13778566122055053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.53543090820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017828434705734253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17172219355901083,
      "backward_entropy": 0.13605096340179443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.9668197631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01789848692715168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17157995700836182,
      "backward_entropy": 0.13775235414505005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.75301361083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017966005951166153,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17143930991490683,
      "backward_entropy": 0.13593748807907105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.68907928466797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0180271714925766,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17130178213119507,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.77890014648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018087545409798622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17116204897562662,
      "backward_entropy": 0.13769853115081787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.42200469970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018150867894291878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17101780573527017,
      "backward_entropy": 0.13767712116241454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.20201110839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018212096765637398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17087443669637045,
      "backward_entropy": 0.13765604496002198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.30252838134766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01827451027929783,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17072800795237222,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.65660858154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018334930762648582,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17058241367340088,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.3480224609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018394919112324715,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17043517033259073,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.0877227783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018457958474755287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17028323809305826,
      "backward_entropy": 0.137565016746521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.46189880371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018530314788222313,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17012105385462442,
      "backward_entropy": 0.135456383228302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.32621002197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018605060875415802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1699566642443339,
      "backward_entropy": 0.13539103269577027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.58063507080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018676478415727615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16979408264160156,
      "backward_entropy": 0.1375034809112549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.85450744628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01874515227973461,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16963350772857666,
      "backward_entropy": 0.13748342990875245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.1006317138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01881818100810051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16946824391682944,
      "backward_entropy": 0.13518247604370118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.67808532714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01889319345355034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1692996621131897,
      "backward_entropy": 0.13744912147521973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.67911529541016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01896975189447403,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16912742455800375,
      "backward_entropy": 0.138629150390625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.90396881103516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01904108375310898,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16895880301793417,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.47047424316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01910981722176075,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16879250605901083,
      "backward_entropy": 0.13862900733947753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.6090545654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019177451729774475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16862533489863077,
      "backward_entropy": 0.13479530811309814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.31175231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019247660413384438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16845413049062094,
      "backward_entropy": 0.137349534034729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.41651916503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01931663416326046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16828225056330362,
      "backward_entropy": 0.13463096618652343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.57220458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01938769780099392,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16810564200083414,
      "backward_entropy": 0.13730254173278808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.1167755126953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01945546269416809,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1679298480351766,
      "backward_entropy": 0.1386288285255432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.08586120605469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019526919350028038,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16774719953536987,
      "backward_entropy": 0.1386289954185486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.1160888671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019595917314291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16756765047709146,
      "backward_entropy": 0.13721010684967042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.97274780273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019665557891130447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16738547881444296,
      "backward_entropy": 0.1371803641319275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.508056640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01974077895283699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1671950419743856,
      "backward_entropy": 0.13715105056762694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.0001983642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019821112975478172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16699755191802979,
      "backward_entropy": 0.13410855531692506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.87456512451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019902288913726807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16679630676905313,
      "backward_entropy": 0.1370926856994629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.9495391845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019981037825345993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16659571727116904,
      "backward_entropy": 0.13705880641937257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.16880798339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020059699192643166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16639461119969687,
      "backward_entropy": 0.133878755569458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.53123474121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02013779617846012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1661916971206665,
      "backward_entropy": 0.13380258083343505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.87869262695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020216986536979675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16598484913508096,
      "backward_entropy": 0.13373162746429443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.2884521484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02029910311102867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16577313343683878,
      "backward_entropy": 0.13691394329071044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.30254364013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020381907001137733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16555806001027426,
      "backward_entropy": 0.13687206506729127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.05685424804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02046213671565056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16534429788589478,
      "backward_entropy": 0.13682880401611328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.372314453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020543616265058517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16512795289357504,
      "backward_entropy": 0.136787748336792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.83197021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0206211656332016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.164915402730306,
      "backward_entropy": 0.1333646297454834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.44834899902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02070060931146145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16470072666803995,
      "backward_entropy": 0.13671157360076905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.13072204589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020784545689821243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16447860995928446,
      "backward_entropy": 0.13318190574645997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.19467163085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020865680649876595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1642575959364573,
      "backward_entropy": 0.13663101196289062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.22733306884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02095315419137478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16402846574783325,
      "backward_entropy": 0.13300416469573975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.16902923583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02103246934711933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1638093888759613,
      "backward_entropy": 0.13291289806365966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.718994140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02110794186592102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16359408696492514,
      "backward_entropy": 0.13650662899017335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.69209289550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02118697762489319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16337299346923828,
      "backward_entropy": 0.1364661455154419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.4801483154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021260570734739304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16315738360087076,
      "backward_entropy": 0.13642373085021972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.6746368408203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021334132179617882,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16293917099634805,
      "backward_entropy": 0.1386293888092041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.30994415283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021409636363387108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16271719336509705,
      "backward_entropy": 0.13632800579071044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.7021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02148318663239479,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16249515612920126,
      "backward_entropy": 0.13233439922332763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.58602142333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021558208391070366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16226796309153238,
      "backward_entropy": 0.13621737957000732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.69548034667969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021630195900797844,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16204520066579184,
      "backward_entropy": 0.13862929344177247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.73173522949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021695921197533607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618309219678243,
      "backward_entropy": 0.1361090660095215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.0887451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02175941690802574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1616191267967224,
      "backward_entropy": 0.13605657815933228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.42965698242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021819015964865685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16141132513682047,
      "backward_entropy": 0.1360013961791992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.4961700439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02188177779316902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16119656960169473,
      "backward_entropy": 0.13594313859939575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.65873718261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0219523087143898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16096832354863486,
      "backward_entropy": 0.13163387775421143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.69491577148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022016223520040512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1607471505800883,
      "backward_entropy": 0.13581485748291017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.94721984863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022086312994360924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16051564613978067,
      "backward_entropy": 0.13144276142120362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.05426788330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022150453180074692,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16029350956281027,
      "backward_entropy": 0.13133546113967895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.350711822509766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02221125364303589,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16007810831069946,
      "backward_entropy": 0.13862922191619872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.9442367553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022265104576945305,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15987253189086914,
      "backward_entropy": 0.1310760498046875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.15535736083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02231791988015175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15966761112213135,
      "backward_entropy": 0.1309398293495178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.59380340576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022368399426341057,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15946699182192484,
      "backward_entropy": 0.13078866004943848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.330078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022415779531002045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15926682949066162,
      "backward_entropy": 0.13065727949142455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.5281219482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022461244836449623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15906989574432373,
      "backward_entropy": 0.13533012866973876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.66990661621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02251361310482025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15886205434799194,
      "backward_entropy": 0.1352755069732666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.81449890136719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02257331646978855,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15864030520121256,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.34722137451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022631673142313957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15842114885648093,
      "backward_entropy": 0.13515858650207518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.8785171508789,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022688575088977814,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15820340315500894,
      "backward_entropy": 0.13862931728363037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.89879608154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02274392358958721,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1579860250155131,
      "backward_entropy": 0.12973520755767823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.76534271240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022800277918577194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15776822964350382,
      "backward_entropy": 0.12955886125564575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.98445892333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022855514660477638,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15755184491475424,
      "backward_entropy": 0.12937694787979126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.317626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022909626364707947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1573361853758494,
      "backward_entropy": 0.1291942596435547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.25407409667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022969461977481842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710949897766113,
      "backward_entropy": 0.13482109308242798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.0091552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02303079143166542,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1568775773048401,
      "backward_entropy": 0.12885441780090331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.58169555664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02309027686715126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15664740403493246,
      "backward_entropy": 0.13468148708343505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.56107330322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023153074085712433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15640961130460104,
      "backward_entropy": 0.13460488319396974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.46244812011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023217206820845604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15616594751675925,
      "backward_entropy": 0.13452370166778566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.68094635009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02327730320394039,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15592539310455322,
      "backward_entropy": 0.12823286056518554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.89423370361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02333364076912403,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15568778912226358,
      "backward_entropy": 0.12809112071990966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.32037353515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023388894274830818,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15545187393824259,
      "backward_entropy": 0.13424930572509766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.90228271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023442553356289864,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15521526336669922,
      "backward_entropy": 0.13414783477783204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.20076751708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023498499765992165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15497295061747232,
      "backward_entropy": 0.13404226303100586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.3798828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023553164675831795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15473188956578574,
      "backward_entropy": 0.13393588066101075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.6983871459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02359730191528797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15450644493103027,
      "backward_entropy": 0.12738611698150634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.28843688964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02364145591855049,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15428108970324197,
      "backward_entropy": 0.1336960792541504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.3734588623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02368849888443947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1540465255578359,
      "backward_entropy": 0.12712314128875732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.41609954833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023740436881780624,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15380342801411948,
      "backward_entropy": 0.12698707580566407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.29105377197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023794742301106453,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1535544196764628,
      "backward_entropy": 0.126854407787323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.02863311767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023848071694374084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15330756704012552,
      "backward_entropy": 0.13320107460021974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.3839111328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023896632716059685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1530678073565165,
      "backward_entropy": 0.13307204246520996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.2677993774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023953163996338844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1528128683567047,
      "backward_entropy": 0.13294222354888915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.18992614746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024008378386497498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15256027380625406,
      "backward_entropy": 0.1262820243835449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.9869842529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02406434528529644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15230721235275269,
      "backward_entropy": 0.126117742061615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.5253143310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02412446402013302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15204749504725137,
      "backward_entropy": 0.1325780153274536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.64485931396484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024188436567783356,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15178235371907553,
      "backward_entropy": 0.1386265516281128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.36746215820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024248922243714333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15152517954508463,
      "backward_entropy": 0.13237227201461793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.23133850097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02431274577975273,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1512603759765625,
      "backward_entropy": 0.1386275053024292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.29132843017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02437659725546837,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1509969731171926,
      "backward_entropy": 0.1386279821395874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.71190643310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024434654042124748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15074251095453897,
      "backward_entropy": 0.13203598260879518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.7598876953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02448919415473938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15049240986506143,
      "backward_entropy": 0.13190441131591796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.63752746582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02454325743019581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1502465009689331,
      "backward_entropy": 0.13179017305374147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.24988555908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02459457516670227,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15000549952189127,
      "backward_entropy": 0.12428529262542724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.00987243652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0246435459703207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1497693657875061,
      "backward_entropy": 0.12404685020446778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.93518829345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024688569828867912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1495408316453298,
      "backward_entropy": 0.13143590688705445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.16505432128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024732962250709534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14930995305379233,
      "backward_entropy": 0.12360150814056396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.02901458740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02478226274251938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14906630913416544,
      "backward_entropy": 0.13113291263580323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.90202713012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02482892945408821,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14882575472195944,
      "backward_entropy": 0.13096487522125244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.3240966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024869907647371292,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14859608809153238,
      "backward_entropy": 0.13079066276550294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.36153411865234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024911168962717056,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1483657956123352,
      "backward_entropy": 0.13862864971160888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.55746459960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024952193722128868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14813278118769327,
      "backward_entropy": 0.13042649030685424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.4095458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02500249817967415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14788409074147543,
      "backward_entropy": 0.13024938106536865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.14502716064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025052417069673538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14763808250427246,
      "backward_entropy": 0.13007988929748535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.0348663330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025101620703935623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14739256103833517,
      "backward_entropy": 0.12990376949310303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.28719329833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025162359699606895,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1471248666445414,
      "backward_entropy": 0.12191855907440186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.81432342529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025223374366760254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14685835440953574,
      "backward_entropy": 0.1295514464378357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.62334442138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02528074011206627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14659810066223145,
      "backward_entropy": 0.12150483131408692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.93799591064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025332601740956306,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14634504914283752,
      "backward_entropy": 0.12915959358215331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.425880432128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025383805856108665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1460946798324585,
      "backward_entropy": 0.1211383581161499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.2510986328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025428760796785355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1458560029665629,
      "backward_entropy": 0.128739595413208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.30414581298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02547350339591503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14561733603477478,
      "backward_entropy": 0.1285173177719116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.40189361572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025514859706163406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14538756012916565,
      "backward_entropy": 0.1283010482788086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.4553985595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025557968765497208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14515240987141928,
      "backward_entropy": 0.12807116508483887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.07370376586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025606080889701843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14490532875061035,
      "backward_entropy": 0.12783044576644897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.18363952636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025648251175880432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1446695327758789,
      "backward_entropy": 0.12002359628677368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.712249755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025690259411931038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14443224668502808,
      "backward_entropy": 0.1273162245750427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.66744995117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02572481334209442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.144207497437795,
      "backward_entropy": 0.11971784830093384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.72315216064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025767449289560318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14396844307581583,
      "backward_entropy": 0.11955535411834717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.1456298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025812096893787384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14372720321019491,
      "backward_entropy": 0.1264970064163208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.65152740478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025854866951704025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1434903840223948,
      "backward_entropy": 0.12623239755630494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.55499267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025898287072777748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14325652519861856,
      "backward_entropy": 0.12599098682403564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.47542572021484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025943536311388016,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1430190106232961,
      "backward_entropy": 0.1386167287826538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.61248779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025988712906837463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14278237024943033,
      "backward_entropy": 0.12549715042114257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.51961517333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026033706963062286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14254595836003622,
      "backward_entropy": 0.11825281381607056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.09281158447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02607729472219944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14231626192728677,
      "backward_entropy": 0.12500169277191162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.44046020507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026124322786927223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420780817667643,
      "backward_entropy": 0.12474603652954101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.56584930419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02617676556110382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14183229207992554,
      "backward_entropy": 0.12450748682022095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.87589263916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0262259803712368,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1415885090827942,
      "backward_entropy": 0.11724910736083985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.58265686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026275115087628365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1413485904534658,
      "backward_entropy": 0.12396880388259887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.71832275390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02632542885839939,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14110583066940308,
      "backward_entropy": 0.12369838953018189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.729736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02637249231338501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14086347818374634,
      "backward_entropy": 0.1233853816986084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.18115997314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02642805129289627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14060529073079428,
      "backward_entropy": 0.12307560443878174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.51093292236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026477206498384476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14036186536153158,
      "backward_entropy": 0.12276415824890137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.44719696044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026524078100919724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1401228109995524,
      "backward_entropy": 0.1224478006362915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.78562927246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02656727284193039,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1398932139078776,
      "backward_entropy": 0.115703284740448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.05357360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0266085397452116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13966625928878784,
      "backward_entropy": 0.12180285453796387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.325237274169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02664993889629841,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13943841060002646,
      "backward_entropy": 0.11527416706085206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.2896957397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026681970804929733,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1392254630724589,
      "backward_entropy": 0.11509590148925782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.88983917236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02671481855213642,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13900870084762573,
      "backward_entropy": 0.11493370532989503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.57575225830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026749003678560257,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1387920379638672,
      "backward_entropy": 0.11474541425704957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.07634735107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02678602561354637,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13857070604960123,
      "backward_entropy": 0.11992509365081787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.4864273071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02682175673544407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13835108280181885,
      "backward_entropy": 0.11434749364852906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.84525299072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026858555153012276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13813180724779764,
      "backward_entropy": 0.11412611007690429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.9311294555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02689608559012413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1379112402598063,
      "backward_entropy": 0.11877744197845459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.92510223388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026935676112771034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13768450419108072,
      "backward_entropy": 0.11836925745010377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.93378448486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026968101039528847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13747079173723856,
      "backward_entropy": 0.11354100704193115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.58512878417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027001939713954926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13725605607032776,
      "backward_entropy": 0.11334567070007324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.9013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027034716680645943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13704256216684976,
      "backward_entropy": 0.11707421541213989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.85595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027068767696619034,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13682816425959268,
      "backward_entropy": 0.11297612190246582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.7782211303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02710198052227497,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13661582271258035,
      "backward_entropy": 0.11620705127716065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.37401580810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027134908363223076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1364081601301829,
      "backward_entropy": 0.1157960057258606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.67193603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027167238295078278,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13620258371035257,
      "backward_entropy": 0.11537848711013794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.49330139160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027198338881134987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13599461317062378,
      "backward_entropy": 0.11491663455963134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.98442840576172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027239779010415077,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13576783736546835,
      "backward_entropy": 0.13858046531677246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.30356216430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027281207963824272,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355396012465159,
      "backward_entropy": 0.11399915218353271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.49862289428711,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027319103479385376,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13531784216562906,
      "backward_entropy": 0.1385749101638794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.5038070678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0273541621863842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1351043482621511,
      "backward_entropy": 0.11303492784500122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.44694519042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027391739189624786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1348846753438314,
      "backward_entropy": 0.1125407338142395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.0253677368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02743016742169857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13466596603393555,
      "backward_entropy": 0.11205976009368897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.51241683959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02746715024113655,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13444880644480386,
      "backward_entropy": 0.11072337627410889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.93758392333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02750117890536785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13423778613408408,
      "backward_entropy": 0.11053522825241088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.49939727783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027541929855942726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13401712973912558,
      "backward_entropy": 0.11054890155792237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.72614288330078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027585221454501152,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13379603624343872,
      "backward_entropy": 0.13855918645858764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.0179443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027625173330307007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13358265161514282,
      "backward_entropy": 0.10961024761199951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.44043731689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027664223685860634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13337566455205283,
      "backward_entropy": 0.10916240215301513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.84925079345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027707543224096298,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13316120704015097,
      "backward_entropy": 0.10920414924621583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.57713317871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027750857174396515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13294551769892374,
      "backward_entropy": 0.10823123455047608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.79972076416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02780173532664776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13271764914194742,
      "backward_entropy": 0.10864702463150025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.62983703613281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027855703607201576,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13248513142267862,
      "backward_entropy": 0.1083529233932495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.41192626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027910703793168068,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13225244482358298,
      "backward_entropy": 0.10685666799545288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.43683624267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027970554307103157,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1320152978102366,
      "backward_entropy": 0.10769357681274414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.90861511230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028027338907122612,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1317862570285797,
      "backward_entropy": 0.10600452423095703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.54487609863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028081044554710388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13156320651372275,
      "backward_entropy": 0.10699832439422607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.782711029052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028132088482379913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1313436528046926,
      "backward_entropy": 0.10503358840942383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.331488609313965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028174983337521553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13113826513290405,
      "backward_entropy": 0.10447130203247071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.746070861816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02820686437189579,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1309520403544108,
      "backward_entropy": 0.13858245611190795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.1466064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028236273676156998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13076907396316528,
      "backward_entropy": 0.10322266817092896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.42645263671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02827240526676178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1305710275967916,
      "backward_entropy": 0.1025692105293274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.37736892700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028307855129241943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1303771436214447,
      "backward_entropy": 0.10193129777908325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.99112319946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02834050916135311,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13018794854482016,
      "backward_entropy": 0.10126732587814331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.97693634033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028369184583425522,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13000952204068503,
      "backward_entropy": 0.10492210388183594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.25593566894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02840324677526951,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1298221747080485,
      "backward_entropy": 0.09996126294136047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.08274459838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028436658903956413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12963658571243286,
      "backward_entropy": 0.10438517332077027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.92204284667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028465837240219116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12945955991744995,
      "backward_entropy": 0.09862757921218872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.95893096923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028500081971287727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12927183508872986,
      "backward_entropy": 0.09793832302093505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.53237915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028539292514324188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12907634178797403,
      "backward_entropy": 0.09727046489715577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.3232650756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02859015204012394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12886273860931396,
      "backward_entropy": 0.10331685543060302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.95635986328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02863883599638939,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12865562240282694,
      "backward_entropy": 0.10302059650421143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.151329040527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0286891907453537,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1284472942352295,
      "backward_entropy": 0.13854548931121827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.97040557861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028733305633068085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12824708223342896,
      "backward_entropy": 0.10244996547698974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.27738571166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028772389516234398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12805949648221335,
      "backward_entropy": 0.09401439428329468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.00626373291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028808724135160446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12787988781929016,
      "backward_entropy": 0.0933383584022522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.57616424560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02884751930832863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12769200404485068,
      "backward_entropy": 0.09263170957565307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.24491119384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028887247666716576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12750478585561117,
      "backward_entropy": 0.09194320440292358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.55458068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028925400227308273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1273163358370463,
      "backward_entropy": 0.10106384754180908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.98941802978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028964385390281677,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12712659438451132,
      "backward_entropy": 0.09048401713371276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.87101745605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029005713760852814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12693087259928384,
      "backward_entropy": 0.08973178863525391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.67496109008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02905101515352726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12672759095827738,
      "backward_entropy": 0.08896676898002624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.53333282470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029092835262417793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12653261423110962,
      "backward_entropy": 0.08819737434387206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.26000213623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029138514772057533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1263277530670166,
      "backward_entropy": 0.08741523027420044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.24698638916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02918264828622341,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12612893184026083,
      "backward_entropy": 0.08664859533309936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.038818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029225312173366547,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1259349783261617,
      "backward_entropy": 0.09947518706321716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.92276763916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029270371422171593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12573756774266562,
      "backward_entropy": 0.08513767719268799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.58815002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02931935526430607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1255359649658203,
      "backward_entropy": 0.09892003536224366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.41776275634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02936650440096855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1253414750099182,
      "backward_entropy": 0.08369967937469483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.55558776855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029412010684609413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12515310446421304,
      "backward_entropy": 0.09830718636512756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.92174530029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02945765294134617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1249621609846751,
      "backward_entropy": 0.0980136513710022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.07626342773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029507197439670563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12476735313733418,
      "backward_entropy": 0.08156743049621581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.73474884033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02955537661910057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1245836615562439,
      "backward_entropy": 0.0809291958808899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.88059997558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029601851478219032,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12440569202105205,
      "backward_entropy": 0.0802764654159546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.273120880126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02964833192527294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1242242157459259,
      "backward_entropy": 0.09659808874130249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.9366455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029687650501728058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12405584255854289,
      "backward_entropy": 0.09627494812011719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.13033294677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029731394723057747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12387774387995402,
      "backward_entropy": 0.07814942002296447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.1387710571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02978111058473587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12369040648142497,
      "backward_entropy": 0.07745734453201295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.93590545654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0298288706690073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12350736061731975,
      "backward_entropy": 0.07675330638885498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.77830505371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029873261228203773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12333256999651591,
      "backward_entropy": 0.09492900371551513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.36623764038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02992328628897667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12314454714457194,
      "backward_entropy": 0.07534786462783813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.68914031982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02996929921209812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12295982241630554,
      "backward_entropy": 0.07459010481834412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.23210525512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030017370358109474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.122772216796875,
      "backward_entropy": 0.09409580826759338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.85791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030062157660722733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12259629368782043,
      "backward_entropy": 0.07311060428619384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.87284088134766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030110904946923256,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1224111517270406,
      "backward_entropy": 0.1385247826576233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.90077590942383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0301615409553051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12222566207249959,
      "backward_entropy": 0.09315664768218994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.7306022644043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030208604410290718,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12204958995183308,
      "backward_entropy": 0.07096667885780335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.95948028564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030253959819674492,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12187294165293376,
      "backward_entropy": 0.09251888990402221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.61164093017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030301708728075027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12169641256332397,
      "backward_entropy": 0.06953141689300538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.25359344482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030355179682374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1215134859085083,
      "backward_entropy": 0.06885992884635925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.00675964355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030411802232265472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12132338682810466,
      "backward_entropy": 0.06818637251853943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.76771926879883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0304732508957386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1211288571357727,
      "backward_entropy": 0.06754125356674194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.64089584350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030531637370586395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12093877792358398,
      "backward_entropy": 0.06686080098152161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.45164489746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030583880841732025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12076130509376526,
      "backward_entropy": 0.06617618799209594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.51873016357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030641166493296623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12057272593180339,
      "backward_entropy": 0.06549290418624878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.97418975830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03069951944053173,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1203810175259908,
      "backward_entropy": 0.13855105638504028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.35802459716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0307551771402359,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12019246816635132,
      "backward_entropy": 0.08948136568069458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.7958755493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030806779861450195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12001344561576843,
      "backward_entropy": 0.06338803768157959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.6740493774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03085814043879509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11983187993367513,
      "backward_entropy": 0.06266052126884461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.02967071533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030911101028323174,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11964711546897888,
      "backward_entropy": 0.06192685961723328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.94462966918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030962076038122177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1194677750269572,
      "backward_entropy": 0.06119930148124695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.52323150634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03100936859846115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11929341157277425,
      "backward_entropy": 0.06044914722442627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.247886657714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031057167798280716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11912401517232259,
      "backward_entropy": 0.05972987413406372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.450897216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03110368736088276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11896295348803203,
      "backward_entropy": 0.059039080142974855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.095760345458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031147027388215065,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11880650122960408,
      "backward_entropy": 0.05833028554916382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.175594329833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031189417466521263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11865146954854329,
      "backward_entropy": 0.05762627124786377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.60767364501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03123079054057598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11849500735600789,
      "backward_entropy": 0.05689607858657837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.6749267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03127153217792511,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11834420760472615,
      "backward_entropy": 0.0561907947063446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.53634262084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031311552971601486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11819271246592204,
      "backward_entropy": 0.08612375259399414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.01184844970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03134923428297043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11804529031117757,
      "backward_entropy": 0.05476992726325989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.12424087524414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03138841316103935,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1178942620754242,
      "backward_entropy": 0.13851068019866944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.793392181396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03142544999718666,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1177519162495931,
      "backward_entropy": 0.05340752601623535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.29712677001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031462330371141434,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11761305729548137,
      "backward_entropy": 0.0848980724811554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.96548461914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03150251880288124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.117464284102122,
      "backward_entropy": 0.05209026336669922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.075660705566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03154419735074043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11732057730356853,
      "backward_entropy": 0.05148416757583618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.47420883178711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03158160299062729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11717939376831055,
      "backward_entropy": 0.050844788551330566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.157955169677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031617071479558945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11704319715499878,
      "backward_entropy": 0.05020111203193665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.60758590698242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03165094181895256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11691746115684509,
      "backward_entropy": 0.04958701133728027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.25602722167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031681451946496964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11679719885190327,
      "backward_entropy": 0.048964619636535645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.06123352050781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0317143090069294,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11666856209437053,
      "backward_entropy": 0.13851480484008788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.36920166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03174930065870285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11653526624043782,
      "backward_entropy": 0.08203479051589965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.69148254394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03178803250193596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11639708280563354,
      "backward_entropy": 0.047156119346618654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.7937240600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03182832896709442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11625467737515767,
      "backward_entropy": 0.08128843307495118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.69477081298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031875453889369965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11610585451126099,
      "backward_entropy": 0.04604133069515228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.150146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03192512318491936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11595173676808675,
      "backward_entropy": 0.08045095205307007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.025012969970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03197181224822998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11580238739649455,
      "backward_entropy": 0.044962707161903384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.99202728271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032012417912483215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11567068099975586,
      "backward_entropy": 0.044432598352432254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.40310668945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03205624595284462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11553110678990682,
      "backward_entropy": 0.04390525817871094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.1363639831543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032101236283779144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11538711190223694,
      "backward_entropy": 0.043370950222015384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.33000564575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03214208781719208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1152535875638326,
      "backward_entropy": 0.04284362494945526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.43240737915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03218097239732742,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11512549718221028,
      "backward_entropy": 0.042318329215049744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.73979568481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03221988305449486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1150020162264506,
      "backward_entropy": 0.04181257784366608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.57990264892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032255347818136215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11489041646321614,
      "backward_entropy": 0.04132427573204041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.554832458496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03229467570781708,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11476585268974304,
      "backward_entropy": 0.13857702016830445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.22752380371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03233052045106888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1146501898765564,
      "backward_entropy": 0.07614127397537232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.290218353271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032372020184993744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1145278016726176,
      "backward_entropy": 0.03991602063179016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.019556045532227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03240989148616791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11441491047541301,
      "backward_entropy": 0.039476093649864194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.3126220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032440945506095886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11431164542833964,
      "backward_entropy": 0.03899307250976562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.97175979614258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03247470408678055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1142068902651469,
      "backward_entropy": 0.03855141401290894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.911346435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03250565007328987,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11410637696584065,
      "backward_entropy": 0.07366863489151002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.84815979003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032535821199417114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11400655905405681,
      "backward_entropy": 0.037656974792480466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.616451263427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032570526003837585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1138949195543925,
      "backward_entropy": 0.07273526191711426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.50698471069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032607611268758774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1137805978457133,
      "backward_entropy": 0.07227479219436646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.34423065185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032641664147377014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11367658774058025,
      "backward_entropy": 0.03635157644748688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.21702194213867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03267474099993706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11357499162356059,
      "backward_entropy": 0.03593899011611938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.976036071777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03270695358514786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11347534259160359,
      "backward_entropy": 0.035522767901420595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.05976486206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03274014592170715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11337201793988545,
      "backward_entropy": 0.07035591602325439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.66099166870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0327707901597023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11328013737996419,
      "backward_entropy": 0.03471579849720001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.14735412597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03280261158943176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11318192879358928,
      "backward_entropy": 0.03431186079978943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.94081687927246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032838962972164154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11306947469711304,
      "backward_entropy": 0.03390414416790009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.17760467529297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032870788127183914,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11296439170837402,
      "backward_entropy": 0.13862283229827882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.268184661865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03290374204516411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11285958687464397,
      "backward_entropy": 0.03308040499687195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.19157409667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032936010509729385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11275740464528401,
      "backward_entropy": 0.032684105634689334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.673072814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03297967463731766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11262638370196025,
      "backward_entropy": 0.032294359803199765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.493408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03302336111664772,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11249445875485738,
      "backward_entropy": 0.06682807207107544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.31062698364258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03307220712304115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1123466690381368,
      "backward_entropy": 0.03149890899658203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.58372497558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03312059864401817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11219984292984009,
      "backward_entropy": 0.031097105145454405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.07374572753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03317536041140556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11204222838083903,
      "backward_entropy": 0.030719223618507385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.21956253051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03323252126574516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11187670628229777,
      "backward_entropy": 0.06547552943229676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.567134857177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03328673541545868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11171907186508179,
      "backward_entropy": 0.029956254363059997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.882694244384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03334001824259758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11156440774599712,
      "backward_entropy": 0.02958735227584839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.63820266723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03339080139994621,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1114152471224467,
      "backward_entropy": 0.06443517208099366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.177785873413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03344272822141647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11126597722371419,
      "backward_entropy": 0.028850817680358888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.632915496826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0334906168282032,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11112717787424724,
      "backward_entropy": 0.06372122764587403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.38640594482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03353323042392731,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11099963386853536,
      "backward_entropy": 0.028127551078796387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.09998321533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03357953205704689,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11086247364679973,
      "backward_entropy": 0.027776768803596495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.33907699584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033624179661273956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11072705189387004,
      "backward_entropy": 0.06268807053565979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.601253509521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03366896137595177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11059337854385376,
      "backward_entropy": 0.06233336329460144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.12205123901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033710528165102005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11046981811523438,
      "backward_entropy": 0.06195508241653443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.75363540649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03375439718365669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11033384005228679,
      "backward_entropy": 0.026409751176834105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.22239875793457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03379862755537033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11019526918729146,
      "backward_entropy": 0.026071780920028688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.07868957519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033839818090200424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11006379127502441,
      "backward_entropy": 0.02573726773262024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.967676162719727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033886510878801346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10992741584777832,
      "backward_entropy": 0.025436684489250183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.246089935302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033928170800209045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1098084847132365,
      "backward_entropy": 0.025151383876800538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.35138702392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033972106873989105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10967987775802612,
      "backward_entropy": 0.024869930744171143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.64606285095215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034023020416498184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10953629016876221,
      "backward_entropy": 0.024607710540294647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.72994995117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03406864032149315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1094097097714742,
      "backward_entropy": 0.024342361092567443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.46406173706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03411777317523956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10927657286326091,
      "backward_entropy": 0.024091285467147828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.39495849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03416682034730911,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10914502541224162,
      "backward_entropy": 0.023846091330051424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.19984817504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034215688705444336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10901767015457153,
      "backward_entropy": 0.05745394229888916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.14358901977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03426286205649376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10889581839243571,
      "backward_entropy": 0.023399817943572997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.6485595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034306880086660385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10878179470698039,
      "backward_entropy": 0.023179948329925537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.899686813354492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034353066235780716,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10865972439448039,
      "backward_entropy": 0.05597742795944214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.291255950927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03439627215266228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10854578018188477,
      "backward_entropy": 0.0227407768368721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.320518493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03444172814488411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.108426829179128,
      "backward_entropy": 0.022526192665100097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.49700927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034487560391426086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10830702384312947,
      "backward_entropy": 0.022319523990154265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.44479751586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03453062102198601,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10819107294082642,
      "backward_entropy": 0.054111266136169435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.95054817199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03457113727927208,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10808006922403972,
      "backward_entropy": 0.05368732213973999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.670738220214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034606046974658966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1079842746257782,
      "backward_entropy": 0.0216463103890419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.763580322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03464249521493912,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10788470506668091,
      "backward_entropy": 0.052821886539459226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.99016571044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03468373417854309,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10777020454406738,
      "backward_entropy": 0.02120741903781891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.100685119628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03472757712006569,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10764576991399129,
      "backward_entropy": 0.13862463235855102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.726655960083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034772276878356934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10751666625340779,
      "backward_entropy": 0.020770463347434997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.40668869018555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03481457009911537,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10739114880561829,
      "backward_entropy": 0.05134320259094238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.738731384277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03485944867134094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10725808143615723,
      "backward_entropy": 0.051025664806365965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.973854064941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03490498661994934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10712556044260661,
      "backward_entropy": 0.020095424354076387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.993648529052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034952905029058456,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10698336362838745,
      "backward_entropy": 0.05038478374481201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.82884979248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03499952331185341,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1068480412165324,
      "backward_entropy": 0.019674763083457947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.45747756958008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03504810854792595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10671266913414001,
      "backward_entropy": 0.019492217898368837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.47065734863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035098735243082047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10657061139742534,
      "backward_entropy": 0.019310866296291352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.58295822143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0351480208337307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10643210013707478,
      "backward_entropy": 0.019126635789871217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.47669982910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03520067036151886,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10628771781921387,
      "backward_entropy": 0.048496437072753903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.686677932739258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03525824472308159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10612561305363973,
      "backward_entropy": 0.018794262409210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.00095748901367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035312339663505554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10597161451975505,
      "backward_entropy": 0.018617796897888183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.7702865600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035364679992198944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10582434137662251,
      "backward_entropy": 0.018448832631111144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.10933303833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03542185574769974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10566530625025432,
      "backward_entropy": 0.018286219239234923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.5751838684082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03548019751906395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10550407568613689,
      "backward_entropy": 0.04672451019287109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.55622100830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03553640469908714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10535028576850891,
      "backward_entropy": 0.017981868982315064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.554588317871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035590510815382004,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10520801941553752,
      "backward_entropy": 0.04592057168483734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.108116149902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03564602509140968,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10506207744280498,
      "backward_entropy": 0.017729288339614867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.083473205566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03570320084691048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1049062709013621,
      "backward_entropy": 0.01759699881076813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.874778747558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03576158732175827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1047481894493103,
      "backward_entropy": 0.01746941953897476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.69130325317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03582107275724411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1045879324277242,
      "backward_entropy": 0.017344816029071806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.444271087646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035878442227840424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1044333279132843,
      "backward_entropy": 0.04390177130699158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.509010314941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035935577005147934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10427731275558472,
      "backward_entropy": 0.04352405667304993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.108497619628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03599211201071739,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10412867863972981,
      "backward_entropy": 0.016986778378486632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.0968132019043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03604986146092415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10397799809773763,
      "backward_entropy": 0.01688632369041443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.10192108154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036105770617723465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10383083422978719,
      "backward_entropy": 0.016782480478286742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.67584991455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03615978732705116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10369372367858887,
      "backward_entropy": 0.01668846607208252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.50873565673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03621380776166916,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10355557004610698,
      "backward_entropy": 0.041362297534942624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.17298126220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03626783937215805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10341643293698628,
      "backward_entropy": 0.04093034863471985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.705114364624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036328207701444626,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1032552719116211,
      "backward_entropy": 0.04053124487400055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.00883674621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036385003477334976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10310440262158711,
      "backward_entropy": 0.0401433527469635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.19183921813965,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03643690422177315,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10297045111656189,
      "backward_entropy": 0.13857777118682862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.450668334960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03648753464221954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10283997654914856,
      "backward_entropy": 0.01612859219312668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.327856063842773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03653550520539284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10271658500035603,
      "backward_entropy": 0.038945254683494565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.347755432128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036581143736839294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10259852806727092,
      "backward_entropy": 0.015946859121322633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.27382278442383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03662775456905365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10247639815012614,
      "backward_entropy": 0.01585662066936493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.62318801879883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0366751067340374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10235385100046794,
      "backward_entropy": 0.015773221850395203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.86806106567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03672465682029724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10222556193669637,
      "backward_entropy": 0.015697668492794036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.180206298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03677487000823021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10209385553995769,
      "backward_entropy": 0.015618158876895905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6006928086280823,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03682715818285942,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10195557276407878,
      "backward_entropy": 0.13854625225067138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.454837799072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036872025579214096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10184264183044434,
      "backward_entropy": 0.015463925898075104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.7033462524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03691795840859413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10172571738560994,
      "backward_entropy": 0.035823628306388855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.410675048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036970965564250946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10158530871073405,
      "backward_entropy": 0.015317679941654205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.32727813720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03702588751912117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10143615802129109,
      "backward_entropy": 0.03511105179786682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.527225494384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03708230331540108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1012826959292094,
      "backward_entropy": 0.015168397128582001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.919865608215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037137214094400406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.101133128007253,
      "backward_entropy": 0.015095074474811555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.43692398071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03718778118491173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10099669297536214,
      "backward_entropy": 0.015018826723098755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.248531341552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03723903372883797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10085574785868327,
      "backward_entropy": 0.014939361810684204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.302860260009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037289097905159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10072086254755656,
      "backward_entropy": 0.014869436621665955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.832916259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03734136000275612,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10057783126831055,
      "backward_entropy": 0.033094930648803714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.791540145874023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03739095851778984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10044409831364949,
      "backward_entropy": 0.014732445776462554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.72313690185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037439752370119095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10031247138977051,
      "backward_entropy": 0.014667622745037079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.50728416442871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037490978837013245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10016920169194539,
      "backward_entropy": 0.014598527550697326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.38839054107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03754135221242905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10002646843592326,
      "backward_entropy": 0.014527754485607147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.13782501220703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037587955594062805,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.09989612301190694,
      "backward_entropy": 0.13853826522827148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.06561279296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037637364119291306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09975072741508484,
      "backward_entropy": 0.03128378689289093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.08431053161621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037687696516513824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09960003693898518,
      "backward_entropy": 0.014297708868980408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.45904541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0377371683716774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09945340951283772,
      "backward_entropy": 0.014222542941570281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.66701126098633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037791959941387177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09928683439890544,
      "backward_entropy": 0.014146566390991211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.6551570892334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037847019731998444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09911864995956421,
      "backward_entropy": 0.014073678851127624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.30007553100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037900909781455994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09895472725232442,
      "backward_entropy": 0.014001533389091492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.2846565246582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037955306470394135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09878645340601604,
      "backward_entropy": 0.029845467209815978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.48967933654785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03801586478948593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0985978643099467,
      "backward_entropy": 0.029623547196388246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.54629135131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03807336464524269,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09841644763946533,
      "backward_entropy": 0.01378597468137741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.989246368408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03813241794705391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09822958707809448,
      "backward_entropy": 0.0137166365981102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.912967681884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03818998113274574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09804677963256836,
      "backward_entropy": 0.028996002674102784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.184316635131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03824606537818909,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09787001212437947,
      "backward_entropy": 0.013583795726299286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.23610305786133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038299329578876495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0977049469947815,
      "backward_entropy": 0.028546732664108277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.74817657470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03835304081439972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09753801425298055,
      "backward_entropy": 0.013470493257045746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.87049102783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038411498069763184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0973542829354604,
      "backward_entropy": 0.028080058097839356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.764535903930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03847002983093262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09716790914535522,
      "backward_entropy": 0.013365471363067627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.15388298034668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03852562606334686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09699263175328572,
      "backward_entropy": 0.01331547200679779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.030488967895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03857996687293053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09682191411654155,
      "backward_entropy": 0.013268443942070007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.417940139770508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038633182644844055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0966564416885376,
      "backward_entropy": 0.01322486400604248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.694351196289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03868420794606209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09649584690729777,
      "backward_entropy": 0.013176681101322174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6164727210998535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038734741508960724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09633354345957439,
      "backward_entropy": 0.026729801297187807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.144264221191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038780275732278824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09619077046712239,
      "backward_entropy": 0.013077327609062194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.108869552612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03882865607738495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09603511293729146,
      "backward_entropy": 0.013028818368911742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.86682891845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038875263184309006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09588509798049927,
      "backward_entropy": 0.02610354721546173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.226280212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03892446681857109,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09572498003641765,
      "backward_entropy": 0.012935644388198853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4438300132751465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03897871449589729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09554802378018697,
      "backward_entropy": 0.012896285951137542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2362910360097885,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039027705788612366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09539074699083964,
      "backward_entropy": 0.012858931720256806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.732805252075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03907051309943199,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09525770942370097,
      "backward_entropy": 0.0128240704536438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.46003341674805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03911198675632477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09513068199157715,
      "backward_entropy": 0.012793023884296418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.9815559387207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039160843938589096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09497394164403279,
      "backward_entropy": 0.012759754061698913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.58504295349121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039213553071022034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09480168422063191,
      "backward_entropy": 0.01272549331188202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.546871185302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039265312254428864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09463385740915935,
      "backward_entropy": 0.024400728940963744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.348567962646484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03931913897395134,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.09445798397064209,
      "backward_entropy": 0.1385770320892334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.205760955810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03937191143631935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09428723653157552,
      "backward_entropy": 0.012643542885780335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.96609878540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039425212889909744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09411398569742839,
      "backward_entropy": 0.012621092796325683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.016870498657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039481889456510544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09392696619033813,
      "backward_entropy": 0.012597131729125976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.123032569885254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03953593969345093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09374946355819702,
      "backward_entropy": 0.012574325501918792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.66904067993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039584774523973465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09359338879585266,
      "backward_entropy": 0.012555186450481415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.757617950439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0396343432366848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09343622128168742,
      "backward_entropy": 0.012541233003139496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.521963119506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03968200832605362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09328542153040568,
      "backward_entropy": 0.012527735531330108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.425487518310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0397292897105217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09313563505808513,
      "backward_entropy": 0.012514972686767578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.643531799316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039776187390089035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09298837184906006,
      "backward_entropy": 0.012504377961158752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.414400100708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039826929569244385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09282543261845906,
      "backward_entropy": 0.01249247118830681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.363985061645508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039875712245702744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0926680862903595,
      "backward_entropy": 0.012478017061948777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.558103561401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03992260619997978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09251885612805684,
      "backward_entropy": 0.012465113401412964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.163408279418945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03996652737259865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09238062302271526,
      "backward_entropy": 0.012451364099979401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.73356819152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04000922292470932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09224504232406616,
      "backward_entropy": 0.012435355037450791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.0439510345459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04005222022533417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0921055277188619,
      "backward_entropy": 0.012416014075279235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.568166732788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04009397327899933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09197088082631429,
      "backward_entropy": 0.012397576123476028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.718766212463379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040136005729436874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09183460474014282,
      "backward_entropy": 0.012378901243209839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.4779052734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040174227207899094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09171296159426372,
      "backward_entropy": 0.01236063614487648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.197532653808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040215909481048584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09157487750053406,
      "backward_entropy": 0.012339608371257782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.72042465209961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04025522992014885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09144558509190877,
      "backward_entropy": 0.020060822367668152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.11171531677246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04029354453086853,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09132236242294312,
      "backward_entropy": 0.01988206058740616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.460023880004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04033246636390686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09119621912638347,
      "backward_entropy": 0.019705238938331603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.925737380981445,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.040373437106609344,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.09105982383092244,
      "backward_entropy": 0.13847432136535645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.838605880737305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040414758026599884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09092160065968831,
      "backward_entropy": 0.012246659398078919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.519187927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04045635834336281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09078224500020345,
      "backward_entropy": 0.012229786813259124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.028779983520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04050103947520256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09062907099723816,
      "backward_entropy": 0.01221088245511055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.193519592285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040546972304582596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09047192335128784,
      "backward_entropy": 0.01219457909464836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.08626174926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0405956506729126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0902998149394989,
      "backward_entropy": 0.012173624336719513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.011573791503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04064653813838959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09012065331141154,
      "backward_entropy": 0.012154541909694672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.211410522460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040695466101169586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08994857470194499,
      "backward_entropy": 0.018490269780158997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.323007583618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04074391722679138,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08977844317754109,
      "backward_entropy": 0.012122625112533569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.8578987121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04079340770840645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0896030068397522,
      "backward_entropy": 0.0182071790099144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.707995414733887,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04084773361682892,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08940707643826802,
      "backward_entropy": 0.13851313591003417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.094635009765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0408996120095253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08922340472539265,
      "backward_entropy": 0.012075819075107574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.92833137512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04095333442091942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08903251091639201,
      "backward_entropy": 0.012064799666404724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.417947769165039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04100866988301277,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08883555730183919,
      "backward_entropy": 0.012056313455104828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.494918823242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04106159880757332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0886481503645579,
      "backward_entropy": 0.01204843819141388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.351404190063477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0411149337887764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08845933278401692,
      "backward_entropy": 0.01735578179359436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.25392532348633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04116863012313843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08826885620752971,
      "backward_entropy": 0.012035942077636719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.044609069824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04122801497578621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08805292844772339,
      "backward_entropy": 0.012026487290859223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.91523551940918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04128468781709671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08784681558609009,
      "backward_entropy": 0.01201578974723816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.63566017150879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04134020581841469,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08764421939849854,
      "backward_entropy": 0.012003548443317413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.357913970947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04139738902449608,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08743169903755188,
      "backward_entropy": 0.011986806988716125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.03022384643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04145733639597893,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08720534046490987,
      "backward_entropy": 0.011967214941978454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.9569206237793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041520919650793076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08696301778157552,
      "backward_entropy": 0.011947091668844223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.100805282592773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04158633574843407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08671520153681438,
      "backward_entropy": 0.011930150538682937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.842390537261963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041650913655757904,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08647026618321736,
      "backward_entropy": 0.011914686858654022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.818409442901611,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04170968011021614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08624927202860515,
      "backward_entropy": 0.0118998222053051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.21759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041763175278902054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08605037132898967,
      "backward_entropy": 0.011886490881443024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.823837280273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04181445762515068,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08586039145787557,
      "backward_entropy": 0.011874622106552124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.384689331054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04186500608921051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08567315340042114,
      "backward_entropy": 0.015930838882923126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.969796180725098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04191610589623451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08548378944396973,
      "backward_entropy": 0.015822833776473998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.15328598022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04196525737643242,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08530223369598389,
      "backward_entropy": 0.011847049742937089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.831969261169434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042014896869659424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0851202408472697,
      "backward_entropy": 0.01184442788362503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.736601829528809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04206261783838272,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08494668205579121,
      "backward_entropy": 0.011844154447317123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14206314086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04210871458053589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08477850755055745,
      "backward_entropy": 0.011843894422054291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.0899715423584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04215202480554581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08462261160214742,
      "backward_entropy": 0.011844810098409653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.507158279418945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04219546541571617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08446415265401204,
      "backward_entropy": 0.011843137443065643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.924772262573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04224011301994324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08430025974909465,
      "backward_entropy": 0.01184220016002655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.921832084655762,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04228460416197777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08413679401079814,
      "backward_entropy": 0.011842139065265656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.73863983154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04232664778828621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08398182193438213,
      "backward_entropy": 0.011838891357183457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.60903549194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04236878082156181,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08382648229598999,
      "backward_entropy": 0.011836260557174683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.267194747924805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04241721332073212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0836435854434967,
      "backward_entropy": 0.01183234080672264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.43451499938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042467646300792694,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08345114191373189,
      "backward_entropy": 0.014480631053447723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.625356674194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04251735284924507,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08326199650764465,
      "backward_entropy": 0.011821597814559937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.638381958007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04256775602698326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08306755622227986,
      "backward_entropy": 0.01181490570306778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.860115051269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04261500760912895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08288683493932088,
      "backward_entropy": 0.011809083819389343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.497880935668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04266060143709183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08271325627962749,
      "backward_entropy": 0.01180405616760254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.9299259185791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04270845279097557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0825288047393163,
      "backward_entropy": 0.01179756000638008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.836231231689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042755793780088425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0823467622200648,
      "backward_entropy": 0.011791958659887313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.228511333465576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04280262812972069,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08216727773348491,
      "backward_entropy": 0.011788024008274079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.501620292663574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042845405638217926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08200568954149882,
      "backward_entropy": 0.01178533062338829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.311455726623535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04288691282272339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08184979359308879,
      "backward_entropy": 0.011784473806619645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.155727386474609,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04292606934905052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08170463641484578,
      "backward_entropy": 0.01178467869758606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259782791137695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0429619699716568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08157319823900859,
      "backward_entropy": 0.011784909665584565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.190845489501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042995862662792206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08145315448443095,
      "backward_entropy": 0.011790989339351654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.248586654663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04302816092967987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08133979638417561,
      "backward_entropy": 0.011797789484262466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.189687728881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04306142404675484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08122194806734721,
      "backward_entropy": 0.011804406344890595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.086877822875977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04309684783220291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08109304308891296,
      "backward_entropy": 0.011807923018932343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.006547927856445,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04313172399997711,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08096622427304585,
      "backward_entropy": 0.13851475715637207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.999472141265869,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04316626861691475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08083906769752502,
      "backward_entropy": 0.011810412257909774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.817401885986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04319915920495987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08071917295455933,
      "backward_entropy": 0.011810336261987686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.850845336914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043234195560216904,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08058874309062958,
      "backward_entropy": 0.012674811482429504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.710840225219727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04326878488063812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08045968413352966,
      "backward_entropy": 0.012589982151985169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.658581733703613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04330415278673172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08032655715942383,
      "backward_entropy": 0.011800613999366761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.535589218139648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043340034782886505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08019245167573293,
      "backward_entropy": 0.011799907684326172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.63782787322998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04337671399116516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08005222678184509,
      "backward_entropy": 0.011794204264879227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.410466194152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043412622064352036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07991700371106465,
      "backward_entropy": 0.011791452765464783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.127788543701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04344907030463219,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07977960507074992,
      "backward_entropy": 0.011789987981319427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.430397987365723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04348735883831978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07963232199350993,
      "backward_entropy": 0.012106069922447204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.60593318939209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04352492094039917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0794870654741923,
      "backward_entropy": 0.011779563128948211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8183116912841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04356053099036217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07935085892677307,
      "backward_entropy": 0.011774941533803939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.534722805023193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04359311982989311,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07922940452893575,
      "backward_entropy": 0.01177349016070366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.221718788146973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04362422227859497,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07911486426989238,
      "backward_entropy": 0.01177336573600769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.702821731567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04365518316626549,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07900092999140422,
      "backward_entropy": 0.01177349016070366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.096537590026855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04369191452860832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07886057098706563,
      "backward_entropy": 0.011770199984312057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.718571662902832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043728057295084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07872164249420166,
      "backward_entropy": 0.01176561787724495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.297155380249023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043764740228652954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07857996225357056,
      "backward_entropy": 0.01176132783293724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.921673774719238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04380299896001816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07843198875586192,
      "backward_entropy": 0.01175801083445549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.29831314086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04384047910571098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07828700045744579,
      "backward_entropy": 0.01175377070903778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.381415367126465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04388188198208809,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0781233012676239,
      "backward_entropy": 0.011746904999017715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.875146865844727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043923359364271164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07795880238215129,
      "backward_entropy": 0.011738698184490203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.760761260986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04396592080593109,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07779004176457723,
      "backward_entropy": 0.01173168495297432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.085927486419678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04400947690010071,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07761718829472859,
      "backward_entropy": 0.011141669005155563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.523677825927734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044050466269254684,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07745651404062907,
      "backward_entropy": 0.13853840827941893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.944938659667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0440950021147728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07727898160616557,
      "backward_entropy": 0.01171376258134842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.31928062438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04413919523358345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07710312803586324,
      "backward_entropy": 0.011707351356744767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.344643592834473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04418410360813141,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07692526777585347,
      "backward_entropy": 0.011703184992074966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.85759973526001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04422735795378685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0767560750246048,
      "backward_entropy": 0.010848286747932433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.968046188354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04426807910203934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0765984058380127,
      "backward_entropy": 0.01170206218957901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.870698928833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04430997744202614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.076434721549352,
      "backward_entropy": 0.011700716614723206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.079257011413574,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044352829456329346,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07626708348592122,
      "backward_entropy": 0.13856112957000732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.025872230529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04439423233270645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07610691587130229,
      "backward_entropy": 0.011702422797679902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.945039749145508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04443422704935074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07595480978488922,
      "backward_entropy": 0.011708752810955047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.887594223022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04447310045361519,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07580747207005818,
      "backward_entropy": 0.011715467274188995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.810338973999023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04451093077659607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07566497723261516,
      "backward_entropy": 0.011723626405000687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.009002685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04454796761274338,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07552459836006165,
      "backward_entropy": 0.011729125678539277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.480771064758301,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04458526894450188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07538314660390218,
      "backward_entropy": 0.011734609305858613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.453685283660889,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04462061822414398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07524968187014262,
      "backward_entropy": 0.011740157753229142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.417816162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04465411975979805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07512507836023967,
      "backward_entropy": 0.01174744889140129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.413022994995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04468595236539841,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07500840723514557,
      "backward_entropy": 0.011756134778261184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.650184631347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044722799211740494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07487106323242188,
      "backward_entropy": 0.011766397953033447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.295687198638916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044759802520275116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07473334670066833,
      "backward_entropy": 0.011777780950069427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.252336025238037,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04479486867785454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0746036966641744,
      "backward_entropy": 0.01178775131702423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1329305171966553,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04482824355363846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07448025047779083,
      "backward_entropy": 0.011795316636562348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.347037315368652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044858887791633606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07436893383661906,
      "backward_entropy": 0.011803370714187623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.343567848205566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044890422374010086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07425278425216675,
      "backward_entropy": 0.011809011548757553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.209988594055176,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04492383450269699,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07412722706794739,
      "backward_entropy": 0.13851625919342042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.113495826721191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04495784640312195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0739982674519221,
      "backward_entropy": 0.011813263595104217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.109407424926758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044991280883550644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07387146353721619,
      "backward_entropy": 0.009412738680839538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.989105224609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0450284443795681,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07372914751370747,
      "backward_entropy": 0.01181352585554123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.949614524841309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04506682977080345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07358176509539287,
      "backward_entropy": 0.011813034117221833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.936448097229004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04510413110256195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07343898713588715,
      "backward_entropy": 0.009245304763317109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.702730178833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04513940587639809,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07330526908238728,
      "backward_entropy": 0.011813715100288391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.599898338317871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045176051557064056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07316558559735616,
      "backward_entropy": 0.011813990771770477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72463607788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045214004814624786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07301959892114003,
      "backward_entropy": 0.011812372505664826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.533684730529785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04525086283683777,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07287910083929698,
      "backward_entropy": 0.00902833417057991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.03487205505371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04528789222240448,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07273739576339722,
      "backward_entropy": 0.00897667407989502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.541193008422852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045328207314014435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07258161902427673,
      "backward_entropy": 0.011809447407722473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.669631481170654,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045367248356342316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07243120173613231,
      "backward_entropy": 0.011807592213153839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.21878719329834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04540402814745903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07229133447011311,
      "backward_entropy": 0.01180732697248459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.160635948181152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045440975576639175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07215012113253276,
      "backward_entropy": 0.01180562824010849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.315412521362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04547789320349693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07201040784517924,
      "backward_entropy": 0.011806187778711319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.746542930603027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0455138199031353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07187532385190327,
      "backward_entropy": 0.011807304620742799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.373668670654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04555092006921768,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07173519829909007,
      "backward_entropy": 0.01180846244096756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.846078872680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045590128749608994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07158605257670085,
      "backward_entropy": 0.011808918416500091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.403619289398193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04562915489077568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07143774628639221,
      "backward_entropy": 0.011809301376342774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.373506546020508,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045665886253118515,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07129999001820882,
      "backward_entropy": 0.13853821754455567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.605409622192383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04570354148745537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07115950187047322,
      "backward_entropy": 0.011815690994262695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.17186164855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0457412451505661,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07101760307947795,
      "backward_entropy": 0.0118173249065876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.281070709228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04577986150979996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07087236642837524,
      "backward_entropy": 0.011819148063659668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.781202793121338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045821432024240494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07071404655774434,
      "backward_entropy": 0.011818294227123261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.005598068237305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045861613005399704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07056078314781189,
      "backward_entropy": 0.011815448105335236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.117161273956299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045904457569122314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07039694984753926,
      "backward_entropy": 0.011812616139650345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.146845817565918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0459446981549263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07024391492207845,
      "backward_entropy": 0.01180969476699829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5432777404785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04598444700241089,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07009442647298177,
      "backward_entropy": 0.011809433996677398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.503726482391357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046020761132240295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06996033092339833,
      "backward_entropy": 0.011811710894107819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.853638648986816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046055980026721954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06983148554960887,
      "backward_entropy": 0.011815956979990005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.851607322692871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04609331116080284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06969360013802846,
      "backward_entropy": 0.011818335950374603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4553492069244385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04613039270043373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06955777605374654,
      "backward_entropy": 0.011822988837957382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.450552225112915,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04616444185376167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06943393747011821,
      "backward_entropy": 0.011825774610042573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.238872051239014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046195633709430695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06932260592778523,
      "backward_entropy": 0.01183006763458252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.576118469238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046226225793361664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06921407580375671,
      "backward_entropy": 0.011835116147994994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513524055480957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04625728726387024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06910352905591328,
      "backward_entropy": 0.011839666962623596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.4590482711792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04628876596689224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06899132827917735,
      "backward_entropy": 0.011843928694725036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.041091442108154,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04632051661610603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06887869536876678,
      "backward_entropy": 0.011849921196699142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.335273742675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04635167866945267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0687679648399353,
      "backward_entropy": 0.011854280531406403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.257756233215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046383097767829895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06865769624710083,
      "backward_entropy": 0.011861573159694671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.784276008605957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04641488939523697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06854481498400371,
      "backward_entropy": 0.011867493391036987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.851107597351074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04644888639450073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06842351456483205,
      "backward_entropy": 0.007395083457231522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.055222511291504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04648200795054436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0683053731918335,
      "backward_entropy": 0.01187688261270523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.997611045837402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04651535674929619,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06818566719690959,
      "backward_entropy": 0.00730329230427742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.157601356506348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046548813581466675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06806579728921254,
      "backward_entropy": 0.011879304796457291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.070109367370605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04658331349492073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0679418941338857,
      "backward_entropy": 0.011879874765872956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.364184379577637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04661876708269119,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06781395276387532,
      "backward_entropy": 0.007175394147634506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.723555564880371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665699601173401,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06767470141251881,
      "backward_entropy": 0.011877503246068954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.489975929260254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046694766730070114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06753806273142497,
      "backward_entropy": 0.011876565963029861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.451624393463135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04673122614622116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06740689277648926,
      "backward_entropy": 0.011875579506158829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.265768051147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04676634445786476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06728275616963704,
      "backward_entropy": 0.011877533048391342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3432769775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04679945483803749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06716654698053996,
      "backward_entropy": 0.01187926009297371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.472649574279785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046831630170345306,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06705475350220998,
      "backward_entropy": 0.011882062256336211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.383176803588867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0468648225069046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06693924466768901,
      "backward_entropy": 0.006882621347904206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.206486225128174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04689900577068329,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06681949893633525,
      "backward_entropy": 0.011887255311012267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.189208984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04693203046917915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06670563419659932,
      "backward_entropy": 0.011891797930002213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03921971842646599,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04696502164006233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06659233570098877,
      "backward_entropy": 0.006749187409877777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.061782836914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04699418321251869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06649551788965861,
      "backward_entropy": 0.011904123425483703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.011947631835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04702373221516609,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0663969616095225,
      "backward_entropy": 0.011910309642553329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.964874267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04705353081226349,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06629780928293864,
      "backward_entropy": 0.011916957795619965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890532493591309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04708271846175194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06620059410730998,
      "backward_entropy": 0.011922339349985123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.792323112487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04711223393678665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06610200802485149,
      "backward_entropy": 0.011927247047424316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.641400337219238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04714285954833031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06599981586138408,
      "backward_entropy": 0.011933136731386185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.867994785308838,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04717551916837692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06588913003603618,
      "backward_entropy": 0.011936309933662414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.36666202545166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04720631614327431,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06578585505485535,
      "backward_entropy": 0.011939554661512374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.928746223449707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04723997041583061,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06567116578420003,
      "backward_entropy": 0.011940608918666839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.39745807647705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04727061465382576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06556974351406097,
      "backward_entropy": 0.011945342272520065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.316487312316895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047302328050136566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06546367208162944,
      "backward_entropy": 0.01194765567779541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.248985290527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04733504354953766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0653525988260905,
      "backward_entropy": 0.006219805032014847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.830206871032715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04736853390932083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06523892283439636,
      "backward_entropy": 0.011945760995149612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.075492858886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0474044531583786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06511654953161876,
      "backward_entropy": 0.011944173276424408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.585966110229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04744090884923935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06499160329500835,
      "backward_entropy": 0.011940144002437592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.360619068145752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047479528933763504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06485844155152638,
      "backward_entropy": 0.011934584379196167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7922885417938232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047516487538814545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06473264594872792,
      "backward_entropy": 0.006050393730401993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.257251739501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04755016043782234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06462056438128154,
      "backward_entropy": 0.01192903071641922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7561509609222412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04758269712328911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06451287865638733,
      "backward_entropy": 0.005979073047637939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1782026290893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04761243984103203,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06441610058148702,
      "backward_entropy": 0.011927926540374756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.430079936981201,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0476413331925869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06432327628135681,
      "backward_entropy": 0.011929608881473541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7206557989120483,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04766865074634552,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06423660119374593,
      "backward_entropy": 0.011932074278593063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.410675048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04769362881779671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06415931383768718,
      "backward_entropy": 0.01193678006529808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3572323322296143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04771998152136803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0640769253174464,
      "backward_entropy": 0.011940140277147293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.98049783706665,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04774497076869011,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06400005022684734,
      "backward_entropy": 0.01194426864385605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5884623527526855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047769639641046524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06392423311869304,
      "backward_entropy": 0.011947322636842728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.533001899719238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04779483750462532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06384610136349995,
      "backward_entropy": 0.011949874460697174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.499159336090088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04782058671116829,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06376518805821736,
      "backward_entropy": 0.0119498610496521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.64461612701416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047846656292676926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06368416547775269,
      "backward_entropy": 0.011951518803834915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.378025054931641,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047874853014945984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06359428664048512,
      "backward_entropy": 0.011949463933706283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.798506736755371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047903332859277725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06350256999333699,
      "backward_entropy": 0.011944697052240372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7237677574157715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04793703183531761,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06339133779207866,
      "backward_entropy": 0.005505060404539108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.315808296203613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047969356179237366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06328687071800232,
      "backward_entropy": 0.0119328111410141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0940191745758057,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04800302907824516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06317803263664246,
      "backward_entropy": 0.011929616332054138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.694689750671387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04803456738591194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06307778259118398,
      "backward_entropy": 0.011928334832191467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.046499729156494,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04806998372077942,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06296393275260925,
      "backward_entropy": 0.13851665258407592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014824877493083477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048104651272296906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0628541608651479,
      "backward_entropy": 0.011926232278347016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9684126377105713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048135578632354736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06275749206542969,
      "backward_entropy": 0.005319571495056153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.328242778778076,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04816469922661781,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06266727050145467,
      "backward_entropy": 0.13852013349533082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8139166831970215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04819458723068237,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06257438659667969,
      "backward_entropy": 0.011923564970493317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.192905902862549,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04822434112429619,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.062482208013534546,
      "backward_entropy": 0.01192270815372467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.149709224700928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04825479909777641,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06238762537638346,
      "backward_entropy": 0.011921500414609909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.065463542938232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048285599797964096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06229392687479655,
      "backward_entropy": 0.011925436556339264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.613507270812988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04831687733530998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.062199145555496216,
      "backward_entropy": 0.01192978471517563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.540401458740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048347651958465576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06210771203041077,
      "backward_entropy": 0.01193784549832344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022661399096250534,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048378169536590576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06201686461766561,
      "backward_entropy": 0.011944247782230378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7394111156463623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04840526729822159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061938141783078514,
      "backward_entropy": 0.011950594931840896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.051850318908691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04843076318502426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06186548372109731,
      "backward_entropy": 0.011959131062030792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3711568117141724,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04845568165183067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06179435054461161,
      "backward_entropy": 0.011967167258262634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.991804838180542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04847831651568413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06173266967137655,
      "backward_entropy": 0.01197943240404129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9516918659210205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04850059002637863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061672275265057884,
      "backward_entropy": 0.011991445720195771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3332573175430298,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048522643744945526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06161183615525564,
      "backward_entropy": 0.011999767273664474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.483644962310791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04854275658726692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06155883272488912,
      "backward_entropy": 0.012010502815246581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.14933443069458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04856434091925621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06150031089782715,
      "backward_entropy": 0.012017960846424102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8381564617156982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04858649894595146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06143904725710551,
      "backward_entropy": 0.012022200226783752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5430397987365723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04860837757587433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06137844920158386,
      "backward_entropy": 0.01202496886253357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.041842937469482,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04862925410270691,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06132074693838755,
      "backward_entropy": 0.01202612668275833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2694882154464722,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04865063354372978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06126182277997335,
      "backward_entropy": 0.012028379738330841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7295587062835693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04867017641663551,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061209703485171,
      "backward_entropy": 0.012032694369554519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.374634265899658,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04868960753083229,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061157931884129844,
      "backward_entropy": 0.012037008255720138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8871893882751465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048711322247982025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06109762191772461,
      "backward_entropy": 0.012036819010972977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4326932430267334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04873350262641907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061035613218943276,
      "backward_entropy": 0.012035205215215682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2154685258865356,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04875459522008896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0609771211942037,
      "backward_entropy": 0.01203339472413063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.775249004364014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048773959279060364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06092435121536255,
      "backward_entropy": 0.012031564116477966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3747897148132324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04879400506615639,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06086920698483785,
      "backward_entropy": 0.012028549611568452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.529684066772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048813216388225555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060816407203674316,
      "backward_entropy": 0.012023767828941346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.996672630310059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04883241653442383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060763234893480934,
      "backward_entropy": 0.012017140537500382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4805245399475098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048853799700737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06070252259572347,
      "backward_entropy": 0.012008792161941529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5981245040893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048874884843826294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06064305702845255,
      "backward_entropy": 0.01200152188539505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1498545408248901,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0488964319229126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060582359631856285,
      "backward_entropy": 0.011994677037000656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1455049514770508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04891623184084892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06052728990713755,
      "backward_entropy": 0.011988086998462677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.377347469329834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04893439635634422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06047805647055308,
      "backward_entropy": 0.01198335960507393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.574464321136475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04895252361893654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060429384311040245,
      "backward_entropy": 0.011980366706848145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.325880765914917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04897208884358406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060376216967900596,
      "backward_entropy": 0.011977048218250274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.388051509857178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04899149388074875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06032391389211019,
      "backward_entropy": 0.011974215507507324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.442084312438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049011580646038055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06026861071586609,
      "backward_entropy": 0.011969243735074997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.236201047897339,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04903294891119003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06020899613698324,
      "backward_entropy": 0.011962918937206269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.285385608673096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049054134637117386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06014905869960785,
      "backward_entropy": 0.011953525245189667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0765659809112549,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049075737595558167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06008796890576681,
      "backward_entropy": 0.011944480985403062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.115872621536255,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0490955114364624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06003353993097941,
      "backward_entropy": 0.011938388645648956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.05313241481781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04911438748240471,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05998228987058004,
      "backward_entropy": 0.011933646351099014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1222851276397705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049131810665130615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0599356492360433,
      "backward_entropy": 0.011928817629814148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.12352991104126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04914923384785652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05988961458206177,
      "backward_entropy": 0.011925871670246124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0564188957214355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04916742071509361,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05984094242254893,
      "backward_entropy": 0.011922774463891983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.076752662658691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04918482154607773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.059795250495274864,
      "backward_entropy": 0.011921539902687073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.023010492324829,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04920365661382675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05974499384562174,
      "backward_entropy": 0.011919706314802169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.989390850067139,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04922090098261833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.059700717528661094,
      "backward_entropy": 0.011920672655105592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.949036121368408,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049241069704294205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05964634815851847,
      "backward_entropy": 0.011917535215616226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.958209276199341,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04926304146647453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05958647529284159,
      "backward_entropy": 0.011914105713367462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9213409423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928449168801308,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05952907601992289,
      "backward_entropy": 0.011913790553808212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.823692321777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04930565133690834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.059471930066744484,
      "backward_entropy": 0.011911533772945404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.873453378677368,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04932786896824837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05941126743952433,
      "backward_entropy": 0.011907817423343658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9544281363487244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049349620938301086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05935218930244446,
      "backward_entropy": 0.011904416233301162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6940598487854,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049369629472494125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05929850538571676,
      "backward_entropy": 0.01190095990896225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7955360412597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049390796571969986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05924079815546671,
      "backward_entropy": 0.011895796656608582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.614207744598389,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049411628395318985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05918411413828532,
      "backward_entropy": 0.011890332400798797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6605818271636963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049433451145887375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0591245690981547,
      "backward_entropy": 0.011884893476963043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8207142353057861,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049455463886260986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05906485517819723,
      "backward_entropy": 0.011880634725093842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6982874870300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04947628453373909,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05900952219963074,
      "backward_entropy": 0.011878391355276107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5588974952697754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04949671030044556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058955530325571694,
      "backward_entropy": 0.011877406388521194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.526454448699951,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04951747879385948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058900674184163414,
      "backward_entropy": 0.011876071989536285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1038618087768555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049538545310497284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05884485443433126,
      "backward_entropy": 0.01187441051006317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7355741262435913,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04956188425421715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0587818572918574,
      "backward_entropy": 0.011870795488357544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5722484588623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04958391562104225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05872318148612976,
      "backward_entropy": 0.011868496239185334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5426509380340576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049605414271354675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0586664080619812,
      "backward_entropy": 0.011867161095142364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.851662814617157,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049626514315605164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058610533674558006,
      "backward_entropy": 0.011864575743675231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.671509861946106,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04964582249522209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058560738960901894,
      "backward_entropy": 0.011864853650331497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6560555696487427,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0496642030775547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058513899644215904,
      "backward_entropy": 0.011865850538015366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.086721897125244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968176409602165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0584695835908254,
      "backward_entropy": 0.011867178976535797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6281038522720337,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04970056936144829,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05842117468516032,
      "backward_entropy": 0.011866046488285065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.629279136657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04971850663423538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05837555229663849,
      "backward_entropy": 0.011865554004907608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1891822814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049738746136426926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058323616782824196,
      "backward_entropy": 0.011865802854299546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.801966667175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04975920915603638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05827133854230245,
      "backward_entropy": 0.011866693198680878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.911142349243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049777910113334656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058225015799204506,
      "backward_entropy": 0.011870769411325454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.556050419807434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049797575920820236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05817599594593048,
      "backward_entropy": 0.011875016987323761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5430978536605835,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04981624335050583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05813001592954,
      "backward_entropy": 0.011879545450210572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011052963323891163,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0498339869081974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05808704594771067,
      "backward_entropy": 0.011884930729866027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0205743312835693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049849674105644226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058050175507863365,
      "backward_entropy": 0.011890850216150283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.743460178375244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04986600577831268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05801145235697428,
      "backward_entropy": 0.011895722895860671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4862393140792847,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988350719213486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05796902378400167,
      "backward_entropy": 0.011900404095649719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.945472478866577,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04990028962492943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05792834858099619,
      "backward_entropy": 0.011903049051761627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6471669673919678,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049917563796043396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05788628260294596,
      "backward_entropy": 0.011905359476804734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7307683229446411,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04993588477373123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05784130096435547,
      "backward_entropy": 0.011907153576612473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8678324222564697,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04995270445942879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05780075987180074,
      "backward_entropy": 0.0119092158973217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.431110143661499,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04996998980641365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05775890747706095,
      "backward_entropy": 0.011910651624202729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.412831425666809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04998638108372688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057720452547073364,
      "backward_entropy": 0.011914990842342377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.18709659576416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500020794570446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05768383045991262,
      "backward_entropy": 0.011918538808822631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7020841836929321,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050019532442092896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0576421320438385,
      "backward_entropy": 0.01192074716091156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.109814167022705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500355064868927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057605077823003135,
      "backward_entropy": 0.011924301832914352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.750819683074951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05005325749516487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.057562400897343956,
      "backward_entropy": 0.003138676658272743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0226924419403076,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05007315054535866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05751341084639231,
      "backward_entropy": 0.011921760439872742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6621272563934326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05009252205491066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05746627847353617,
      "backward_entropy": 0.011920540779829025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9804868698120117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050112076103687286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05741855502128601,
      "backward_entropy": 0.011918282508850098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3102251291275024,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050131142139434814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0573724110921224,
      "backward_entropy": 0.011916861683130265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5821127891540527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05014917999505997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05732939640680949,
      "backward_entropy": 0.011916355788707733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2845289707183838,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0501675046980381,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0572854628165563,
      "backward_entropy": 0.01191476806998253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5327627658843994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05018486827611923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05724441011746725,
      "backward_entropy": 0.011914287507534028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.510694742202759,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05020254850387573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05720242361227671,
      "backward_entropy": 0.01191326379776001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7204933166503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05022044852375984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05716022849082947,
      "backward_entropy": 0.0119131900370121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0685489177703857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05023973807692528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05711416403452555,
      "backward_entropy": 0.011911799758672714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8275572061538696,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05025969073176384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05706624190012614,
      "backward_entropy": 0.011909542232751846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.000574827194214,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05027902498841286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05702056487401327,
      "backward_entropy": 0.011908909678459168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7810819149017334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050299011170864105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05697297056516012,
      "backward_entropy": 0.011907192319631577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3495290279388428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05031849071383476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05692653854688009,
      "backward_entropy": 0.01190391555428505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.32338285446167,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050338007509708405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056880066792170204,
      "backward_entropy": 0.011900652199983597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2963855266571045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05035754293203354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05683368444442749,
      "backward_entropy": 0.011897768080234527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.272359609603882,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05037710815668106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05678722759087881,
      "backward_entropy": 0.011894521117210389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2397758960723877,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050396647304296494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.05674112836519877,
      "backward_entropy": 0.13851120471954345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1162123680114746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05041629076004028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05669418474038442,
      "backward_entropy": 0.011887016892433166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1011286973953247,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05043477192521095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.056650797526041664,
      "backward_entropy": 0.13851969242095946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5466116666793823,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05045225843787193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05661024649937948,
      "backward_entropy": 0.011881540715694427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5493584275245667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05046834796667099,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05657320221265157,
      "backward_entropy": 0.0028397707268595696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008501020260155201,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05048301815986633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056540727615356445,
      "backward_entropy": 0.01187918707728386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1650900840759277,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050495974719524384,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.05651283264160156,
      "backward_entropy": 0.13852324485778808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6143577098846436,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050510622560977936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056480358044306435,
      "backward_entropy": 0.011880481243133545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0392898321151733,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052625387907028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056445141633351646,
      "backward_entropy": 0.011879663169384002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.055605411529541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05054117366671562,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05641160408655802,
      "backward_entropy": 0.011878190934658051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005264269653707743,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05055644363164902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056377420822779335,
      "backward_entropy": 0.011877579987049103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0124660730361938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05057000368833542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05634749929110209,
      "backward_entropy": 0.01187659353017807,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.7758029950829224,
    "avg_log_Z": -0.049663368575274945,
    "success_rate": 1.0,
    "avg_reward": 85.7,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.02,
      "2": 0.95
    },
    "avg_forward_entropy": 0.05857737913727761,
    "avg_backward_entropy": 0.015538219111040237,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}