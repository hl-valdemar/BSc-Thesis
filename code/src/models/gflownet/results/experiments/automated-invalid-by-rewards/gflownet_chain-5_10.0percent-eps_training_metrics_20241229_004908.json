{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13862526416778564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.1382655382156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.68710327148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303443988164267,
      "backward_entropy": 0.13843697309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.6671905517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830381155014038,
      "backward_entropy": 0.13843886852264403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.166748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00020000003860332072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18304161230723062,
      "backward_entropy": 0.1386261224746704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.627685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0002982585574500263,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304500977198282,
      "backward_entropy": 0.13844223022460939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.17141723632812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00039731094148010015,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304828802744547,
      "backward_entropy": 0.13830163478851318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.15167236328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00049690215382725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18305142720540366,
      "backward_entropy": 0.13862719535827636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.04112243652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005968443583697081,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305440743764242,
      "backward_entropy": 0.13831894397735595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.5140380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006976623553782701,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18305726846059164,
      "backward_entropy": 0.13862781524658202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.4658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007964722462929785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830600698788961,
      "backward_entropy": 0.13845053911209107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.8472442626953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008968762122094631,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306273221969604,
      "backward_entropy": 0.13834238052368164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.92405700683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0009978845482692122,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830652952194214,
      "backward_entropy": 0.13834927082061768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.26504516601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001098265522159636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830677588780721,
      "backward_entropy": 0.13845624923706054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.3685760498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00120007514487952,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830701231956482,
      "backward_entropy": 0.13836281299591063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.21536254882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013031307607889175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307232856750488,
      "backward_entropy": 0.13846036195755004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.9702606201172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014070654287934303,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830743948618571,
      "backward_entropy": 0.13837621212005616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.94970703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015097649302333593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307636181513467,
      "backward_entropy": 0.13862934112548828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.3981475830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016114204190671444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307816982269287,
      "backward_entropy": 0.1384664535522461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.47305297851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017145550809800625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307979901631674,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.97412109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018166110385209322,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830812692642212,
      "backward_entropy": 0.13840115070343018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.6300506591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019206079887226224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830826203028361,
      "backward_entropy": 0.13862937688827515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.72560119628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00202542613260448,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308387200037637,
      "backward_entropy": 0.13862929344177247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.70248413085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021298774518072605,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830849846204122,
      "backward_entropy": 0.13841910362243653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.36940002441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0022340035066008568,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830859581629435,
      "backward_entropy": 0.13842488527297975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.6543426513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0023366988170892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308677275975546,
      "backward_entropy": 0.138480281829834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.45771026611328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024377796798944473,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308748801549277,
      "backward_entropy": 0.138435959815979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.48129272460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002536358777433634,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308806419372559,
      "backward_entropy": 0.13848369121551513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.01953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026352067943662405,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308852116266885,
      "backward_entropy": 0.1384853482246399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.8585205078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027358222287148237,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830888589223226,
      "backward_entropy": 0.13845131397247315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.09945678710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028389941435307264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308903773625693,
      "backward_entropy": 0.13862712383270265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.93350219726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029434580355882645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308903773625693,
      "backward_entropy": 0.13849070072174072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.7873992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003050052560865879,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830888589223226,
      "backward_entropy": 0.13849254846572875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.0369415283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003157001454383135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308856089909872,
      "backward_entropy": 0.13862550258636475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.56187438964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00326324999332428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830881635348002,
      "backward_entropy": 0.13862481117248535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.44305419921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003370380960404873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830875277519226,
      "backward_entropy": 0.1386240839958191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.64169311523438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034750502090901136,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308683236440024,
      "backward_entropy": 0.13848503828048705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.3260955810547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003582814708352089,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830859382947286,
      "backward_entropy": 0.13848953247070311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.14535522460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0036939233541488647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830849051475525,
      "backward_entropy": 0.13862147331237792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.8522186279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038071488961577415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308363358179727,
      "backward_entropy": 0.13850561380386353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.63706970214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0039218030869960785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308224280675253,
      "backward_entropy": 0.13850769996643067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.40989685058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004032437689602375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.183080792427063,
      "backward_entropy": 0.13850977420806884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.75599670410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0041416059248149395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307918310165405,
      "backward_entropy": 0.1385117769241333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.2252197265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004252709913998842,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18307737509409586,
      "backward_entropy": 0.13851535320281982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.50514221191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004361271392554045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307544787724814,
      "backward_entropy": 0.1385156512260437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.74368286132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004467946011573076,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307346105575562,
      "backward_entropy": 0.138517427444458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.2413330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004573400132358074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307129542032877,
      "backward_entropy": 0.13861052989959716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.990234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004679365083575249,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306889136632284,
      "backward_entropy": 0.13852062225341796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.92042541503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004788252990692854,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306618928909302,
      "backward_entropy": 0.13853342533111573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.87398529052734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004896734841167927,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830633282661438,
      "backward_entropy": 0.13853673934936522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.6673583984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005000684875994921,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306036790211996,
      "backward_entropy": 0.13860325813293456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.29150390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0051019927486777306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305728832880655,
      "backward_entropy": 0.13852624893188475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.55796813964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005206718109548092,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18305393060048422,
      "backward_entropy": 0.13859908580780028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.80235290527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005314083304256201,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305031458536783,
      "backward_entropy": 0.13854904174804689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.07542419433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005420405883342028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18304646015167236,
      "backward_entropy": 0.13859457969665528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.82310485839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005525445565581322,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304244677225748,
      "backward_entropy": 0.13853118419647217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.38734436035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00563428271561861,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830381155014038,
      "backward_entropy": 0.13858976364135742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.8594970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005742882844060659,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303358554840088,
      "backward_entropy": 0.1385335922241211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.17214965820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005849627312272787,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830289363861084,
      "backward_entropy": 0.13858451843261718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.22174072265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005953592713922262,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302408854166666,
      "backward_entropy": 0.13856509923934937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2101593017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006053391844034195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301922082901,
      "backward_entropy": 0.13857898712158204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.1829376220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00615216139703989,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830141544342041,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.37179565429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006250015459954739,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300898869832358,
      "backward_entropy": 0.13857176303863525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.4768829345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006348302122205496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300368388493857,
      "backward_entropy": 0.13856971263885498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.61854553222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006447212770581245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299814065297446,
      "backward_entropy": 0.13856635093688965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.5045928955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006543389055877924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299251794815063,
      "backward_entropy": 0.13856279850006104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.7034149169922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00663880817592144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298669656117758,
      "backward_entropy": 0.1385805368423462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.7874298095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00673211645334959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298075596491495,
      "backward_entropy": 0.1385552167892456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.5155792236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006826518569141626,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829745372136434,
      "backward_entropy": 0.13854732513427734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.66653442382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0069186571054160595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18296819925308228,
      "backward_entropy": 0.13854684829711914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.9324951171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007011004723608494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18296162287394205,
      "backward_entropy": 0.13858884572982788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.19728088378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007103166077286005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18295480807622275,
      "backward_entropy": 0.13855209350585937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.99337768554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007194784004241228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829478939374288,
      "backward_entropy": 0.13855377435684205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.0641326904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007291052490472794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294048309326172,
      "backward_entropy": 0.13852859735488893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.81802368164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007389846723526716,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293273448944092,
      "backward_entropy": 0.1385571241378784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.97209930419922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0074877431616187096,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292474746704102,
      "backward_entropy": 0.13859982490539552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.98833465576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007580220699310303,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291672070821127,
      "backward_entropy": 0.13856042623519899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.557373046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007668951526284218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290863434473673,
      "backward_entropy": 0.13850753307342528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.095458984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007756518665701151,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290038903554282,
      "backward_entropy": 0.13860596418380738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.05614471435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007849888876080513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289156754811606,
      "backward_entropy": 0.1385655403137207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.58387756347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00793967954814434,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18288270632425943,
      "backward_entropy": 0.13860976696014404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.71844482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008035114035010338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287326892217,
      "backward_entropy": 0.13856925964355468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.423583984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00812714546918869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286371231079102,
      "backward_entropy": 0.1384760856628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.90908432006836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00821763463318348,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285399675369263,
      "backward_entropy": 0.13861488103866576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.65750122070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008298077620565891,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18284457921981812,
      "backward_entropy": 0.13857437372207643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.05229949951172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008377757854759693,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18283490339914957,
      "backward_entropy": 0.13861770629882814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.4658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008455486968159676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828251282374064,
      "backward_entropy": 0.13844749927520753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.2926025390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008534568361938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18281495571136475,
      "backward_entropy": 0.13843986988067628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.12266540527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008613480255007744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828045646349589,
      "backward_entropy": 0.13858067989349365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.9363555908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008691980503499508,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279383579889932,
      "backward_entropy": 0.13862252235412598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.35134887695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008776118978857994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278233210245767,
      "backward_entropy": 0.13841569423675537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.03945922851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00885890144854784,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277060985565186,
      "backward_entropy": 0.13862451314926147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.43003845214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008940890431404114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275860945383707,
      "backward_entropy": 0.13839808702468873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.2955551147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00902413111180067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274617195129395,
      "backward_entropy": 0.13838914632797242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.27297973632812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009102795273065567,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18273377418518066,
      "backward_entropy": 0.13862684965133668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.61720275878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009190251119434834,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18272042274475098,
      "backward_entropy": 0.13862746953964233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.46804809570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00927795935422182,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18270671367645264,
      "backward_entropy": 0.1386279821395874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.41744995117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009364505298435688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18269272645314535,
      "backward_entropy": 0.13835055828094484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.28720092773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009452094323933125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18267834186553955,
      "backward_entropy": 0.13859717845916747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.72389221191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009544765576720238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266318241755167,
      "backward_entropy": 0.1385986328125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1710968017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009632052853703499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18264816204706827,
      "backward_entropy": 0.1383203983306885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4642333984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009720033966004848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18263272444407144,
      "backward_entropy": 0.13860149383544923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.95628356933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009807108901441097,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261698881785074,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.46044921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009894651360809803,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826008359591166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.5015411376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009989122860133648,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18258372942606607,
      "backward_entropy": 0.13860533237457276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.55308532714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010090894997119904,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256558974583945,
      "backward_entropy": 0.13826799392700195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.61753845214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010196208022534847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254671494166055,
      "backward_entropy": 0.13860751390457154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.22900390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010301696136593819,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18252738316853842,
      "backward_entropy": 0.13862888813018798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.98153686523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01040875818580389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250747521718344,
      "backward_entropy": 0.13860952854156494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.06570434570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010521036572754383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18248661359151205,
      "backward_entropy": 0.13861051797866822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.2312774658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01063279528170824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824654539426168,
      "backward_entropy": 0.13861145973205566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.27867889404297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010742389596998692,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18244419495264688,
      "backward_entropy": 0.1386277198791504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.4546661376953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010845527984201908,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242319424947104,
      "backward_entropy": 0.13862738609313965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.36349487304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010947915725409985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240181605021158,
      "backward_entropy": 0.13818089962005614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.58010864257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01105513609945774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18237942457199097,
      "backward_entropy": 0.13861479759216308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.68722534179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011162704788148403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235655625661215,
      "backward_entropy": 0.13815844058990479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.19236755371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011266623623669147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233364820480347,
      "backward_entropy": 0.13861615657806398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.68533325195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01137072965502739,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18231022357940674,
      "backward_entropy": 0.13862558603286743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.39189147949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011473805643618107,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822864611943563,
      "backward_entropy": 0.13812243938446045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.51890563964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011572025716304779,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18226277828216553,
      "backward_entropy": 0.13862478733062744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.2716064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011672225780785084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18223836024602255,
      "backward_entropy": 0.13809609413146973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.60054016113281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011765007860958576,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18221439917882284,
      "backward_entropy": 0.13862388134002684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.91566467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01185450330376625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18219047784805298,
      "backward_entropy": 0.13862028121948242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.26502990722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011944365687668324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18216603994369507,
      "backward_entropy": 0.13862093687057495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.45057678222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01204161997884512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18214007218678793,
      "backward_entropy": 0.1380384922027588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.5589599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012142477557063103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18211313088734946,
      "backward_entropy": 0.138023841381073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.5919189453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012248027138411999,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18208497762680054,
      "backward_entropy": 0.13862276077270508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.02024841308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012349228374660015,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820568839708964,
      "backward_entropy": 0.13862138986587524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.91439056396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012451345100998878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18202813466389975,
      "backward_entropy": 0.13798017501831056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.4734344482422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012545544654130936,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18200006087621054,
      "backward_entropy": 0.1386207103729248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.99673461914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012639276683330536,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18197151025136313,
      "backward_entropy": 0.13862484693527222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.38963317871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012734070420265198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18194182713826498,
      "backward_entropy": 0.13862533569335939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.72828674316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012828339822590351,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18191113074620566,
      "backward_entropy": 0.13861924409866333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.0359344482422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012928158044815063,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818786859512329,
      "backward_entropy": 0.1386188268661499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.212646484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013027304783463478,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18184560537338257,
      "backward_entropy": 0.13788254261016847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.2830810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01313028484582901,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18181111415227255,
      "backward_entropy": 0.1386270046234131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.04576110839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013232539407908916,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18177594741185507,
      "backward_entropy": 0.13862740993499756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.73927307128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01333184540271759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18174058198928833,
      "backward_entropy": 0.1378314733505249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.44203186035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013428904116153717,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817048986752828,
      "backward_entropy": 0.13861689567565919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.6516876220703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013526384718716145,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18166844050089517,
      "backward_entropy": 0.1386164426803589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.05551147460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013626080006361008,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816301941871643,
      "backward_entropy": 0.1386286973953247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.14248657226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013730434700846672,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1815895438194275,
      "backward_entropy": 0.13862892389297485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.84867095947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013839143328368664,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18154672781626383,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.48045349121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013942847028374672,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18150395154953003,
      "backward_entropy": 0.13861486911773682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.8426971435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01404673233628273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18146008253097534,
      "backward_entropy": 0.13862936496734618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.62660217285156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014147721230983734,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18141667048136392,
      "backward_entropy": 0.13861401081085206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.58934020996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01424878928810358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18137248357137045,
      "backward_entropy": 0.13765581846237182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.0610809326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014346981421113014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18132803837458292,
      "backward_entropy": 0.1386293888092041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.15533447265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014448544010519981,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18128180503845215,
      "backward_entropy": 0.1386292815208435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.49712371826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01454191654920578,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1812366247177124,
      "backward_entropy": 0.1375828504562378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.97999572753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014630141668021679,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18119188149770102,
      "backward_entropy": 0.13861045837402344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.06832885742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01471692230552435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18114662170410156,
      "backward_entropy": 0.13752646446228028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.80502319335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014807256869971752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810996135075887,
      "backward_entropy": 0.13749849796295166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.76788330078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014898914843797684,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18105135361353555,
      "backward_entropy": 0.1386272430419922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.23936462402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014985459856688976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18100361029307047,
      "backward_entropy": 0.13743979930877687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.70506286621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015072246082127094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18095489343007407,
      "backward_entropy": 0.1386255741119385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.0914535522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015165476128458977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18090357383092245,
      "backward_entropy": 0.13862459659576415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.10519409179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015254966914653778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18085243304570517,
      "backward_entropy": 0.13734812736511232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.7362289428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015347598120570183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18079952398935953,
      "backward_entropy": 0.13862216472625732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.22080993652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015435291454195976,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1807472507158915,
      "backward_entropy": 0.1386020541191101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.3280029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015522701665759087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18069408337275186,
      "backward_entropy": 0.1372508406639099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.51365661621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015610132366418839,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18064000209172568,
      "backward_entropy": 0.13861706256866455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.05038452148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01570042222738266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18058409293492636,
      "backward_entropy": 0.1371791124343872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.74118041992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015790173783898354,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1805273691813151,
      "backward_entropy": 0.1385974407196045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.67770385742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015887102112174034,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1804675062497457,
      "backward_entropy": 0.13859647512435913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.3084259033203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01598319225013256,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1804069479306539,
      "backward_entropy": 0.13859543800354004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.10182189941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016086090356111526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18034332990646362,
      "backward_entropy": 0.13860459327697755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.32041931152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01618923246860504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1802786389986674,
      "backward_entropy": 0.13699191808700562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.79054260253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01628802716732025,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18021464347839355,
      "backward_entropy": 0.13859355449676514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.8339080810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01638972759246826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1801484227180481,
      "backward_entropy": 0.13859530687332153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.43312072753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016488313674926758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18008220195770264,
      "backward_entropy": 0.13687386512756347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.81947326660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016588645055890083,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18001439174016318,
      "backward_entropy": 0.13859089612960815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.45631408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01668788120150566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17994598547617593,
      "backward_entropy": 0.13858346939086913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.44407653808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016789965331554413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17987537384033203,
      "backward_entropy": 0.13857922554016114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.7061309814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016892096027731895,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17980370918909708,
      "backward_entropy": 0.13858802318573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.26429748535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016991326585412025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1797321637471517,
      "backward_entropy": 0.13856972455978395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.70982360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0170984398573637,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1796566049257914,
      "backward_entropy": 0.1366058349609375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.5601348876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017206721007823944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17957951625188193,
      "backward_entropy": 0.13656151294708252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.95751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01731422170996666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1795016129811605,
      "backward_entropy": 0.13855412006378173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.10545349121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01742270588874817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17942219972610474,
      "backward_entropy": 0.13854812383651732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.66116333007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01752893067896366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17934258778889975,
      "backward_entropy": 0.13641819953918458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.95993041992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017640434205532074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17925955851872763,
      "backward_entropy": 0.13853492736816406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.78121948242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01774934120476246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791763703028361,
      "backward_entropy": 0.13631758689880372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.7848663330078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0178547203540802,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17909340063730875,
      "backward_entropy": 0.13858067989349365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.30496215820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017956266179680824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.179010808467865,
      "backward_entropy": 0.1385103225708008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.17977905273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018054498359560966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1789283553759257,
      "backward_entropy": 0.13850014209747313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.92353820800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018154390156269073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17884379625320435,
      "backward_entropy": 0.13607299327850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.69334411621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018249645829200745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17876009146372476,
      "backward_entropy": 0.13600149154663085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.15660095214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018342358991503716,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17867628733317056,
      "backward_entropy": 0.13856863975524902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.7904510498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01843169890344143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1785929799079895,
      "backward_entropy": 0.1385652780532837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.1295928955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01852058805525303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17850855986277261,
      "backward_entropy": 0.1357724666595459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.6418914794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0186089426279068,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17842300732930502,
      "backward_entropy": 0.13842086791992186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.5439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01870184950530529,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17833385864893594,
      "backward_entropy": 0.13561183214187622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.64059448242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018795805051922798,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1782429019610087,
      "backward_entropy": 0.1385520100593567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.64588928222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01889096386730671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17814979950586954,
      "backward_entropy": 0.13837428092956544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.7397689819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018984680995345116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1780542532602946,
      "backward_entropy": 0.1383572220802307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.03030395507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019074933603405952,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17795878648757935,
      "backward_entropy": 0.13833893537521363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.47177124023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019165052101016045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17786169052124023,
      "backward_entropy": 0.13519859313964844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.5282440185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01925824023783207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17776127656300864,
      "backward_entropy": 0.13830063343048096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.404052734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019349247217178345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17766046524047852,
      "backward_entropy": 0.13828003406524658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.6958465576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019445830956101418,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1775547663370768,
      "backward_entropy": 0.1382594585418701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.2638397216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019547242671251297,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17744457721710205,
      "backward_entropy": 0.1385282039642334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.8468780517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019650759175419807,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17733176549275717,
      "backward_entropy": 0.13852661848068237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.32847595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01975446194410324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17721732457478842,
      "backward_entropy": 0.13468501567840577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.98123168945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019862188026309013,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17709954579671225,
      "backward_entropy": 0.13852400779724122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.2584686279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01997385546565056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17697793245315552,
      "backward_entropy": 0.13451985120773316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.25778198242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020088884979486465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17685258388519287,
      "backward_entropy": 0.13812676668167115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.0171356201172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02020258456468582,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1767264405886332,
      "backward_entropy": 0.13852252960205078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.33677673339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020316874608397484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17659838994344076,
      "backward_entropy": 0.13427407741546632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.938232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020435424521565437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17646580934524536,
      "backward_entropy": 0.13805370330810546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 231.6349639892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02055223472416401,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17633267243703207,
      "backward_entropy": 0.13410463333129882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.440185546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020673099905252457,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1761950651804606,
      "backward_entropy": 0.13800137042999266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.91097259521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020796194672584534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17605419953664145,
      "backward_entropy": 0.13797526359558104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.6836700439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020912637934088707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1759162743886312,
      "backward_entropy": 0.13794559240341187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.59715270996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02102774567902088,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17577767372131348,
      "backward_entropy": 0.13852105140686036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.86021423339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02114441618323326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17563619216283163,
      "backward_entropy": 0.13788328170776368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.74464416503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021256757900118828,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17549622058868408,
      "backward_entropy": 0.1378492832183838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.47933959960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02136942930519581,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1753542423248291,
      "backward_entropy": 0.1378143310546875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.98802185058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0214786846190691,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17521262168884277,
      "backward_entropy": 0.1385156035423279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.02303314208984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021584220230579376,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17507219314575195,
      "backward_entropy": 0.1385122299194336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.7652587890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02168137952685356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17493651310602823,
      "backward_entropy": 0.1376883268356323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.6763916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021783336997032166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1747953693072001,
      "backward_entropy": 0.13764235973358155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.69267272949219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021888811141252518,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17465015252431235,
      "backward_entropy": 0.13849968910217286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.53311157226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0219894889742136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17450722058614096,
      "backward_entropy": 0.13268826007843018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.55491638183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02208729088306427,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17436500390370688,
      "backward_entropy": 0.1384915828704834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.85665893554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022183552384376526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17422211170196533,
      "backward_entropy": 0.13744764328002929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.36592102050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02228139340877533,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17407596111297607,
      "backward_entropy": 0.13739285469055176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.80097198486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022375205531716347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17393171787261963,
      "backward_entropy": 0.13210413455963135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.5268783569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022463804110884666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17379053433736166,
      "backward_entropy": 0.1372716784477234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022547442466020584,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1736520528793335,
      "backward_entropy": 0.13720390796661378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.17796325683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022634370252490044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17350906133651733,
      "backward_entropy": 0.13158650398254396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.64259338378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022716239094734192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17336875200271606,
      "backward_entropy": 0.1370623826980591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.2136993408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02280503325164318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1732210318247477,
      "backward_entropy": 0.1312227725982666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.08702087402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02289644069969654,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17306919892628989,
      "backward_entropy": 0.13842958211898804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.7290496826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022990189492702484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17291303475697836,
      "backward_entropy": 0.1308733582496643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.4369125366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023082030937075615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17275667190551758,
      "backward_entropy": 0.13677937984466554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.32157135009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023168064653873444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17260475953420004,
      "backward_entropy": 0.1367009162902832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.10069274902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023249268531799316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17245552937189737,
      "backward_entropy": 0.13661570549011232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.24266052246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02332545630633831,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17231003443400064,
      "backward_entropy": 0.13652536869049073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.3303680419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023405326530337334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17215879758199057,
      "backward_entropy": 0.12990751266479492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.19684600830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023488758131861687,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17200221618016562,
      "backward_entropy": 0.129699444770813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.0668182373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023569628596305847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17184658845265707,
      "backward_entropy": 0.12948391437530518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.5513458251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023649921640753746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1716899871826172,
      "backward_entropy": 0.13614866733551026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.8081817626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02373388037085533,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17152651151021323,
      "backward_entropy": 0.13605180978775025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.08544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023820994421839714,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17135759194691977,
      "backward_entropy": 0.1359553575515747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.91212463378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02391374111175537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1711807648340861,
      "backward_entropy": 0.1286396026611328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.7162322998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024005619809031487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1710030436515808,
      "backward_entropy": 0.1357640504837036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.8909912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02409541793167591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17082800467809042,
      "backward_entropy": 0.12819498777389526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.2972869873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02418491616845131,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17065159479777017,
      "backward_entropy": 0.12796459197998047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.481201171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024281425401568413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1704661250114441,
      "backward_entropy": 0.12774903774261476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.99539947509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024377329275012016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17028021812438965,
      "backward_entropy": 0.1353604793548584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.21367645263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024467848241329193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1700986623764038,
      "backward_entropy": 0.1273043155670166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.81745147705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024551386013627052,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16992328564325967,
      "backward_entropy": 0.13513054847717285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.7670135498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024632101878523827,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16974949836730957,
      "backward_entropy": 0.1350025177001953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.97129821777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024720631539821625,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16956518093744913,
      "backward_entropy": 0.13825968503952027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.43270874023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024807019159197807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16938143968582153,
      "backward_entropy": 0.13475313186645507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.76414489746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02489933930337429,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.169189453125,
      "backward_entropy": 0.13463058471679687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.43143463134766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02499108761548996,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1689966917037964,
      "backward_entropy": 0.13823518753051758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.95909118652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025076547637581825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16881044705708823,
      "backward_entropy": 0.12542048692703248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.5572280883789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025164850056171417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16861911614735922,
      "backward_entropy": 0.12513415813446044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.35539245605469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02524840645492077,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16843223571777344,
      "backward_entropy": 0.13820343017578124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.4912567138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025329014286398888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16824738184611002,
      "backward_entropy": 0.13392815589904786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.75935363769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02541579119861126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16805328925450644,
      "backward_entropy": 0.13377716541290283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.5526351928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025499433279037476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1678617000579834,
      "backward_entropy": 0.12386784553527833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.0886688232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02557867206633091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16767428318659464,
      "backward_entropy": 0.13344777822494508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.92963409423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025658562779426575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16748464107513428,
      "backward_entropy": 0.13327325582504274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.19905853271484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025736553594470024,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1672967473665873,
      "backward_entropy": 0.1381152868270874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.43740844726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025812707841396332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16711026430130005,
      "backward_entropy": 0.12246801853179931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.30213928222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02588958851993084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16692233085632324,
      "backward_entropy": 0.12210465669631958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.47471618652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025967128574848175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16673219203948975,
      "backward_entropy": 0.121730637550354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.524169921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026048649102449417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1665355364481608,
      "backward_entropy": 0.12136750221252442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.7686309814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02612932026386261,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16633901000022888,
      "backward_entropy": 0.132151198387146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.0890655517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02620910294353962,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16614269216855368,
      "backward_entropy": 0.13802070617675782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.18766784667969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026292266324162483,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16594040393829346,
      "backward_entropy": 0.13800735473632814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.1839141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026371261104941368,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16574276487032572,
      "backward_entropy": 0.1315469980239868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.10389709472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026450473815202713,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16554319858551025,
      "backward_entropy": 0.13133082389831544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.66871643066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026530932635068893,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16534135739008585,
      "backward_entropy": 0.13111593723297119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.9094696044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02661498263478279,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16513375441233316,
      "backward_entropy": 0.1186232328414917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.41148376464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026699403300881386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1649244725704193,
      "backward_entropy": 0.11822201013565063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.5895538330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026790326461195946,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1647060513496399,
      "backward_entropy": 0.13048856258392333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.18241882324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026882082223892212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.164485365152359,
      "backward_entropy": 0.1302832007408142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.92933654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026967385783791542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16427303353945413,
      "backward_entropy": 0.11706008911132812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.34151458740234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027053063735365868,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16405944029490152,
      "backward_entropy": 0.13789787292480468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.37467193603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02713620848953724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16384883721669516,
      "backward_entropy": 0.1162304162979126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.00027465820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027215493842959404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16364306211471558,
      "backward_entropy": 0.1293488025665283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.69749450683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027294084429740906,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16343740622202554,
      "backward_entropy": 0.12909431457519532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.23231506347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02736755460500717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1632384459177653,
      "backward_entropy": 0.11488069295883178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.440185546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027447426691651344,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16302945216496786,
      "backward_entropy": 0.13782076835632323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.44831848144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027522459626197815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16282731294631958,
      "backward_entropy": 0.12830355167388915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.24913024902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027597246691584587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16262451807657877,
      "backward_entropy": 0.11354306936264039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.7201156616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027674442157149315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16241689523061117,
      "backward_entropy": 0.12775123119354248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.76140594482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0277476217597723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16221391161282858,
      "backward_entropy": 0.1274542212486267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.96202087402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02781638875603676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620171070098877,
      "backward_entropy": 0.11202528476715087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.68614196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027887022122740746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618165373802185,
      "backward_entropy": 0.11149264574050903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.35079956054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027956441044807434,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1616171101729075,
      "backward_entropy": 0.12650279998779296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.20875549316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02802925370633602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1614116132259369,
      "backward_entropy": 0.12618234157562255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.27674102783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028106549754738808,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16119888424873352,
      "backward_entropy": 0.12586688995361328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.81634521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028180530294775963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16099011898040771,
      "backward_entropy": 0.1255343198776245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.99842834472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02825312316417694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16078299283981323,
      "backward_entropy": 0.10880171060562134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.5995864868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028327248990535736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16057290633519491,
      "backward_entropy": 0.12485097646713257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.50383758544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028398137539625168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16036693255106607,
      "backward_entropy": 0.10767557621002197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.83151245117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028465047478675842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16016709804534912,
      "backward_entropy": 0.10708733797073364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.63472747802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028534356504678726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1599629521369934,
      "backward_entropy": 0.12374975681304931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.3363037109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028599729761481285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1597647269566854,
      "backward_entropy": 0.10591508150100708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.2196044921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02867056243121624,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1595573623975118,
      "backward_entropy": 0.12299258708953857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.95934295654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028739867731928825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15935174624125162,
      "backward_entropy": 0.12260771989822387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.40708923339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02880926989018917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15914522608121237,
      "backward_entropy": 0.12221336364746094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.56898498535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028883490711450577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1589307188987732,
      "backward_entropy": 0.10351669788360596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.62750244140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028965000063180923,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15870481729507446,
      "backward_entropy": 0.12146825790405273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.65547943115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02904394641518593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15848260124524435,
      "backward_entropy": 0.1023280143737793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.6919937133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029119135811924934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15826634565989176,
      "backward_entropy": 0.12068312168121338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.89894104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029193062335252762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1580523451169332,
      "backward_entropy": 0.10104813575744628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.04499053955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029266120865941048,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15784014264742532,
      "backward_entropy": 0.11985964775085449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.43612670898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029337892308831215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15762990713119507,
      "backward_entropy": 0.11943658590316772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.95996856689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0294118020683527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15741624434789023,
      "backward_entropy": 0.11902108192443847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.0816650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029481565579771996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15720961491266885,
      "backward_entropy": 0.09852384328842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.9886474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029553692787885666,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15699933966000876,
      "backward_entropy": 0.13716366291046142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.0305938720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02963094599545002,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1567812959353129,
      "backward_entropy": 0.09730961322784423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.8581085205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02971099317073822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15655895074208578,
      "backward_entropy": 0.09672206044197082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.91455078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02979522943496704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.156330406665802,
      "backward_entropy": 0.0961517333984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.14315795898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029881425201892853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1560989816983541,
      "backward_entropy": 0.0955713450908661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.93851470947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02997167408466339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1558623413244883,
      "backward_entropy": 0.09504007697105407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.23848724365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0300605446100235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15562840302785239,
      "backward_entropy": 0.115789794921875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.22606658935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03014712780714035,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1553990642229716,
      "backward_entropy": 0.11538784503936768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.9430694580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030222678557038307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15518728892008463,
      "backward_entropy": 0.11492083072662354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.05068969726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030299782752990723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1549732287724813,
      "backward_entropy": 0.11445623636245728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.00305938720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03037816844880581,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15475744009017944,
      "backward_entropy": 0.1139904499053955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.56726837158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030453519895672798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15454713503519693,
      "backward_entropy": 0.09130710363388062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.09696197509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030524181202054024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15434460838635763,
      "backward_entropy": 0.09059969186782837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.11673736572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030593670904636383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15414392948150635,
      "backward_entropy": 0.08987425565719605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.55372619628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030659591779112816,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1539496382077535,
      "backward_entropy": 0.13694770336151124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.1381072998047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03072415664792061,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1537583867708842,
      "backward_entropy": 0.13690736293792724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.1011962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030793290585279465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15355974435806274,
      "backward_entropy": 0.1108582854270935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.2824935913086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03086603246629238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15335545937220255,
      "backward_entropy": 0.08705298900604248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.37265014648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03093745931982994,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15315348903338113,
      "backward_entropy": 0.1098200798034668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.14768981933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031012408435344696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15294631322224936,
      "backward_entropy": 0.10930743217468261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.30455017089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031090525910258293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1527345379193624,
      "backward_entropy": 0.10880670547485352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.2950668334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031174439936876297,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15251443783442178,
      "backward_entropy": 0.08435943722724915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.58935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03125608712434769,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1522988478342692,
      "backward_entropy": 0.10783860683441163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.806396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03134060278534889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15207981069882712,
      "backward_entropy": 0.0830552339553833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.7889404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031423307955265045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15186554193496704,
      "backward_entropy": 0.10688031911849975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.217529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03150804713368416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15164868036905924,
      "backward_entropy": 0.10639481544494629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.76215362548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03158953785896301,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15143833557764688,
      "backward_entropy": 0.08109562397003174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.08439636230469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03167085722088814,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15122934182484946,
      "backward_entropy": 0.13676092624664307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.16668701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03174722194671631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1510289510091146,
      "backward_entropy": 0.07972007989883423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.13616943359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031827040016651154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15082436800003052,
      "backward_entropy": 0.0790412187576294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.78510284423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03190389648079872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15062537789344788,
      "backward_entropy": 0.07834756374359131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.4239044189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03197772800922394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1504318912823995,
      "backward_entropy": 0.07762353420257569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.15160369873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032053392380476,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1502362092336019,
      "backward_entropy": 0.13665354251861572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.31889343261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03211987018585205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15005600452423096,
      "backward_entropy": 0.07611488699913024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.36924743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03218633309006691,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1498767832914988,
      "backward_entropy": 0.07534087896347046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.63209533691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032258495688438416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14968939622243246,
      "backward_entropy": 0.10070831775665283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.31884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03233553096652031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14949530363082886,
      "backward_entropy": 0.07388603687286377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.36763000488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032409362494945526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1493070125579834,
      "backward_entropy": 0.09951444268226624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.73059844970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032483551651239395,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14911923805872598,
      "backward_entropy": 0.13645964860916138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.49689483642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032554034143686295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14893853664398193,
      "backward_entropy": 0.09826730489730835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.56507873535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03262406215071678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14875954389572144,
      "backward_entropy": 0.07086008787155151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.2119140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03269357606768608,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14858238895734152,
      "backward_entropy": 0.07010374665260315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6433868408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032770074903964996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14839585622151694,
      "backward_entropy": 0.06940104961395263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.61223602294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03285027667880058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14820540944735208,
      "backward_entropy": 0.0958351194858551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.95851135253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032927315682172775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1480210324128469,
      "backward_entropy": 0.09524375200271606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.21678161621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033008940517902374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1478313406308492,
      "backward_entropy": 0.0673830270767212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.61734008789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033091288059949875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14764193693796793,
      "backward_entropy": 0.06669017672538757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.53538513183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03317756950855255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14744862914085388,
      "backward_entropy": 0.06601413488388061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.24141693115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03326599299907684,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14725389083226523,
      "backward_entropy": 0.0929690420627594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.31756591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03334943577647209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14706836144129434,
      "backward_entropy": 0.06466050148010254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.7290267944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033431362360715866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14688674608866373,
      "backward_entropy": 0.06397799253463746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.37381744384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03351110219955444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14670942227045694,
      "backward_entropy": 0.063259357213974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.27059936523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03358771651983261,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14653789003690085,
      "backward_entropy": 0.09049580097198487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.27982330322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03367040306329727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14635953307151794,
      "backward_entropy": 0.08987722396850586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.72427368164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03375251218676567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1461833119392395,
      "backward_entropy": 0.08924394845962524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.95458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03383772447705269,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14600481589635214,
      "backward_entropy": 0.06040542721748352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.47346496582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03391968086361885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14583279689153036,
      "backward_entropy": 0.059720611572265624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.15511322021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03400176391005516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14566226800282797,
      "backward_entropy": 0.08742432594299317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.25944519042969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034081168472766876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14549715320269266,
      "backward_entropy": 0.08680715560913085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.80259704589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03415747359395027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14533762137095133,
      "backward_entropy": 0.08616136908531188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.58399963378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03423171490430832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14518247048060098,
      "backward_entropy": 0.05700018405914307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.98699188232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03430692106485367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14502749840418497,
      "backward_entropy": 0.056330549716949466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.96510314941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0343826599419117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14487301309903464,
      "backward_entropy": 0.08423588871955871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.48493766784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03445877879858017,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14471924304962158,
      "backward_entropy": 0.054989755153656006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.73933410644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03452667221426964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14457831780115762,
      "backward_entropy": 0.08291524648666382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.66279602050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03459296375513077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14444067080815634,
      "backward_entropy": 0.05355815887451172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.05573272705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03466203436255455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14430033167203268,
      "backward_entropy": 0.05284897685050964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.33583068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034728605300188065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14416494965553284,
      "backward_entropy": 0.08084510564804077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.45340728759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03479528799653053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.144030491511027,
      "backward_entropy": 0.08015981912612916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.13516998291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03486092388629913,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14389872550964355,
      "backward_entropy": 0.07947551012039185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.05241394042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03492669761180878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1437679131825765,
      "backward_entropy": 0.05010929107666016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.26202392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034990984946489334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14364015062650046,
      "backward_entropy": 0.07809939384460449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.61597442626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03505278006196022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14351685841878256,
      "backward_entropy": 0.0487201988697052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.4098358154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03511818125844002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14339019854863486,
      "backward_entropy": 0.07670915722846985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.59657287597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035189829766750336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1432568629582723,
      "backward_entropy": 0.04741955101490021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.2748794555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03526295721530914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14312334855397543,
      "backward_entropy": 0.07545281052589417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.27864074707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03533302992582321,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14299525817235312,
      "backward_entropy": 0.046208697557449344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.30683898925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03540615737438202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14286486307779947,
      "backward_entropy": 0.07420745491981506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.36580657958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03547604754567146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14273999134699503,
      "backward_entropy": 0.0735754132270813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.70890808105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035547886043787,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14261420567830405,
      "backward_entropy": 0.07297444343566895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.95415496826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03562253713607788,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14248653252919516,
      "backward_entropy": 0.04391120076179504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.52355194091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03569939360022545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14235776662826538,
      "backward_entropy": 0.07182373404502869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.16535186767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03577835485339165,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14222810665766397,
      "backward_entropy": 0.07125990390777588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.07860565185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03585381805896759,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14210431774457297,
      "backward_entropy": 0.07067295312881469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.00231170654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03592881187796593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14198258519172668,
      "backward_entropy": 0.041724559664726255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.56690979003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036000631749629974,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14186630646387735,
      "backward_entropy": 0.06948645114898681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.1390380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03607376292347908,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14174996813138327,
      "backward_entropy": 0.04062471985816955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.54400634765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03614693135023117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1416351000467936,
      "backward_entropy": 0.06831592321395874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.5753402709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03621971607208252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14152202010154724,
      "backward_entropy": 0.039549794793128965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.94145965576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036292724311351776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14141019185384116,
      "backward_entropy": 0.06715143918991089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.61031341552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03636231645941734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14130348960558572,
      "backward_entropy": 0.03847429156303406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.20396423339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036432161927223206,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14119804898897806,
      "backward_entropy": 0.06594382524490357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.43074798583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03650553151965141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14109015464782715,
      "backward_entropy": 0.06538384556770324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.26798248291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036575522273778915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14098734656969705,
      "backward_entropy": 0.0647949755191803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.9029541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036648623645305634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14088255167007446,
      "backward_entropy": 0.0363921046257019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.35367584228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03672349825501442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14077728986740112,
      "backward_entropy": 0.0636819839477539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.70167541503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03679944574832916,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14067235589027405,
      "backward_entropy": 0.0631430983543396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.1229476928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03687375783920288,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14057070016860962,
      "backward_entropy": 0.06259997487068177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.50791931152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036947980523109436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14047032594680786,
      "backward_entropy": 0.034473782777786253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.11155700683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03702733665704727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14036659399668375,
      "backward_entropy": 0.061545705795288085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.93661117553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03710758686065674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14026359717051187,
      "backward_entropy": 0.03356086313724518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.85799789428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03718026354908943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14016979932785034,
      "backward_entropy": 0.06049821376800537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.38386535644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0372488833963871,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14008132616678873,
      "backward_entropy": 0.059938091039657596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.01131057739258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0373213030397892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13999039928118387,
      "backward_entropy": 0.05941709280014038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.88722610473633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037388477474451065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13990587989489237,
      "backward_entropy": 0.05887596011161804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.72136688232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037453584372997284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13982465863227844,
      "backward_entropy": 0.031257688999176025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.6970329284668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037521131336688995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13974213600158691,
      "backward_entropy": 0.05779877305030823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.18342208862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03758399561047554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13966529568036398,
      "backward_entropy": 0.03037170469760895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.73700714111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03764382377266884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13959244887034097,
      "backward_entropy": 0.02991921305656433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.24636459350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03770533576607704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1395189861456553,
      "backward_entropy": 0.02948337197303772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.57694244384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03776536136865616,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1394480069478353,
      "backward_entropy": 0.029045802354812623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.87646484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037826891988515854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13937636216481528,
      "backward_entropy": 0.028616273403167726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.29195404052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03789413720369339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13930049538612366,
      "backward_entropy": 0.028216221928596498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.33343505859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03796682879328728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1392208139101664,
      "backward_entropy": 0.027852708101272584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.65574645996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03804562985897064,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13913707931836447,
      "backward_entropy": 0.05378987789154053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.22850799560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03812267258763313,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13905624548594156,
      "backward_entropy": 0.053383749723434445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.310951232910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03819989040493965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13897677262624106,
      "backward_entropy": 0.0268505334854126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.50530242919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03827356919646263,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13890182971954346,
      "backward_entropy": 0.05258862972259522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.81764602661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038346659392118454,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13882848620414734,
      "backward_entropy": 0.05220041275024414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.19506072998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03841728717088699,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1387583613395691,
      "backward_entropy": 0.05179797410964966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.79389190673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03848622739315033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13869072993596396,
      "backward_entropy": 0.025577691197395325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.8261947631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03855696693062782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1386226216952006,
      "backward_entropy": 0.02525370717048645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.951576232910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03862880915403366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13855473200480142,
      "backward_entropy": 0.050615108013153075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.60850524902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03869735822081566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1384905775388082,
      "backward_entropy": 0.050223696231842044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.52327728271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03876961022615433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1384241779645284,
      "backward_entropy": 0.024332433938980103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.73128128051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0388450063765049,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13835665583610535,
      "backward_entropy": 0.049490082263946536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.2405776977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038917843252420425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13829209407170615,
      "backward_entropy": 0.04911549389362335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.64430236816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03899115324020386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13822835683822632,
      "backward_entropy": 0.023431141674518586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.21156311035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03906763345003128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13816332817077637,
      "backward_entropy": 0.023140767216682435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.42258834838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039147160947322845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13809707760810852,
      "backward_entropy": 0.04805774092674255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.82719421386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03922123461961746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1380363404750824,
      "backward_entropy": 0.0477005660533905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.2694320678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03929842635989189,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13797444105148315,
      "backward_entropy": 0.02229628711938858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.68119049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03937459737062454,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13791425029436746,
      "backward_entropy": 0.04701724350452423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.36048889160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039449092000722885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13785632451375326,
      "backward_entropy": 0.021732883155345918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.349308013916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039524469524621964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1377985179424286,
      "backward_entropy": 0.021461237967014313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.11948776245117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03959735482931137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13774370153745016,
      "backward_entropy": 0.045975673198699954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.5513916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039668112993240356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13769152760505676,
      "backward_entropy": 0.04562642872333526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.20423126220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039737552404403687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13764060537020364,
      "backward_entropy": 0.045297497510910036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.59224700927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03981243446469307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13758655389149985,
      "backward_entropy": 0.04501427710056305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.424198150634766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03989330306649208,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13752909501393637,
      "backward_entropy": 0.13638336658477784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.1721420288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039971403777599335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13747475544611612,
      "backward_entropy": 0.04450284838676453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.49730682373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0400497242808342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13742130994796753,
      "backward_entropy": 0.04424157738685608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.29048919677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04012695699930191,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13736951351165771,
      "backward_entropy": 0.04397768378257751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.9996337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04020562767982483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13731785615285239,
      "backward_entropy": 0.04371245801448822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.13280487060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040283385664224625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13726775844891867,
      "backward_entropy": 0.043455970287322995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.21025085449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040357641875743866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13722068071365356,
      "backward_entropy": 0.04319626390933991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.62590789794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04043237492442131,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1371740996837616,
      "backward_entropy": 0.018643540143966675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.3875503540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04050635173916817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1371287703514099,
      "backward_entropy": 0.018424060940742493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.526161193847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04057975485920906,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13708450396855673,
      "backward_entropy": 0.04240675866603851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.21234130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04065033793449402,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13704262177149454,
      "backward_entropy": 0.017999690771102906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.36802673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04072209447622299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.137000838915507,
      "backward_entropy": 0.041912853717803955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.52165985107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04079757258296013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13695748647054037,
      "backward_entropy": 0.041689062118530275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.89105224609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04087264463305473,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13691492875417074,
      "backward_entropy": 0.017423780262470247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.287776947021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04094947874546051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13687223196029663,
      "backward_entropy": 0.04126161336898804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.84428787231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04102405905723572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13683158159255981,
      "backward_entropy": 0.01704876571893692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.88927459716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041097160428762436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1367923617362976,
      "backward_entropy": 0.040827909111976625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.83731460571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041172780096530914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1367522676785787,
      "backward_entropy": 0.01670044958591461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.60115051269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041244927793741226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13671485582987467,
      "backward_entropy": 0.040433838963508606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.57227325439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041318077594041824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13667744398117065,
      "backward_entropy": 0.040235483646392824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.05818176269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04139178991317749,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1366403897603353,
      "backward_entropy": 0.040029790997505185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.0399169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04146662726998329,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13660321633021036,
      "backward_entropy": 0.039842069149017334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.1097412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04153874143958092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13656802972157797,
      "backward_entropy": 0.03966670334339142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.9490852355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041617460548877716,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13652977347373962,
      "backward_entropy": 0.03952375948429108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.98204803466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041693758219480515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13649370272954306,
      "backward_entropy": 0.03936576247215271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.85794830322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04177328944206238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13645641009012857,
      "backward_entropy": 0.015404516458511352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.09593963623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041854552924633026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1364187995592753,
      "backward_entropy": 0.039077508449554446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.04788970947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041935525834560394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13638202349344888,
      "backward_entropy": 0.015115156769752502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.99337387084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04201515391469002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13634665807088217,
      "backward_entropy": 0.03875229954719543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.87241744995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04209265112876892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13631303111712137,
      "backward_entropy": 0.014807182550430297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.96412658691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042168159037828445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13628081480662027,
      "backward_entropy": 0.014656957983970643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.624420166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04224824160337448,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13624676068623862,
      "backward_entropy": 0.03827933371067047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.64847564697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04232592508196831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13621447483698526,
      "backward_entropy": 0.014370442926883697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.64006233215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04240695759654045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13618101676305136,
      "backward_entropy": 0.014237576723098755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.643043518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042481642216444016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13615131378173828,
      "backward_entropy": 0.0378547340631485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.936702728271484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04255315288901329,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1361236572265625,
      "backward_entropy": 0.13741528987884521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.82140350341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04262332245707512,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13609706362088522,
      "backward_entropy": 0.03754898309707642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.677581787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042692214250564575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13607150316238403,
      "backward_entropy": 0.037395650148391725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.563838958740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0427599661052227,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360468566417694,
      "backward_entropy": 0.01353231817483902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.803558349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04282662644982338,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602308432261148,
      "backward_entropy": 0.013391646742820739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.4466667175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04289170354604721,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13600019613901773,
      "backward_entropy": 0.013264167308807372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.52979850769043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04295786842703819,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359768509864807,
      "backward_entropy": 0.013149717450141906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.26354217529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04302038252353668,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359557012716929,
      "backward_entropy": 0.03674289286136627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.8084602355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04308386147022247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13593449195226034,
      "backward_entropy": 0.036629664897918704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.24749755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04314696416258812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591349124908447,
      "backward_entropy": 0.036522507667541504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.836143493652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0432121567428112,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589147726694742,
      "backward_entropy": 0.03642174005508423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.298519134521484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043277911841869354,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13586964209874472,
      "backward_entropy": 0.13757249116897582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.49026870727539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04334145411849022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584919770558676,
      "backward_entropy": 0.012448154389858246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.4361572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043405819684267044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13582855463027954,
      "backward_entropy": 0.03611016869544983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.18692398071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04347055405378342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358080506324768,
      "backward_entropy": 0.012215182930231095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.02170181274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04353593289852142,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578741749127707,
      "backward_entropy": 0.0358783096075058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.545740127563477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04360190033912659,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576674461364746,
      "backward_entropy": 0.011984479427337647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.639469146728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043664827942848206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13574769099553427,
      "backward_entropy": 0.011874300986528396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.4777717590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04372883215546608,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357283592224121,
      "backward_entropy": 0.011770277470350265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.33930206298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043792422860860825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13570940494537354,
      "backward_entropy": 0.011669144034385681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.03514099121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04385696351528168,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569021224975586,
      "backward_entropy": 0.03542968034744263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.80225372314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04393114894628525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566704591115317,
      "backward_entropy": 0.011485511064529419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.71842193603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04400917887687683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356424887975057,
      "backward_entropy": 0.03534358143806458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.6339225769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04408799856901169,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13561785221099854,
      "backward_entropy": 0.03531543612480163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.9751968383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044166162610054016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13559375206629434,
      "backward_entropy": 0.011255929619073868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.85176086425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04424767196178436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13556846976280212,
      "backward_entropy": 0.03527017235755921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.123260498046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044330962002277374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13554269075393677,
      "backward_entropy": 0.03526446521282196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.27297592163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04441278427839279,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13551785548528036,
      "backward_entropy": 0.0110461987555027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.41108703613281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04449140653014183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1354945500691732,
      "backward_entropy": 0.03522137403488159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.396915435791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044570524245500565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13547133406003317,
      "backward_entropy": 0.010905573517084122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.91021728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044645071029663086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13545028368631998,
      "backward_entropy": 0.035170266032218934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.12421417236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044717077165842056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13543051481246948,
      "backward_entropy": 0.0351470410823822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.3172607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04478902742266655,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13541082541147867,
      "backward_entropy": 0.035120454430580136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.31236267089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04485978186130524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13539169232050577,
      "backward_entropy": 0.0350942999124527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.02360916137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04493209347128868,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13537208239237467,
      "backward_entropy": 0.035076451301574704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.4560432434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04500317573547363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13535316785176596,
      "backward_entropy": 0.010474486649036408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.6790542602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04507409781217575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13533443212509155,
      "backward_entropy": 0.010401463508605957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.581512451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04514668509364128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13531519969304404,
      "backward_entropy": 0.010335180163383483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.8791389465332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04521802067756653,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13529664278030396,
      "backward_entropy": 0.03499257564544678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.42362403869629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04528944194316864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13527804613113403,
      "backward_entropy": 0.03497768640518188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.9331283569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04535750672221184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13526088992754617,
      "backward_entropy": 0.034973764419555665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.271928787231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045427121222019196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13524303833643594,
      "backward_entropy": 0.01007988527417183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.86441421508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04549343138933182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352266470591227,
      "backward_entropy": 0.010018795728683472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.69003677368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045559123158454895,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13521058360735574,
      "backward_entropy": 0.03495160341262817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.068889617919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045624516904354095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13519452015558878,
      "backward_entropy": 0.009901125729084016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.93456268310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045686714351177216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13517997662226358,
      "backward_entropy": 0.03495016098022461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.09868621826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04575136676430702,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13516422112782797,
      "backward_entropy": 0.03495543897151947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.026283264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04581436887383461,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1351493994394938,
      "backward_entropy": 0.034960830211639406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.904945373535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045875631272792816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13513541221618652,
      "backward_entropy": 0.009669296443462372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.65823745727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045935459434986115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13512210051218668,
      "backward_entropy": 0.034942051768302916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.06507110595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04599273204803467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13510998090108237,
      "backward_entropy": 0.009546193480491637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.69583511352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04605276510119438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13509668906529745,
      "backward_entropy": 0.03490892648696899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.546356201171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04611276462674141,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1350832680861155,
      "backward_entropy": 0.009424575418233872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.6236343383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04617292061448097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1350698471069336,
      "backward_entropy": 0.009367478638887405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.37142181396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04623805359005928,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135054349899292,
      "backward_entropy": 0.03488584458827972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.186187744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04630771279335022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13503681619962057,
      "backward_entropy": 0.009263834357261658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.084400177001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04637607932090759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13501991828282675,
      "backward_entropy": 0.009207782149314881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.952259063720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04644107073545456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13500455021858215,
      "backward_entropy": 0.009149599075317382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.45977020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04650350287556648,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13499024510383606,
      "backward_entropy": 0.009098350256681442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.45182418823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04656946659088135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13497438033421835,
      "backward_entropy": 0.009050124138593674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.15967559814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046636346727609634,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13495808839797974,
      "backward_entropy": 0.034911254048347475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.458919525146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046705055981874466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13494100173314413,
      "backward_entropy": 0.008964961767196656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.963401794433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04677191004157066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1349246104558309,
      "backward_entropy": 0.034976810216903687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.042659759521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04683934524655342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13490793108940125,
      "backward_entropy": 0.008887834101915359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.881414413452148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04690583422780037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13489166895548502,
      "backward_entropy": 0.00884484052658081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.92227172851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046967048197984695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13487770160039267,
      "backward_entropy": 0.03506859540939331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.93278121948242,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047031648457050323,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1348622739315033,
      "backward_entropy": 0.13829641342163085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.125198364257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04709445312619209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13484758138656616,
      "backward_entropy": 0.00871882438659668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.70339584350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04715484753251076,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1348338524500529,
      "backward_entropy": 0.03513851463794708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.2322998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0472140870988369,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13482064008712769,
      "backward_entropy": 0.008641228824853898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.68986892700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04727330803871155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13480732838312784,
      "backward_entropy": 0.008601421117782592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.08596420288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04733379930257797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13479329148928323,
      "backward_entropy": 0.008561713993549347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.372188568115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04739682003855705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13477811217308044,
      "backward_entropy": 0.035264787077903745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.193077087402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04746072366833687,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13476244608561197,
      "backward_entropy": 0.008487936109304428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.51648712158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04752562940120697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13474626342455545,
      "backward_entropy": 0.00845441222190857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.957401275634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04759255051612854,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13472893834114075,
      "backward_entropy": 0.035384255647659305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.27202606201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047657549381256104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1347124973932902,
      "backward_entropy": 0.035424554347991945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.730369567871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047722045332193375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13469630479812622,
      "backward_entropy": 0.008354359865188598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.00049591064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04778490960597992,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13468082745869955,
      "backward_entropy": 0.03549731373786926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.51589584350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04784742370247841,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13466525077819824,
      "backward_entropy": 0.008283707499504089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.6982192993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04790844768285751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13465025027592978,
      "backward_entropy": 0.00824754238128662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.19137954711914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04797285422682762,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13463365038235983,
      "backward_entropy": 0.03558189272880554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.24246215820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04803892970085144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13461623589197794,
      "backward_entropy": 0.00817006230354309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.828645706176758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04810791462659836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13459724187850952,
      "backward_entropy": 0.035600912570953366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.143531799316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04817349463701248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13457981745402017,
      "backward_entropy": 0.008089593797922134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.835350036621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048238638788461685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13456247250239053,
      "backward_entropy": 0.035624510049819945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.028987884521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048301927745342255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13454586267471313,
      "backward_entropy": 0.008014007657766341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.610137939453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048365868628025055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13452879587809244,
      "backward_entropy": 0.03564242124557495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.87987518310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04842807725071907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13451246420542398,
      "backward_entropy": 0.007932628691196441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.37204360961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04849359765648842,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1344944437344869,
      "backward_entropy": 0.035650378465652464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.46822357177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04855751618742943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13447697957356772,
      "backward_entropy": 0.03566949963569641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.16548538208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048625655472278595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13445736964543661,
      "backward_entropy": 0.03568629324436188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.00834274291992,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04869413748383522,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13443746169408163,
      "backward_entropy": 0.13841760158538818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.80234909057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048761628568172455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13441785176595053,
      "backward_entropy": 0.03572356998920441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.70662307739258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04882965609431267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13439780473709106,
      "backward_entropy": 0.035752618312835695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.667125701904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048896826803684235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1343779961268107,
      "backward_entropy": 0.03578354120254516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.145530700683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048962026834487915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13435902198155722,
      "backward_entropy": 0.007661936432123184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.43065071105957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04902883991599083,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1343390146891276,
      "backward_entropy": 0.035839369893074034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.12173080444336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04909380525350571,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13431978225708008,
      "backward_entropy": 0.03586961030960083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.53499221801758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0491582453250885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13430060942967734,
      "backward_entropy": 0.03590400218963623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.582870483398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04922449216246605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13428029417991638,
      "backward_entropy": 0.007542116940021515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.693687438964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928678274154663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13426183660825095,
      "backward_entropy": 0.0075179293751716616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.2570915222168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049348846077919006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13424337903658548,
      "backward_entropy": 0.03604606986045837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.41463088989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049411527812480927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.134224404891332,
      "backward_entropy": 0.007467543333768844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.91913986206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04947406426072121,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13420525193214417,
      "backward_entropy": 0.03613596558570862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.97118377685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049537383019924164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13418545325597128,
      "backward_entropy": 0.03618515133857727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.990966796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049603745341300964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13416382670402527,
      "backward_entropy": 0.03623374700546265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.397682189941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04966939985752106,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1341423193613688,
      "backward_entropy": 0.036284413933753965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.127662658691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04973554238677025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13412034511566162,
      "backward_entropy": 0.03633478879928589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.063949584960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04979754239320755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1341005563735962,
      "backward_entropy": 0.0073289602994918825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.36526107788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04985807463526726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13408122460047403,
      "backward_entropy": 0.03644628524780273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.04822540283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049920544028282166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1340604821840922,
      "backward_entropy": 0.036490461230278014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.956085205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04998727887868881,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13403725624084473,
      "backward_entropy": 0.007260522246360779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.839591026306152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05005564168095589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1340128779411316,
      "backward_entropy": 0.007240170240402221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.83747100830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0501195453107357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13399078448613486,
      "backward_entropy": 0.13849918842315673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.021121978759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05018305405974388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13396868109703064,
      "backward_entropy": 0.007201002538204193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.84943771362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05024723708629608,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13394582271575928,
      "backward_entropy": 0.036774981021881106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.943607330322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05031197890639305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13392249743143717,
      "backward_entropy": 0.007164380699396134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.4990119934082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05037824809551239,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13389799992243448,
      "backward_entropy": 0.007144135981798172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.10795211791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05044464394450188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13387306531270346,
      "backward_entropy": 0.007120951265096665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.605998992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050510358065366745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13384824991226196,
      "backward_entropy": 0.03697351813316345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.81953811645508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05057293549180031,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1338250438372294,
      "backward_entropy": 0.03701763153076172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.436187744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05063507705926895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13380180795987448,
      "backward_entropy": 0.007056878507137298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.44874382019043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05069439485669136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13378002246220908,
      "backward_entropy": 0.007033992558717728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.27492332458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05075247958302498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1337587038675944,
      "backward_entropy": 0.03714625239372253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.28559875488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05080818012356758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13373868664105734,
      "backward_entropy": 0.006989006698131561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.13862419128418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05086403340101242,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1337182323137919,
      "backward_entropy": 0.006965513527393341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.045602798461914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0509190633893013,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1336980660756429,
      "backward_entropy": 0.13852559328079223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0334625244140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050971973687410355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1336789925893148,
      "backward_entropy": 0.03730076253414154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.746177673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051020748913288116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13366254170735678,
      "backward_entropy": 0.037337273359298706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.7581729888916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05107145756483078,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1336443324883779,
      "backward_entropy": 0.03737044632434845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.863171577453613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05112161859869957,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13362616300582886,
      "backward_entropy": 0.037400007247924805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.456443786621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05116914585232735,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13360963265101114,
      "backward_entropy": 0.03743436336517334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.630388259887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05121765658259392,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13359230756759644,
      "backward_entropy": 0.037468844652175905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.399646759033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05126487836241722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13357553879419962,
      "backward_entropy": 0.03751090466976166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.566959381103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05131196975708008,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1335586210091909,
      "backward_entropy": 0.037553143501281736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.00722885131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05136344954371452,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13353844483693442,
      "backward_entropy": 0.006745845079421997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.82123327255249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05141565203666687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13351755340894064,
      "backward_entropy": 0.037645536661148074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.005882263183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051463693380355835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1334993044535319,
      "backward_entropy": 0.03768856525421142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.653053283691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05151600390672684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13347784678141275,
      "backward_entropy": 0.0066880442202091215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.529685974121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05156882852315903,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13345575332641602,
      "backward_entropy": 0.03777588605880737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.7468376159668,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05162200704216957,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13343310356140137,
      "backward_entropy": 0.13853271007537843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.276145935058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051677681505680084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13340840737024942,
      "backward_entropy": 0.03784945607185364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.908493041992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05173344910144806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13338332374890646,
      "backward_entropy": 0.037880876660346986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.02048110961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0517871119081974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13335947195688883,
      "backward_entropy": 0.0065886683762073515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.03076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05184106156229973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13333511352539062,
      "backward_entropy": 0.006568826735019684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.847591400146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05189736932516098,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13330870866775513,
      "backward_entropy": 0.03797744512557984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.080182075500488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051955923438072205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13328027725219727,
      "backward_entropy": 0.006526748836040497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.495948791503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052011001855134964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13325426975886026,
      "backward_entropy": 0.006507357954978943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.3692741394043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05206620320677757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13322778542836508,
      "backward_entropy": 0.006488030403852462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.361509323120117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052121710032224655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13320082426071167,
      "backward_entropy": 0.00647171437740326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.93714141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052175119519233704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13317513465881348,
      "backward_entropy": 0.03816903233528137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.75411605834961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05223096162080765,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13314725955327353,
      "backward_entropy": 0.13853862285614013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.48575210571289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052288979291915894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1331172784169515,
      "backward_entropy": 0.03825107216835022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.71043586730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05234575271606445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1330880026022593,
      "backward_entropy": 0.03829250335693359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.966644287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052402377128601074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13305840889612833,
      "backward_entropy": 0.0063882596790790554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.171127319335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05245684087276459,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13303019603093466,
      "backward_entropy": 0.03837367296218872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.58030319213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05251046642661095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1330024003982544,
      "backward_entropy": 0.038426488637924194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.65889358520508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05256537348031998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13297313451766968,
      "backward_entropy": 0.038475632667541504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.65605354309082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05262268707156181,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13294164339701334,
      "backward_entropy": 0.006330891698598862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.93448829650879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052677784115076065,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13291166226069132,
      "backward_entropy": 0.006319540739059448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.95303726196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052733082324266434,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13288116455078125,
      "backward_entropy": 0.038667359948158266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.417755126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05278939753770828,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1328493853410085,
      "backward_entropy": 0.03872931599617004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.44187355041504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05284339189529419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13281909624735513,
      "backward_entropy": 0.006285699456930161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.64426040649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05289638787508011,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13278929392496744,
      "backward_entropy": 0.006272166967391968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.092517852783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0529528446495533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13275610407193503,
      "backward_entropy": 0.006258171796798706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.20974349975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05300504341721535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1327264110247294,
      "backward_entropy": 0.0389498233795166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.0366153717041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053059641271829605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13269418478012085,
      "backward_entropy": 0.0390062004327774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.9879150390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05311218649148941,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1326633890469869,
      "backward_entropy": 0.039066141843795775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.842050552368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05316179245710373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1326349377632141,
      "backward_entropy": 0.006212583929300308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.675540924072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05321089178323746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1326065460840861,
      "backward_entropy": 0.006201813742518425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.55855369567871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053260527551174164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13257724046707153,
      "backward_entropy": 0.03925092220306396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.441543579101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05331066623330116,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13254706064860025,
      "backward_entropy": 0.13856396675109864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.3227481842041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05336137115955353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1325160264968872,
      "backward_entropy": 0.03936613798141479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.364368438720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05341266468167305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1324840486049652,
      "backward_entropy": 0.006158063933253288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.462987899780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053463105112314224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13245250781377158,
      "backward_entropy": 0.039494872093200684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.60649585723877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05351190268993378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13242214918136597,
      "backward_entropy": 0.006135838106274605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.38019561767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053558044135570526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13239399592081705,
      "backward_entropy": 0.03961685001850128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.25759506225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053607113659381866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1323625644048055,
      "backward_entropy": 0.039670920372009276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.622770309448242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053654689341783524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13233226537704468,
      "backward_entropy": 0.039732331037521364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.812427520751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053702887147665024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13230093320210776,
      "backward_entropy": 0.03978763818740845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.395877838134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05375054106116295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13226970036824545,
      "backward_entropy": 0.006078239530324936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.983091354370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053798940032720566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13223729530970255,
      "backward_entropy": 0.03988848328590393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.912790298461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05384594947099686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13220604260762533,
      "backward_entropy": 0.039952442049980164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.242643356323242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05389150604605675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1321759025255839,
      "backward_entropy": 0.04001142084598541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.12215805053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05393470451235771,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13214780886967978,
      "backward_entropy": 0.0060355812311172485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.4066276550293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0539809986948967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13211604952812195,
      "backward_entropy": 0.040115568041801455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.726200103759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05402917414903641,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13208194573720297,
      "backward_entropy": 0.04016560912132263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.09748649597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05407780408859253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13204689820607504,
      "backward_entropy": 0.04020644724369049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.509489059448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054126087576150894,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1320119003454844,
      "backward_entropy": 0.005987270176410675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.38274574279785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0541728213429451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13197815418243408,
      "backward_entropy": 0.04031676650047302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.268274307250977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05422027409076691,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1319432258605957,
      "backward_entropy": 0.005966322496533394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.576744079589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05426833778619766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13190714518229166,
      "backward_entropy": 0.040425422787666324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.631864547729492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05431796982884407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1318689783414205,
      "backward_entropy": 0.005944054573774338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.406471252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05436690151691437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13183109958966574,
      "backward_entropy": 0.00593196339905262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.740522384643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05441205948591232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13179707527160645,
      "backward_entropy": 0.005919713899493218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.70485305786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054454926401376724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1317652960618337,
      "backward_entropy": 0.005908140912652016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.589038848876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054501865059137344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1317284107208252,
      "backward_entropy": 0.005895047262310982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.4730167388916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0545494519174099,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13169040282567343,
      "backward_entropy": 0.04068949520587921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.559126853942871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054597560316324234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13165130217870077,
      "backward_entropy": 0.005869318172335625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.760690689086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054642997682094574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1316149334112803,
      "backward_entropy": 0.040763625502586366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.13991928100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05468720197677612,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13157959779103598,
      "backward_entropy": 0.040808504819869994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028077563270926476,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0547323003411293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13154281179110208,
      "backward_entropy": 0.04085430800914765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.1115779876709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054773006588220596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1315110127131144,
      "backward_entropy": 0.040904170274734496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.826974868774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054815880954265594,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1314761439959208,
      "backward_entropy": 0.040946590900421145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.30228328704834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05485968291759491,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13143964608510336,
      "backward_entropy": 0.04098457098007202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.85653305053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054901123046875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13140561183293661,
      "backward_entropy": 0.005783770605921746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.223679542541504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05494567006826401,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13136727611223856,
      "backward_entropy": 0.041035589575767514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.256501197814941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05498811602592468,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13133134444554648,
      "backward_entropy": 0.041075849533081056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.251508712768555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055029574781656265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13129631678263345,
      "backward_entropy": 0.041122549772262575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.20789909362793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05507111921906471,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13126071294148764,
      "backward_entropy": 0.041170930862426756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.08819580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05511382222175598,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1312232812245687,
      "backward_entropy": 0.041224390268325806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.011640548706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05515650287270546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13118547201156616,
      "backward_entropy": 0.005718034505844116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.925251007080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05519820749759674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13114861647288004,
      "backward_entropy": 0.0413453221321106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.79477310180664,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055240027606487274,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13111121455828348,
      "backward_entropy": 0.13858323097229003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.82683277130127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05528271943330765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13107206424077353,
      "backward_entropy": 0.041470059752464296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025034060701727867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05532436817884445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1310339073340098,
      "backward_entropy": 0.04152932465076446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.709721565246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05536198988556862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13100085655848184,
      "backward_entropy": 0.005680571496486664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.65725040435791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055398959666490555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13096837202707926,
      "backward_entropy": 0.04165164530277252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.9023323059082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055435437709093094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13093632459640503,
      "backward_entropy": 0.0417130708694458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023255374282598495,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05547647178173065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13089744249979654,
      "backward_entropy": 0.04176726341247559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.31162452697754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05551348626613617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13086392482121786,
      "backward_entropy": 0.04182230532169342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.4334077835083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05555098503828049,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13082927465438843,
      "backward_entropy": 0.005639843642711639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.737062454223633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055587802082300186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13079516092936197,
      "backward_entropy": 0.0056306648999452594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.62225341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05562702193856239,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13075716296831766,
      "backward_entropy": 0.04197011590003967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.755216598510742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0556684248149395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1307155986626943,
      "backward_entropy": 0.04200641214847565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.376249313354492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055710870772600174,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1306721568107605,
      "backward_entropy": 0.04204598069190979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.8383846282959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05575520917773247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1306255062421163,
      "backward_entropy": 0.04208380579948425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.43544578552246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055799271911382675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13057884573936462,
      "backward_entropy": 0.04212477207183838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.64439010620117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05584416165947914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13053054610888162,
      "backward_entropy": 0.04217380583286286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.208099365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055891625583171844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13047785560290018,
      "backward_entropy": 0.0055584974586963655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.92960739135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05593946576118469,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13042426109313965,
      "backward_entropy": 0.005548647046089173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.7303352355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055990416556596756,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13036532203356424,
      "backward_entropy": 0.04228222668170929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.395191192626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05604422464966774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13030151526133218,
      "backward_entropy": 0.005521499365568161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.769458770751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05609869211912155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13023603955904642,
      "backward_entropy": 0.04231060743331909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.545915603637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05615468695759773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13016762336095175,
      "backward_entropy": 0.042320793867111205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.468772888183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05620817467570305,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1301023761431376,
      "backward_entropy": 0.04233672022819519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.848617553710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05625949054956436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13004000981648764,
      "backward_entropy": 0.04236498773097992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.75034523010254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056309740990400314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.129978617032369,
      "backward_entropy": 0.005455951392650604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.65444564819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056359026581048965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12991817792256674,
      "backward_entropy": 0.04243097901344299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.09537887573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05640745535492897,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1298584540685018,
      "backward_entropy": 0.04247019290924072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.102048873901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056458890438079834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12979310750961304,
      "backward_entropy": 0.04250150322914124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.70315933227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0565083809196949,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12973048289616904,
      "backward_entropy": 0.042547601461410525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.570545196533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056560829281806946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1296623150507609,
      "backward_entropy": 0.005406184121966362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.876086235046387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056613050401210785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1295938491821289,
      "backward_entropy": 0.0053979303687810894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2827067375183105,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05666317790746689,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12952826420466104,
      "backward_entropy": 0.13858463764190673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.445154190063477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05670944228768349,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1294687589009603,
      "backward_entropy": 0.04276052117347717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.523515701293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05675686150789261,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12940643231074014,
      "backward_entropy": 0.042811626195907594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.59282112121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05680639669299126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12933971484502158,
      "backward_entropy": 0.04286080598831177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.524208068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05685395747423172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1292757789293925,
      "backward_entropy": 0.04290895462036133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.74631690979004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0568997785449028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12921414772669473,
      "backward_entropy": 0.005352779477834702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.634990692138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056945838034152985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12915142377217612,
      "backward_entropy": 0.04300212264060974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.422285079956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056992147117853165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12908758719762167,
      "backward_entropy": 0.005333299562335014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.335508346557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05703773722052574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1290242870648702,
      "backward_entropy": 0.043079280853271486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.301898956298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05708281695842743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12896133462587991,
      "backward_entropy": 0.0431292325258255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.124456405639648,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.057128217071294785,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12889701128005981,
      "backward_entropy": 0.1385880470275879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.059924125671387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057172082364559174,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12883501251538595,
      "backward_entropy": 0.04322676062583923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.00639820098877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057214509695768356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12877508997917175,
      "backward_entropy": 0.005289801210165024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.966160297393799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05725473538041115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12871885299682617,
      "backward_entropy": 0.005282288417220116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.930892467498779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0572928749024868,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12866610288619995,
      "backward_entropy": 0.04338580071926117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.705686569213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05732927471399307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12861635287602743,
      "backward_entropy": 0.04344567656517029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.614717483520508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05736690014600754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12856357296307883,
      "backward_entropy": 0.043508118391036986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.11965560913086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05740562081336975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1285079816977183,
      "backward_entropy": 0.04357266426086426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.656643867492676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05744894966483116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12844246625900269,
      "backward_entropy": 0.005246828496456146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.596132278442383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05749078094959259,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12837928533554077,
      "backward_entropy": 0.04367384314537048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.375960350036621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05753130465745926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12831825017929077,
      "backward_entropy": 0.005228553339838982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.297540664672852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057571589946746826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12825696667035422,
      "backward_entropy": 0.005218705907464027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.219260215759277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057611651718616486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12819547454516092,
      "backward_entropy": 0.043798035383224486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.361322402954102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05765147879719734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1281338334083557,
      "backward_entropy": 0.04383428692817688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.351083755493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05769018083810806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1280739704767863,
      "backward_entropy": 0.005187185108661651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7621078491210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057731568813323975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.128007709980011,
      "backward_entropy": 0.043901273608207704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.188332557678223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05776989832520485,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1279476284980774,
      "backward_entropy": 0.043940839171409604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.429341793060303,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057807259261608124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12788882851600647,
      "backward_entropy": 0.04398155510425568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.14352798461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057842839509248734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1278335452079773,
      "backward_entropy": 0.005146521329879761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.026466369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057880427688360214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12777342398961386,
      "backward_entropy": 0.005135985463857651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.973637580871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05791706219315529,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12771456440289816,
      "backward_entropy": 0.04409492611885071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.455142974853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05795290321111679,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12765701611836752,
      "backward_entropy": 0.04413220882415771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.478859901428223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057991549372673035,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12759238481521606,
      "backward_entropy": 0.044158154726028444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.808143615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05803004652261734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12752744555473328,
      "backward_entropy": 0.005090416222810745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.64218521118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058067552745342255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12746418515841165,
      "backward_entropy": 0.005078905820846557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.250906944274902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058108676224946976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1273920238018036,
      "backward_entropy": 0.005067237839102745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5582025051116943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05814945325255394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12732003132502237,
      "backward_entropy": 0.0442688375711441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.098074913024902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05818724259734154,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12725461522738138,
      "backward_entropy": 0.04431067109107971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.029123306274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058225005865097046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12718870242436728,
      "backward_entropy": 0.005037956684827804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.427536010742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058266256004571915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12711373964945474,
      "backward_entropy": 0.0443923681974411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.325345993041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05830814316868782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12703674038251242,
      "backward_entropy": 0.005020125955343247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.781316757202148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05835052207112312,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1269578735033671,
      "backward_entropy": 0.0444985032081604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.960479736328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05839233845472336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12687958280245462,
      "backward_entropy": 0.04455218911170959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.215861320495605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05843620374798775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12679549058278403,
      "backward_entropy": 0.04459114074707031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.291393280029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05847839266061783,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12671470642089844,
      "backward_entropy": 0.044625237584114075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.806949615478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058521807193756104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12663012742996216,
      "backward_entropy": 0.04465881884098053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.02960205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05856537073850632,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12654471397399902,
      "backward_entropy": 0.0446875661611557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.915691375732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05860741063952446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1264624297618866,
      "backward_entropy": 0.0049547266215085985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.496313095092773,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058650605380535126,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12637637058893839,
      "backward_entropy": 0.13858968019485474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.293421983718872,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058694079518318176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1262890100479126,
      "backward_entropy": 0.004935315251350403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.273317813873291,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05873417481780052,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1262098252773285,
      "backward_entropy": 0.13858965635299683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.729823112487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058771148324012756,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12613819042841592,
      "backward_entropy": 0.04487575888633728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.678960800170898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05880710482597351,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12606861193974814,
      "backward_entropy": 0.004905921965837478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.032678604125977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058842260390520096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1260005533695221,
      "backward_entropy": 0.004896648973226547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.574355125427246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05887835845351219,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12592929601669312,
      "backward_entropy": 0.044993150234222415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.356252193450928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05891348794102669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1258600354194641,
      "backward_entropy": 0.0048769261687994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.628355979919434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05894697830080986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12579460938771567,
      "backward_entropy": 0.004867490008473396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.24342918395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05898072198033333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12572792172431946,
      "backward_entropy": 0.004858624935150146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.136343479156494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05901900678873062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12564805150032043,
      "backward_entropy": 0.04515544772148132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.219461917877197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0590544119477272,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1255756119887034,
      "backward_entropy": 0.045197409391403195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.187821865081787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05908804386854172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12550756335258484,
      "backward_entropy": 0.04523611068725586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.294731140136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059120144695043564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12544326980908713,
      "backward_entropy": 0.004821769520640373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.179359436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05915255472064018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1253775159517924,
      "backward_entropy": 0.045316803455352786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.361032485961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05918441712856293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12531272570292154,
      "backward_entropy": 0.04535849094390869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.060348987579346,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05922073498368263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12523424625396729,
      "backward_entropy": 0.004791373759508133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.038209915161133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059255268424749374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12516047557195029,
      "backward_entropy": 0.045411354303359984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.96605396270752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05929063633084297,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12508351604143778,
      "backward_entropy": 0.04543417692184448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.839168548583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059325914829969406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12500619888305664,
      "backward_entropy": 0.04545365869998932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.828173637390137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05936288833618164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12492289145787557,
      "backward_entropy": 0.04547742009162903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.886390686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05939971283078194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12483955423037212,
      "backward_entropy": 0.004734598100185394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.688817024230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05943455174565315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12476150194803874,
      "backward_entropy": 0.004723116010427475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.621903419494629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059469301253557205,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12468293309211731,
      "backward_entropy": 0.04555177688598633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9038240909576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05950396507978439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12460380792617798,
      "backward_entropy": 0.045567440986633304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625445365905762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05953618884086609,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12453196446100871,
      "backward_entropy": 0.04559627771377563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.287240982055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05956781283020973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12446129322052002,
      "backward_entropy": 0.04562822580337524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.532114028930664,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05960051342844963,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12438657879829407,
      "backward_entropy": 0.13858401775360107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8418476581573486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05963249132037163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12431339422861735,
      "backward_entropy": 0.004655270278453827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.062743186950684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059662267565727234,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12424691518147786,
      "backward_entropy": 0.04571933150291443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01693374291062355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05969337746500969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12417552868525188,
      "backward_entropy": 0.045759037137031555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.142224311828613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059721410274505615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12411363919576009,
      "backward_entropy": 0.045797455310821536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5522236824035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05975016579031944,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12404879927635193,
      "backward_entropy": 0.04584640860557556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27995491027832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05977782607078552,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12398711840311687,
      "backward_entropy": 0.0458982914686203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.500304222106934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059805307537317276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12392568588256836,
      "backward_entropy": 0.045950460433959964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.475236415863037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059831831604242325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12386691570281982,
      "backward_entropy": 0.0460071861743927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.600667953491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05985749140381813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.123810480038325,
      "backward_entropy": 0.046067613363265994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.944721221923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059884797781705856,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.123747984568278,
      "backward_entropy": 0.04612573981285095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.774680137634277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05991526320576668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12367433309555054,
      "backward_entropy": 0.004578535631299019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.716852188110352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059946030378341675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12359891335169475,
      "backward_entropy": 0.04623548686504364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.639114379882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059977080672979355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12352201342582703,
      "backward_entropy": 0.046285593509674074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.306548118591309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06001081317663193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1234351893266042,
      "backward_entropy": 0.0045559704303741455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.905068397521973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060042984783649445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12335326274236043,
      "backward_entropy": 0.04638197422027588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.703262329101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06007452309131622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12327299515406291,
      "backward_entropy": 0.004542619362473488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.609793663024902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06010785698890686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12318580349286397,
      "backward_entropy": 0.04649017453193664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.510757446289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06014286354184151,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12309202551841736,
      "backward_entropy": 0.0465423583984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.278032302856445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060179341584444046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12299245595932007,
      "backward_entropy": 0.04659317433834076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.758109092712402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06021556630730629,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1228930155436198,
      "backward_entropy": 0.04664932489395142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.079232215881348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060252346098423004,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12279093265533447,
      "backward_entropy": 0.046707096695899966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.560973167419434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06028720363974571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1226951281229655,
      "backward_entropy": 0.004503523558378219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0151495933532715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06032106280326843,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12260222434997559,
      "backward_entropy": 0.04682800769805908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.436788558959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06035327538847923,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12251476446787517,
      "backward_entropy": 0.04689159095287323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.954073429107666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06038634851574898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12242333094278972,
      "backward_entropy": 0.046951848268508914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.741353034973145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0604177750647068,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1223373810450236,
      "backward_entropy": 0.047009524703025815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.210433959960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06045098975300789,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12224408984184265,
      "backward_entropy": 0.04707136154174805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.862484455108643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060485050082206726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1221468448638916,
      "backward_entropy": 0.04714016616344452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.648481369018555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06051729619503021,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12205582857131958,
      "backward_entropy": 0.04720045626163483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.76775550842285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060549478977918625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12196419636408488,
      "backward_entropy": 0.04725119471549988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.770979404449463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06058397889137268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12186294794082642,
      "backward_entropy": 0.004447425901889801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.549190521240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06061670184135437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12176793813705444,
      "backward_entropy": 0.0044390872120857235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.089933395385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06065170466899872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12166326244672139,
      "backward_entropy": 0.004430196806788444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017450254410505295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06068798154592514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12155276536941528,
      "backward_entropy": 0.047411540150642396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.897894859313965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06072083115577698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12145531177520752,
      "backward_entropy": 0.004413692653179169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3149967193603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06075497716665268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1213519275188446,
      "backward_entropy": 0.004403788223862648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8665876388549805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060786571353673935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12125815947850545,
      "backward_entropy": 0.0475258469581604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.823821544647217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060817502439022064,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12116636832555135,
      "backward_entropy": 0.047569045424461366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.291990280151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06084773316979408,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12107669313748677,
      "backward_entropy": 0.04761197566986084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.701827049255371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06087879091501236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12098286549250285,
      "backward_entropy": 0.04764573276042938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.368756294250488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06091223284602165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12087847789128621,
      "backward_entropy": 0.004357831180095672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.435909748077393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060946960002183914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12076804041862488,
      "backward_entropy": 0.04770961403846741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.211592197418213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06097986176609993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12066445748011272,
      "backward_entropy": 0.004338117316365242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.557999610900879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06101032346487045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12057056029637654,
      "backward_entropy": 0.04778142273426056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.683725357055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06104009598493576,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12047890822092693,
      "backward_entropy": 0.04781880974769592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.240802764892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06106993928551674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12038614352544148,
      "backward_entropy": 0.047849297523498535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.706441879272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06110289692878723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12027941147486369,
      "backward_entropy": 0.047872498631477356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.262399673461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061136309057474136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12016993761062622,
      "backward_entropy": 0.04788576364517212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.125396728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06116793304681778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1200674573580424,
      "backward_entropy": 0.04789992272853851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.112213611602783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06119716167449951,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.119974950949351,
      "backward_entropy": 0.047913140058517455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.264137268066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061224352568387985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11989112695058186,
      "backward_entropy": 0.047936815023422244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29727554321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06125114858150482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11980811754862468,
      "backward_entropy": 0.04796346426010132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.363594055175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061278197914361954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11972278356552124,
      "backward_entropy": 0.0479795515537262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.240225791931152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061307042837142944,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11962900559107463,
      "backward_entropy": 0.047993674874305725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.141541481018066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06133681535720825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11953041950861613,
      "backward_entropy": 0.004201373457908631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.069282054901123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061366718262434006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11943068106969197,
      "backward_entropy": 0.048036471009254456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.021599054336548,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06139586493372917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11933355530103047,
      "backward_entropy": 0.004179232567548752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.98513650894165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061422958970069885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11924540996551514,
      "backward_entropy": 0.048088347911834715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9762938022613525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061450354754924774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11915519833564758,
      "backward_entropy": 0.04811935424804688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.888293743133545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06147653982043266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11907001336415608,
      "backward_entropy": 0.04815061688423157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.928969144821167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06150306016206741,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1189825435479482,
      "backward_entropy": 0.04817765951156616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.739197731018066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06152849644422531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11889962355295818,
      "backward_entropy": 0.004128061980009079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.613158226013184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06155504286289215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11881073315938313,
      "backward_entropy": 0.048238429427146914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.696206092834473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0615835078060627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11871228615442912,
      "backward_entropy": 0.004108487442135811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.645592212677002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06161210313439369,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11861217021942139,
      "backward_entropy": 0.04831709563732147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9107364416122437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0616409033536911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11851115028063457,
      "backward_entropy": 0.04836280643939972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.546305179595947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06166757643222809,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11841946840286255,
      "backward_entropy": 0.048405003547668454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.498157978057861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06169453635811806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11832580963770549,
      "backward_entropy": 0.04844673871994019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.166725158691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06172169744968414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11823034286499023,
      "backward_entropy": 0.04848356246948242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.553420066833496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06175050511956215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1181261936823527,
      "backward_entropy": 0.04851841926574707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.181172370910645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06177869066596031,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11802445848782857,
      "backward_entropy": 0.048558229207992555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.937660217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06180756166577339,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11791843175888062,
      "backward_entropy": 0.0485842764377594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.856375694274902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061837874352931976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11780466636021932,
      "backward_entropy": 0.04860958158969879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8096126317977905,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06186940521001816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11768404642740886,
      "backward_entropy": 0.004014796763658524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.35528564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0618986152112484,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11757451295852661,
      "backward_entropy": 0.04865469634532928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.317781925201416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06192699074745178,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11746843655904134,
      "backward_entropy": 0.04867469668388367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.545971870422363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06195465847849846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11736512184143066,
      "backward_entropy": 0.048693254590034485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.242682456970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0619838573038578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11725357174873352,
      "backward_entropy": 0.04871492087841034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.393255233764648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06201232597231865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11714505155881245,
      "backward_entropy": 0.04874118566513062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.165490627288818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062042225152254105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11702836553255717,
      "backward_entropy": 0.04877026677131653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.83125638961792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062071289867162704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11691540479660034,
      "backward_entropy": 0.003940045088529587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.398648500442505,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0621003732085228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11680173873901367,
      "backward_entropy": 0.048840147256851194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.374037027359009,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06212804093956947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11669481794039409,
      "backward_entropy": 0.0488841712474823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.68611478805542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06215433403849602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11659468213717143,
      "backward_entropy": 0.04892290830612182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9842352867126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06218079850077629,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11649277806282043,
      "backward_entropy": 0.048959273099899295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.595867156982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06220671907067299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11639340718587239,
      "backward_entropy": 0.048993974924087524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183255195617676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06223295256495476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11629135409990947,
      "backward_entropy": 0.0038868792355060576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.746502876281738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06226002797484398,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11618420481681824,
      "backward_entropy": 0.049084591865539554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017207222059369087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062288541346788406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11606857180595398,
      "backward_entropy": 0.04912685751914978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.606152534484863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06231436878442764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1159672240416209,
      "backward_entropy": 0.04918011426925659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.362540245056152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062341682612895966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11585688591003418,
      "backward_entropy": 0.003854493796825409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.741328716278076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06236893683671951,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11574626962343852,
      "backward_entropy": 0.04925963580608368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.397473335266113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06239556893706322,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11563832561175029,
      "backward_entropy": 0.04929661750793457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.773789405822754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062423668801784515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11552160978317261,
      "backward_entropy": 0.04933692216873169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.634445667266846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06245237961411476,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11540074149767558,
      "backward_entropy": 0.049377113580703735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017225822433829308,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06248035281896591,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11528343955675761,
      "backward_entropy": 0.04942432641983032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0497071743011475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06250571459531784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1151805321375529,
      "backward_entropy": 0.04948442578315735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.536190509796143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06252986192703247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11508393287658691,
      "backward_entropy": 0.049536263942718504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5059309005737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06255373358726501,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11498847603797913,
      "backward_entropy": 0.049595266580581665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4495134353637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0625772699713707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11489424109458923,
      "backward_entropy": 0.04965316653251648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.398105621337891,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06260183453559875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1147934893767039,
      "backward_entropy": 0.0037752650678157806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3448076248168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06262730807065964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11468676726023357,
      "backward_entropy": 0.049770277738571164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.289780139923096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06265361607074738,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11457436283429463,
      "backward_entropy": 0.04983116090297699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.676791191101074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06268054246902466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11445780595143636,
      "backward_entropy": 0.0037544090300798416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.311278820037842,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06270872056484222,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11433303356170654,
      "backward_entropy": 0.0037462834268808367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.276956558227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06273609399795532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11421240369478862,
      "backward_entropy": 0.0037380699068307877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.288701057434082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0627627819776535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11409517129262288,
      "backward_entropy": 0.05001916885375977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.207099437713623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06279198080301285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11396225293477376,
      "backward_entropy": 0.050060003995895386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.942115306854248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06282035261392593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11383369565010071,
      "backward_entropy": 0.05011042356491089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7632381916046143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06284914165735245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11370191971460979,
      "backward_entropy": 0.050158238410949706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.102508068084717,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06287635117769241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11357901493708293,
      "backward_entropy": 0.050201648473739625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.122812271118164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06290286034345627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11345989505449931,
      "backward_entropy": 0.05024966597557068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.035709857940674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06293059885501862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11333237091700236,
      "backward_entropy": 0.0036830902099609375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.00271463394165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06295754015445709,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11320916811625163,
      "backward_entropy": 0.05034545063972473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6061506271362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06298372894525528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11309027671813965,
      "backward_entropy": 0.05039185285568237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.24514102935791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06301052868366241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11296633879343669,
      "backward_entropy": 0.05044105052947998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2014055252075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06303710490465164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11284335454305013,
      "backward_entropy": 0.003650500625371933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.728644847869873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06306354701519012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11272052923838298,
      "backward_entropy": 0.05051296353340149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.11306095123291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06309112161397934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1125897467136383,
      "backward_entropy": 0.050545227527618405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.068337440490723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06311850249767303,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11245956023534139,
      "backward_entropy": 0.050580114126205444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.276546001434326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06314574182033539,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11232964197794597,
      "backward_entropy": 0.05062267780303955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.979517936706543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06317336857318878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11219639579455058,
      "backward_entropy": 0.0036046311259269716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.165346622467041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06320083886384964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11206348737080891,
      "backward_entropy": 0.05070991516113281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6723382472991943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06322870403528214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11192731062571208,
      "backward_entropy": 0.05075905323028564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0558762550354,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06325574964284897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11179583271344502,
      "backward_entropy": 0.003582240641117096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.608180284500122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06328318268060684,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11166101694107056,
      "backward_entropy": 0.050871527194976805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5768229961395264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0633096918463707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11153169473012288,
      "backward_entropy": 0.050920867919921876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.897349834442139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06333533674478531,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11140747865041097,
      "backward_entropy": 0.050961607694625856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.348022699356079,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0633615180850029,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11127904057502747,
      "backward_entropy": 0.05100584626197815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4856526851654053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0633864626288414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11115809281667073,
      "backward_entropy": 0.05106284618377686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.749133110046387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0634106993675232,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11104134718577068,
      "backward_entropy": 0.051112550497055056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.701090335845947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06343555450439453,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11091988285382588,
      "backward_entropy": 0.05116239786148071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.650698661804199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06346087157726288,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11079446474711101,
      "backward_entropy": 0.051203960180282594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2508862018585205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06348667293787003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11066508293151855,
      "backward_entropy": 0.003509347140789032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2315478324890137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06351111829280853,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11054444313049316,
      "backward_entropy": 0.05128722190856934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.213946580886841,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06353435665369034,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11043163140614827,
      "backward_entropy": 0.138593590259552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.46459436416626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06355645507574081,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1103261411190033,
      "backward_entropy": 0.05136674642562866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3405842781066895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06357929110527039,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11021483937899272,
      "backward_entropy": 0.05140266418457031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4479289054870605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06360211223363876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11010297139485677,
      "backward_entropy": 0.05142862796783447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1415178775787354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06362611055374146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10998249053955078,
      "backward_entropy": 0.051447367668151854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.177457094192505,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06364898383617401,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10986965894699097,
      "backward_entropy": 0.05147604346275329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.242556095123291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06367139518260956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10975903272628784,
      "backward_entropy": 0.051511985063552854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0883524417877197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06369438767433167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10964325070381165,
      "backward_entropy": 0.05153930187225342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.183740139007568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06371639668941498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10953433314959209,
      "backward_entropy": 0.051581114530563354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0546321868896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0637395828962326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10941640535990398,
      "backward_entropy": 0.051613378524780276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.048490524291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0637616515159607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10930587848027547,
      "backward_entropy": 0.05164783596992493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.025882720947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06378323584794998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10919843117396037,
      "backward_entropy": 0.05168022513389588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9930737018585205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06380493938922882,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10908935467402141,
      "backward_entropy": 0.05171172022819519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.945313930511475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06382672488689423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1089792549610138,
      "backward_entropy": 0.051738685369491576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9485912322998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06384916603565216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10886375109354655,
      "backward_entropy": 0.003351833298802376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9846791625022888,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06387106329202652,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1087518036365509,
      "backward_entropy": 0.05179215669631958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.861685276031494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06389152258634567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10864986975987752,
      "backward_entropy": 0.05183492302894592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8774991035461426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06391220539808273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10854557156562805,
      "backward_entropy": 0.05187827944755554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.854353666305542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06393250077962875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10844381650288899,
      "backward_entropy": 0.05191919207572937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.648416042327881,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0639524981379509,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10834360122680664,
      "backward_entropy": 0.051963132619857785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.669305324554443,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06397377699613571,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10823337237040202,
      "backward_entropy": 0.1385840058326721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.552249431610107,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06399577856063843,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10811683535575867,
      "backward_entropy": 0.13858402967453004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.586010456085205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06401881575584412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10799231131871541,
      "backward_entropy": 0.05208127498626709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.827430009841919,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0640423521399498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10786306858062744,
      "backward_entropy": 0.052122706174850465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8095484972000122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06406460702419281,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1077432930469513,
      "backward_entropy": 0.05215821266174316,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.413573870435357,
    "avg_log_Z": -0.06284175928682088,
    "success_rate": 1.0,
    "avg_reward": 22.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.81,
      "2": 0.16
    },
    "avg_forward_entropy": 0.11350512961546581,
    "avg_backward_entropy": 0.04538789953663946,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}