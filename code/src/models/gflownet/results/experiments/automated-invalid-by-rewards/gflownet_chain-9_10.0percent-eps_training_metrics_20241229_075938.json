{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07698553138309056,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07698553138309056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07698553138309056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07698553138309056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07698553138309056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07698553138309056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07698553138309056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07696551746792263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.77522277832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933027267456055,
      "backward_entropy": 0.07697036531236437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.75476837158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10932819843292237,
      "backward_entropy": 0.07697077592213948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.21565246582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0002000001259148121,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093260407447815,
      "backward_entropy": 0.07696633868747288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.71377563476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0002998987038154155,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932379961013794,
      "backward_entropy": 0.07696672280629475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.6932144165039,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003998620668426156,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10932146310806275,
      "backward_entropy": 0.07699131965637207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.50717163085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004998633521609008,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109319007396698,
      "backward_entropy": 0.07699265082677205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.4840087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006005988689139485,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10931644439697266,
      "backward_entropy": 0.07697272300720215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.11168670654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007019106415100396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10931376218795777,
      "backward_entropy": 0.07697314686245388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.95556640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008024515118449926,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10931092500686646,
      "backward_entropy": 0.07699644565582275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.28271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009037511190399528,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930788516998291,
      "backward_entropy": 0.07696904076470269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.6051025390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010027576936408877,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930471420288086,
      "backward_entropy": 0.07696935865614149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.8445587158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011018413351848722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930135250091552,
      "backward_entropy": 0.0769696765475803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.45408630371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012018707348033786,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10929808616638184,
      "backward_entropy": 0.07700069745381673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.83592224121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013040101621299982,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10929477214813232,
      "backward_entropy": 0.07697506745656331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.81187438964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014065227005630732,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10929129123687745,
      "backward_entropy": 0.07697539859347874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.07691955566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015093318652361631,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10928765535354615,
      "backward_entropy": 0.07697570323944092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.72349548339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016132921446114779,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1092839002609253,
      "backward_entropy": 0.07697602113087972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.73924255371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017169942148029804,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10928012132644653,
      "backward_entropy": 0.07700535323884752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.62843322753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018207165412604809,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10927619934082031,
      "backward_entropy": 0.07700616783565944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.0108184814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019134823232889175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10927248001098633,
      "backward_entropy": 0.07697174946467082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.35163116455078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002009112387895584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10926849842071533,
      "backward_entropy": 0.07700743940141466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.60362243652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00210408098064363,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10926443338394165,
      "backward_entropy": 0.0769715706507365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.37074279785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021999033633619547,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10926024913787842,
      "backward_entropy": 0.07700855202145046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.42616271972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002297820523381233,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10925594568252564,
      "backward_entropy": 0.07700907521777683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.10208129882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0023979824036359787,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10925137996673584,
      "backward_entropy": 0.07700958516862658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.15875244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002500698668882251,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10924663543701171,
      "backward_entropy": 0.07697081565856934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.0400390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026073423214256763,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1092416763305664,
      "backward_entropy": 0.07697597477171156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.49502563476562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002715359441936016,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923657417297364,
      "backward_entropy": 0.07701101568010119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.0474090576172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028223369736224413,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923134088516236,
      "backward_entropy": 0.07701143953535292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.53053283691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002932567149400711,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10922589302062988,
      "backward_entropy": 0.07696996794806586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.2011260986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0030455398373305798,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10922020673751831,
      "backward_entropy": 0.07697525289323595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.86692810058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003159817075356841,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10921437740325927,
      "backward_entropy": 0.07701258526908027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.56105041503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032717392314225435,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10920851230621338,
      "backward_entropy": 0.07701288329230414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.33587646484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003382615279406309,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920261144638062,
      "backward_entropy": 0.0769686566458808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.14891052246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003493994241580367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10919651985168458,
      "backward_entropy": 0.07697398132748073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5604705810547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003607255406677723,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10919005870819092,
      "backward_entropy": 0.07701359854804145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.46115112304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003719652770087123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10918333530426025,
      "backward_entropy": 0.07696702745225695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.45848083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003828129032626748,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1091766595840454,
      "backward_entropy": 0.07697255081600612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.235595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003936041612178087,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10916987657546998,
      "backward_entropy": 0.07697186205122206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.364990234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004047208931297064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10916273593902588,
      "backward_entropy": 0.0769711865319146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.896240234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004159651696681976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10915544033050537,
      "backward_entropy": 0.07697045803070068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.07553100585938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0042734877206385136,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914785861968994,
      "backward_entropy": 0.07701441976759169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.00640869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0043894266709685326,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10914002656936646,
      "backward_entropy": 0.07696890830993652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.2192840576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00450188759714365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10913230180740356,
      "backward_entropy": 0.07696795463562012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.01537322998047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0046152835711836815,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10912437438964843,
      "backward_entropy": 0.07701461844974095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.71473693847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00472261430695653,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10911663770675659,
      "backward_entropy": 0.07701461844974095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.9866180419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0048318239860236645,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109108567237854,
      "backward_entropy": 0.07695652378929986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.98989868164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0049387067556381226,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10910038948059082,
      "backward_entropy": 0.07695496082305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.31866455078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005049283616244793,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909191370010377,
      "backward_entropy": 0.07695335812038845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.5704345703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005159665830433369,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10908336639404297,
      "backward_entropy": 0.07701456546783447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.96102905273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005268566310405731,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10907471179962158,
      "backward_entropy": 0.0769498348236084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.87620544433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005378677509725094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10906583070755005,
      "backward_entropy": 0.07695708009931776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.72332763671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00548958545550704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090567946434021,
      "backward_entropy": 0.07695542441474067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.37075805664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005597234237939119,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904780626296998,
      "backward_entropy": 0.0769536362753974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.87310791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005706313531845808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10903850793838502,
      "backward_entropy": 0.07694174183739556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.38861083984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0058220806531608105,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090285301208496,
      "backward_entropy": 0.07695020569695367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.04092407226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005938549060374498,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10901814699172974,
      "backward_entropy": 0.07701420783996582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.73728942871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0060567185282707214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10900731086730957,
      "backward_entropy": 0.0769469208187527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.74427795410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006171782501041889,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10899658203125,
      "backward_entropy": 0.07701417472627428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.7662353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006287410389631987,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10898549556732177,
      "backward_entropy": 0.07694330480363634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.8376007080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006400671787559986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10897433757781982,
      "backward_entropy": 0.07693000634511311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.29792022705078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006512713152915239,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10896313190460205,
      "backward_entropy": 0.07701404227150811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.14022827148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006619745399802923,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10895209312438965,
      "backward_entropy": 0.07701394293043348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.11412048339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0067251743748784065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1089409351348877,
      "backward_entropy": 0.07693462901645237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.73846435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006832984276115894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10892943143844605,
      "backward_entropy": 0.07693221833970812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.85079956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006940380670130253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1089176893234253,
      "backward_entropy": 0.07691655556360881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.87612915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007044586353003979,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10890605449676513,
      "backward_entropy": 0.07691354221767849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.08137512207031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007153956685215235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10889346599578857,
      "backward_entropy": 0.07691072093115912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.33245849609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007258184254169464,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10888075828552246,
      "backward_entropy": 0.07701326078838772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.67308044433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007359889801591635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10886774063110352,
      "backward_entropy": 0.0769192377726237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.62940979003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0074586402624845505,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10885468721389771,
      "backward_entropy": 0.07701294289694892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.77662658691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007559082470834255,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1088411808013916,
      "backward_entropy": 0.07701277732849121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.45091247558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00765822222456336,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10882749557495117,
      "backward_entropy": 0.07691007852554321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007762118708342314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10881297588348389,
      "backward_entropy": 0.0769070718023512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.03253173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007865909487009048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10879814624786377,
      "backward_entropy": 0.07690396573808458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.98785400390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007975229062139988,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10878236293792724,
      "backward_entropy": 0.07690110471513537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.31005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008085297420620918,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10876612663269043,
      "backward_entropy": 0.07689824369218615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.60174560546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008195387199521065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10874971151351928,
      "backward_entropy": 0.07687605089611477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.32191467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008303270675241947,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10873318910598755,
      "backward_entropy": 0.07689214415020412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.80136108398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008411905728280544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10871626138687134,
      "backward_entropy": 0.07688899172676934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.91766357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008521318435668945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10869888067245484,
      "backward_entropy": 0.07686491807301839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.7587432861328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008633601479232311,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10868089199066162,
      "backward_entropy": 0.0770119031270345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.05545043945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008746442385017872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10866243839263916,
      "backward_entropy": 0.07685768604278564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.381103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00885824952274561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10864369869232178,
      "backward_entropy": 0.07687628269195557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.77943420410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008973159827291965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10862419605255128,
      "backward_entropy": 0.07685083150863647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.33775329589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009084143675863743,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10860474109649658,
      "backward_entropy": 0.07701191637251112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.46078491210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00919384602457285,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10858516693115235,
      "backward_entropy": 0.07701187663608128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.87872314453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009304923936724663,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10856517553329467,
      "backward_entropy": 0.07701185014512804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.03599548339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009417076595127583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10854477882385254,
      "backward_entropy": 0.07683510250515407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.11647033691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009531962685286999,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10852363109588622,
      "backward_entropy": 0.07685518264770508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.57510375976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009642968885600567,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10850251913070678,
      "backward_entropy": 0.0768512487411499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.94671630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009752464480698109,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1084813117980957,
      "backward_entropy": 0.07682192325592041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.88827514648438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009866240434348583,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10845911502838135,
      "backward_entropy": 0.0770119031270345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.95977783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00997566245496273,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10843695402145385,
      "backward_entropy": 0.07683884435229832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.86473083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010081707499921322,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10841444730758668,
      "backward_entropy": 0.07683429453108045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.84381103515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010184451006352901,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10839189291000366,
      "backward_entropy": 0.07701181040869819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.39849853515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01028544083237648,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10836913585662841,
      "backward_entropy": 0.07679640584521824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.17221069335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010386449284851551,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10834591388702393,
      "backward_entropy": 0.07701163821750218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.8359832763672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010485479608178139,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10832263231277466,
      "backward_entropy": 0.07701151900821263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.78286743164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010586041025817394,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1082986831665039,
      "backward_entropy": 0.07680786318249172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.78184509277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01068796031177044,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10827405452728271,
      "backward_entropy": 0.07701130708058675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.29930114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010792476125061512,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1082485556602478,
      "backward_entropy": 0.07679658465915257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.98751831054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010900753550231457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10822193622589112,
      "backward_entropy": 0.07679115401373969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.9347381591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01100769080221653,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10819498300552369,
      "backward_entropy": 0.07675233152177599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.53724670410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011113425716757774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10816779136657714,
      "backward_entropy": 0.07677940527598064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 270.00750732421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011221273802220821,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10813970565795898,
      "backward_entropy": 0.07673839065763685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.9194793701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011335821822285652,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10810998678207398,
      "backward_entropy": 0.07701122760772705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.8134307861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011447633616626263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10808016061782837,
      "backward_entropy": 0.07672557565901014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.802490234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011560650542378426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10804960727691651,
      "backward_entropy": 0.07671892642974854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.17247009277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011669626459479332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10801922082901001,
      "backward_entropy": 0.07671182685428196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.60340881347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011782628484070301,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10798759460449218,
      "backward_entropy": 0.07701136006249322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.133544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011893889866769314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10795581340789795,
      "backward_entropy": 0.07673703961902195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.53948974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011996626853942871,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1079251766204834,
      "backward_entropy": 0.07668925656212701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.49290466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012101730331778526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10789353847503662,
      "backward_entropy": 0.07672296630011664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.8034210205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012206152081489563,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10786148309707641,
      "backward_entropy": 0.0767157408926222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.86865234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012313716113567352,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10782829523086548,
      "backward_entropy": 0.07701099581188625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.76580810546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012418760918080807,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10779510736465454,
      "backward_entropy": 0.0770108766025967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.82306671142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0125243766233325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10776126384735107,
      "backward_entropy": 0.07664624849955241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.69940185546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01262473315000534,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10772804021835328,
      "backward_entropy": 0.07668485244115193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.08685302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012726414017379284,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10769393444061279,
      "backward_entropy": 0.07667643494076198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.9061050415039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012827472761273384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10765947103500366,
      "backward_entropy": 0.07666778564453125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.759765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012921244837343693,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10762608051300049,
      "backward_entropy": 0.07700978385077582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.32716369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01301918737590313,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10759124755859376,
      "backward_entropy": 0.0765942997402615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.26226806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013118172995746136,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10755566358566285,
      "backward_entropy": 0.07663974497053358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.98631286621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013218088075518608,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10751941204071044,
      "backward_entropy": 0.07663021485010783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.79440307617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013314906507730484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10748332738876343,
      "backward_entropy": 0.07656017276975843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.2802276611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01341185625642538,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10744658708572388,
      "backward_entropy": 0.07661000225279066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.0603485107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01350734569132328,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10740952491760254,
      "backward_entropy": 0.07659945885340373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.96149444580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01360440906137228,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10737178325653077,
      "backward_entropy": 0.0770074658923679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.9272918701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013695665635168552,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1073349118232727,
      "backward_entropy": 0.0770070023006863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.02052307128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013788948766887188,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10729691982269288,
      "backward_entropy": 0.07649796538882786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.16551208496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013882873579859734,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1072581171989441,
      "backward_entropy": 0.07700626055399577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.6149444580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013974448665976524,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1072192907333374,
      "backward_entropy": 0.07700586318969727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.76870727539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014069448225200176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10717871189117431,
      "backward_entropy": 0.07653325133853489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.418701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014164646156132221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10713710784912109,
      "backward_entropy": 0.07644561926523845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.88973999023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014258973300457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10709409713745117,
      "backward_entropy": 0.07643234729766846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.57247924804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014352657832205296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10705018043518066,
      "backward_entropy": 0.07649921046362983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.7649383544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0144446836784482,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10700592994689942,
      "backward_entropy": 0.07640436622831556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.9927749633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01453828439116478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10696040391921997,
      "backward_entropy": 0.07638925313949585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.15792846679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014628355391323566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1069150447845459,
      "backward_entropy": 0.07637341817220052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.1385955810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0147140147164464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10687015056610108,
      "backward_entropy": 0.07644805643293592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.01719665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014798041433095932,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10682500600814819,
      "backward_entropy": 0.07633986737993029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.09214782714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014880328439176083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10677955150604249,
      "backward_entropy": 0.0763217740588718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.19557189941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01496161986142397,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10673344135284424,
      "backward_entropy": 0.0764040814505683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.73095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015042836777865887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10668656826019288,
      "backward_entropy": 0.07638871669769287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.18565368652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01512441411614418,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10663878917694092,
      "backward_entropy": 0.07637310028076172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.95425415039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015204103663563728,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10659091472625733,
      "backward_entropy": 0.07624403635660808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.9315948486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01528850756585598,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10654065608978272,
      "backward_entropy": 0.0763408210542467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.45030212402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015372542664408684,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10648974180221557,
      "backward_entropy": 0.07632458209991455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.18174743652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01545923762023449,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10643712282180787,
      "backward_entropy": 0.07630846897761027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.7626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015547249466180801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10638316869735717,
      "backward_entropy": 0.07629232274161445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.01382446289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015631917864084244,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10632965564727784,
      "backward_entropy": 0.07627554072274102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.87890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015715256333351135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10627579689025879,
      "backward_entropy": 0.07699521382649739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.60567474365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015800008550286293,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10622086524963378,
      "backward_entropy": 0.07624079121483697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.96852111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01587878353893757,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10616759061813355,
      "backward_entropy": 0.07607230212953356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.03915405273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015957944095134735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10611345767974853,
      "backward_entropy": 0.07620296213361952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.6919403076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01603802666068077,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10605816841125489,
      "backward_entropy": 0.07699233955807155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.08906555175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01611727476119995,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1060024380683899,
      "backward_entropy": 0.07616419924630059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.57392120361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016192378476262093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10594762563705444,
      "backward_entropy": 0.07614354292551677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.67008972167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016263898462057114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1058935284614563,
      "backward_entropy": 0.07612189981672499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.57183837890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016332780942320824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10583970546722413,
      "backward_entropy": 0.07609954145219591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.50425720214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01640661060810089,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10578298568725586,
      "backward_entropy": 0.0769873857498169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.979248046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01648567244410515,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10572336912155152,
      "backward_entropy": 0.07698684268527561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.305908203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01656121201813221,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10566442012786866,
      "backward_entropy": 0.07698610093858507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.30848693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01664101332426071,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10560280084609985,
      "backward_entropy": 0.07581255171034071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.05938720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01672145538032055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10554006099700927,
      "backward_entropy": 0.0759918557273017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.69325256347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016804572194814682,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10547528266906739,
      "backward_entropy": 0.0759706629647149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.82404327392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016892656683921814,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10540744066238403,
      "backward_entropy": 0.07595067554050022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.74993896484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016977746039628983,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10534012317657471,
      "backward_entropy": 0.07698542541927761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.07274627685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017065832391381264,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10527055263519287,
      "backward_entropy": 0.07569256093766955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.20172119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01715049147605896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1052017331123352,
      "backward_entropy": 0.07588509718577068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.09358215332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017240753397345543,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10512943267822265,
      "backward_entropy": 0.0758628315395779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.4833526611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01732794940471649,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10505770444869995,
      "backward_entropy": 0.07561160458458795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.88550567626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017413360998034477,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10498592853546143,
      "backward_entropy": 0.07581482993231879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.66386413574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01749478280544281,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1049152135848999,
      "backward_entropy": 0.07578909397125244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.00787353515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01757202483713627,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10484572649002075,
      "backward_entropy": 0.07698339223861694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.47315979003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017654208466410637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10477285385131836,
      "backward_entropy": 0.0757345888349745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.8357391357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01773986779153347,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10469732284545899,
      "backward_entropy": 0.0757077866130405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.147705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017826031893491745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10462057590484619,
      "backward_entropy": 0.07568070623609754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.47323608398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017913607880473137,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10454214811325073,
      "backward_entropy": 0.07565325498580933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.93276977539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018006103113293648,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10446021556854249,
      "backward_entropy": 0.0756261216269599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.92013549804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018097972497344017,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10437767505645752,
      "backward_entropy": 0.0755982134077284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.28173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018190940842032433,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1042935848236084,
      "backward_entropy": 0.0755700601471795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.79249572753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018283382058143616,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10420877933502197,
      "backward_entropy": 0.07554111215803358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.02938842773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01837714947760105,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10412229299545288,
      "backward_entropy": 0.07551215092341106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.31944274902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01846863329410553,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10403608083724976,
      "backward_entropy": 0.07698440551757812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.35578155517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01856369897723198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10394669771194458,
      "backward_entropy": 0.07545102967156304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.69647216796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018654800951480865,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10385854244232177,
      "backward_entropy": 0.07698482937282985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.1398468017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018745282664895058,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10376977920532227,
      "backward_entropy": 0.07538463009728326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.11997985839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01883535459637642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10368026494979858,
      "backward_entropy": 0.07502688301934136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.48216247558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018923670053482056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1035907506942749,
      "backward_entropy": 0.0753139787250095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.00604248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019011950120329857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10350028276443482,
      "backward_entropy": 0.0749387608634101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.71034240722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019102299585938454,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10340759754180909,
      "backward_entropy": 0.07524075773027208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.0798797607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01919393427670002,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10331311225891113,
      "backward_entropy": 0.07520386907789442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.69473266601562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019284911453723907,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10321801900863647,
      "backward_entropy": 0.07698456446329753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.10838317871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019370241090655327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10312561988830567,
      "backward_entropy": 0.07512554195192125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.22088623046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019454455003142357,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10303293466567993,
      "backward_entropy": 0.0769839816623264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.33392333984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0195386353880167,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10293926000595092,
      "backward_entropy": 0.07504079076978895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.65139770507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019625714048743248,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10284265279769897,
      "backward_entropy": 0.07499767674340142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.71343994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019712908193469048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10274497270584107,
      "backward_entropy": 0.07495363553365071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.0391082763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019801167771220207,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10264555215835572,
      "backward_entropy": 0.07490853468577068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.07904052734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019892193377017975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1025432825088501,
      "backward_entropy": 0.07698180940416124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.08738708496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019981686025857925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10244112014770508,
      "backward_entropy": 0.07481642564137776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.88904571533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020072732120752335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1023369312286377,
      "backward_entropy": 0.07434487342834473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.69328308105469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02015957236289978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10223464965820313,
      "backward_entropy": 0.07428827550676134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.46974182128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020237233489751816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10213658809661866,
      "backward_entropy": 0.07422502835591634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.62350463867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020319059491157532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10203443765640259,
      "backward_entropy": 0.07416444354587132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.65658569335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02039526030421257,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10193519592285157,
      "backward_entropy": 0.07409848107231988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.38331604003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020472705364227295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1018338680267334,
      "backward_entropy": 0.07450433572133382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.07737731933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020550012588500977,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1017315149307251,
      "backward_entropy": 0.074447943104638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.1147918701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020626608282327652,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10162848234176636,
      "backward_entropy": 0.07697188854217529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.52545166015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02070612832903862,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10152220726013184,
      "backward_entropy": 0.07697076267666286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.75322723388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020785169675946236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10141527652740479,
      "backward_entropy": 0.07427186436123318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.41873168945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020862363278865814,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10130882263183594,
      "backward_entropy": 0.07696830564075047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.96014404296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020940596237778664,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10120048522949218,
      "backward_entropy": 0.07696680227915446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.84097290039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02102021314203739,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10109014511108398,
      "backward_entropy": 0.0735140707757738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.16586303710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021101078018546104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10097789764404297,
      "backward_entropy": 0.07402071687910292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.81146240234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021182920783758163,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10086393356323242,
      "backward_entropy": 0.0769637558195326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.42900848388672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021268587559461594,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10074604749679565,
      "backward_entropy": 0.07696363661024305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.01597595214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0213487409055233,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10063186883926392,
      "backward_entropy": 0.07382531298531426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.2349090576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021429209038615227,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10051534175872803,
      "backward_entropy": 0.07375597953796387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.98007202148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021512115374207497,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10039557218551635,
      "backward_entropy": 0.07368636131286621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.95904541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02159816399216652,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10027201175689697,
      "backward_entropy": 0.07361620002322727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.68148803710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02168482542037964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10014698505401612,
      "backward_entropy": 0.07287855280770196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.50531005859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021767633035779,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10002443790435792,
      "backward_entropy": 0.07279222541385227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.06187438964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021849533542990685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09990168809890747,
      "backward_entropy": 0.07270309660169813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.02960205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021933890879154205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.099775892496109,
      "backward_entropy": 0.0733256737391154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.7812271118164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02201658859848976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09965054988861084,
      "backward_entropy": 0.0732489029566447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.57476806640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022097276523709297,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09952618479728699,
      "backward_entropy": 0.07695797416898939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.7801055908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02217743918299675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09940139055252076,
      "backward_entropy": 0.07232442167070177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.93954467773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022258257493376732,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09927505850791932,
      "backward_entropy": 0.07300673590766059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.03433227539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022343870252370834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0991435170173645,
      "backward_entropy": 0.07211816310882568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.33181762695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022431286051869392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09900951385498047,
      "backward_entropy": 0.07201439804501003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.34242248535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022513579577207565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09887940883636474,
      "backward_entropy": 0.07275458176930745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.35882568359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02260531857609749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09874019026756287,
      "backward_entropy": 0.07179509268866645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.63066864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02269555628299713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09860166311264038,
      "backward_entropy": 0.07258501980039808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.49337768554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022781912237405777,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09846624135971069,
      "backward_entropy": 0.07249471214082506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.0815658569336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0228652935475111,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09833282232284546,
      "backward_entropy": 0.07146505514780681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.93553924560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022948332130908966,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09819904565811158,
      "backward_entropy": 0.07135106457604302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.288818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0230253953486681,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09807032346725464,
      "backward_entropy": 0.07219734456804064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.71021270751953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023105287924408913,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09793809652328492,
      "backward_entropy": 0.07695092095269097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.15754699707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023183325305581093,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09780697226524353,
      "backward_entropy": 0.07097413804796007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.60649108886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023259852081537247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09767667651176452,
      "backward_entropy": 0.07084478934605916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.3418731689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023335179314017296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09754692316055298,
      "backward_entropy": 0.0717643764283922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.23672485351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023413995280861855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0974130630493164,
      "backward_entropy": 0.07058669461144342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.05575561523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023491086438298225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09728026986122132,
      "backward_entropy": 0.07153940200805664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.18968963623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023567449301481247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09714740514755249,
      "backward_entropy": 0.0703154272503323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.16716003417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023643776774406433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09701392650604249,
      "backward_entropy": 0.07017257478502062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.21759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02371818572282791,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0968817114830017,
      "backward_entropy": 0.07117774089177449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.1989974975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023794500157237053,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09674695730209351,
      "backward_entropy": 0.07105284267001682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.93351745605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023867309093475342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09661521911621093,
      "backward_entropy": 0.06971659262975057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.49923706054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023938877508044243,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09648419618606567,
      "backward_entropy": 0.07692942354414198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.09596252441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024010930210351944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09635206460952758,
      "backward_entropy": 0.07065703471501668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.9603729248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024087538942694664,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09621460437774658,
      "backward_entropy": 0.06922850343916151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.42825317382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024167126044631004,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09607356190681457,
      "backward_entropy": 0.07692212528652614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.66059112548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024248432368040085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09593042135238647,
      "backward_entropy": 0.07026050488154094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.19152069091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024326074868440628,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0957908034324646,
      "backward_entropy": 0.07691927750905354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.89102172851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024403458461165428,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0956510066986084,
      "backward_entropy": 0.06857438882191975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.73438262939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02448030561208725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09551128149032592,
      "backward_entropy": 0.06983811325497097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.75096893310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024555237963795662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09537187814712525,
      "backward_entropy": 0.06821244955062866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.62245178222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024628767743706703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09523332118988037,
      "backward_entropy": 0.06953563292821248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.25580596923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024708453565835953,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09508776664733887,
      "backward_entropy": 0.0693855153189765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.43634033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024785291403532028,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09494505524635315,
      "backward_entropy": 0.069231735335456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.44703674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024867486208677292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09479610323905945,
      "backward_entropy": 0.06747812694973415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.1801300048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024950260296463966,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09464616775512695,
      "backward_entropy": 0.06892338063981798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.7288589477539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02503974735736847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09448895454406739,
      "backward_entropy": 0.06711151864793566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.19999313354492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025126071646809578,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09433506727218628,
      "backward_entropy": 0.06861462857988146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.69060516357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025201182812452316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09419393539428711,
      "backward_entropy": 0.06844457652833727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.8655014038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02527584880590439,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09405292272567749,
      "backward_entropy": 0.06648446453942193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.47180938720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025348998606204987,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0939133644104004,
      "backward_entropy": 0.068093650870853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.08018493652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02542126178741455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09377461075782775,
      "backward_entropy": 0.06791443957222833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.12449645996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025495899841189384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09363303184509278,
      "backward_entropy": 0.06773694356282552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.79728698730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02556568570435047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0934968650341034,
      "backward_entropy": 0.06558799081378514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.78607177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025636376813054085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09335947036743164,
      "backward_entropy": 0.0653601951069302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.70632934570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025709161534905434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0932195246219635,
      "backward_entropy": 0.06513331996070014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.13516235351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02578209713101387,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09307925701141358,
      "backward_entropy": 0.06490120622846815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.0475845336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025852300226688385,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09294207692146302,
      "backward_entropy": 0.06679599814944798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.87229919433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02591698057949543,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09281125664710999,
      "backward_entropy": 0.06659404436747234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.92453002929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025988342240452766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09267274141311646,
      "backward_entropy": 0.06639602449205187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.86207580566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02606302499771118,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09253048896789551,
      "backward_entropy": 0.07683317528830634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.05839538574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026139741763472557,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09238609671592712,
      "backward_entropy": 0.06369021866056654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.28716278076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026216872036457062,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09224146604537964,
      "backward_entropy": 0.06580809752146403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.34773254394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026294225826859474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0920967698097229,
      "backward_entropy": 0.06560935576756795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.73786926269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02637004293501377,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09195398092269898,
      "backward_entropy": 0.06297985050413343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.3616943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026445917785167694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09181125164031982,
      "backward_entropy": 0.06519448757171631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.1566162109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026521537452936172,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09166896343231201,
      "backward_entropy": 0.07681620121002197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.99507141113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02659406140446663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09153046607971191,
      "backward_entropy": 0.06475692987442017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.66682434082031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026666684076189995,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09139201641082764,
      "backward_entropy": 0.06453181637658013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.13176727294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02673620730638504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09125736951828003,
      "backward_entropy": 0.06429970264434814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.2772674560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02680390328168869,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09112510681152344,
      "backward_entropy": 0.0613731410768297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.88735961914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02687348611652851,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09099079966545105,
      "backward_entropy": 0.07678653796513875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.89559936523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026944445446133614,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09085522890090943,
      "backward_entropy": 0.06358887089623345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.57035064697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02701137587428093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0907246708869934,
      "backward_entropy": 0.06334447860717773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.25475311279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027076775208115578,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09059621095657348,
      "backward_entropy": 0.06309696700837877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.14051055908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027141287922859192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09046905636787414,
      "backward_entropy": 0.059918344020843506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.71526336669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027206940576434135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09034082889556885,
      "backward_entropy": 0.05962361229790582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.46446228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02727058157324791,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09021525382995606,
      "backward_entropy": 0.06234206755956014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.76007080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02733674831688404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09008699059486389,
      "backward_entropy": 0.06208433707555135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.78544616699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027406936511397362,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08995453119277955,
      "backward_entropy": 0.058702667554219566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.43907928466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02747291699051857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08982745409011841,
      "backward_entropy": 0.05837894810570611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.0679168701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027540257200598717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08969929218292236,
      "backward_entropy": 0.0580599308013916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.80933380126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02761152572929859,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08956713676452636,
      "backward_entropy": 0.0577490594651964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.12848663330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027680279687047005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08943843841552734,
      "backward_entropy": 0.06076543860965305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.89368438720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027747422456741333,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08931214809417724,
      "backward_entropy": 0.06049283345540365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.87876892089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02781425043940544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0891867458820343,
      "backward_entropy": 0.060214724805619985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.53992462158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02788667194545269,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08905565738677979,
      "backward_entropy": 0.05645442008972168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.14810180664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02795826457440853,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0889261782169342,
      "backward_entropy": 0.05613076686859131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.87500762939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028026876971125603,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0888007938861847,
      "backward_entropy": 0.05578943755891588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.79283905029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02809665910899639,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08867467641830444,
      "backward_entropy": 0.05909097194671631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.84133911132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02816702425479889,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08854860067367554,
      "backward_entropy": 0.05510170592202081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.26362609863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028238244354724884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08842232227325439,
      "backward_entropy": 0.05475656853781806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.14309692382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02831040322780609,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08829571008682251,
      "backward_entropy": 0.0544158418973287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.02790832519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028384363278746605,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08816789984703063,
      "backward_entropy": 0.057925687895880804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.4619140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02845565415918827,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0880439043045044,
      "backward_entropy": 0.057625253995259605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.24761962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02852710708975792,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08792059421539307,
      "backward_entropy": 0.053343978193071157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.456809997558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0286023560911417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08779401779174804,
      "backward_entropy": 0.052988284164004855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.83409881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0286716241389513,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0876755177974701,
      "backward_entropy": 0.05261179804801941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.34942626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028737127780914307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08756123185157776,
      "backward_entropy": 0.05638611316680908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.57017517089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02880532294511795,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08744484186172485,
      "backward_entropy": 0.05606140030754937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.43167114257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028872139751911163,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08733088374137879,
      "backward_entropy": 0.05573477347691854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.346435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028939953073859215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08721659779548645,
      "backward_entropy": 0.055406669775644936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.85365295410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02900994010269642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0871008038520813,
      "backward_entropy": 0.05070288644896613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.27014923095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029083309695124626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0869824767112732,
      "backward_entropy": 0.05474953850110372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.49945831298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02915242314338684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08686974048614501,
      "backward_entropy": 0.04992389016681247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.837223052978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029224567115306854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08675472140312195,
      "backward_entropy": 0.05408141016960144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.45043182373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02929229848086834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08664525151252747,
      "backward_entropy": 0.053748379151026406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.61151123046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029356535524129868,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08654037117958069,
      "backward_entropy": 0.05340682135687934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.42420196533203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029417965561151505,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08643926382064819,
      "backward_entropy": 0.07651527722676595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.74005126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02947816252708435,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08634026050567627,
      "backward_entropy": 0.05270653631952074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.07504272460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029547514393925667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08623280525207519,
      "backward_entropy": 0.05236777663230896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.41429138183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02961486577987671,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08612838387489319,
      "backward_entropy": 0.05202409956190321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.03858184814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02968643419444561,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08602074384689332,
      "backward_entropy": 0.04683738615777758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.69371032714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029756614938378334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08591536283493043,
      "backward_entropy": 0.04647009571393331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.53710174560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02983245626091957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08580544590950012,
      "backward_entropy": 0.0510245164235433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.52098083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029904432594776154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08570052981376648,
      "backward_entropy": 0.050688998566733465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.73095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029982807114720345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08559064269065857,
      "backward_entropy": 0.05036090479956733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.97915267944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030060088261961937,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08548298478126526,
      "backward_entropy": 0.05002842677964105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.9837417602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030131807550787926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08538199663162231,
      "backward_entropy": 0.04968599478403727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.07686614990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030203284695744514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08528223037719726,
      "backward_entropy": 0.044306304719713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.82640075683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030272819101810455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0851853609085083,
      "backward_entropy": 0.04899840222464667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.13030242919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030347490683197975,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08508481979370117,
      "backward_entropy": 0.04865706629223294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.64871215820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030419155955314636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08498806953430176,
      "backward_entropy": 0.043193423085742526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.9755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030492965131998062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08489048480987549,
      "backward_entropy": 0.04282392395867242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.20858764648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030562257394194603,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08479850292205811,
      "backward_entropy": 0.042427500089009605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.55003356933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030632393434643745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08470686078071595,
      "backward_entropy": 0.04725634058316549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0925064086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03070748783648014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08461194038391114,
      "backward_entropy": 0.046902219454447426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.02814483642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0307856947183609,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08451507091522217,
      "backward_entropy": 0.041264229350619845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.9018096923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030859658494591713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08442336916923524,
      "backward_entropy": 0.04621328247918023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.4222640991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030937615782022476,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08432918787002563,
      "backward_entropy": 0.04587464862399631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.13601684570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031017303466796875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08423476219177246,
      "backward_entropy": 0.040160033437940806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.25179290771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03109855391085148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08414025902748108,
      "backward_entropy": 0.045203321509891085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.9578857421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03117784857749939,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08404840230941772,
      "backward_entropy": 0.04486928383509318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.64773559570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031256310641765594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08395842909812927,
      "backward_entropy": 0.03909907076093885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.80741882324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03133215382695198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08387191295623779,
      "backward_entropy": 0.04418892330593533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.27098083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031407374888658524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08378738164901733,
      "backward_entropy": 0.04384590519799127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.84893035888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03148756921291351,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08369938135147095,
      "backward_entropy": 0.03803487287627326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.2695541381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031569648534059525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08361122608184815,
      "backward_entropy": 0.03769803047180176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.7178726196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03165358304977417,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08352270126342773,
      "backward_entropy": 0.0428649385770162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.55606079101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03173750266432762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08343546986579894,
      "backward_entropy": 0.03703920046488444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.7730484008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03181881457567215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08335152268409729,
      "backward_entropy": 0.0422164433532291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.00004577636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03189698979258537,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08327155113220215,
      "backward_entropy": 0.036355833212534584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.27716064453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03197268024086952,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08319478034973145,
      "backward_entropy": 0.07646947436862522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.51951599121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03205244615674019,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08311573266983033,
      "backward_entropy": 0.0764700969060262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.16289520263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032135553658008575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08303525447845458,
      "backward_entropy": 0.035321053531434804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.452415466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032214660197496414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08295893669128418,
      "backward_entropy": 0.04055164919959174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.57302856445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032288141548633575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08288836479187012,
      "backward_entropy": 0.040208667516708374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.84181213378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03236563131213188,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08281575441360474,
      "backward_entropy": 0.03987508681085375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.02064514160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03244013711810112,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08274697065353394,
      "backward_entropy": 0.0764571295844184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.30113983154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03251294419169426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08268048763275146,
      "backward_entropy": 0.033539666069878474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.913795471191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03258286044001579,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08261699676513672,
      "backward_entropy": 0.03883865806791517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.7148666381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03264586627483368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08255960941314697,
      "backward_entropy": 0.032798075013690524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.45260620117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03270715847611427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08250410556793213,
      "backward_entropy": 0.03242826461791992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.20907592773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03276968374848366,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0824482798576355,
      "backward_entropy": 0.037785367833243474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.15270233154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03283373638987541,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08239256143569947,
      "backward_entropy": 0.03743913107448154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.72030639648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032897088676691055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0823380708694458,
      "backward_entropy": 0.031326224406560264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.68152618408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03295934200286865,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08228554725646972,
      "backward_entropy": 0.036739726861317955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.064329147338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03301957622170448,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08223506212234497,
      "backward_entropy": 0.03638307915793525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.01054382324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03307419270277023,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08218916654586791,
      "backward_entropy": 0.03602352076106601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.75066375732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033131878823041916,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0821419358253479,
      "backward_entropy": 0.03567218780517578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.29188537597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03319081664085388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08209465742111206,
      "backward_entropy": 0.03532497750388251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.10604858398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03324953466653824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08204828500747681,
      "backward_entropy": 0.034979025522867836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.31913757324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03330807760357857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08200282454490662,
      "backward_entropy": 0.02869125869539049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.30919647216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033369217067956924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195632696151733,
      "backward_entropy": 0.0283294849925571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.14286804199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03343254700303078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08190923929214478,
      "backward_entropy": 0.027971671687232122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.78978729248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03349851071834564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08186095952987671,
      "backward_entropy": 0.027630825837453205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.37284851074219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033563338220119476,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08181450963020324,
      "backward_entropy": 0.03332169850667318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.19385528564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03362660855054855,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0817695438861847,
      "backward_entropy": 0.033003661367628306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.87171936035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03369273245334625,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08172334432601928,
      "backward_entropy": 0.03269941276974148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.297916412353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033758729696273804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08167773485183716,
      "backward_entropy": 0.03240383995903863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.36786651611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03382005915045738,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08163590431213379,
      "backward_entropy": 0.032104313373565674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.74234008789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033881139010190964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08159502744674682,
      "backward_entropy": 0.02568933367729187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.24940490722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03394424542784691,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08155396580696106,
      "backward_entropy": 0.03150313761499193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.94076156616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03400600329041481,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08151503205299378,
      "backward_entropy": 0.031192647086249456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.691120147705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034065622836351395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08147772550582885,
      "backward_entropy": 0.030893729792700872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.03968048095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03411931172013283,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08144518136978149,
      "backward_entropy": 0.030585100253423054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.39679718017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0341731421649456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08141340613365174,
      "backward_entropy": 0.030274881256951228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.43806457519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034233156591653824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08137845396995544,
      "backward_entropy": 0.02998042768902249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.08409881591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03428930044174194,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08134648799896241,
      "backward_entropy": 0.029686921172671847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.93048095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034347716718912125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0813134789466858,
      "backward_entropy": 0.02940731578403049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.7817497253418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03440701588988304,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0812800645828247,
      "backward_entropy": 0.029141293631659612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.22999572753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034465137869119644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08124807476997375,
      "backward_entropy": 0.028876953654819064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.032906532287598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03452476114034653,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08121591806411743,
      "backward_entropy": 0.028615719742245145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.5390853881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034576665610075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08118976354598999,
      "backward_entropy": 0.021969828340742324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.525108337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034631844609975815,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08116168975830078,
      "backward_entropy": 0.021691716379589505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.26819610595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03468602895736694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08113491535186768,
      "backward_entropy": 0.021406983335812885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.861934661865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03474132716655731,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0811078429222107,
      "backward_entropy": 0.02113496098253462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.057071685791016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.034795988351106644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0810815930366516,
      "backward_entropy": 0.0760498046875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.22044372558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034849777817726135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08105655312538147,
      "backward_entropy": 0.027064614825778537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.26939392089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03490344434976578,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08103199005126953,
      "backward_entropy": 0.026823429597748652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.87821960449219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.034959547221660614,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08100658655166626,
      "backward_entropy": 0.07603671815660265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.42971420288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035020679235458374,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08097881078720093,
      "backward_entropy": 0.026374232437875535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.54114532470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03508038818836212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08095287680625915,
      "backward_entropy": 0.019588955574565463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.78746032714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03514033183455467,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08092662096023559,
      "backward_entropy": 0.025938012533717685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.54167938232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035199325531721115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08090186715126038,
      "backward_entropy": 0.025723616282145183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.38411712646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035259295254945755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08087676763534546,
      "backward_entropy": 0.02552051345507304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.0307388305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03532249853014946,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08085052967071533,
      "backward_entropy": 0.02532553838358985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.04928588867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03538644313812256,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08082404136657714,
      "backward_entropy": 0.0184602290391922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.09511947631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03545472025871277,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08079571723937988,
      "backward_entropy": 0.024975392553541396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.88395690917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03552224487066269,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0807679533958435,
      "backward_entropy": 0.01808652612898085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.44685363769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03559490293264389,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0807381272315979,
      "backward_entropy": 0.017912412683169048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.491905212402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03566413372755051,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0807107925415039,
      "backward_entropy": 0.02451292508178287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.3783187866211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035731617361307144,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0806849718093872,
      "backward_entropy": 0.024352800514962938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.28055572509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0358048640191555,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08065650463104249,
      "backward_entropy": 0.0242101831568612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.851173400878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035877302289009094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0806290864944458,
      "backward_entropy": 0.017206599315007527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.839290618896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03594786673784256,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08060305714607238,
      "backward_entropy": 0.017034648193253413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.96827697753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036013804376125336,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08058007955551147,
      "backward_entropy": 0.02377526627646552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.224454879760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036079395562410355,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08055795431137085,
      "backward_entropy": 0.02362211545308431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.33230590820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03614003211259842,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08053868412971496,
      "backward_entropy": 0.0234724051422543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.45626831054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03620119020342827,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08051968216896058,
      "backward_entropy": 0.02332466509607103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.6919174194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03626490756869316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0804995596408844,
      "backward_entropy": 0.02319244212574429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.65785217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036331627517938614,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08047829866409302,
      "backward_entropy": 0.023063189453548856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.47134399414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036398448050022125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08045743703842163,
      "backward_entropy": 0.022935918635792203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.53071594238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03646537661552429,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08043693900108337,
      "backward_entropy": 0.015631349550353155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.42202758789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03653210774064064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08041714429855347,
      "backward_entropy": 0.015463017755084567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.56790542602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036600880324840546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08039638996124268,
      "backward_entropy": 0.015309626857439676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.34060287475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03666568174958229,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08037803173065186,
      "backward_entropy": 0.02245255642467075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.27601623535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03672807663679123,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08036129474639893,
      "backward_entropy": 0.07639233933554755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.1631965637207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03679237887263298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08034395575523376,
      "backward_entropy": 0.014836018284161886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.75265121459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036853350698947906,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08032849431037903,
      "backward_entropy": 0.01468047665225135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.55914306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036913495510816574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08031395077705383,
      "backward_entropy": 0.014521045817269219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.62973022460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03697595372796059,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08029848337173462,
      "backward_entropy": 0.02188885708649953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.189212799072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03703936189413071,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08028266429901124,
      "backward_entropy": 0.021789302428563435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.5037841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03710189089179039,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08026765584945679,
      "backward_entropy": 0.014073039094607035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.41350555419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037168506532907486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08025119304656983,
      "backward_entropy": 0.02158354388342963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.52388000488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03723524138331413,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08023511171340943,
      "backward_entropy": 0.021480994092093572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.883392333984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037299059331417084,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08022103309631348,
      "backward_entropy": 0.02137037283844418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.4121208190918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037361010909080505,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08020836710929871,
      "backward_entropy": 0.021266682280434504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.0921630859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03741984814405441,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08019814491271973,
      "backward_entropy": 0.021166718668407865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.60239028930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03748519718647003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08018468618392945,
      "backward_entropy": 0.021077427599165175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.857967376708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037550702691078186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08017114400863648,
      "backward_entropy": 0.020985292063819036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.00757598876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03761536255478859,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08015809059143067,
      "backward_entropy": 0.02089654240343306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.13363265991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0376824215054512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08014383316040039,
      "backward_entropy": 0.012767918407917023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.22329711914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03774935007095337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08013026714324951,
      "backward_entropy": 0.012637952963511149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.97893524169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03781744837760925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08011670112609863,
      "backward_entropy": 0.02065989375114441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.34257507324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037883203476667404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08010460138320923,
      "backward_entropy": 0.012372070716487037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.21422576904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03795098140835762,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08009159564971924,
      "backward_entropy": 0.02050802277194129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.75421142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03802043944597244,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08007769584655762,
      "backward_entropy": 0.02043959332836999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.01319885253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03808872774243355,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08006441593170166,
      "backward_entropy": 0.020371619198057387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.9841365814209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03815526142716408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08005276322364807,
      "backward_entropy": 0.011878588961230384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.2830696105957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03821880370378494,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08004259467124938,
      "backward_entropy": 0.020225857694943745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.929813385009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03828321024775505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08003222942352295,
      "backward_entropy": 0.011641581025388505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.12484359741211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03834599629044533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08002250790596008,
      "backward_entropy": 0.011529836389753554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.74913024902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038406770676374435,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08001396656036378,
      "backward_entropy": 0.02004864811897278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.80362319946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03847124055027962,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08000411987304687,
      "backward_entropy": 0.011304747727182176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.484371185302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03853369131684303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07999549508094787,
      "backward_entropy": 0.011194629801644219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.71330261230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03859701007604599,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07998666763305665,
      "backward_entropy": 0.01989073223537869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.94717788696289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038667671382427216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07997440695762634,
      "backward_entropy": 0.01098696059650845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.63302612304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038737669587135315,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07996231317520142,
      "backward_entropy": 0.019812183247672185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.983524322509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03880931809544563,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07994949817657471,
      "backward_entropy": 0.019782043165630765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.97758483886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038879528641700745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0799376130104065,
      "backward_entropy": 0.010717127058241103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.168758392333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03895346075296402,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07992433309555054,
      "backward_entropy": 0.010625745687219832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.80915069580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039023928344249725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0799134612083435,
      "backward_entropy": 0.010524876415729523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.432273864746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039095863699913025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07990211248397827,
      "backward_entropy": 0.019617802566952176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.027544021606445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03916550055146217,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07989189624786378,
      "backward_entropy": 0.01033641149600347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.772159576416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03923100233078003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07988427877426148,
      "backward_entropy": 0.01953695880042182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.907865524291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039296697825193405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07987651824951172,
      "backward_entropy": 0.019489301575554743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.913785934448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03935808315873146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07987080812454224,
      "backward_entropy": 0.010038546390003629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.55313873291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039415787905454636,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07986711859703063,
      "backward_entropy": 0.019392500321070354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.828304290771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039476267993450165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07986208200454711,
      "backward_entropy": 0.009827100568347506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.1556282043457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039538003504276276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0798566460609436,
      "backward_entropy": 0.019302336706055537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.59503173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03959962725639343,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0798514723777771,
      "backward_entropy": 0.019267669982380338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.199817657470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0396597720682621,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0798471748828888,
      "backward_entropy": 0.019235604339175753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.05683898925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03971695527434349,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07984451055526734,
      "backward_entropy": 0.01919814944267273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.22091674804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03977372497320175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07984222173690796,
      "backward_entropy": 0.00935350606838862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.871124267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039835743606090546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0798376441001892,
      "backward_entropy": 0.009257867932319641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.06746292114258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03989477828145027,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07983436584472656,
      "backward_entropy": 0.0190578516986635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.476112365722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039952512830495834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07983195781707764,
      "backward_entropy": 0.019015856915050082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.70708465576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040006205439567566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07983138561248779,
      "backward_entropy": 0.008971172902319167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.68280792236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04006287828087807,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07982994318008423,
      "backward_entropy": 0.008877948754363589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.68899536132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040123723447322845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07982690930366516,
      "backward_entropy": 0.018895660837491352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.028343200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04018954932689667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07982170581817627,
      "backward_entropy": 0.008712687426143222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.048608779907227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04025554656982422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07981650829315186,
      "backward_entropy": 0.008628944555918375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.42399597167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04031699150800705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07981331348419189,
      "backward_entropy": 0.008543082409434848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.479007720947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04037806764245033,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07981033325195312,
      "backward_entropy": 0.008457841144667732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.48841094970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04043981432914734,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07980724573135375,
      "backward_entropy": 0.018717512488365173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.94233703613281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040506087243556976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07980242967605591,
      "backward_entropy": 0.018674655093087092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.907676696777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040570180863142014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07979884147644042,
      "backward_entropy": 0.01863306098514133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.51927185058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040629368275403976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07979774475097656,
      "backward_entropy": 0.018584400415420532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.40477180480957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04069260507822037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979499697685241,
      "backward_entropy": 0.008025287754005857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.3523006439209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04075336083769798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979339361190796,
      "backward_entropy": 0.00794999467002021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.55760383605957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04081176966428757,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07979235649108887,
      "backward_entropy": 0.018512599998050265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.9067268371582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04086612910032272,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979311943054199,
      "backward_entropy": 0.007804461651378208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.33089828491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04092235490679741,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979322671890259,
      "backward_entropy": 0.0077325329184532166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.152082443237305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04097512364387512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979475259780884,
      "backward_entropy": 0.007660125692685445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.652652740478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041025903075933456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07979711890220642,
      "backward_entropy": 0.018437700139151678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.6501579284668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04107758402824402,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979918122291565,
      "backward_entropy": 0.007517646584245894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.65880584716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04112963005900383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07980117797851563,
      "backward_entropy": 0.018402540021472506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.390403747558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04118635505437851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07980122566223144,
      "backward_entropy": 0.018391254875395033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.734163284301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04124263674020767,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07980133295059204,
      "backward_entropy": 0.0183929271168179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.84723663330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04129662364721298,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07980243563652038,
      "backward_entropy": 0.018391099241044786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.170494079589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0413598008453846,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0798000454902649,
      "backward_entropy": 0.0766441822052002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.746944427490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041421450674533844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0797982931137085,
      "backward_entropy": 0.007150998546017541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.54593276977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04148272052407265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07979676127433777,
      "backward_entropy": 0.018396255042817857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.05199432373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0415438711643219,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979531288146972,
      "backward_entropy": 0.007038965821266174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.8275032043457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04160897061228752,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0797922134399414,
      "backward_entropy": 0.01841426557964749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.512962341308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041674669831991196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07978902459144592,
      "backward_entropy": 0.006943952292203903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.39815902709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041736166924238205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07978742122650147,
      "backward_entropy": 0.006896537211206224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.27336120605469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041796524077653885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07978618144989014,
      "backward_entropy": 0.01846667793061998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.40534973144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04185805842280388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07978452444076538,
      "backward_entropy": 0.01848740213447147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.32765197753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04192434996366501,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07978113889694213,
      "backward_entropy": 0.01850824389192793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.72441101074219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04199241101741791,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07977713346481323,
      "backward_entropy": 0.018527681628863018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.57793045043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04206085950136185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0797729253768921,
      "backward_entropy": 0.006680082529783249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.196041107177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04212944954633713,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07976877093315124,
      "backward_entropy": 0.006634893930620617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.57139587402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042196352034807205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0797654628753662,
      "backward_entropy": 0.006581981148984697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.20395278930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04226135462522507,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07976288795471191,
      "backward_entropy": 0.00653087596098582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.566749572753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04232833907008171,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07975956797599792,
      "backward_entropy": 0.018556348151630826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.84539794921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04239451512694359,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07975654602050782,
      "backward_entropy": 0.018559442626105413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.027931213378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042462147772312164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07975291013717652,
      "backward_entropy": 0.006384267161289851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.85394287109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042525921016931534,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07975084781646728,
      "backward_entropy": 0.018544291456540424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.87084197998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04258662462234497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07975001335144043,
      "backward_entropy": 0.00627351055542628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.83047866821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04264754801988602,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07974898815155029,
      "backward_entropy": 0.006223037838935852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.719017028808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04270808398723602,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07974819540977478,
      "backward_entropy": 0.006171564261118571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.492530822753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04277103766798973,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07974660396575928,
      "backward_entropy": 0.006123394187953737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.33888626098633,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.042836256325244904,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0797439157962799,
      "backward_entropy": 0.07678792874018352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.115638732910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04290086030960083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07974141836166382,
      "backward_entropy": 0.006035433047347599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.97541427612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04296628013253212,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07973854541778565,
      "backward_entropy": 0.018535607390933566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.4643783569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043032146990299225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07973552942276001,
      "backward_entropy": 0.018541206916173298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.67359924316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043102119117975235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07973098754882812,
      "backward_entropy": 0.005909813774956597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.17253112792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04317118227481842,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0797266960144043,
      "backward_entropy": 0.005870321144660314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.67692756652832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04324185848236084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07972173690795899,
      "backward_entropy": 0.005833619170718723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.66180992126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04330956190824509,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07971770763397217,
      "backward_entropy": 0.018600540028678045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.05921936035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04337403550744057,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07971482872962951,
      "backward_entropy": 0.018628234664599102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.759766578674316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04343795031309128,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07971214056015015,
      "backward_entropy": 0.018653621276219685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.038984298706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043497830629348755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0797109603881836,
      "backward_entropy": 0.018678986363940768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.889850616455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04355670139193535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07971004843711853,
      "backward_entropy": 0.005673858854505751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.829139709472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04361492767930031,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07970919609069824,
      "backward_entropy": 0.018751480513148837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.720563888549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04367221146821976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07970863580703735,
      "backward_entropy": 0.005622364580631256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.77991485595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04372864216566086,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07970831394195557,
      "backward_entropy": 0.018838043014208477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.13862609863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04378663748502731,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07970734238624573,
      "backward_entropy": 0.018881107370058697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.388996124267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043847452849149704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07970517873764038,
      "backward_entropy": 0.005550992157724168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.29170227050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0439070500433445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0797033965587616,
      "backward_entropy": 0.018976791037453547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.72142219543457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043967779725790024,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07970114946365356,
      "backward_entropy": 0.01902226938141717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.4266471862793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04402586445212364,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07969987392425537,
      "backward_entropy": 0.01906340155336592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.635677337646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044086210429668427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07969775199890136,
      "backward_entropy": 0.005452872150474125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.044692039489746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04414982348680496,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07969431877136231,
      "backward_entropy": 0.005425223873721229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.668245315551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04420950263738632,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07969229221343994,
      "backward_entropy": 0.019161452849706013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.19599914550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04426829516887665,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07969042062759399,
      "backward_entropy": 0.01920331186718411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.19614028930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04432883858680725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07968782186508179,
      "backward_entropy": 0.019257980916235182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.964866638183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044386740773916245,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07968617677688598,
      "backward_entropy": 0.01930694944328732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.49752044677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044445645064115524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07968407869338989,
      "backward_entropy": 0.019346285197469924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.128313064575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04450937360525131,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07968010902404785,
      "backward_entropy": 0.0052866749465465546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.048381805419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04457152634859085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0796765923500061,
      "backward_entropy": 0.019428201847606234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.060733795166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04463193938136101,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07967371940612793,
      "backward_entropy": 0.0052386489179399275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.91678237915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04469224810600281,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0796707808971405,
      "backward_entropy": 0.005213926649755902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.90205764770508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04475245624780655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07966775894165039,
      "backward_entropy": 0.019531132446395025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.47121238708496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04481355845928192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07966435551643372,
      "backward_entropy": 0.005163958503140343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.59565353393555,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04487209767103195,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07966179847717285,
      "backward_entropy": 0.07692307233810425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.296388626098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044932980090379715,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965829372406005,
      "backward_entropy": 0.019622458351982966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.233646392822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04499131813645363,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965567111968994,
      "backward_entropy": 0.019652634859085083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.186617851257324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04504942148923874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0796530783176422,
      "backward_entropy": 0.005060839570230908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1770920753479,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045103803277015686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07965186834335328,
      "backward_entropy": 0.005031370040443208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.890918731689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04515376687049866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0796522855758667,
      "backward_entropy": 0.019709231124983892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.87232780456543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04520341381430626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965284585952759,
      "backward_entropy": 0.01972651978333791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.836828231811523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04525185376405716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965372800827027,
      "backward_entropy": 0.019752022292878892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.00747299194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04529884085059166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965511083602905,
      "backward_entropy": 0.019774493243959215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.68838882446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04535042122006416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965456247329712,
      "backward_entropy": 0.019796788692474365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.18833923339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045400235801935196,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0796546459197998,
      "backward_entropy": 0.019816560877694026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.656673431396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045451097190380096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07965416312217713,
      "backward_entropy": 0.004840383927027385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.217008590698242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04550480097532272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965253591537476,
      "backward_entropy": 0.019862832294570074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.008949279785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045557595789432526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07965120673179626,
      "backward_entropy": 0.0047873444855213165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.37318420410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045614298433065414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0796483039855957,
      "backward_entropy": 0.004760631670554479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.54697036743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04567239433526993,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07964473962783813,
      "backward_entropy": 0.0047357165151172215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.34231185913086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045730408281087875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07964105010032654,
      "backward_entropy": 0.01993254820505778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.421517372131348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045791711658239365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07963614463806153,
      "backward_entropy": 0.004685407297478782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.103328704833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0458490215241909,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07963266372680664,
      "backward_entropy": 0.0199602958228853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.82569694519043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04590645059943199,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07962903380393982,
      "backward_entropy": 0.004633556637499068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.24300765991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04596194252371788,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0796259582042694,
      "backward_entropy": 0.020001449518733554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.718116760253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04601409286260605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07962414026260375,
      "backward_entropy": 0.004588834113544888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.099836349487305,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04606660082936287,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.079622083902359,
      "backward_entropy": 0.07692103253470527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.511934280395508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04611837863922119,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0796202540397644,
      "backward_entropy": 0.02006078428692288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.323726654052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04616876691579819,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07961875200271606,
      "backward_entropy": 0.02008818917804294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.24980926513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046219877898693085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07961690425872803,
      "backward_entropy": 0.02011651297410329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.3006591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046277184039354324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07961257100105286,
      "backward_entropy": 0.004480205476284027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.858590126037598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04633215814828873,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07960906624794006,
      "backward_entropy": 0.0044595715072419904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.465003967285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04638397693634033,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07960668802261353,
      "backward_entropy": 0.004439229352606667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.97340393066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046435244381427765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0796044111251831,
      "backward_entropy": 0.02021840214729309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.718250274658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04648829251527786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07960128784179688,
      "backward_entropy": 0.004400616304741966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.924720764160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04653806611895561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07959939241409301,
      "backward_entropy": 0.020267425311936274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.06275177001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04659092053771019,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07959628105163574,
      "backward_entropy": 0.004359531733724806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.553465843200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04664298892021179,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07959330081939697,
      "backward_entropy": 0.020315213335884943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.5789794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04669201001524925,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07959147095680237,
      "backward_entropy": 0.004318956285715103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.75901985168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046745263040065765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07958782911300659,
      "backward_entropy": 0.02035838199986352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.3900728225708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04679762199521065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07958444356918334,
      "backward_entropy": 0.020378609498341877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.5640811920166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04684703052043915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07958214282989502,
      "backward_entropy": 0.0042595648103290135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.45094108581543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04689574986696243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07958003878593445,
      "backward_entropy": 0.02041168510913849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.347156524658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04694420099258423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07957793474197387,
      "backward_entropy": 0.0042171325120661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.264909744262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046992577612400055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07957572340965272,
      "backward_entropy": 0.004199039191007614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.172863006591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04704054445028305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0795735239982605,
      "backward_entropy": 0.004180629634194904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.06231117248535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047089461237192154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07957084774971009,
      "backward_entropy": 0.02050418158372243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.966733932495117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04713894799351692,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07956784963607788,
      "backward_entropy": 0.004145585414436128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.86705207824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04718807712197304,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07956482172012329,
      "backward_entropy": 0.02055072784423828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.768268585205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047236934304237366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07956181168556213,
      "backward_entropy": 0.004112451440758175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.46328353881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047285594046115875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07955870032310486,
      "backward_entropy": 0.00409814715385437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.848944664001465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047336090356111526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07955475449562073,
      "backward_entropy": 0.02064535187350379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.172813415527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04738361015915871,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07955195903778076,
      "backward_entropy": 0.02067072523964776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.383913040161133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04743306338787079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07954821586608887,
      "backward_entropy": 0.004051082250144746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.487762451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04748208448290825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0795445442199707,
      "backward_entropy": 0.00403525142206086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.185771942138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0475296825170517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07954130172729493,
      "backward_entropy": 0.004020298520723979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.845001220703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047577232122421265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07953797578811646,
      "backward_entropy": 0.020789871613184612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.002559661865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04762571305036545,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07953410148620606,
      "backward_entropy": 0.020830608076519437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.609468460083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0476737916469574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07953028678894043,
      "backward_entropy": 0.020869397454791598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.495145797729492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04772263392806053,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0795259952545166,
      "backward_entropy": 0.02090694506963094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.672428131103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04777190461754799,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07952144145965576,
      "backward_entropy": 0.020935739080111187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.982746124267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04782415181398392,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07951546907424926,
      "backward_entropy": 0.020969311396280926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.71385955810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0478743314743042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07951022386550903,
      "backward_entropy": 0.02099623613887363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.245742797851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04792625829577446,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07950417399406433,
      "backward_entropy": 0.021027551756964788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.41313171386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047975216060876846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0794992208480835,
      "backward_entropy": 0.003900838808880912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.613929271697998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04802606999874115,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07949329614639282,
      "backward_entropy": 0.0038887783885002136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.60246467590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04807298630475998,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07948898077011109,
      "backward_entropy": 0.0038763412998782266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.016984939575195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04811863973736763,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07948507070541382,
      "backward_entropy": 0.021165008346239727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.538245677947998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04816436022520065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07948099374771118,
      "backward_entropy": 0.0038544212778409324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.520739555358887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04820683225989342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07947819232940674,
      "backward_entropy": 0.0038452164994345773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.922966957092285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048246148973703384,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0794766902923584,
      "backward_entropy": 0.0038349765042463937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.290367126464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04828373342752457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07947582602500916,
      "backward_entropy": 0.0038241147994995117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.61943244934082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04832082614302635,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07947508096694947,
      "backward_entropy": 0.0038125448756747777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.54576301574707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048358671367168427,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07947386503219604,
      "backward_entropy": 0.021411346064673528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.818397521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04839710518717766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07947223782539367,
      "backward_entropy": 0.0037902088628874887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.05638885498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048437170684337616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07946975827217102,
      "backward_entropy": 0.0037789717316627502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.23992156982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04847666621208191,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07946741580963135,
      "backward_entropy": 0.003768614182869593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.353227615356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04851996898651123,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0794632077217102,
      "backward_entropy": 0.021562973658243816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.140228271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04856020212173462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07946024537086487,
      "backward_entropy": 0.021607062882847257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.814200401306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048601020127534866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07945688962936401,
      "backward_entropy": 0.02165642215145959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.985374450683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04864100366830826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07945380210876465,
      "backward_entropy": 0.0037353113293647766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.690587997436523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048681288957595825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07945040464401246,
      "backward_entropy": 0.0037262580460972255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.590084075927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048720989376306534,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07944715023040771,
      "backward_entropy": 0.0037182263202137416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.07837677001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048765432089567184,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07944166660308838,
      "backward_entropy": 0.02183042301072015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.499505043029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04881182312965393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07943515777587891,
      "backward_entropy": 0.021868344810273912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.677947998046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04885676130652428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07942918539047242,
      "backward_entropy": 0.021901870767275494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.463340759277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048902735114097595,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07942254543304443,
      "backward_entropy": 0.02193779746691386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.45263671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04894845932722092,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07941591739654541,
      "backward_entropy": 0.02197279863887363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.335538864135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048994965851306915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07940878868103027,
      "backward_entropy": 0.003663640883233812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.251256942749023,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049042247235774994,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07940112352371216,
      "backward_entropy": 0.0769745839966668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.09630584716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04909126088023186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07939255237579346,
      "backward_entropy": 0.02207049893008338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.95722198486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04914074391126633,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07938361167907715,
      "backward_entropy": 0.022101236714257136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.007040023803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919171705842018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0793737530708313,
      "backward_entropy": 0.0036263345844215816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.85598087310791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923886060714722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07936558127403259,
      "backward_entropy": 0.0036180520223246682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.530223846435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049284592270851135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07935792207717896,
      "backward_entropy": 0.022202604346805148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.718392372131348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04933204874396324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07934926152229309,
      "backward_entropy": 0.0036007285945945317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.513986587524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04937790706753731,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07934128046035767,
      "backward_entropy": 0.0035906189845667947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.64752960205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04942357540130615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07933316230773926,
      "backward_entropy": 0.02228811548815833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.96318817138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049474213272333145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07932257056236267,
      "backward_entropy": 0.022317234012815688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.01288414001465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04952612146735191,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07931121587753295,
      "backward_entropy": 0.022344781292809382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.34872055053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049578238278627396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0792995810508728,
      "backward_entropy": 0.02237499091360304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.50434112548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049628306180238724,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07928873896598816,
      "backward_entropy": 0.022402885887357924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.760311603546143,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04967963322997093,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07927716970443725,
      "backward_entropy": 0.07698121998045179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.126204490661621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049726929515600204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07926738262176514,
      "backward_entropy": 0.02245247695181105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.728715896606445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049772609025239944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07925825119018555,
      "backward_entropy": 0.00351720800002416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.636289596557617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04981795325875282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.079249107837677,
      "backward_entropy": 0.0035072664419809976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.66691255569458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049863193184137344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07923985719680786,
      "backward_entropy": 0.022525275746981304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.676851272583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04990497604012489,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07923220992088317,
      "backward_entropy": 0.02255229651927948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.96240997314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994902387261391,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07922321557998657,
      "backward_entropy": 0.0034829945200019414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.161330223083496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04999392107129097,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07921364307403564,
      "backward_entropy": 0.022615989049275715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.662362098693848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05003666877746582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07920496463775635,
      "backward_entropy": 0.022653571433491178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.5994291305542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050078291445970535,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07919675707817078,
      "backward_entropy": 0.0226889881822798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.04743194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05011902377009392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0791887879371643,
      "backward_entropy": 0.0034573833561605876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.43290901184082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016395449638367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07917855978012085,
      "backward_entropy": 0.0034513953659269544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.775678634643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05020947381854057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07916784286499023,
      "backward_entropy": 0.0034443108985821405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.63774299621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05025671049952507,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07915604710578919,
      "backward_entropy": 0.022824645042419434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.262598037719727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05030519887804985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0791434407234192,
      "backward_entropy": 0.02284720540046692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.192549705505371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05035192519426346,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0791316032409668,
      "backward_entropy": 0.003420156944129202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.123819351196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05039706453680992,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07912042737007141,
      "backward_entropy": 0.022887991534339056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.40097427368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05044092237949371,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07910972833633423,
      "backward_entropy": 0.022911962535646226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673163414001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050484586507081985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07909898161888122,
      "backward_entropy": 0.0033952806972795064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.53278350830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050525929778814316,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07908931970596314,
      "backward_entropy": 0.0033872011635038587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.427833557128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05056825280189514,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07907896041870117,
      "backward_entropy": 0.07698655128479004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.3199405670166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05061138793826103,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07906799912452697,
      "backward_entropy": 0.003370394309361776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.973939895629883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050655338913202286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07905635833740235,
      "backward_entropy": 0.023024342126316495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.316558837890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05069908872246742,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07904468178749084,
      "backward_entropy": 0.0033544310265117222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.604308128356934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05074455961585045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07903188467025757,
      "backward_entropy": 0.0033469870686531067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.538751602172852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05078867822885513,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07901965975761413,
      "backward_entropy": 0.023099137677086726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.773366928100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05083151534199715,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07900794744491577,
      "backward_entropy": 0.0033339764922857285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.5375919342041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050875239074230194,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07899556756019592,
      "backward_entropy": 0.023158383038308885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.558263778686523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05091877281665802,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07898308634757996,
      "backward_entropy": 0.023192269934548274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.195735931396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05096304789185524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07896999120712281,
      "backward_entropy": 0.023226080669297114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.474267959594727,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05100485309958458,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07895820140838623,
      "backward_entropy": 0.07698923349380493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.151522636413574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05104947090148926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07894456386566162,
      "backward_entropy": 0.02328147490819295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.045846939086914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05109269171953201,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07893154621124268,
      "backward_entropy": 0.07698975006739299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.028264999389648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05113261938095093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07892031669616699,
      "backward_entropy": 0.023333056105507746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.951891899108887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05117147043347359,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07890955209732056,
      "backward_entropy": 0.003285553513301743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.762632369995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05121047794818878,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07889852523803711,
      "backward_entropy": 0.0032784471081362832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.791024208068848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05125254765152931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07888549566268921,
      "backward_entropy": 0.003271576844983631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.786744117736816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051294442266225815,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07887240052223206,
      "backward_entropy": 0.0032650079164240095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.330873489379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05133518576622009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07885979413986206,
      "backward_entropy": 0.0032585437099138894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022320624440908432,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05137864872813225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0788453459739685,
      "backward_entropy": 0.0032511924703915915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.323518753051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05141790583729744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07883333563804626,
      "backward_entropy": 0.003244405819310082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.542991638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051458120346069336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07882053852081299,
      "backward_entropy": 0.003237279959850841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.126850128173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05149735510349274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07880819439888001,
      "backward_entropy": 0.02352626125017802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.828514099121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051537640392780304,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07879500389099121,
      "backward_entropy": 0.02354858650101556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.703571319580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05157976225018501,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07878045439720154,
      "backward_entropy": 0.0032176762405369016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.091541290283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051623500883579254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07876468896865844,
      "backward_entropy": 0.0032108918660216862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.6983642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051670629531145096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07874663472175598,
      "backward_entropy": 0.023606661293241713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.581571578979492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051717955619096756,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07872824668884278,
      "backward_entropy": 0.023625171846813627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39775276184082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051765501499176025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07870948314666748,
      "backward_entropy": 0.003191305117474662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.687372207641602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051810380071401596,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07869222164154052,
      "backward_entropy": 0.023670287595854864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.89048957824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051854781806468964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07867509126663208,
      "backward_entropy": 0.02369788123501672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.264743328094482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05190054699778557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07865684032440186,
      "backward_entropy": 0.023724421858787537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.22248649597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05194373428821564,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0786400556564331,
      "backward_entropy": 0.02375093102455139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.182105541229248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05198466777801514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07862461805343628,
      "backward_entropy": 0.0237800313366784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.958961486816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052023421972990036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07861044406890869,
      "backward_entropy": 0.003161577300892936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.27410125732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052065007388591766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0785941481590271,
      "backward_entropy": 0.0031565270490116542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.104281425476074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05210817605257034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07857655286788941,
      "backward_entropy": 0.0031514016704426873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.520060539245605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05215086042881012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0785590648651123,
      "backward_entropy": 0.0031460819558964837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.420536041259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05219219624996185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07854231595993041,
      "backward_entropy": 0.003140933190782865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.857870101928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052234113216400146,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07852489948272705,
      "backward_entropy": 0.023924440145492554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.656455993652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05227562040090561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07850754857063294,
      "backward_entropy": 0.023943909340434603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.94927978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05231863632798195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07848894596099854,
      "backward_entropy": 0.02396244804064433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.79401397705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052364006638526917,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0784684181213379,
      "backward_entropy": 0.003117768300904168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.763966083526611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052411407232284546,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07844622135162353,
      "backward_entropy": 0.02400219440460205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.072075843811035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05245603993535042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07842579483985901,
      "backward_entropy": 0.003106761309835646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.995567321777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05249902233481407,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07840635180473328,
      "backward_entropy": 0.024042184154192608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.86537742614746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05254605785012245,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07838376760482788,
      "backward_entropy": 0.024059818850623235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.87113094329834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052594058215618134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07836019396781921,
      "backward_entropy": 0.024079951975080702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.066324234008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05264022946357727,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07833770513534546,
      "backward_entropy": 0.0030855368822813034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.700672149658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05268555507063866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07831564545631409,
      "backward_entropy": 0.024130786458651226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.105323791503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05273275449872017,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0782918930053711,
      "backward_entropy": 0.0030764544175730813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.796407699584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05277986079454422,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07826789617538452,
      "backward_entropy": 0.024174385600619845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.707403182983398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05282597616314888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07824442386627198,
      "backward_entropy": 0.0030665803286764356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.468741416931152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287119001150131,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0782213568687439,
      "backward_entropy": 0.0030616362475686604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1453957557678223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05291460454463959,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07819943428039551,
      "backward_entropy": 0.024235972099834018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.570670127868652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05295464023947716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07817991375923157,
      "backward_entropy": 0.024254666434393987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.56450080871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05299530178308487,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0781596839427948,
      "backward_entropy": 0.024276087681452434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.300005912780762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05303739756345749,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07813800573348999,
      "backward_entropy": 0.02429859505759345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.32359504699707,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05307886004447937,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07811659574508667,
      "backward_entropy": 0.07699541250864665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.076298713684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05312160775065422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07809385061264038,
      "backward_entropy": 0.003030687156650755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.026283025741577,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05316191166639328,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07807289361953736,
      "backward_entropy": 0.003025215119123459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.9898681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053199220448732376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07805420756340027,
      "backward_entropy": 0.0030203182250261307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.89450740814209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0532364696264267,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07803529500961304,
      "backward_entropy": 0.003015749156475067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.761709213256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05327446013689041,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07801551818847656,
      "backward_entropy": 0.003010928009947141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.77066707611084,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053313978016376495,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07799421548843384,
      "backward_entropy": 0.07699543899959987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.774612426757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05335323512554169,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0779728651046753,
      "backward_entropy": 0.02445931401517656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.525458335876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053391214460134506,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07795237898826599,
      "backward_entropy": 0.024479069643550448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.433208465576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05342990905046463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07793103456497193,
      "backward_entropy": 0.0029918814284933936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.800373077392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0534692145884037,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07790893316268921,
      "backward_entropy": 0.024523691998587713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547282218933105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053512439131736755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07788293361663819,
      "backward_entropy": 0.02454294264316559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.787382125854492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053554050624370575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07785775661468505,
      "backward_entropy": 0.02456297642654843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.229292869567871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053597670048475266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07783038020133973,
      "backward_entropy": 0.024583313200208876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.931916236877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05364040657877922,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07780328392982483,
      "backward_entropy": 0.024601024058130052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.830484390258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05368325114250183,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07777574062347412,
      "backward_entropy": 0.02461863226360745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.499030590057373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053726281970739365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07774765491485595,
      "backward_entropy": 0.02463986145125495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.184415817260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05376683920621872,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07772163152694703,
      "backward_entropy": 0.024662310878435772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.539337158203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05380599945783615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07769653797149659,
      "backward_entropy": 0.0029510046458906597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.446249961853027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05384553596377373,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07767075300216675,
      "backward_entropy": 0.024704951379034255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.683680534362793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053885478526353836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07764426469802857,
      "backward_entropy": 0.02472584115134345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.609759330749512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053924839943647385,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07761799097061158,
      "backward_entropy": 0.024744053681691486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.428964614868164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05396376922726631,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07759183049201965,
      "backward_entropy": 0.07699803511301677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.681774139404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054004788398742676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07756330966949462,
      "backward_entropy": 0.024783329831229314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.338956832885742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054046764969825745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07753363847732545,
      "backward_entropy": 0.0029230208860503305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.294182777404785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054092131555080414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07750009298324585,
      "backward_entropy": 0.0029181717998451656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.211438179016113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05413636937737465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07746748924255371,
      "backward_entropy": 0.0029132264769739574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.071474075317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054179660975933075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07743549346923828,
      "backward_entropy": 0.002908754265970654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.522934675216675,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05422043800354004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07740586400032043,
      "backward_entropy": 0.002904759719967842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.983802795410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054258108139038086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07737921476364136,
      "backward_entropy": 0.002901138116916021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.914870262145996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05429535359144211,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07735269665718078,
      "backward_entropy": 0.02491857608159383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.846090316772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05433226376771927,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07732623815536499,
      "backward_entropy": 0.024939813547664218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.6615629196167,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05436880886554718,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0772998571395874,
      "backward_entropy": 0.0028885826468467712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.132048606872559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05440666154026985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07727174758911133,
      "backward_entropy": 0.02497650186220805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.449875831604004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05444485694169998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07724289894104004,
      "backward_entropy": 0.02499269445737203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.176003932952881,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05448418855667114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07721255421638488,
      "backward_entropy": 0.025008440017700195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.123440265655518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0545220784842968,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07718345522880554,
      "backward_entropy": 0.02502363423506419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.426445960998535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054558683186769485,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07715550661087037,
      "backward_entropy": 0.02503885825475057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.022920608520508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05459495633840561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07712764739990234,
      "backward_entropy": 0.02505519986152649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.653316020965576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05463019013404846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07710076570510864,
      "backward_entropy": 0.025075635976261564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.23384952545166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05466363579034805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07707566618919373,
      "backward_entropy": 0.025097936391830444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.172125816345215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05469711497426033,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07705029249191284,
      "backward_entropy": 0.02512357963456048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.386276245117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054730501025915146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0770246922969818,
      "backward_entropy": 0.0028433923919995627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.048961639404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476461723446846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07699793577194214,
      "backward_entropy": 0.025170627567503188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7433552742004395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05479857698082924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07697107791900634,
      "backward_entropy": 0.02519297765360938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.384428977966309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054831668734550476,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07694504261016846,
      "backward_entropy": 0.02521767218907674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.650453567504883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054866205900907516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07691696882247925,
      "backward_entropy": 0.002827824196881718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.198561668395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054899685084819794,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07688985466957092,
      "backward_entropy": 0.0028231978002521726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.375149250030518,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0549345426261425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07686076164245606,
      "backward_entropy": 0.002818247303366661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67944622039795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05496758595108986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07683367133140565,
      "backward_entropy": 0.02529047926266988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.619474411010742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055000606924295425,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07680634260177613,
      "backward_entropy": 0.025311200155152216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.422563076019287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05503357946872711,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07677877545356751,
      "backward_entropy": 0.025333940982818604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.501858711242676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05506571754813194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07675203084945678,
      "backward_entropy": 0.0028019843416081536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.552084922790527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055097874253988266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07672499418258667,
      "backward_entropy": 0.02538413968351152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.571549415588379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055130764842033386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07669668793678283,
      "backward_entropy": 0.025408963362375896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.479262351989746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05516504496335983,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0766663134098053,
      "backward_entropy": 0.025431262122260198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.072676658630371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05520063638687134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0766339659690857,
      "backward_entropy": 0.025454329119788274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.104945659637451,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05523356795310974,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07660486698150634,
      "backward_entropy": 0.07700040605333117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.177605628967285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055264756083488464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07657777070999146,
      "backward_entropy": 0.025500885314411588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.125405311584473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05529669672250748,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07654937505722045,
      "backward_entropy": 0.0027762092649936676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.027445793151855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0553300715982914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07651874423027039,
      "backward_entropy": 0.025539603498246934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.988985300064087,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05536327138543129,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07648811340332032,
      "backward_entropy": 0.07700030008951823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.936387538909912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055394720286130905,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07645959854125976,
      "backward_entropy": 0.025580207506815594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.895847797393799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05542533099651337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07643193006515503,
      "backward_entropy": 0.002758970691098107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.75288200378418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055455297231674194,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07640485763549805,
      "backward_entropy": 0.025620328055487737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.489709854125977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05548607558012009,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0763763964176178,
      "backward_entropy": 0.02564073105653127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.449911117553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05551985651254654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07634350657463074,
      "backward_entropy": 0.0027467929240730074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.818495035171509,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055555567145347595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07630766630172729,
      "backward_entropy": 0.0027426988300349978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.677762031555176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05558938533067703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07627415060997009,
      "backward_entropy": 0.02570484247472551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.00931167602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05562214553356171,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07624191045761108,
      "backward_entropy": 0.025728689299689397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.3064546585083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05565761402249336,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07620550990104676,
      "backward_entropy": 0.025750577449798584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.540865421295166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055693235248327255,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07616851925849914,
      "backward_entropy": 0.02576901184187995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.981736183166504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055727556347846985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07613310813903809,
      "backward_entropy": 0.0027240607887506485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.0756254196167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05576286092400551,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07609589099884033,
      "backward_entropy": 0.02580149968465169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.795662879943848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05579829961061478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07605817317962646,
      "backward_entropy": 0.00271409149799082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009955523535609245,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0558345764875412,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07601879239082336,
      "backward_entropy": 0.025823987192577787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.777479648590088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05586740002036095,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0759844183921814,
      "backward_entropy": 0.025839837061034307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5183892250061035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05589784309267998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0759534239768982,
      "backward_entropy": 0.025861144065856934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4935781955718994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05592675134539604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07592437863349914,
      "backward_entropy": 0.02588278717464871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.929912090301514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055954329669475555,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07589705586433411,
      "backward_entropy": 0.02590658598475986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.882450580596924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05598205700516701,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07586932182312012,
      "backward_entropy": 0.025928598311212327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.659677505493164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056009985506534576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07584093809127808,
      "backward_entropy": 0.025952120621999104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7022652626037598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056040920317173004,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07580761909484864,
      "backward_entropy": 0.025975447562005784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.732637405395508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056069515645504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07577766180038452,
      "backward_entropy": 0.025997315843900044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.683456897735596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05609821900725365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07574731111526489,
      "backward_entropy": 0.02602140439881219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.97841739654541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056126877665519714,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07571671009063721,
      "backward_entropy": 0.026041593816545274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.942612171173096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056154947727918625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0756867527961731,
      "backward_entropy": 0.0026678058008352914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.540372848510742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05618247762322426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07565741539001465,
      "backward_entropy": 0.02609273460176256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.493612766265869,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05621013045310974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.075627601146698,
      "backward_entropy": 0.026118896073765226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2278571128845215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05623786523938179,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07559729814529419,
      "backward_entropy": 0.02614327271779378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6071395874023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05626433342695236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07556891441345215,
      "backward_entropy": 0.002655604233344396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.772860050201416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05628887936472893,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07554340958595276,
      "backward_entropy": 0.02619305087460412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.320173740386963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056313131004571915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07551819086074829,
      "backward_entropy": 0.026216891076829698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.981377601623535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056337788701057434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07549198865890502,
      "backward_entropy": 0.026240103774600558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.120887041091919,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056364819407463074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07546156644821167,
      "backward_entropy": 0.0026413272652361128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.280582427978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05639072135090828,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07543274164199829,
      "backward_entropy": 0.002638265076610777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.74551010131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056418225169181824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0754010558128357,
      "backward_entropy": 0.026310513416926067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.094327926635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056447867304086685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07536521553993225,
      "backward_entropy": 0.026336610317230225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.045143127441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056477319449186325,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07532955408096313,
      "backward_entropy": 0.07700032658047146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.505353569984436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05650659278035164,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07529386281967163,
      "backward_entropy": 0.0263827426566018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.493986964225769,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056533657014369965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07526181936264038,
      "backward_entropy": 0.0026220656517479154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.909664630889893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05655880272388458,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07523283958435059,
      "backward_entropy": 0.0026186611503362656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9379594326019287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056584153324365616,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07520334124565124,
      "backward_entropy": 0.026446499758296542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9178740978240967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05660832300782204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07517558336257935,
      "backward_entropy": 0.02646415928999583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.34389066696167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05663144215941429,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07514953017234802,
      "backward_entropy": 0.026480519109302096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.187394618988037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056654393672943115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07512348890304565,
      "backward_entropy": 0.02650036911169688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.859842538833618,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056678447872400284,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07509515881538391,
      "backward_entropy": 0.026520457532670762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.257426738739014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05670150741934776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07506852149963379,
      "backward_entropy": 0.002594903732339541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.636608600616455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056724317371845245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07504202127456665,
      "backward_entropy": 0.002591265779402521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.200740814208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05674753338098526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07501454949378968,
      "backward_entropy": 0.02658160361978743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.560962200164795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056770507246255875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0749872088432312,
      "backward_entropy": 0.00258379222618209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3863943815231323,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056793857365846634,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0749589443206787,
      "backward_entropy": 0.026621444357766047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.747396230697632,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056815531104803085,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0749336838722229,
      "backward_entropy": 0.07699841923183864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.091827869415283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056836389005184174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07490962147712707,
      "backward_entropy": 0.02665381630261739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7133219242095947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056857138872146606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07488560676574707,
      "backward_entropy": 0.02666757173008389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.041849136352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05687717720866203,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07486268877983093,
      "backward_entropy": 0.02668192485968272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6806013584136963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05689721181988716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0748395562171936,
      "backward_entropy": 0.026696450180477567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6648101806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05691662058234215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07481739521026612,
      "backward_entropy": 0.002553212973806593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.292182445526123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05693542957305908,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07479627132415771,
      "backward_entropy": 0.026728535691897076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.887341499328613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0569549985229969,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07477341890335083,
      "backward_entropy": 0.002544709170858065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.920886754989624,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05697651952505112,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0747465193271637,
      "backward_entropy": 0.0025403497533665765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1910786628723145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05699790641665459,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07471967935562134,
      "backward_entropy": 0.02677516804801093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.155728816986084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05701984465122223,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07469146251678467,
      "backward_entropy": 0.026793950133853488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.39805793762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05704222619533539,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0746622085571289,
      "backward_entropy": 0.026813073290718928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2754329442977905,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05706559494137764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07463075518608094,
      "backward_entropy": 0.02683043148782518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.088370323181152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05708732455968857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07460235357284546,
      "backward_entropy": 0.0025214097566074794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7574470043182373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05711199343204498,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07456781864166259,
      "backward_entropy": 0.026863397823439703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4877471923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05713606998324394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07453420758247375,
      "backward_entropy": 0.002512796264555719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.932398796081543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05715898796916008,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07450276613235474,
      "backward_entropy": 0.026884327332178753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.895320892333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05718214437365532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07447055578231812,
      "backward_entropy": 0.02689243687523736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.857861518859863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05720556154847145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0744375467300415,
      "backward_entropy": 0.0024979066931539113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4131791591644287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057229187339544296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07440384626388549,
      "backward_entropy": 0.026911636193593342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.784328937530518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057251736521720886,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0743721604347229,
      "backward_entropy": 0.0269216216272778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3772778511047363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05727458372712135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07433958053588867,
      "backward_entropy": 0.026932610405815974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.890334606170654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0572965070605278,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07430880069732666,
      "backward_entropy": 0.026947119169765048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.013214588165283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057319384068250656,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07427566051483155,
      "backward_entropy": 0.02696162462234497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.48098087310791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057343751192092896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07423917651176452,
      "backward_entropy": 0.02697689996825324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.601777076721191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05736760422587395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07420353293418884,
      "backward_entropy": 0.026993175347646076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.564508438110352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05739154294133186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0741674244403839,
      "backward_entropy": 0.0024642900874217353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.657073020935059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057415612041950226,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07413074374198914,
      "backward_entropy": 0.02702352735731337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2474162578582764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057440344244241714,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07409241795539856,
      "backward_entropy": 0.02703778280152215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.340384006500244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057463936507701874,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07405637502670288,
      "backward_entropy": 0.027055442333221436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.313886880874634,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057487014681100845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0740210771560669,
      "backward_entropy": 0.0024495824343628353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0998417139053345,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05750971660017967,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07398643493652343,
      "backward_entropy": 0.027091708448198106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2633004188537598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05753080174326897,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07395514845848083,
      "backward_entropy": 0.002443213222755326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0839093923568726,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05755161866545677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07392414808273315,
      "backward_entropy": 0.027129285865359835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.146681785583496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057571060955524445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07389609217643738,
      "backward_entropy": 0.02715030974811978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.259307384490967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05758974328637123,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07386953830718994,
      "backward_entropy": 0.027168042129940458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.286132335662842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057608965784311295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07384148836135865,
      "backward_entropy": 0.027184411883354187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1509063243865967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05762924998998642,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07381072640419006,
      "backward_entropy": 0.027198897467719182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1687846183776855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05764935165643692,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07378023862838745,
      "backward_entropy": 0.027214811907874212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.203666687011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057669878005981445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07374846935272217,
      "backward_entropy": 0.02723215685950385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0797417163848877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05769193544983864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07371317148208618,
      "backward_entropy": 0.002415454015135765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.088253974914551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05771363154053688,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07367823123931885,
      "backward_entropy": 0.027269413073857624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.029759168624878,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057736191898584366,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07364116311073303,
      "backward_entropy": 0.02729136413998074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0051209926605225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05775829777121544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07360494136810303,
      "backward_entropy": 0.027312818500730727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9973064064979553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057780079543590546,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07356922626495362,
      "backward_entropy": 0.027338350812594097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9424757957458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05780032277107239,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07353686094284058,
      "backward_entropy": 0.027363416221406724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0055837794207036495,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05782094970345497,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07350336909294128,
      "backward_entropy": 0.027389700214068096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.884657859802246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05783959478139877,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07347443103790283,
      "backward_entropy": 0.02741659681002299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.89384388923645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0578586719930172,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07344424724578857,
      "backward_entropy": 0.02744000322288937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8288466930389404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05787760391831398,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07341418266296387,
      "backward_entropy": 0.02746234503057268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.749183177947998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057896941900253296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07338294386863708,
      "backward_entropy": 0.0023904904309246275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9466990828514099,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057917241007089615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07334898710250855,
      "backward_entropy": 0.02750163111421797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9397630095481873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05793612450361252,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07331844568252563,
      "backward_entropy": 0.0023843494968281854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7893311977386475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05795373395085335,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07329080104827881,
      "backward_entropy": 0.027539506554603577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7700998783111572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0579712837934494,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07326307296752929,
      "backward_entropy": 0.027556121349334717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7509281635284424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05798880383372307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07323517799377441,
      "backward_entropy": 0.027572191423839994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5496134757995605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05800632759928703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0732070803642273,
      "backward_entropy": 0.027589345971743267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7115352153778076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05802500247955322,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07317599654197693,
      "backward_entropy": 0.027609181072976854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.482372760772705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05804358422756195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07314481735229492,
      "backward_entropy": 0.027631037765079074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8934987783432007,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05806317925453186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07311084270477294,
      "backward_entropy": 0.027654157744513616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.296459674835205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05808141455054283,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07308014631271362,
      "backward_entropy": 0.02767646312713623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.629495620727539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058101192116737366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07304538488388061,
      "backward_entropy": 0.0023578117705053752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4763681888580322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05812069773674011,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07301094532012939,
      "backward_entropy": 0.027719454632865057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.308966636657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058140531182289124,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07297553420066834,
      "backward_entropy": 0.027741905715730455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4188318252563477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058161165565252304,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07293778657913208,
      "backward_entropy": 0.0023502823379304674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.38934326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058181941509246826,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07289947271347046,
      "backward_entropy": 0.027782165341907077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.198126792907715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05820280686020851,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07286067008972168,
      "backward_entropy": 0.002344058412644598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4979753494262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05822435021400452,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07281990051269531,
      "backward_entropy": 0.0278140041563246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6521800756454468,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05824539065361023,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07278015613555908,
      "backward_entropy": 0.027829103999667697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.637844443321228,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05826539918780327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07274293899536133,
      "backward_entropy": 0.02784161104096307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.673104763031006,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05828455090522766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07270779013633728,
      "backward_entropy": 0.0023300742937458884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6096211671829224,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05830554664134979,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07266746759414673,
      "backward_entropy": 0.02786842319700453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1862566471099854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05832556262612343,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07262960076332092,
      "backward_entropy": 0.027882185247209337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5815269947052002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05834574997425079,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07259101867675781,
      "backward_entropy": 0.027896341350343492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3499767780303955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05836501717567444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07255464792251587,
      "backward_entropy": 0.0023156344476673338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5549933910369873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05838384851813316,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07251929044723511,
      "backward_entropy": 0.002311220806505945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0798561573028564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05840186029672623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07248595952987671,
      "backward_entropy": 0.027926166852315266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2919044494628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05842018499970436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07245163917541504,
      "backward_entropy": 0.0023021685580412545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2730796337127686,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058438319712877274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07241754531860352,
      "backward_entropy": 0.02794264753659566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7547292113304138,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05845627933740616,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07238377332687378,
      "backward_entropy": 0.02795443932215373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4931278228759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05847301706671715,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07235318422317505,
      "backward_entropy": 0.027967247698042128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.436931610107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058489199727773666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07232394218444824,
      "backward_entropy": 0.027982360786861844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9354517459869385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058506887406110764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0722903072834015,
      "backward_entropy": 0.002283687392870585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7312583327293396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05852489918470383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07225551605224609,
      "backward_entropy": 0.02801241808467441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.888303518295288,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0585416778922081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07222397923469544,
      "backward_entropy": 0.0022769692457384532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.440656661987305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05855884030461311,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07219121456146241,
      "backward_entropy": 0.028041687276628282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.54634690284729,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05857891961932182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0721498966217041,
      "backward_entropy": 0.0022701817668146556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8102028369903564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0585995689034462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07210671901702881,
      "backward_entropy": 0.02807075447506375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.865949630737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05862024053931236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07206323742866516,
      "backward_entropy": 0.028086539771821763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3788142204284668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05864241346716881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07201519012451171,
      "backward_entropy": 0.0022607756157716117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7250754833221436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05866342782974243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07197030782699584,
      "backward_entropy": 0.028120345539516874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6779371500015259,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05868435651063919,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07192543745040894,
      "backward_entropy": 0.0022548215670718085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6717448234558105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05870371311903,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07188482284545898,
      "backward_entropy": 0.002251585324605306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3255233764648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058723174035549164,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0718437373638153,
      "backward_entropy": 0.02816824780570136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9676529169082642,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058741699904203415,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07180528044700622,
      "backward_entropy": 0.0022453578809897103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9498145580291748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058759890496730804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07176761627197266,
      "backward_entropy": 0.028202219141854182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.145201206207275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058777786791324615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07173057794570922,
      "backward_entropy": 0.02822162045372857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.276941180229187,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058797817677259445,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07168682813644409,
      "backward_entropy": 0.07698983616299099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5244386196136475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058816809207201004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07164608240127564,
      "backward_entropy": 0.0022325519886281756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8759700059890747,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058835819363594055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07160502672195435,
      "backward_entropy": 0.02827247314982944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7112905979156494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05885440111160278,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0715650737285614,
      "backward_entropy": 0.02828721867667304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6733243465423584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058873992413282394,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07152175903320312,
      "backward_entropy": 0.028300742308298748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8190985918045044,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058894507586956024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07147541046142578,
      "backward_entropy": 0.0022166909443007577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9969916343688965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058914486318826675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0714305281639099,
      "backward_entropy": 0.028332680463790894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5565202236175537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05893486365675926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07138403058052063,
      "backward_entropy": 0.028350770473480225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3455679416656494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058956079185009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07133467197418213,
      "backward_entropy": 0.002206117949552006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7405589818954468,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0589771531522274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07128544449806214,
      "backward_entropy": 0.02839266260464986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8658294677734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05899757146835327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07123799324035644,
      "backward_entropy": 0.028416073984569974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3993799686431885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059018343687057495,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07118914127349854,
      "backward_entropy": 0.02844126025835673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5636153817176819,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05903985723853111,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07113763093948364,
      "backward_entropy": 0.028466499514049955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1108167171478271,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05905978009104729,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07109094858169555,
      "backward_entropy": 0.028494434224234685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.098808765411377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0590786412358284,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07104752063751221,
      "backward_entropy": 0.028520133760240342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.713548183441162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05909664183855057,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07100655436515808,
      "backward_entropy": 0.028549353281656902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.613259196281433,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059115130454301834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07096375823020935,
      "backward_entropy": 0.0021850408779250253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.658121347427368,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0591331347823143,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07092232704162597,
      "backward_entropy": 0.028602444463306002,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.012535507841967,
    "avg_log_Z": -0.058163904100656506,
    "success_rate": 1.0,
    "avg_reward": 30.7,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.01,
      "1": 0.73,
      "2": 0.26
    },
    "avg_forward_entropy": 0.07284419512748717,
    "avg_backward_entropy": 0.021575630590733558,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}