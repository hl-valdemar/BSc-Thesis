{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06291166760704735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06295503269542348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.89404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149326880772908,
      "backward_entropy": 0.06290553916584361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.4273681640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914937953154246,
      "backward_entropy": 0.0629071755842729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2902069091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00020004701218567789,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149422248204549,
      "backward_entropy": 0.0629193674434315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.40601348876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00030032260110601783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149460991223653,
      "backward_entropy": 0.06295889074152167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.80137634277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0003981876070611179,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149496754010518,
      "backward_entropy": 0.06291193311864679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.22842407226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004972335300408304,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149523576100667,
      "backward_entropy": 0.06291348283941095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.48235321044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005970510537736118,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149545431137085,
      "backward_entropy": 0.06296279213645241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.74020385742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006924282643012702,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149564305941264,
      "backward_entropy": 0.06293703209270131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.29763793945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007895270246081054,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149575233459473,
      "backward_entropy": 0.06294027783653953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.69967651367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008868296863511205,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149580200513203,
      "backward_entropy": 0.06291929158297452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.81362915039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009854038944467902,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149578213691711,
      "backward_entropy": 0.06292070042003285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.82624053955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010839407332241535,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149570266405742,
      "backward_entropy": 0.0629220659082586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.91714477539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011807454284280539,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149562319119771,
      "backward_entropy": 0.06295244260267778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.62142944335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012802350101992488,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149546424547832,
      "backward_entropy": 0.06297076832164418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.43920135498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013804382178932428,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914952556292216,
      "backward_entropy": 0.06295799125324596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.8492889404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014788344269618392,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149496754010518,
      "backward_entropy": 0.06292723525654186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.27442932128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00157979188952595,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149467945098877,
      "backward_entropy": 0.06292849237268622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.2473907470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016827628714963794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149434169133504,
      "backward_entropy": 0.06292979283766313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.48574829101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017846185946837068,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149392445882161,
      "backward_entropy": 0.06296814571727406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.50965881347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018877286929637194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149345755577087,
      "backward_entropy": 0.0629322041164745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.5369873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019907099194824696,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149295091629028,
      "backward_entropy": 0.06293336369774559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.53135681152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0020921393297612667,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914924144744873,
      "backward_entropy": 0.06297983906485817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.7168426513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002195083536207676,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149178862571716,
      "backward_entropy": 0.06297705390236595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.22088623046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002296893624588847,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149110317230225,
      "backward_entropy": 0.06298176808790727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.64962768554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002398284850642085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914904276529948,
      "backward_entropy": 0.06293748725544322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.55921936035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002501907991245389,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148967266082764,
      "backward_entropy": 0.06298357248306274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.59868621826172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026039897929877043,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148890773455302,
      "backward_entropy": 0.0629845532503995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.13740539550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002703043632209301,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148812294006348,
      "backward_entropy": 0.06298517097126353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.67638397216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002799543086439371,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148731827735901,
      "backward_entropy": 0.06294086846438321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.38516235351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002893914934247732,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148647387822469,
      "backward_entropy": 0.06298643892461603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.34695434570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00298762577585876,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148560961087544,
      "backward_entropy": 0.06294205513867465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.66822814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003085916396230459,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914846658706665,
      "backward_entropy": 0.06298753348263827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.44256591796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003185937413945794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148365259170532,
      "backward_entropy": 0.06294332851063121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2494354248047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00328477518633008,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148259957631429,
      "backward_entropy": 0.06299433924935081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.87452697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003383925650268793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148150682449341,
      "backward_entropy": 0.06298896399411288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.94577026367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034857653081417084,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148033459981282,
      "backward_entropy": 0.06299662590026855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.6473846435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003586284350603819,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147911270459493,
      "backward_entropy": 0.06294534423134544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.9864501953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003690379438921809,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914778212706248,
      "backward_entropy": 0.06294582648710771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.59994506835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00379111897200346,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147650003433228,
      "backward_entropy": 0.06299966031854803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.57293701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038917018100619316,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147514899571736,
      "backward_entropy": 0.06294654716144908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.49415588378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003995866514742374,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147371848424275,
      "backward_entropy": 0.06300140510905873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.09640502929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004096721298992634,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147225817044576,
      "backward_entropy": 0.0629471865567294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.07713317871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004197457805275917,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147072831789653,
      "backward_entropy": 0.06300288980657404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.19264221191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004298089072108269,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146915872891744,
      "backward_entropy": 0.06300357255068692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.92880249023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00440456997603178,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914674699306488,
      "backward_entropy": 0.0629918250170621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.12754821777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0045099020935595036,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146575133005778,
      "backward_entropy": 0.0629481619054621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.95446014404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004614692181348801,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146396319071452,
      "backward_entropy": 0.06299213929609819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.92620849609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004716067109256983,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914621353149414,
      "backward_entropy": 0.0630060000853105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.053955078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004820965230464935,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146020809809367,
      "backward_entropy": 0.0630064769224687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.38467407226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004923432134091854,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914582908153534,
      "backward_entropy": 0.0630068995735862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.01837158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005025255959481001,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145633379618327,
      "backward_entropy": 0.06294846534729004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.13523864746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005124966613948345,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145435690879822,
      "backward_entropy": 0.06294838948683305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.90158081054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005225703585892916,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145234028498332,
      "backward_entropy": 0.06300796161998402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3057403564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005328635685145855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145025412241618,
      "backward_entropy": 0.06294817274267023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.94647216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005430841352790594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144812822341919,
      "backward_entropy": 0.06299184127287431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.16754150390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005530846305191517,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144598245620728,
      "backward_entropy": 0.06300880692221901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.79957580566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005634502042084932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144372741381328,
      "backward_entropy": 0.06299141320315274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.89306640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00573549373075366,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914414922396342,
      "backward_entropy": 0.06294724074277011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.98446655273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005837061908096075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143921732902527,
      "backward_entropy": 0.06299082799391313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.16810607910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0059367078356444836,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914369026819865,
      "backward_entropy": 0.06300964138724587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.03858947753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006042527500540018,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143448869387309,
      "backward_entropy": 0.06300982561978427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.48635864257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006151188164949417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143195549647014,
      "backward_entropy": 0.0629458102312955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.22744750976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006257181521505117,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142937262852986,
      "backward_entropy": 0.06301012906161221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.40576171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006362926680594683,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142676989237468,
      "backward_entropy": 0.06301026452671397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.61476135253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00647138012573123,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142406781514485,
      "backward_entropy": 0.0630103891546076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.60655212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006580931134521961,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142126639684041,
      "backward_entropy": 0.06298805366862904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.51495361328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006690732203423977,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141834576924641,
      "backward_entropy": 0.06301061673597856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.46682739257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006805333774536848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141525626182556,
      "backward_entropy": 0.06298708915710449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.86990356445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0069174678064882755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141214688618977,
      "backward_entropy": 0.06298654729669745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.9764862060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00702908867970109,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140896797180176,
      "backward_entropy": 0.06294073299928145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.5237579345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007145287003368139,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140561024347942,
      "backward_entropy": 0.06293997439471158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.435791015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007263963110744953,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140212337176006,
      "backward_entropy": 0.06293922120874579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.83460998535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007376953959465027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139867623647054,
      "backward_entropy": 0.06293832713907416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.27291870117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007486613001674414,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139519929885864,
      "backward_entropy": 0.0630111585963856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.21653747558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00759667856618762,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139178196589152,
      "backward_entropy": 0.06298264590176669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.7849884033203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007708799559623003,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138814608256023,
      "backward_entropy": 0.06301122361963446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.828369140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007825254462659359,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138419230779012,
      "backward_entropy": 0.0629809715531089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.13099670410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007938876748085022,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138014912605286,
      "backward_entropy": 0.06293309276754205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.16009521484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008054018951952457,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137593706448872,
      "backward_entropy": 0.06301131031729958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.76026916503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008165322244167328,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137162566184998,
      "backward_entropy": 0.06301131031729958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.98001098632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008274287916719913,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136714537938435,
      "backward_entropy": 0.06292931600050493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.11050415039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008384370245039463,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136233727137248,
      "backward_entropy": 0.06297588890249078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.27142333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008493908680975437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135732054710388,
      "backward_entropy": 0.06297479976307262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.83541870117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008609109558165073,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135196606318156,
      "backward_entropy": 0.06297378106550737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4729766845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008725274354219437,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913464625676473,
      "backward_entropy": 0.06301133199171587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.33157348632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00883723609149456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134089946746826,
      "backward_entropy": 0.06297168948433617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.88191986083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008947963826358318,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133525689442952,
      "backward_entropy": 0.06292138316414574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.37188720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009051966480910778,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132967392603557,
      "backward_entropy": 0.0629198442805897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.98043823242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009158501401543617,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09132386247316997,
      "backward_entropy": 0.06301135908473622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.9287872314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009262892417609692,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131800134976704,
      "backward_entropy": 0.0629666881127791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.11045837402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00936813186854124,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131197134653728,
      "backward_entropy": 0.06301135366613214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.12644958496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009469724260270596,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130593140920003,
      "backward_entropy": 0.06301134282892401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.98777770996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009573870338499546,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129965305328369,
      "backward_entropy": 0.06291126663034613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.24681091308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009676342830061913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129326542218526,
      "backward_entropy": 0.0629604621367021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.3777618408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00977973360568285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128671884536743,
      "backward_entropy": 0.06295870650898326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.54298400878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009881395846605301,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09128008286158244,
      "backward_entropy": 0.06290523572401567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.90182495117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009985707700252533,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09127317865689595,
      "backward_entropy": 0.0629549730907787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.51797485351562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010089275427162647,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126617511113484,
      "backward_entropy": 0.06301126154986295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.33968353271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010191576555371284,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912590225537618,
      "backward_entropy": 0.06289883093400435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.23873901367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0102893291041255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912519097328186,
      "backward_entropy": 0.06289643591100519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.57102966308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010385923087596893,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091244637966156,
      "backward_entropy": 0.06289393251592462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.33602905273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010484187863767147,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123714764912923,
      "backward_entropy": 0.06301110441034491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.69225311279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010586410760879517,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912293295065562,
      "backward_entropy": 0.06288903409784491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.68409729003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010683940723538399,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912215809027354,
      "backward_entropy": 0.06293887441808527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.43124389648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010781428776681423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121368328730266,
      "backward_entropy": 0.06293611093000932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.0637969970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010879505425691605,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120553731918335,
      "backward_entropy": 0.0628812692382119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.5808868408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010977357625961304,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119728207588196,
      "backward_entropy": 0.0628787712617354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.78846740722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011078165844082832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118865927060445,
      "backward_entropy": 0.0629273544658314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.97357177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011175950057804585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117986758550008,
      "backward_entropy": 0.06287360733205621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.26486206054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011272543109953403,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117097655932109,
      "backward_entropy": 0.06287081675095992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.94501495361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011369820684194565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09116220474243164,
      "backward_entropy": 0.06286794489080255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01146393921226263,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115347266197205,
      "backward_entropy": 0.06286482377485796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.34486389160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01155876275151968,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09114450216293335,
      "backward_entropy": 0.06286164847287265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.82078552246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01165690179914236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113516410191853,
      "backward_entropy": 0.06285851110111583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.34756469726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011753812432289124,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09112569689750671,
      "backward_entropy": 0.06301023743369362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0084228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011854986660182476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09111582239468892,
      "backward_entropy": 0.06290007721294057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.1031951904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011952950619161129,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09110594789187114,
      "backward_entropy": 0.06284871426495639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.80389404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01205266360193491,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109575549761455,
      "backward_entropy": 0.06284514340487393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.842041015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012151222676038742,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108540415763855,
      "backward_entropy": 0.06284126910296353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.64219665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012249993160367012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09107482433319092,
      "backward_entropy": 0.06288396228443492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.32635498046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012342927046120167,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09106441338857015,
      "backward_entropy": 0.06283284859223799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.4131622314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012436797842383385,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09105372428894043,
      "backward_entropy": 0.06282832405783913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.63906860351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012533959001302719,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09104261795679729,
      "backward_entropy": 0.0628238320350647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.60213470458984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012630227953195572,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09103134274482727,
      "backward_entropy": 0.063009267503565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.6749725341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012722213752567768,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09102015693982442,
      "backward_entropy": 0.06300900741056963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.39289093017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012816354632377625,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09100862344106038,
      "backward_entropy": 0.06280905550176447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.43004608154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012906054966151714,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099709987640381,
      "backward_entropy": 0.0628036152232777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.42974853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01298946887254715,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09098581473032634,
      "backward_entropy": 0.06279773061925714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.32623291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013072142377495766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09097433090209961,
      "backward_entropy": 0.06283605640584772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.99778747558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013155189342796803,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09096260865529378,
      "backward_entropy": 0.06300745768980547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.96072387695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013240259140729904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095048904418945,
      "backward_entropy": 0.06282345815138383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.33778381347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01332714594900608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09093805154164632,
      "backward_entropy": 0.06281714005903764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.16664123535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01341425720602274,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09092513720194499,
      "backward_entropy": 0.06281070817600597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.2677001953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01349369715899229,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09091244141260783,
      "backward_entropy": 0.06300617348064076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.25094604492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013574140146374702,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09089931845664978,
      "backward_entropy": 0.06300578334114769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.76731872558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013656784780323505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09088568886121114,
      "backward_entropy": 0.06278898499228737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.54388427734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013741540722548962,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09087153275807698,
      "backward_entropy": 0.0627392747185447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.93284606933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01383258681744337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09085653225580852,
      "backward_entropy": 0.06273278323086826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.2099609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013929073698818684,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09084074695905049,
      "backward_entropy": 0.06272667104547675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.69586944580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01403119508177042,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09082423647244771,
      "backward_entropy": 0.06272095983678644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.20773315429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014128576032817364,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09080795447031657,
      "backward_entropy": 0.06300498138774525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.49105834960938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014229312539100647,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09079104661941528,
      "backward_entropy": 0.06300501931797374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.55300903320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014331428334116936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09077367186546326,
      "backward_entropy": 0.06274112246253273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.05718994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014435024000704288,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09075574080149333,
      "backward_entropy": 0.06269633769989014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.52106475830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014540061354637146,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09073736270268758,
      "backward_entropy": 0.06269017132845792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.77554321289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01464004348963499,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09071911374727885,
      "backward_entropy": 0.06268337639895352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.73138427734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014738840982317924,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09070058663686116,
      "backward_entropy": 0.06267626719041304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.65264892578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014836577698588371,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09068180123964946,
      "backward_entropy": 0.06300522522492842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.12142944335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014934626407921314,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09066258867581685,
      "backward_entropy": 0.06300516562028365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.58035278320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0150343282148242,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09064280986785889,
      "backward_entropy": 0.06268570639870384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.30535888671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015136854723095894,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09062234560648601,
      "backward_entropy": 0.06300513310865923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.89096069335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015242514200508595,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09060098727544148,
      "backward_entropy": 0.06263836947354404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.33741760253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015347498469054699,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09057895342508952,
      "backward_entropy": 0.06263063712553545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.4026641845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015450494363904,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09055666128794353,
      "backward_entropy": 0.06300522522492842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.01025390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015551969408988953,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09053404132525127,
      "backward_entropy": 0.06261413747614081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.66138458251953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015651289373636246,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0905112624168396,
      "backward_entropy": 0.06300502473657782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.58326721191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015746239572763443,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0904885729153951,
      "backward_entropy": 0.06300477006218651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.27166748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015844378620386124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09046502908070882,
      "backward_entropy": 0.0626029372215271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.59669494628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01594451256096363,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09044071038564046,
      "backward_entropy": 0.06257696585221724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.59213256835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0160432830452919,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09041609366734822,
      "backward_entropy": 0.06256710399280895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.91734313964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01614385098218918,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09039073189099629,
      "backward_entropy": 0.06300409273667769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.44105529785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01624133624136448,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09036535024642944,
      "backward_entropy": 0.06254664334383878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.06964111328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01633772999048233,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0903396209081014,
      "backward_entropy": 0.06300359422510321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.77853393554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016435066238045692,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09031324585278828,
      "backward_entropy": 0.06252485513687134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 301.0366516113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016531195491552353,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0902865727742513,
      "backward_entropy": 0.06251337311484596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.64688110351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01663888618350029,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09025772412618001,
      "backward_entropy": 0.06250333786010742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.28359985351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016748681664466858,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09022802114486694,
      "backward_entropy": 0.06247942014174028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.17054748535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016856307163834572,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09019813934961955,
      "backward_entropy": 0.06248255209489302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.05226135253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016966400668025017,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09016728401184082,
      "backward_entropy": 0.06247187744487415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.61109924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017074018716812134,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09013628959655762,
      "backward_entropy": 0.06246040084145286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9716339111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017176499590277672,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09010565280914307,
      "backward_entropy": 0.06300320408561012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.87892150878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017275763675570488,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09007503588994344,
      "backward_entropy": 0.062434174797751686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.17100524902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017373662441968918,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09004410107930501,
      "backward_entropy": 0.0630025484345176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.439208984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017473211511969566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0900123119354248,
      "backward_entropy": 0.062365797432986175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.76007080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017577029764652252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08997919162114461,
      "backward_entropy": 0.06239127029072155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.52630615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017680760473012924,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08994547526041667,
      "backward_entropy": 0.06237653168764981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.58079528808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017782388255000114,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08991159001986186,
      "backward_entropy": 0.06300128589976918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.22863006591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017882391810417175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08987743655840556,
      "backward_entropy": 0.06228640946474942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.32890319824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017978010699152946,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08984357118606567,
      "backward_entropy": 0.06232725490223278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.95950317382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018065933138132095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08981072902679443,
      "backward_entropy": 0.06223883412101052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.20172882080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018153773620724678,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08977731068929036,
      "backward_entropy": 0.062213745984164154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.07102966308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018238727003335953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08974391222000122,
      "backward_entropy": 0.06218753077767112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.99067687988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018325043842196465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08970964948336284,
      "backward_entropy": 0.06216046485033902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.61561584472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018408359959721565,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08967522780100505,
      "backward_entropy": 0.06213187087665905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.5477294921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01849362440407276,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08963959415753682,
      "backward_entropy": 0.06220472942699085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.60293579101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01857883855700493,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08960328499476115,
      "backward_entropy": 0.06207369674335827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.97274780273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01866428554058075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08956623077392578,
      "backward_entropy": 0.062160036780617454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.8024444580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018751615658402443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08952802419662476,
      "backward_entropy": 0.06201466647061435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.83349609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018838565796613693,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08948926130930583,
      "backward_entropy": 0.06299099597063931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.66613006591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018927255645394325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08944936593373616,
      "backward_entropy": 0.06195359880273992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.56399536132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0190108772367239,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0894101361433665,
      "backward_entropy": 0.0620672269300981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.2115478515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019089041277766228,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0893716812133789,
      "backward_entropy": 0.061884419484571976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.555419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01916547305881977,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08933300773302714,
      "backward_entropy": 0.06201358274980025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.042724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019244765862822533,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08929288387298584,
      "backward_entropy": 0.061812487515536224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.38154602050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01932007446885109,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08925339579582214,
      "backward_entropy": 0.061958676034753975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.149169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01939353533089161,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08921341101328532,
      "backward_entropy": 0.06193067810752175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.48126220703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019466927275061607,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08917294939359029,
      "backward_entropy": 0.06190219792452725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.70913696289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01954285241663456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08913109699885051,
      "backward_entropy": 0.06187383695082231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.09832763671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019618894904851913,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08908849954605103,
      "backward_entropy": 0.061844923279502174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.55358123779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019703468307852745,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08904281258583069,
      "backward_entropy": 0.06297789920460094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.08688354492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019785143435001373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08899728457132976,
      "backward_entropy": 0.06178985942493786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.5585174560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019870324060320854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08895001808802287,
      "backward_entropy": 0.061498587781732734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.59202575683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0199558325111866,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08890190720558167,
      "backward_entropy": 0.06297644701871005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.5918731689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020039798691868782,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08885353803634644,
      "backward_entropy": 0.061703855341131035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.53482055664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02012857422232628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0888029436270396,
      "backward_entropy": 0.06137314167889682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.69764709472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020218728110194206,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08875113725662231,
      "backward_entropy": 0.061645887114784935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.99513244628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02030857466161251,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08869864543279012,
      "backward_entropy": 0.06128556078130549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.22181701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020396867766976357,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0886458953221639,
      "backward_entropy": 0.06158440763300115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.22483825683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020485471934080124,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08859222133954366,
      "backward_entropy": 0.061552448706193405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.03179931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020568033680319786,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08853989839553833,
      "backward_entropy": 0.06151797554709695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.26133728027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020656686276197433,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0884846846262614,
      "backward_entropy": 0.06148468364368786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.6611328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020747296512126923,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08842798074086507,
      "backward_entropy": 0.061451949856498024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.01727294921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02083742618560791,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08837061127026875,
      "backward_entropy": 0.06297365643761375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.234619140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02092698961496353,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08831260601679485,
      "backward_entropy": 0.06297343969345093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.46063232421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021013328805565834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08825496832529704,
      "backward_entropy": 0.06089156324213201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.68414306640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02110426127910614,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08819477756818135,
      "backward_entropy": 0.06297261606563222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.2374267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021196652203798294,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08813315629959106,
      "backward_entropy": 0.06077976118434559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.83424377441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021283665671944618,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08807279666264851,
      "backward_entropy": 0.06071827628395774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.15472412109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021367432549595833,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0880128542582194,
      "backward_entropy": 0.0629702318798412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.48857879638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021452859044075012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08795138200124104,
      "backward_entropy": 0.060583699833263054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.74788665771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021533465012907982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08789112170537312,
      "backward_entropy": 0.06050963835282759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.67823028564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021611763164401054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0878308117389679,
      "backward_entropy": 0.06104421073740179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0457763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02168799191713333,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08777060111363728,
      "backward_entropy": 0.060355554927479134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.58753967285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021762222051620483,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08771039048830669,
      "backward_entropy": 0.06094186956232244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.50933837890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021836258471012115,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08764939506848653,
      "backward_entropy": 0.06088849631222812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.64270782470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021910129114985466,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08758760492006938,
      "backward_entropy": 0.0601041858846491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.99784088134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02197902463376522,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0875272552172343,
      "backward_entropy": 0.06077496571974321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.61566162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022045796737074852,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08746706446011861,
      "backward_entropy": 0.06071470000527122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.78269958496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02212090604007244,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0874022642771403,
      "backward_entropy": 0.060658059336922386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.41175842285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022200213745236397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08733461300532024,
      "backward_entropy": 0.059747078201987526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.02310180664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02228129841387272,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08726483583450317,
      "backward_entropy": 0.06054608388380571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.91635131835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02236153744161129,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0871942937374115,
      "backward_entropy": 0.059565852988849984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.12976837158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022442465648055077,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08712246020634969,
      "backward_entropy": 0.060429919849742546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.7236328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02251596748828888,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08705361684163411,
      "backward_entropy": 0.06036555225198919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.81281280517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02259085513651371,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08698305487632751,
      "backward_entropy": 0.05926852334629406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.10613250732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02266114391386509,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08691396315892537,
      "backward_entropy": 0.059161717241460625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.28038024902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022725358605384827,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08684726556142171,
      "backward_entropy": 0.06292469934983687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.27403259277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022792654111981392,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08677794535954793,
      "backward_entropy": 0.058938969265330925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.54791259765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02286345325410366,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08670578400293986,
      "backward_entropy": 0.06291805614124645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.7138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022943509742617607,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0866278608640035,
      "backward_entropy": 0.059948390180414375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.4697265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023024458438158035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08654846747716267,
      "backward_entropy": 0.05988090146671642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.61317443847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0231059268116951,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08646781245867412,
      "backward_entropy": 0.06291460990905762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.06730651855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023186713457107544,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08638655145963033,
      "backward_entropy": 0.0597406192259355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.83348846435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02326529286801815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08630563815434773,
      "backward_entropy": 0.05828768556768244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.17721557617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02334262616932392,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08622427781422932,
      "backward_entropy": 0.05959194898605347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.49533081054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02341694012284279,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08614381154378255,
      "backward_entropy": 0.0580595081502741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.98541259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02349437028169632,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0860605239868164,
      "backward_entropy": 0.05943477153778076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.51312255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02357127144932747,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08597654104232788,
      "backward_entropy": 0.057825933803211556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.00285339355469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023652328178286552,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08588911096254985,
      "backward_entropy": 0.06290430372411554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.82554626464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023729274049401283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08580323060353597,
      "backward_entropy": 0.05757980996912176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.615234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023806052282452583,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08571645617485046,
      "backward_entropy": 0.0629003643989563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.83736419677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02387782372534275,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08563205599784851,
      "backward_entropy": 0.059009400281039154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.17237091064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02394849993288517,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0855471392472585,
      "backward_entropy": 0.05717040733857588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.1463623046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024018049240112305,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08546208341916402,
      "backward_entropy": 0.06289034540002997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.96123504638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0240886602550745,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0853753387928009,
      "backward_entropy": 0.05872065370733088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.21725463867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024157140403985977,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08528908093770345,
      "backward_entropy": 0.056737997315146706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.690673828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024226365610957146,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08520132303237915,
      "backward_entropy": 0.05851879986849698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.50872802734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02429642155766487,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08511200547218323,
      "backward_entropy": 0.06287895549427379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.05392456054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02437504194676876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08501622080802917,
      "backward_entropy": 0.05630671977996826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.66563415527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024453695863485336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08491931358973186,
      "backward_entropy": 0.05617213249206543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.8328399658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024530772119760513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08482301235198975,
      "backward_entropy": 0.05812152407386086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.39730834960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024608055129647255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08472523093223572,
      "backward_entropy": 0.05801987648010254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.37454223632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024686990305781364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08462501565615337,
      "backward_entropy": 0.057918006723577324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.67970275878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024766674265265465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08452330032984416,
      "backward_entropy": 0.05560406771573154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.53298950195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024844558909535408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08442211151123047,
      "backward_entropy": 0.055450276895002884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.63019561767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024923166260123253,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08431937297185262,
      "backward_entropy": 0.05759011073545976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.26573181152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025000398978590965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08421671390533447,
      "backward_entropy": 0.05747416344555942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.08878326416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025078436359763145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08411245544751485,
      "backward_entropy": 0.05735487287694758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.57595825195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02515457011759281,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08400871356328328,
      "backward_entropy": 0.054776126688176933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.61714172363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02523178793489933,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0839034120241801,
      "backward_entropy": 0.05459135228937322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.77409362792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025307655334472656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0837979515393575,
      "backward_entropy": 0.054405505006963555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.4732666015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025380529463291168,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08369381229082744,
      "backward_entropy": 0.056840479373931885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.90806579589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025451747700572014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08359028895696004,
      "backward_entropy": 0.054016189141706986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.07019805908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025526652112603188,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08348288138707478,
      "backward_entropy": 0.06286126917058771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.18260192871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025599408894777298,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08337630828221639,
      "backward_entropy": 0.0564185922796076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.08998107910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025676418095827103,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08326560258865356,
      "backward_entropy": 0.053397937254472214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.65330505371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025747064501047134,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08315946658452351,
      "backward_entropy": 0.06284811279990456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.29175567626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025816775858402252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08305322130521138,
      "backward_entropy": 0.05596529895609075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.88775634765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025881482288241386,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08295038342475891,
      "backward_entropy": 0.055803526531566276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.25291442871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02594735287129879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08284512162208557,
      "backward_entropy": 0.05249353430487893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.41203308105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026017380878329277,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08273553848266602,
      "backward_entropy": 0.0554841702634638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.41156768798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026086116209626198,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08262657125790913,
      "backward_entropy": 0.05532337860627608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.37901306152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02615148387849331,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08251983920733134,
      "backward_entropy": 0.05180695382031528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.23835754394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026221247389912605,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08240844806035359,
      "backward_entropy": 0.05499685352498835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.05947875976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026290083304047585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08229708671569824,
      "backward_entropy": 0.05134353854439475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.9576416015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026362981647253036,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08218132456143697,
      "backward_entropy": 0.06280109015378085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.46048736572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026436293497681618,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08206439018249512,
      "backward_entropy": 0.05450019511309537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.33456420898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026508506387472153,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08194773395856221,
      "backward_entropy": 0.05432679978283969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.80628967285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02657896839082241,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08183189233144124,
      "backward_entropy": 0.050387312065471306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.33255004882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02664879523217678,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0817159116268158,
      "backward_entropy": 0.06278284029527144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.24789428710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026723798364400864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08159451683362325,
      "backward_entropy": 0.05378048528324474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026796242222189903,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08147493998209636,
      "backward_entropy": 0.05359380353580822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.36869049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026870131492614746,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08135319749514262,
      "backward_entropy": 0.05340924588116733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.75686645507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026945024728775024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08122979601224263,
      "backward_entropy": 0.049146614291451195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.16343688964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027019044384360313,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08110669255256653,
      "backward_entropy": 0.05303737792101773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.15203857421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02709716185927391,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0809793770313263,
      "backward_entropy": 0.05285642905668779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.54867553710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027177350595593452,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08084913591543834,
      "backward_entropy": 0.05267776142467152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.33356475830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027258796617388725,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08071687817573547,
      "backward_entropy": 0.052497451955621895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.84838104248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02733750455081463,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08058682084083557,
      "backward_entropy": 0.04796679995276711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.02308654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02741469256579876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08045770227909088,
      "backward_entropy": 0.04770810495723377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.47687530517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027493471279740334,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08032642801602681,
      "backward_entropy": 0.05191060629757968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.92517852783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0275719091296196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08019489546616872,
      "backward_entropy": 0.047178463502363724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.25289916992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02765020728111267,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08006282647450765,
      "backward_entropy": 0.04690364815972068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.57933807373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027729706838726997,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07992904384930928,
      "backward_entropy": 0.05128777568990534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.04798889160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027808280661702156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07979583740234375,
      "backward_entropy": 0.05107424475929954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.25641632080078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027882752940058708,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07966642578442891,
      "backward_entropy": 0.06275085969404741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.08948516845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027957528829574585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07953597108523051,
      "backward_entropy": 0.05063097043470903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.54220581054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028032589703798294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07940482099850972,
      "backward_entropy": 0.05040720917961814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.075313568115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028108077123761177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07927271723747253,
      "backward_entropy": 0.04519089785489169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.21211242675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028174666687846184,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07915019989013672,
      "backward_entropy": 0.049937324090437454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.230712890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028242556378245354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0790256957213084,
      "backward_entropy": 0.04456672343340787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.79762268066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02831633761525154,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07889431218306224,
      "backward_entropy": 0.04946491393175992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.93267059326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028393642976880074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07875913878281911,
      "backward_entropy": 0.04923635179346258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.45813751220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028467770665884018,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0786270300547282,
      "backward_entropy": 0.048996806144714355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.91128540039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02853669598698616,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07850030561288197,
      "backward_entropy": 0.048745252869345924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.51526641845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02860362082719803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07837538917859395,
      "backward_entropy": 0.04848568005995317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.41876983642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028667425736784935,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825360695521037,
      "backward_entropy": 0.04822004383260554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.71925354003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028731733560562134,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07813084125518799,
      "backward_entropy": 0.042365079576318916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.96388244628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028799153864383698,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07800534864266713,
      "backward_entropy": 0.04204326597127048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.023536682128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02886822447180748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07787629961967468,
      "backward_entropy": 0.04743913086977872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.44595336914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028931183740496635,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07775382200876872,
      "backward_entropy": 0.04717678915370594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.17415618896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02899266965687275,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07763314247131348,
      "backward_entropy": 0.04691230167042126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.52333068847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029053859412670135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07751269141832988,
      "backward_entropy": 0.04075090451674028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.43279266357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02911362610757351,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07739356656869252,
      "backward_entropy": 0.040405885739759964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.73015594482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029173940420150757,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07727360725402832,
      "backward_entropy": 0.04005983200940219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.36582946777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029232259839773178,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07715590794881184,
      "backward_entropy": 0.04580584439364346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.45086669921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029287997633218765,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07704100012779236,
      "backward_entropy": 0.045515916564247826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.0669174194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029349032789468765,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07691966493924458,
      "backward_entropy": 0.03901263258673928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.62371063232422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029405910521745682,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0768033762772878,
      "backward_entropy": 0.06256343017924916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.78492736816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029462384060025215,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07668741544087727,
      "backward_entropy": 0.06255225701765581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.34951782226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029523290693759918,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656622926394145,
      "backward_entropy": 0.03795626759529114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.77069854736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029584279283881187,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0764447848002116,
      "backward_entropy": 0.0440835410898382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.59012603759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02964780107140541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07632031043370564,
      "backward_entropy": 0.037266314029693604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.33212280273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029713615775108337,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07619319359461467,
      "backward_entropy": 0.03693521293726834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.45555114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029782824218273163,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07606238126754761,
      "backward_entropy": 0.04326254400339993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.25211334228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02985493466258049,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07592848936716716,
      "backward_entropy": 0.04299858212471008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.36515808105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029925402253866196,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07579727967580159,
      "backward_entropy": 0.04272950779307972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.5494842529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029991263523697853,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07567158341407776,
      "backward_entropy": 0.042449132962660355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.46073913574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030066844075918198,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0755341649055481,
      "backward_entropy": 0.042191806164654816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.39263916015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030140630900859833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.075399915377299,
      "backward_entropy": 0.035037875175476074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.53773498535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030217379331588745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07526252667109172,
      "backward_entropy": 0.034750515764409844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.98948669433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03029276803135872,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07512704034646352,
      "backward_entropy": 0.04141818393360485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.41656494140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03037164732813835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07498774925867717,
      "backward_entropy": 0.04115817763588645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.00406646728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030446985736489296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07485329111417134,
      "backward_entropy": 0.03383742679249157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.59735870361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03052162192761898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07471983631451924,
      "backward_entropy": 0.04061918367039074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.68272399902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030597899109125137,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07458449403444926,
      "backward_entropy": 0.04035468264059587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.44672393798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030673887580633163,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07445007065931956,
      "backward_entropy": 0.04009044712240046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.76750183105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030750775709748268,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07431494692961375,
      "backward_entropy": 0.03982613303444602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.54241180419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030826514586806297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07418143252531688,
      "backward_entropy": 0.03233503211628307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.43753051757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030900757759809494,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07405008872350057,
      "backward_entropy": 0.06258727745576338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.45635223388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03097580187022686,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07391793032487233,
      "backward_entropy": 0.03902972828258167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.57625579833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031050918623805046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07378575205802917,
      "backward_entropy": 0.03145339001308788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.45022583007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031125955283641815,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07365379730860393,
      "backward_entropy": 0.038498556072061714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.42913818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031206563115119934,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07351614038149516,
      "backward_entropy": 0.03824280337853865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.97637939453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031288985162973404,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07337677478790283,
      "backward_entropy": 0.037986928766424004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.32069396972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03137367591261864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07323521375656128,
      "backward_entropy": 0.030302305113185535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.49009704589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03146009519696236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07309246559937795,
      "backward_entropy": 0.030020212585275822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.12350463867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031543903052806854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07295331358909607,
      "backward_entropy": 0.029735554348338734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.12550354003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03163427859544754,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07280731201171875,
      "backward_entropy": 0.036980409513820305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.21270751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031725507229566574,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07266119122505188,
      "backward_entropy": 0.036729801784862175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.1759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031812068074941635,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07252130409081776,
      "backward_entropy": 0.036466341127048836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.57908630371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0318981371819973,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07238334914048512,
      "backward_entropy": 0.06265593658794057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.21380615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03198057413101196,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225009799003601,
      "backward_entropy": 0.03591164946556091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.28020477294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03206848353147507,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07211063305536906,
      "backward_entropy": 0.03564719720320268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.94595336914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03215228021144867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07197725772857666,
      "backward_entropy": 0.027704978531057186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.55928802490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03223796561360359,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07184245189030965,
      "backward_entropy": 0.02741297808560458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.2967529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03232598677277565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07170566916465759,
      "backward_entropy": 0.03484693440524014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.84914016723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0324123241007328,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07157163321971893,
      "backward_entropy": 0.0345809974453666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.61405944824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03249138966202736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0714471439520518,
      "backward_entropy": 0.026551230387254196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.86640167236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03256472945213318,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07133026917775472,
      "backward_entropy": 0.033998156135732475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.85665893554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03263067081570625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0712231993675232,
      "backward_entropy": 0.02590954845601862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.49008178710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032700709998607635,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07111122210820515,
      "backward_entropy": 0.02560118924487721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.03009796142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032778818160295486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07099052270253499,
      "backward_entropy": 0.03311713175340132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.03958129882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03285074234008789,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07087825735410054,
      "backward_entropy": 0.03283470327203924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.94379425048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0329316183924675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0707569420337677,
      "backward_entropy": 0.02474821155721491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.28076934814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.033010855317115784,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07063797612984975,
      "backward_entropy": 0.06263704733415083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.61160278320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0330883152782917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07052174707253774,
      "backward_entropy": 0.03203769434582104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.48360061645508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033163875341415405,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07040844360987346,
      "backward_entropy": 0.023920433087782425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.20271301269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03323361277580261,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07030282417933147,
      "backward_entropy": 0.023632163351232357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.88226318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03330115228891373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07020039359728496,
      "backward_entropy": 0.031194621866399593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.65209197998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03337429091334343,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07009191314379375,
      "backward_entropy": 0.03092745759270408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.20073699951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033445097506046295,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06998727222283681,
      "backward_entropy": 0.030660260807384144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.24087524414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033514443784952164,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0698845386505127,
      "backward_entropy": 0.02252827449278398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.95896911621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03358471393585205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0697805682818095,
      "backward_entropy": 0.022260763428427956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.11382293701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03366127610206604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06967102487881978,
      "backward_entropy": 0.022003125060688366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.78176879882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03373854607343674,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06956129769484203,
      "backward_entropy": 0.02963104573163119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.22700881958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0338178351521492,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06945015986760457,
      "backward_entropy": 0.029383236711675472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.72574996948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03389064967632294,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06934754053751628,
      "backward_entropy": 0.021230904893441635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.94355773925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033959563821554184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06925037999947865,
      "backward_entropy": 0.020958472381938587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.27325439453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03402797877788544,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06915423770745595,
      "backward_entropy": 0.0625961802222512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.07693481445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034094713628292084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06906054417292277,
      "backward_entropy": 0.02042886479334398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.64019012451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03416401892900467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06896465023358662,
      "backward_entropy": 0.020175416361201893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.84400939941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03423268720507622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06887028614679973,
      "backward_entropy": 0.019923911853270096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.93551635742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03430360555648804,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0687738557656606,
      "backward_entropy": 0.01967692646113309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.66897583007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03437328711152077,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06867968539396922,
      "backward_entropy": 0.027343327348882503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.3689727783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034443438053131104,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06858576834201813,
      "backward_entropy": 0.02709639072418213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.2798614501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034518513828516006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06848720709482829,
      "backward_entropy": 0.02685743028467352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.03614044189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034597862511873245,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06838481624921162,
      "backward_entropy": 0.026624703949148006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.44728088378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03467460721731186,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0682861606280009,
      "backward_entropy": 0.026394123380834408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.33350372314453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03475562855601311,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06818339228630066,
      "backward_entropy": 0.0625883774323897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.32200622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0348389707505703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06807933747768402,
      "backward_entropy": 0.01798037507317283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.62343978881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034920115023851395,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0679788887500763,
      "backward_entropy": 0.0257280170917511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.23335266113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03499699756503105,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06788428624471028,
      "backward_entropy": 0.02550086649981412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.10922241210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035074226558208466,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06778963406880696,
      "backward_entropy": 0.025281047279184513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.18083190917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035149604082107544,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06769790252049764,
      "backward_entropy": 0.0250529944896698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.93138122558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03522519767284393,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06760667264461517,
      "backward_entropy": 0.024827312339435924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.32089614868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03529978170990944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06751732031504314,
      "backward_entropy": 0.01661406863819469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.10427856445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03537054732441902,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06743290026982625,
      "backward_entropy": 0.024378486654975197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.860774993896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03544358164072037,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0673470397790273,
      "backward_entropy": 0.024160813201557507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.90258026123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03551315888762474,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06726552546024323,
      "backward_entropy": 0.02394348924810236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.65796661376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03558150678873062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06718596816062927,
      "backward_entropy": 0.023736170747063377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.86966705322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03564797714352608,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06710891922314961,
      "backward_entropy": 0.023527307943864303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.44634246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03571658954024315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06703028579552968,
      "backward_entropy": 0.015311055562712929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.05693817138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03578730300068855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06694986422856648,
      "backward_entropy": 0.023107184605164963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.94164276123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03585903346538544,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06686920424302419,
      "backward_entropy": 0.01488754695112055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.371891021728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03593258559703827,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06678751111030579,
      "backward_entropy": 0.014677962118929083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.536865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03600141033530235,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06671164433161418,
      "backward_entropy": 0.022499096664515408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.83773422241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03607690706849098,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06662935018539429,
      "backward_entropy": 0.02230849320238287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.688236236572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03615059331059456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06654967864354451,
      "backward_entropy": 0.014081693508408287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.71426773071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03622082248330116,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06647434830665588,
      "backward_entropy": 0.02194370600310239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.80006408691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036287806928157806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0664031853278478,
      "backward_entropy": 0.013698469508777966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.10205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036360353231430054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06632683674494426,
      "backward_entropy": 0.021586399186741222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.18032836914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03643655404448509,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0662471850713094,
      "backward_entropy": 0.0214186662977392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.85167694091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03651738166809082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06616343061129253,
      "backward_entropy": 0.02125724743713032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.7647705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03659835830330849,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06608021259307861,
      "backward_entropy": 0.021097324111244896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.69010543823242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03667932376265526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06599774956703186,
      "backward_entropy": 0.02093649994243275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.00337219238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03675791248679161,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06591851512591045,
      "backward_entropy": 0.012671764601360668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.48033905029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03683706745505333,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06583908200263977,
      "backward_entropy": 0.020630932667038658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.93082427978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03691910207271576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06575750311215718,
      "backward_entropy": 0.012358840216289867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.00240325927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03700551018118858,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06567227840423584,
      "backward_entropy": 0.02035748687657443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.01687622070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037093911319971085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06558568278948466,
      "backward_entropy": 0.02022728459401564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.83341598510742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03718339651823044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06549880901972453,
      "backward_entropy": 0.0201055570082231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.08797454833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03726808354258537,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06541753808657329,
      "backward_entropy": 0.019981317899443886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.95378875732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037356261163949966,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06533336639404297,
      "backward_entropy": 0.019857555627822876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.617919921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03744199499487877,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06525221467018127,
      "backward_entropy": 0.019719947468150745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.43379592895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03753071650862694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06516880790392558,
      "backward_entropy": 0.011352537707848982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.12173080444336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03761579468846321,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06508997082710266,
      "backward_entropy": 0.019468651576475662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.567317962646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03769775852560997,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06501508752504985,
      "backward_entropy": 0.01933651620691473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.921512603759766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03777739778161049,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06494327386220296,
      "backward_entropy": 0.06274266676469283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.59964370727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037853170186281204,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06487599511941274,
      "backward_entropy": 0.019088396971875973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.79600524902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0379268042743206,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06481124957402547,
      "backward_entropy": 0.010644882240078667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.30728149414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038002487272024155,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06474475065867107,
      "backward_entropy": 0.010504992170767351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.96649932861328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03807931765913963,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.064677099386851,
      "backward_entropy": 0.06275383992628618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.08378601074219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03815734013915062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0646086831887563,
      "backward_entropy": 0.018637256188826126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.73176574707031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03823598474264145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0645397553841273,
      "backward_entropy": 0.018543905832550743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.42518615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03831924498081207,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06446649630864461,
      "backward_entropy": 0.01845610954544761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.869239807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03840206190943718,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06439390778541565,
      "backward_entropy": 0.01838383620435541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.33543395996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03847995400428772,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06432693203290303,
      "backward_entropy": 0.009806947951967066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.67494201660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038555439561605453,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06426269312699635,
      "backward_entropy": 0.018231287598609924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.90597534179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038632832467556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06419698397318523,
      "backward_entropy": 0.009584346955472773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.25839233398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03871065005660057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06413129965464275,
      "backward_entropy": 0.009468902241099964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.69845962524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038789454847574234,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06406469146410625,
      "backward_entropy": 0.017976330085234207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.669368743896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03886525705456734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06400141616662343,
      "backward_entropy": 0.01790385896509344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.5716552734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038938216865062714,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06394140422344208,
      "backward_entropy": 0.0628125775944103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.86180877685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039013076573610306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06387974321842194,
      "backward_entropy": 0.01775730604475195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.25247955322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03908636048436165,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06381993492444356,
      "backward_entropy": 0.017681394111026417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.4449462890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03916097804903984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06375892460346222,
      "backward_entropy": 0.008839662779461254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.79741668701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0392342135310173,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06369944910208385,
      "backward_entropy": 0.017548227852041073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.54025268554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039310526102781296,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06363655130068462,
      "backward_entropy": 0.017498563636432995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.76138687133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03938629850745201,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06357480585575104,
      "backward_entropy": 0.017444683746858078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.24458312988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03945930302143097,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06351623435815175,
      "backward_entropy": 0.01739267869429155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.42433166503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03953196480870247,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06345807512601216,
      "backward_entropy": 0.00838218629360199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.94223022460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03960675001144409,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06339782973130544,
      "backward_entropy": 0.017268485643646934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.40325164794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03968088701367378,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06333833932876587,
      "backward_entropy": 0.017198630354621193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.25945281982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03975503519177437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06327895323435466,
      "backward_entropy": 0.008094469254667109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.0970230102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03983047604560852,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06321842471758525,
      "backward_entropy": 0.01708028804172169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.87364959716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03990566357970238,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06315817435582478,
      "backward_entropy": 0.01702615483240648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.99504470825195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03998317942023277,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06309557954470317,
      "backward_entropy": 0.016972994262521916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.049991607666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04005610942840576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0630382349093755,
      "backward_entropy": 0.007738282057372006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.60775375366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040125772356987,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0629847248395284,
      "backward_entropy": 0.0076429396867752075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.69149398803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040193088352680206,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06293392181396484,
      "backward_entropy": 0.01677996732971885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.18347930908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04025687277317047,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06288747986157735,
      "backward_entropy": 0.01671527326107025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.77903747558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04032600298523903,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06283484399318695,
      "backward_entropy": 0.016668417237021706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.618213653564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04039556905627251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06278170645236969,
      "backward_entropy": 0.016626110131090336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.70505142211914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04046013578772545,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06273447473843892,
      "backward_entropy": 0.016580455682494423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.935997009277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04052348807454109,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0626884897549947,
      "backward_entropy": 0.007137779485095631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.44992446899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04058504477143288,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06264459590117137,
      "backward_entropy": 0.016509660265662453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.32384490966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04064641147851944,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06260086099306743,
      "backward_entropy": 0.016471650112758984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.739906311035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0407114252448082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06255292892456055,
      "backward_entropy": 0.01643387566913258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.0792236328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040773656219244,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06250828007857005,
      "backward_entropy": 0.01640278371897611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.27394104003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04083551838994026,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06246408820152283,
      "backward_entropy": 0.016368492083116012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.28965759277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0408988818526268,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06241785486539205,
      "backward_entropy": 0.01634308153932745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.446998596191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04096318781375885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06237056851387024,
      "backward_entropy": 0.00662637705152685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.868064880371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04102467745542526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.062326436241467796,
      "backward_entropy": 0.016290773044932972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.76921844482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04108491167426109,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06228382885456085,
      "backward_entropy": 0.01626737415790558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.6214599609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04115131497383118,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.062234342098236084,
      "backward_entropy": 0.016238329085436733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.72008514404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04122062027454376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06218118965625763,
      "backward_entropy": 0.006355818022381176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.533653259277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04129182547330856,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06212587157885233,
      "backward_entropy": 0.016174668615514583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.762168884277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04135843738913536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06207593778769175,
      "backward_entropy": 0.01615530794317072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.39796447753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04142637923359871,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06202442944049835,
      "backward_entropy": 0.016151025891304016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.166587829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04149177670478821,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061975965897242226,
      "backward_entropy": 0.006116999143903906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.29031753540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04155516251921654,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06192986170450846,
      "backward_entropy": 0.016113806854594837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.866024017333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04162007197737694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06188171108563741,
      "backward_entropy": 0.016104030338200657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.77081298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04168509691953659,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06183320780595144,
      "backward_entropy": 0.016104595227675003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.40482330322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041750095784664154,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06178449591000875,
      "backward_entropy": 0.016111459244381298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.37424087524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0418182872235775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06173203388849894,
      "backward_entropy": 0.0058456523851914835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.147428512573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04188640043139458,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061679099996884666,
      "backward_entropy": 0.016121005470102482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.42395782470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04195140674710274,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061630070209503174,
      "backward_entropy": 0.01613163948059082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.19829559326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042017240077257156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06157991290092468,
      "backward_entropy": 0.016137887131084095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.73466110229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042083948850631714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06152841945489248,
      "backward_entropy": 0.005661165172403509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.80093765258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04214947670698166,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06147812803586324,
      "backward_entropy": 0.016162148930809715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.75962829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04221341386437416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06142966449260712,
      "backward_entropy": 0.00557772307233377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.430240631103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04227815568447113,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06138001879056295,
      "backward_entropy": 0.01618770577690818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.60540008544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04234177991747856,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061331545313199363,
      "backward_entropy": 0.016205385327339172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.108768463134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04240460321307182,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06128373742103577,
      "backward_entropy": 0.016207575798034668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.01851272583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04246774688363075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06123542785644531,
      "backward_entropy": 0.016220153732733292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.094520568847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04253190755844116,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061185866594314575,
      "backward_entropy": 0.016228876330635765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.54355239868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04259462282061577,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06113794445991516,
      "backward_entropy": 0.016238758509809322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.575321197509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04265877977013588,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06108762820561727,
      "backward_entropy": 0.01625326004895297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.20250701904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04272359609603882,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06103634834289551,
      "backward_entropy": 0.016257184472951023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.50431823730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04278441518545151,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.060990139842033386,
      "backward_entropy": 0.016262573274699123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.909299850463867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042849332094192505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06093831857045492,
      "backward_entropy": 0.016271722587672146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.701906204223633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0429111123085022,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.060890515645345054,
      "backward_entropy": 0.016273269599134273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.340295791625977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0429704524576664,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06084562838077545,
      "backward_entropy": 0.016276289116252552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.02861022949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043024979531764984,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06080701947212219,
      "backward_entropy": 0.016280423511158337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.09574508666992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04308287799358368,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06076390047868093,
      "backward_entropy": 0.016286156394264915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.022796630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04313984885811806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06072184443473816,
      "backward_entropy": 0.004936890845948999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.02752685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04319586604833603,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.060680786768595375,
      "backward_entropy": 0.0162910209460692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.601398468017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043256331235170364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06063354015350342,
      "backward_entropy": 0.016294304620135914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.185476303100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04331351816654205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06059040625890096,
      "backward_entropy": 0.004816144704818726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.29620361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04336850345134735,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060550153255462646,
      "backward_entropy": 0.004776814444498582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.921688079833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04342607036232948,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06050590674082438,
      "backward_entropy": 0.016333978284489025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.14280319213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04348387196660042,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06046112875143687,
      "backward_entropy": 0.01634647629477761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.97532653808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043543361127376556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06041366855303446,
      "backward_entropy": 0.016357003287835556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.324264526367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04360436648130417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06036388874053955,
      "backward_entropy": 0.016365954821760006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.26468658447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04366181045770645,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06031899650891622,
      "backward_entropy": 0.016377904198386452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.1480484008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04372742399573326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060262590646743774,
      "backward_entropy": 0.004564403810284354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.234981536865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043796129524707794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06020176410675049,
      "backward_entropy": 0.016399202021685513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.379762649536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04386553168296814,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06013985971609751,
      "backward_entropy": 0.004492816938595338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.78407669067383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04393153637647629,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06008229653040568,
      "backward_entropy": 0.016412021084265274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.18756866455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04399669170379639,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.060025682051976524,
      "backward_entropy": 0.01640669053251093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.74134826660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04405887797474861,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059973071018854775,
      "backward_entropy": 0.016400142149491745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.26253890991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044123273342847824,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059916943311691284,
      "backward_entropy": 0.00433696061372757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.22830200195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04418722540140152,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05986137191454569,
      "backward_entropy": 0.016380608081817627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.71573257446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04425355792045593,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059802075227101646,
      "backward_entropy": 0.01637677306478674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.79257583618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04431874305009842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05974400043487549,
      "backward_entropy": 0.004225714640183883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.533998489379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04438617452979088,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059682304660479225,
      "backward_entropy": 0.016402615742249924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.39447021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0444507822394371,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059624304374059044,
      "backward_entropy": 0.01641989837993275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.27485656738281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04451417550444603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05956768989562988,
      "backward_entropy": 0.004136825488372283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.94561767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044577453285455704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05951084693272909,
      "backward_entropy": 0.004107935523444956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.422466278076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044642288237810135,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05945118268330892,
      "backward_entropy": 0.0164918222210624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.41645812988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04470265284180641,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05939814945062002,
      "backward_entropy": 0.01650552993470972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.8411865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044766802340745926,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05933905144532522,
      "backward_entropy": 0.01651514524763281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.69259643554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04482954367995262,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059281726678212486,
      "backward_entropy": 0.016526476903395218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.04270553588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04489723592996597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05921657383441925,
      "backward_entropy": 0.003961492668498646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.032711029052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04496600851416588,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059149290124575295,
      "backward_entropy": 0.003936351361599835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.96814727783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045034851878881454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0590813010931015,
      "backward_entropy": 0.01658356867053292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.52702331542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04510334134101868,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059013545513153076,
      "backward_entropy": 0.01660824634812095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.3070068359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04517247527837753,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05894455313682556,
      "backward_entropy": 0.016633581031452526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.93006896972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045245520770549774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05886948108673096,
      "backward_entropy": 0.003829045051878149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.778297424316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045322392135858536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.058787946899731956,
      "backward_entropy": 0.003801933066411452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.15430450439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045396558940410614,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05871009826660156,
      "backward_entropy": 0.003774504431269386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.01317024230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045469582080841064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05863352616628011,
      "backward_entropy": 0.003747972236438231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.32891845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045538973063230515,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05856230358282725,
      "backward_entropy": 0.01670777662233873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.108192443847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045608650892972946,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.058490181962649025,
      "backward_entropy": 0.016721134836023503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.301734924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04567869007587433,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05841688315073649,
      "backward_entropy": 0.01673519340428439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.71792221069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04574420675635338,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05835069219271342,
      "backward_entropy": 0.003641202368519523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.857975006103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04581049084663391,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.058282315731048584,
      "backward_entropy": 0.016770300540057095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.26226806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04587499052286148,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05821657180786133,
      "backward_entropy": 0.016785413026809692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.39377975463867,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04594078287482262,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05814801653226217,
      "backward_entropy": 0.06299561803991144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.39771270751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04600868001580238,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.058075581987698875,
      "backward_entropy": 0.016837633468888023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.138132095336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046079736202955246,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05799742043018341,
      "backward_entropy": 0.016867643052881413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.8687973022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04614723473787308,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05792470773061117,
      "backward_entropy": 0.0035012269561940975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.292823791503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0462179034948349,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05784618854522705,
      "backward_entropy": 0.016917738047513096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.896785736083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046287063509225845,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.057769750555356346,
      "backward_entropy": 0.016926547343080692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.901527404785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04635433852672577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05769589046637217,
      "backward_entropy": 0.003428609533743425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.68654251098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046422455459833145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.057620043555895485,
      "backward_entropy": 0.016962609507820824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.498517990112305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04648994654417038,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05754463871320089,
      "backward_entropy": 0.01698756217956543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.34693908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046554431319236755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.057473952571551,
      "backward_entropy": 0.01701529865915125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.28065490722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04662095755338669,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.057399133841196694,
      "backward_entropy": 0.017042827877131374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.15354919433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04668562486767769,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05732702215512594,
      "backward_entropy": 0.01706685396757993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.806541442871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04674861580133438,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057257071137428284,
      "backward_entropy": 0.0032989375970580363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.41913604736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0468125119805336,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05718518296877543,
      "backward_entropy": 0.017106780951673336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.60674285888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04687878489494324,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05710874001185099,
      "backward_entropy": 0.01713367754762823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.28018569946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04694436118006706,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05703273912270864,
      "backward_entropy": 0.01715569739991968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.511838912963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04701025038957596,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.056955705086390175,
      "backward_entropy": 0.017166145823218605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.952168464660645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047074321657419205,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05688127875328064,
      "backward_entropy": 0.017176055095412514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.568655014038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04713413491845131,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05681427319844564,
      "backward_entropy": 0.01717980612408031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.20621109008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04719147831201553,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056751400232315063,
      "backward_entropy": 0.0031358569183132863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.364240646362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04724744334816933,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05669058859348297,
      "backward_entropy": 0.01717712391506542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.026799201965332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047301534563302994,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05663293103377024,
      "backward_entropy": 0.017178310589356857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.818986892700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047351639717817307,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056582510471343994,
      "backward_entropy": 0.0030575909397818827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.703184127807617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04740150645375252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.056531806786855064,
      "backward_entropy": 0.017201754179867832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.15441131591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047451261430978775,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05648106336593628,
      "backward_entropy": 0.01721809533509341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.41631031036377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0475020594894886,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0564278761545817,
      "backward_entropy": 0.017235426740212875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.398906707763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047550562769174576,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.056378692388534546,
      "backward_entropy": 0.017263335260477932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.27556037902832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04759908840060234,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.056328783432642617,
      "backward_entropy": 0.01729086312380704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.757080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047647830098867416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05627788106600443,
      "backward_entropy": 0.0029349513351917267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.344444274902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04769532382488251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05622902512550354,
      "backward_entropy": 0.017356329343535683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.38521957397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047746844589710236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05617170532544454,
      "backward_entropy": 0.017398429187861355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.61265563964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04779941216111183,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05611178278923035,
      "backward_entropy": 0.06300272724845192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.24375534057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04785424470901489,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05604684352874756,
      "backward_entropy": 0.01749813963066448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.34470748901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047912683337926865,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05597444872061411,
      "backward_entropy": 0.017532909458333797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.964120864868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047972191125154495,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.055899471044540405,
      "backward_entropy": 0.0175570317290046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.410160064697266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04802821949124336,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05583085119724274,
      "backward_entropy": 0.06300506808541038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.81568908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048083674162626266,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05576300621032715,
      "backward_entropy": 0.01761473308910023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.45188522338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048140574246644974,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05569201707839966,
      "backward_entropy": 0.01764328506859866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.110261917114258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04819744452834129,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05562052130699158,
      "backward_entropy": 0.017663633281534367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.45479202270508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04825325682759285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05555059015750885,
      "backward_entropy": 0.017680153250694275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.24570846557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04831158369779587,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05547508100668589,
      "backward_entropy": 0.017691724679686806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.69710350036621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048372164368629456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055394530296325684,
      "backward_entropy": 0.0027097456834533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.66196823120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04843178763985634,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05531536042690277,
      "backward_entropy": 0.017718800089576027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.55228042602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048491474241018295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05523552497227987,
      "backward_entropy": 0.002674769948829304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.32620906829834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04855372756719589,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05514983832836151,
      "backward_entropy": 0.0177746442231265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.15979766845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048612505197525024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055070956548055015,
      "backward_entropy": 0.002646693282506683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.82322311401367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048674456775188446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05498499174912771,
      "backward_entropy": 0.017844720320268112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.054325103759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048740632832050323,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.054889827966690063,
      "backward_entropy": 0.017867766998030922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.22292709350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04880394786596298,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05480016767978668,
      "backward_entropy": 0.017896900122815914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.37028121948242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04887140542268753,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05470167597134908,
      "backward_entropy": 0.017925670201128178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.75983428955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04893936589360237,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05460137128829956,
      "backward_entropy": 0.0025711298327554355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.23699951171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04900417476892471,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05450721581776937,
      "backward_entropy": 0.01799609037962827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.524168014526367,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049068156629800797,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.054414267341295876,
      "backward_entropy": 0.06300917538729581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.46823501586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04912974312901497,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05432582894961039,
      "backward_entropy": 0.018064347180453213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.073162078857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04918879270553589,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05424232284228007,
      "backward_entropy": 0.01810574260624972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.59314727783203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04924655333161354,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05416107177734375,
      "backward_entropy": 0.06301039999181574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.06430435180664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04930443316698074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05407888690630595,
      "backward_entropy": 0.018178187988021156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.12781524658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049363598227500916,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05399323503176371,
      "backward_entropy": 0.018217143687334927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.030681610107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049420252442359924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05391267438729604,
      "backward_entropy": 0.002464731308546933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.88995361328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04947473853826523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.053836445013682045,
      "backward_entropy": 0.018285797400908035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.398508071899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04952782019972801,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05376265446345011,
      "backward_entropy": 0.018336008895527233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.272464752197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049579981714487076,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05369044840335846,
      "backward_entropy": 0.01837387816472487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.211938858032227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04963149502873421,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05361912647883097,
      "backward_entropy": 0.01840743151578036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.02812957763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04968051239848137,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05355292558670044,
      "backward_entropy": 0.018449821255423805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.964216232299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04972954839468002,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05348605910936991,
      "backward_entropy": 0.01849962906403975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.986019134521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049778230488300323,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0534194807211558,
      "backward_entropy": 0.0023792755197394977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.719837188720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04983028769493103,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.053344398736953735,
      "backward_entropy": 0.01859034326943484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.980224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04988203942775726,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.053269341588020325,
      "backward_entropy": 0.018642986362630672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.07992935180664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04993763938546181,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05318476756413778,
      "backward_entropy": 0.01868683099746704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.133342742919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04999757930636406,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.053090075651804604,
      "backward_entropy": 0.018714632500301708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.758411407470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05005495622754097,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05300085743268331,
      "backward_entropy": 0.018740576776591213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.949562072753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05010930448770523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05291816592216492,
      "backward_entropy": 0.018779456615447998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.66236877441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016172304749489,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052839537461598717,
      "backward_entropy": 0.00229770994999192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.965322494506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050216514617204666,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05275478462378184,
      "backward_entropy": 0.0188455960967324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.963783264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05027021840214729,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05267207324504852,
      "backward_entropy": 0.018865181641145187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.694705963134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050324276089668274,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05258798599243164,
      "backward_entropy": 0.018884862011129207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.444067001342773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050377752631902695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05250460902849833,
      "backward_entropy": 0.0022419579327106476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.534080505371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050428297370672226,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05242802699406942,
      "backward_entropy": 0.01894538781859658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.396259307861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05047966539859772,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0523490309715271,
      "backward_entropy": 0.018982922488992863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.299050331115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050530433654785156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.052270740270614624,
      "backward_entropy": 0.019017086787657303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.13981628417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05057835206389427,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05219908058643341,
      "backward_entropy": 0.019046114249662918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.004676818847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050628215074539185,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05212192237377167,
      "backward_entropy": 0.01907250149683519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.79960250854492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05067902430891991,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05204207201798757,
      "backward_entropy": 0.019108341498808426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.868112564086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050731733441352844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0519567479689916,
      "backward_entropy": 0.019150855866345493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.180600166320801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0507836788892746,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.051872839530309044,
      "backward_entropy": 0.019190157001668758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.49114227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05083131417632103,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05179959535598755,
      "backward_entropy": 0.0021347379819913344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.925314903259277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05087990686297417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05172329147656759,
      "backward_entropy": 0.019247607751326126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.41786575317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0509258434176445,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.051653350392977394,
      "backward_entropy": 0.019274584271691063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.58540153503418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05097734183073044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0515690545241038,
      "backward_entropy": 0.019306559454311024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.7079963684082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05102702975273132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05148873229821523,
      "backward_entropy": 0.01933611116626046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.959630489349365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05107865482568741,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.051402981082598366,
      "backward_entropy": 0.019371878017078747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.996551513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05112660303711891,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05132624010245005,
      "backward_entropy": 0.019417318430813877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.960365295410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05117463693022728,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05124868949254354,
      "backward_entropy": 0.019474295052615078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27388259768486023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0512220524251461,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05117242534955343,
      "backward_entropy": 0.01951510797847401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.24606704711914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05126471817493439,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05110843976338705,
      "backward_entropy": 0.019550362771207638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.062339782714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05131170526146889,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05103235443433126,
      "backward_entropy": 0.01957560127431696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.126285552978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0513572059571743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05095997949441274,
      "backward_entropy": 0.002009829336946661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.876022338867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05140361189842224,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.050884515047073364,
      "backward_entropy": 0.019612197171558033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.93903732299805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0514490082859993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05081131557623545,
      "backward_entropy": 0.0019849833439696918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.263858795166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05149737745523453,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05073005457719167,
      "backward_entropy": 0.019664352590387516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.667255401611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051547300070524216,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05064439276854197,
      "backward_entropy": 0.001959005370736122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.28708267211914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051595594733953476,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.050562649965286255,
      "backward_entropy": 0.06301308761943471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.07381534576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05164868012070656,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.050467719634373985,
      "backward_entropy": 0.019708550789139488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.221595764160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051698870956897736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05038008590539297,
      "backward_entropy": 0.0019197396256706932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.16663360595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051749370992183685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.050291274984677635,
      "backward_entropy": 0.01974253762852062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.92775535583496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05180353671312332,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05019247531890869,
      "backward_entropy": 0.019759018312801014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.172977447509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05185776203870773,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.050092920660972595,
      "backward_entropy": 0.019776084206321022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.075809478759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051909830421209335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.049998730421066284,
      "backward_entropy": 0.01979143511165272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.756967544555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051960114389657974,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04990891615549723,
      "backward_entropy": 0.019810906865380028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.370269775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0520075224339962,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04982670148213705,
      "backward_entropy": 0.019827512177554043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.88481330871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05205579847097397,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.049741571148236595,
      "backward_entropy": 0.01985136487267234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.771702766418457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05210208147764206,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04966148237387339,
      "backward_entropy": 0.019858780232342808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.30771255493164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05214706435799599,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.049584537744522095,
      "backward_entropy": 0.019869943911379032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.626410484313965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0521952360868454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.049498344461123146,
      "backward_entropy": 0.0017943543127991936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.521828651428223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05224182829260826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04941607515017191,
      "backward_entropy": 0.019909923726862126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.538423538208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052287403494119644,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0493362694978714,
      "backward_entropy": 0.019944907589392227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.45308494567871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05233297869563103,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04925585786501566,
      "backward_entropy": 0.0017643425274978984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.272116661071777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05237838625907898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04917536675930023,
      "backward_entropy": 0.02003110267899253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.32296371459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05242178589105606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04910011092821757,
      "backward_entropy": 0.020084637132557957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.115867614746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0524703711271286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04900995393594106,
      "backward_entropy": 0.0017411966215480459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.00081443786621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052521608769893646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04891202847162882,
      "backward_entropy": 0.0017335621470754797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.06845474243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05257374420762062,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04881125191847483,
      "backward_entropy": 0.0017234129323200746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.03933334350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052623093128204346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04871792594591776,
      "backward_entropy": 0.020233492959629406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.899269104003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05266961082816124,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04863224426905314,
      "backward_entropy": 0.02026084471832622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.32347869873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052723027765750885,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.048527161280314125,
      "backward_entropy": 0.02028720893643119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.32961082458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052777547389268875,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04841866592566172,
      "backward_entropy": 0.020317990671504627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.20929718017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0528319850564003,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04830995202064514,
      "backward_entropy": 0.0203518501736901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.509439468383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05288601294159889,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04820201297601064,
      "backward_entropy": 0.020376594229177994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.380802154541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05293793976306915,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04809969663619995,
      "backward_entropy": 0.02040592513301156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.058916091918945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05299203470349312,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.047990779081980385,
      "backward_entropy": 0.020436189391396263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.279397010803223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05304490402340889,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04788475235303243,
      "backward_entropy": 0.020463332533836365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.82439041137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05309544503688812,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0477852871020635,
      "backward_entropy": 0.020479662851853805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.343769073486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053147848695516586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047680253783861794,
      "backward_entropy": 0.0016156309707598252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.606908798217773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05320030078291893,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.047574798266092934,
      "backward_entropy": 0.020495230501348324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.076831817626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053251735866069794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.047471841176350914,
      "backward_entropy": 0.020509771325371483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.938966751098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05330313369631767,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04736854135990143,
      "backward_entropy": 0.020522117614746094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.259166717529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05335449054837227,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04726497828960419,
      "backward_entropy": 0.020532818003134293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.162076950073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05340515449643135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04716286063194275,
      "backward_entropy": 0.0015623598274859514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.595033645629883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05345502868294716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.047062575817108154,
      "backward_entropy": 0.020584860985929317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.824007034301758,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05350314453244209,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04696711401144663,
      "backward_entropy": 0.06301262703808871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.035326957702637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053552769124507904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04686663051446279,
      "backward_entropy": 0.0015369667248292403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.54581069946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053599532693624496,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.046774392326672874,
      "backward_entropy": 0.020686248486692257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.320608139038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053647518157958984,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04667818546295166,
      "backward_entropy": 0.020710273222489792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.867088317871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05369343236088753,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04658769567807516,
      "backward_entropy": 0.020719318227334457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.76038360595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05373707786202431,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04650366803010305,
      "backward_entropy": 0.020740297707644375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7825345993042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053781669586896896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046416411797205605,
      "backward_entropy": 0.0014896533367308703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.524200439453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053823959082365036,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04633585115273794,
      "backward_entropy": 0.02080522613091902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.912193298339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0538673922419548,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04625135660171509,
      "backward_entropy": 0.02084884453903545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.30352783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05391363799571991,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046158025662104286,
      "backward_entropy": 0.0014678659764203158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.602438926696777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053960371762514114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046062553922335304,
      "backward_entropy": 0.0014612789858471263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.72098159790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05400440841913223,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04597502946853638,
      "backward_entropy": 0.001453674313696948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.95052146911621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054047100245952606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04589127500851949,
      "backward_entropy": 0.021014260974797336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.361820220947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05409059673547745,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04580467442671458,
      "backward_entropy": 0.021049108017574657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.713247299194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05413852259516716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04570440948009491,
      "backward_entropy": 0.021074999462474476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.843875885009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0541866309940815,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.045603265364964805,
      "backward_entropy": 0.021099188111045143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.454200744628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05423743650317192,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04549371202786764,
      "backward_entropy": 0.021106554703278976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.281034469604492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05428803712129593,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04538452625274658,
      "backward_entropy": 0.02111241492358121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.185612678527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054337676614522934,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04527803758780161,
      "backward_entropy": 0.02112614702094685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.06293487548828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05438536778092384,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.045177375276883446,
      "backward_entropy": 0.06301308220083063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098691940307617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054433055222034454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.045076568921407066,
      "backward_entropy": 0.02115644785490903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.933045387268066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05447783321142197,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.044984628756841026,
      "backward_entropy": 0.021163195371627808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.56846809387207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05452151224017143,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.044895678758621216,
      "backward_entropy": 0.021188410845669834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.933204174041748,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05456692725419998,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04480068882306417,
      "backward_entropy": 0.06301290880550038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.15358543395996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05460995063185692,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04471284647782644,
      "backward_entropy": 0.02126140621575442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.49625301361084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05465549975633621,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04461677372455597,
      "backward_entropy": 0.02129748599095778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.982900857925415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054700516164302826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04452202717463175,
      "backward_entropy": 0.02133524688807401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.735651016235352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05474225804209709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04443731904029846,
      "backward_entropy": 0.0013180898333137686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.21373176574707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05478209629654884,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044358243544896446,
      "backward_entropy": 0.0013124061409722674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.620288848876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0548221655189991,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04427787661552429,
      "backward_entropy": 0.021490701220252297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.070588111877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054864224046468735,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04419078926245371,
      "backward_entropy": 0.02155582064932043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.382320404052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054905883967876434,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04410471518834432,
      "backward_entropy": 0.021611724387515675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.555755615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05494903773069382,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04401368399461111,
      "backward_entropy": 0.021658411080187016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.499917984008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05499278008937836,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04392040769259135,
      "backward_entropy": 0.02170550281351263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.838444232940674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055033985525369644,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04383491973082224,
      "backward_entropy": 0.02174196189100092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3920369148254395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05507178232073784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0437601904074351,
      "backward_entropy": 0.0012714086439121854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7447409629821777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055107928812503815,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.043690502643585205,
      "backward_entropy": 0.021788778630169956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18668071925640106,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05514184385538101,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04362762967745463,
      "backward_entropy": 0.02183246612548828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7145960330963135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05517233535647392,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04357576370239258,
      "backward_entropy": 0.021870187737725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.370742797851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055201075971126556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04352918267250061,
      "backward_entropy": 0.021919464523142033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.297600746154785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05523059144616127,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.043479859828948975,
      "backward_entropy": 0.021959605542096226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.708837509155273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05526094511151314,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04342744747797648,
      "backward_entropy": 0.02199701558459889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.682912826538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05529124289751053,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04337464769681295,
      "backward_entropy": 0.02203766730698672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.567089080810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055321190506219864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04332280158996582,
      "backward_entropy": 0.022066934542222458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.586132049560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05535462871193886,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043259307742118835,
      "backward_entropy": 0.0012084249915047126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.965754508972168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05538732931017876,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04319805900255839,
      "backward_entropy": 0.022099759091030468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.74209976196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05542052909731865,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04313473403453827,
      "backward_entropy": 0.022109484130685978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.221240997314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05545628070831299,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0430628110965093,
      "backward_entropy": 0.0011828415603800254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.33686637878418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0554933063685894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042986432711283364,
      "backward_entropy": 0.0011758427558974786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9047417640686035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05552958697080612,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04291220009326935,
      "backward_entropy": 0.0011692199517380107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.872649669647217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05556424707174301,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04284307360649109,
      "backward_entropy": 0.02222364463589408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.51731276512146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055597372353076935,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04277863105138143,
      "backward_entropy": 0.022256321527741173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.789590835571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055627886205911636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042722806334495544,
      "backward_entropy": 0.001148101535033096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.707223892211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055657487362623215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04266944030920664,
      "backward_entropy": 0.0011410045183517716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.223955154418945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05568871274590492,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042610431710879006,
      "backward_entropy": 0.0011338923465121877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.97559642791748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05572304502129555,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04254141946633657,
      "backward_entropy": 0.02233989401297136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.42210578918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05575679987668991,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04247373342514038,
      "backward_entropy": 0.022356751290234653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.581422805786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05579208955168724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0424006978670756,
      "backward_entropy": 0.0011122600090774622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.021078109741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055829472839832306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.042320698499679565,
      "backward_entropy": 0.022421010515906593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.760747909545898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05586694926023483,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04224018255869547,
      "backward_entropy": 0.022459390488537876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.694123268127441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055903296917676926,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04216334720452627,
      "backward_entropy": 0.022486582398414612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.642243385314941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05593876168131828,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.042089169224103294,
      "backward_entropy": 0.022510455413298172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587044715881348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0559733584523201,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04201763371626536,
      "backward_entropy": 0.022528400475328617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.401924133300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05600716918706894,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0419485867023468,
      "backward_entropy": 0.02254150401462208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.483280181884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056039419025182724,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04188449184099833,
      "backward_entropy": 0.022553815083070236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.490373611450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05607910454273224,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.041796356439590454,
      "backward_entropy": 0.022562682628631592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.47957992553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056118667125701904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04170843958854675,
      "backward_entropy": 0.022582388736984947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.374105453491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05615894868969917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.041618029276529946,
      "backward_entropy": 0.022609802809628574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.26315689086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05619986727833748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0415253092845281,
      "backward_entropy": 0.02264327352697199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.159453392028809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056241411715745926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041430329283078514,
      "backward_entropy": 0.001035524532198906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.063823699951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056283432990312576,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0413336455821991,
      "backward_entropy": 0.02273138544776223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.058743953704834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05632566660642624,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04123625655968984,
      "backward_entropy": 0.022769965908744118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.78272247314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056365590542554855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04114635040362676,
      "backward_entropy": 0.02280821583487771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0465381145477295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05640693008899689,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04105164359013239,
      "backward_entropy": 0.022847999225963245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.546287536621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056445274502038956,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04096660017967224,
      "backward_entropy": 0.02289300886067477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.034374475479126,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056485023349523544,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04087689518928528,
      "backward_entropy": 0.022930863228711216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72575855255127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05652150884270668,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.040798102815945946,
      "backward_entropy": 0.022954114458777687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.18703842163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05655696615576744,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04072254151105881,
      "backward_entropy": 0.022973504933443935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.430805206298828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05659427493810654,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.040640659630298615,
      "backward_entropy": 0.06301335854963823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.990400314331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056631408631801605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04055915276209513,
      "backward_entropy": 0.000983761115507646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.063380241394043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056669723242521286,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04047377904256185,
      "backward_entropy": 0.023037788542834194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.675326824188232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056708551943302155,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0403865377108256,
      "backward_entropy": 0.023049229925329037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.121219635009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05674514174461365,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.040306697289148964,
      "backward_entropy": 0.023055458610708065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.755019187927246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0567847415804863,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04021711150805155,
      "backward_entropy": 0.02305381406437267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.96063232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056824833154678345,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04012580215930939,
      "backward_entropy": 0.023061660203066738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8150248527526855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056864283978939056,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0400366485118866,
      "backward_entropy": 0.02306830341165716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.460301399230957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056900762021541595,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03995726009209951,
      "backward_entropy": 0.0230771465735002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.033641815185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056935425847768784,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03988368809223175,
      "backward_entropy": 0.02308964187448675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.390681743621826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05697155371308327,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03980531543493271,
      "backward_entropy": 0.023093424060127953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.580809593200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05700582638382912,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03973288337389628,
      "backward_entropy": 0.02309823848984458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.082985877990723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05704007297754288,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03966038922468821,
      "backward_entropy": 0.02310393073342063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.44162368774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05707547441124916,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.039583747585614525,
      "backward_entropy": 0.023128081451762806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8199896812438965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057110656052827835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.039507851004600525,
      "backward_entropy": 0.023147081786935978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.928417205810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0571446493268013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03943556547164917,
      "backward_entropy": 0.023155518553473732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.161030292510986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05718095228075981,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.039355178674062095,
      "backward_entropy": 0.02316008914600719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.11751651763916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05721556767821312,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03928000976641973,
      "backward_entropy": 0.023176464167508213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.073981285095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0572487898170948,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03920917212963104,
      "backward_entropy": 0.023210709745233708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.543540954589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05728216841816902,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.039137626687685646,
      "backward_entropy": 0.023249376903880726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.486103534698486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05731470510363579,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03906866908073425,
      "backward_entropy": 0.0008635787631977688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.445508003234863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057346608489751816,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03900156418482462,
      "backward_entropy": 0.023319331082430752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.540137767791748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05737780034542084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03893661995728811,
      "backward_entropy": 0.0008540116250514984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.762556076049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05740687623620033,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03887854019800822,
      "backward_entropy": 0.023385183377699417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.305191993713379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05743633955717087,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03881894300381342,
      "backward_entropy": 0.02341621301390908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.249453067779541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05746538192033768,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03876050810019175,
      "backward_entropy": 0.023446630347858776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.840378761291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057494230568408966,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.038702428340911865,
      "backward_entropy": 0.023486389355225998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.819960594177246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05752207338809967,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03864741822083791,
      "backward_entropy": 0.02353402159430764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.51519012451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057548873126506805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03859566152095795,
      "backward_entropy": 0.023582011461257935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.071939468383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05757838487625122,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.038534934322039284,
      "backward_entropy": 0.02361213348128579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.610260009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057609762996435165,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.038467747469743095,
      "backward_entropy": 0.0236384624784643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.285871505737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057644184678792953,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03839065134525299,
      "backward_entropy": 0.023649930953979492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.95732307434082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05767839401960373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.038314297795295715,
      "backward_entropy": 0.023660692301663486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.145185470581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05771133676171303,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03824225813150406,
      "backward_entropy": 0.02365803447636691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.844347953796387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057744260877370834,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03817016134659449,
      "backward_entropy": 0.023661022836511784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.787961006164551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057776231318712234,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.038101245959599815,
      "backward_entropy": 0.023660727522589943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.72980260848999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05780746787786484,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03803471972544988,
      "backward_entropy": 0.02366328239440918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890689849853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05783822387456894,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03796958923339844,
      "backward_entropy": 0.02367930520664562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.653195858001709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05786909535527229,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03790400673945745,
      "backward_entropy": 0.023694897239858456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.268595695495605,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05789920315146446,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03784098227818807,
      "backward_entropy": 0.06301243738694624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.551341533660889,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057931676506996155,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03777011235555013,
      "backward_entropy": 0.0007577267560091885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.91089916229248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05796334147453308,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03770196189483007,
      "backward_entropy": 0.02371789108623158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.57133960723877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05799639970064163,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03762920945882797,
      "backward_entropy": 0.0007461416958407922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2027132511138916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058029308915138245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037556921442349754,
      "backward_entropy": 0.0007403812117197297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.440831184387207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05805984139442444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.037492476403713226,
      "backward_entropy": 0.023733848875219173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.23664665222168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05809052661061287,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.037427425384521484,
      "backward_entropy": 0.023749430071223866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30990982055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05811990052461624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03736661374568939,
      "backward_entropy": 0.0007250268350947987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.296747207641602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05814976617693901,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03730402886867523,
      "backward_entropy": 0.023811714215712113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21706485748291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05818072333931923,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0372375026345253,
      "backward_entropy": 0.023858287117697975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.194019317626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058211445808410645,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.037171865502993263,
      "backward_entropy": 0.023887095126238735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.059891700744629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05824605002999306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03709364930788676,
      "backward_entropy": 0.02391915429722179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.979461669921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058281876146793365,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03701149423917135,
      "backward_entropy": 0.06301245906136253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.99144172668457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05831801891326904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03692838052908579,
      "backward_entropy": 0.023989959196610885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8689703941345215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05835259333252907,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03685058653354645,
      "backward_entropy": 0.02400715784593062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.799017906188965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058386754244565964,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03677413364251455,
      "backward_entropy": 0.024023627693002873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.64700698852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05842059105634689,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03669863442579905,
      "backward_entropy": 0.02404414252801375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.461101531982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058454759418964386,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.036622087160746254,
      "backward_entropy": 0.024062644351612438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.600776195526123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0584898516535759,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.036542716125647225,
      "backward_entropy": 0.02407397465272383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8157308101654053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05852443352341652,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.036465066174666085,
      "backward_entropy": 0.024086033756082707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7898635864257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05855710431933403,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0363935778538386,
      "backward_entropy": 0.024099501696499912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.06573486328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0585879310965538,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03632810960213343,
      "backward_entropy": 0.02410757541656494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.978041648864746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05862007290124893,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036258503794670105,
      "backward_entropy": 0.000659430187872865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6921679973602295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058653268963098526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.036185652017593384,
      "backward_entropy": 0.024117093194614758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.444040775299072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05868461728096008,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.036118740836779274,
      "backward_entropy": 0.024117044427178123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.46071720123291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058714982122182846,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.036055028438568115,
      "backward_entropy": 0.024114256555383854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8634257316589355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058747392147779465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03598471979300181,
      "backward_entropy": 0.024114559997211803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.77143669128418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05877699702978134,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03592358777920405,
      "backward_entropy": 0.024096190929412842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.705541610717773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05880742147564888,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03585983067750931,
      "backward_entropy": 0.0006270787932656028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.922129154205322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05883839353919029,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.035794282952944435,
      "backward_entropy": 0.024089352651075882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7835139036178589,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05886918678879738,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03572928160429001,
      "backward_entropy": 0.024092378941449253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.52469253540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05889776349067688,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.035671321054299675,
      "backward_entropy": 0.024101728742772884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.084823131561279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058929137885570526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03560453156630198,
      "backward_entropy": 0.024110821160403164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.750190258026123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05895955488085747,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.035540834069252014,
      "backward_entropy": 0.024120970205827194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.99439811706543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05898749828338623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03548505405584971,
      "backward_entropy": 0.0005978668447245251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.20317268371582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05901499092578888,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03543060521284739,
      "backward_entropy": 0.024130672216415405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.311411142349243,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059043433517217636,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03537308176358541,
      "backward_entropy": 0.024151720783927223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2815797328948975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05907048285007477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03531994173924128,
      "backward_entropy": 0.024172113700346512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6774981021881104,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05909638851881027,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03527033825715383,
      "backward_entropy": 0.06300828131762418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.385134696960449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059120386838912964,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.035226707657178245,
      "backward_entropy": 0.02422160722992637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.916351318359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05914488434791565,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03518145531415939,
      "backward_entropy": 0.0005737475796856663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.288714408874512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05917012318968773,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03513364990552267,
      "backward_entropy": 0.02425854043527083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.706145763397217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05919583514332771,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.035084317127863564,
      "backward_entropy": 0.024280615828254005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.670747756958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05922110378742218,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03503626585006714,
      "backward_entropy": 0.024304010651328346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6292033195495605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05924597010016441,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03498941163221995,
      "backward_entropy": 0.02432783083482222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.596747875213623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05927068740129471,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034942892690499626,
      "backward_entropy": 0.02436467463319952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.069350242614746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059295207262039185,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03489682078361511,
      "backward_entropy": 0.024409773674878208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.012460708618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05931880325078964,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03485358754793803,
      "backward_entropy": 0.02445746280930259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.928208351135254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059343088418245316,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03480799744526545,
      "backward_entropy": 0.024518646977164528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.464696884155273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05936901643872261,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034757221738497414,
      "backward_entropy": 0.024574315006082707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.437880992889404,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.059394530951976776,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03470758597056071,
      "backward_entropy": 0.06301204724745317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.390775203704834,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05941944569349289,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03465978801250458,
      "backward_entropy": 0.06301235068928111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.369290351867676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05944418907165527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03461232781410217,
      "backward_entropy": 0.0005375921133566986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.17506217956543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05946844071149826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03456625590721766,
      "backward_entropy": 0.024783459576693447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.892871379852295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05949358642101288,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034517399966716766,
      "backward_entropy": 0.024828060106797653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.465301513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05951756611466408,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034472095469633736,
      "backward_entropy": 0.024867583404887806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.618303298950195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05954305827617645,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034421982864538826,
      "backward_entropy": 0.024900864471088757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.191276550292969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05956872180104256,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034371244410673775,
      "backward_entropy": 0.02493489601395347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.799854040145874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05959402769804001,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03432148198286692,
      "backward_entropy": 0.024977174672213467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.488777160644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05961817502975464,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034275258580843605,
      "backward_entropy": 0.025016616691242565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.122278213500977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0596424899995327,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034228419264157615,
      "backward_entropy": 0.02504856207154014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.057840347290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05966847389936447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034176324804623924,
      "backward_entropy": 0.02508848634633151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07255058735609055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05969402939081192,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034125469624996185,
      "backward_entropy": 0.025134178725155918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.690006732940674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05971701070666313,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034082502126693726,
      "backward_entropy": 0.02517045627940785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.276123523712158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05973903089761734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03404243290424347,
      "backward_entropy": 0.025204132903705944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2368011474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05976137891411781,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0340012659629186,
      "backward_entropy": 0.06301331520080566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.047002792358398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05978401377797127,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03395915528138479,
      "backward_entropy": 0.0252555175261064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1486358642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05980868637561798,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.033910791079203285,
      "backward_entropy": 0.025266709652814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5833680629730225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059833504259586334,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0338619202375412,
      "backward_entropy": 0.02527938105843284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8215010166168213,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.059857212007045746,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03381637980540594,
      "backward_entropy": 0.0630133802240545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.259152889251709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05988030135631561,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03377272188663483,
      "backward_entropy": 0.025298221544785934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.435110092163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05990436300635338,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.033726061383883156,
      "backward_entropy": 0.0253090424971147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.713121175765991,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059929922223091125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.033674776554107666,
      "backward_entropy": 0.02532646601850336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6841695308685303,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059954967349767685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.033625051379203796,
      "backward_entropy": 0.025348890911449085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.439702033996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05997944250702858,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.033576992650826774,
      "backward_entropy": 0.02537060867656361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35781478881836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06000586226582527,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03352305789788564,
      "backward_entropy": 0.06301330436359752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5793826580047607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06003406271338463,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.033463917672634125,
      "backward_entropy": 0.02541853352026506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5441293716430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06006140261888504,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03340740998586019,
      "backward_entropy": 0.025445398959246548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.514042377471924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06008795648813248,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03335322936375936,
      "backward_entropy": 0.025473264130679043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.481046199798584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06011369451880455,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.033301579455534615,
      "backward_entropy": 0.025495718825947155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.964105606079102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06013868749141693,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03325217465559641,
      "backward_entropy": 0.02551447261463512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.527655124664307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0601654089987278,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03319770594437917,
      "backward_entropy": 0.025530525229193947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.382946014404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06019198149442673,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03314368178447088,
      "backward_entropy": 0.025550609285181217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.449019908905029,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06021765246987343,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0330924466252327,
      "backward_entropy": 0.025565036318518898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3055994510650635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06024301052093506,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0330422098437945,
      "backward_entropy": 0.025569823655215176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2800498008728027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06026787310838699,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03299337128798167,
      "backward_entropy": 0.025587767362594604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1898293495178223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06029212847352028,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032946303486824036,
      "backward_entropy": 0.025607453151182694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.164389133453369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06031513214111328,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03290296842654546,
      "backward_entropy": 0.025621034882285378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1947133541107178,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06033715605735779,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032862454652786255,
      "backward_entropy": 0.02563939040357416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.169503688812256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06035878509283066,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03282304604848226,
      "backward_entropy": 0.0004327889447185126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.192285537719727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060380008071660995,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03278482457002004,
      "backward_entropy": 0.025671712376854637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.072677731513977,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.060402192175388336,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.032743712266286217,
      "backward_entropy": 0.06301291964270851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.084129571914673,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0604228675365448,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032706928749879204,
      "backward_entropy": 0.02571977268565785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0533158779144287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06044335663318634,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03267063945531845,
      "backward_entropy": 0.02574962106618014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0425848960876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060463182628154755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032636143267154694,
      "backward_entropy": 0.025788399306210606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.030644416809082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06048225983977318,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03260374069213867,
      "backward_entropy": 0.025825346058065243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9744062423706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06050056219100952,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0325735608736674,
      "backward_entropy": 0.025855002078143032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.835914134979248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060519326478242874,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032541945576667786,
      "backward_entropy": 0.025879369540648026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0099209547042847,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06054071709513664,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0325027604897817,
      "backward_entropy": 0.025898031213066795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9197211265563965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06056074798107147,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032467362781365715,
      "backward_entropy": 0.025926308198408646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.953262209892273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06058051809668541,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0324326828122139,
      "backward_entropy": 0.025952948765321213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.869351387023926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06059933081269264,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03240080177783966,
      "backward_entropy": 0.025968107310208408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7830615043640137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0606180839240551,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03236893812815348,
      "backward_entropy": 0.02598876031962308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.679495334625244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060637254267930984,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03233580539623896,
      "backward_entropy": 0.026009746573188088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.728315591812134,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0606573149561882,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032300107181072235,
      "backward_entropy": 0.02602972767569802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7811484336853027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060677420347929,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032264262437820435,
      "backward_entropy": 0.02603512460535223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.566507816314697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06069713458418846,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032229540248711906,
      "backward_entropy": 0.026034108617089012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.625304698944092,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06071743741631508,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03219317893187205,
      "backward_entropy": 0.00038887966762889516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.475864887237549,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060737885534763336,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03215636809666952,
      "backward_entropy": 0.02600715918974443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8006895780563354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06075906381011009,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032117463648319244,
      "backward_entropy": 0.025996628132733433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.78281569480896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06077927350997925,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03208120912313461,
      "backward_entropy": 0.025989554145119408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0773844718933105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060798659920692444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03204732884963354,
      "backward_entropy": 0.025988849726590244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.605095148086548,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06081991642713547,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03200817108154297,
      "backward_entropy": 0.02599071372639049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.734201192855835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06084069982171059,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031970361868540444,
      "backward_entropy": 0.025993417609821667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.389230489730835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06086055561900139,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0319351131717364,
      "backward_entropy": 0.025997963818636807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.528337001800537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06088078394532204,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031898741920789085,
      "backward_entropy": 0.026014103130860763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6844251155853271,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06090080365538597,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03186294684807459,
      "backward_entropy": 0.02603955160487782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.114593029022217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06092004477977753,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03182928760846456,
      "backward_entropy": 0.026069237427278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6570956707000732,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060940101742744446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03179331372181574,
      "backward_entropy": 0.026100077412345192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.041990280151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060959234833717346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03175989786783854,
      "backward_entropy": 0.02612641995603388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.416830539703369,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06097908690571785,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.031724477807680763,
      "backward_entropy": 0.0630117654800415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1812570095062256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060998640954494476,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031689852476119995,
      "backward_entropy": 0.026174637404355137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.704911708831787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061018362641334534,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0316547155380249,
      "backward_entropy": 0.02619805390184576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.659545421600342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06103932112455368,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03161612153053284,
      "backward_entropy": 0.02622531218962236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3251454830169678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06106129661202431,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03157480557759603,
      "backward_entropy": 0.0262492759661241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3019840717315674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06108264625072479,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03153521319230398,
      "backward_entropy": 0.026270963928916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2762515544891357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06110338494181633,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03149733444054922,
      "backward_entropy": 0.02628811381079934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7700914740562439,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061123646795749664,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031460766990979515,
      "backward_entropy": 0.02630676193670793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.425925254821777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06114273518323898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03142736852169037,
      "backward_entropy": 0.026342782107266514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9297921657562256,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06116299331188202,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0313907265663147,
      "backward_entropy": 0.06301271915435791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1860690116882324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06118343025445938,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031353533267974854,
      "backward_entropy": 0.02641714702952992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8765199184417725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061203427612781525,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03131755689779917,
      "backward_entropy": 0.02645752646706321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.25654411315918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06122339889407158,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031281655033429466,
      "backward_entropy": 0.026489962231029163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.122750997543335,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061244141310453415,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031243736545244854,
      "backward_entropy": 0.026502771811051803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.156597137451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06126426160335541,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031207529207070667,
      "backward_entropy": 0.026509910821914673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.110062122344971,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06128544360399246,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031168421109517414,
      "backward_entropy": 0.026523403146050194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3784047365188599,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06130756437778473,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031126844386259716,
      "backward_entropy": 0.02654317021369934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3631242513656616,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06132853031158447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031088364621003468,
      "backward_entropy": 0.026565280827608975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.25994873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06134844943881035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031052735944588978,
      "backward_entropy": 0.026589155197143555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6286418437957764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061371639370918274,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031008467078208923,
      "backward_entropy": 0.026606752113862472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2391042709350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06139448285102844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030965228875478108,
      "backward_entropy": 0.026624013077129017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9341490268707275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06141737103462219,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030922003090381622,
      "backward_entropy": 0.026633360169150612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.161062717437744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061439357697963715,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030881280700365703,
      "backward_entropy": 0.026635969227010555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6480831503868103,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06146136298775673,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030840521057446797,
      "backward_entropy": 0.02662722630934282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8597972393035889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06148182973265648,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030803886552651722,
      "backward_entropy": 0.02662959153001959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2361127138137817,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06150177866220474,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030768637855847675,
      "backward_entropy": 0.026639011773196133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2238860130310059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06152082234621048,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030735755960146587,
      "backward_entropy": 0.02665680917826566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9769046306610107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06153900548815727,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030705104271570843,
      "backward_entropy": 0.026677795431830666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7802908420562744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061557818204164505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030672801037629444,
      "backward_entropy": 0.026704251766204834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0687642097473145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061576250940561295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03064146141211192,
      "backward_entropy": 0.00030480532652952456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.602569580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06159606948494911,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.030606473485628765,
      "backward_entropy": 0.026758128946477718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.542465686798096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06161446124315262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03057526300350825,
      "backward_entropy": 0.0003018235279755159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8166773319244385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06163463369011879,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03053947041432063,
      "backward_entropy": 0.02680760622024536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.236603021621704,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06165509298443794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0305029700199763,
      "backward_entropy": 0.026829454031857578,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.548986127898097,
    "avg_log_Z": -0.06062280233949423,
    "success_rate": 1.0,
    "avg_reward": 12.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.06,
      "1": 0.9,
      "2": 0.04
    },
    "avg_forward_entropy": 0.03238063509265581,
    "avg_backward_entropy": 0.027112805404785004,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}