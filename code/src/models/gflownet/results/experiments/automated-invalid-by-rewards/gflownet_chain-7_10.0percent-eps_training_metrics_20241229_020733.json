{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09875077860695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.0988594378743853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.25048828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724616169929504,
      "backward_entropy": 0.09885399682181222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.65147399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372469812631607,
      "backward_entropy": 0.09875456775937762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.16082763671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0001999767409870401,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724765181541443,
      "backward_entropy": 0.09887080533163888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.5631561279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0002999766147695482,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724815845489502,
      "backward_entropy": 0.09887592281614031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.3697509765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003999528125859797,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372484713792801,
      "backward_entropy": 0.09888093812125069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.454833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00050048076082021,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724859058856964,
      "backward_entropy": 0.0987694604056222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.9912109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006011446239426732,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724853098392487,
      "backward_entropy": 0.09886045115334648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.81219482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000701439450494945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724830746650696,
      "backward_entropy": 0.0988614388874599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.04840087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008019099477678537,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724790513515472,
      "backward_entropy": 0.09886243513652257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.27874755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009015005198307335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724735379219055,
      "backward_entropy": 0.0988633462360927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.3441162109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0010014810832217336,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724660873413086,
      "backward_entropy": 0.0989081859588623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.37742614746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011018429649993777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724565505981445,
      "backward_entropy": 0.09886518546513148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.4507598876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011991990031674504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724452257156372,
      "backward_entropy": 0.09879423039300102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.0637512207031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012962640030309558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724321126937866,
      "backward_entropy": 0.09879721914018903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.77587890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013947449624538422,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724172115325928,
      "backward_entropy": 0.09892306157520839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.54698181152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014933510683476925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724006712436676,
      "backward_entropy": 0.09886811460767474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.01153564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001589946448802948,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372382938861847,
      "backward_entropy": 0.09886879580361503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.10357666015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016838278388604522,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723652064800262,
      "backward_entropy": 0.09893292188644409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.06455993652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017785436939448118,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723456859588623,
      "backward_entropy": 0.09893596172332764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.3624267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018739786464720964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372324526309967,
      "backward_entropy": 0.09887044770377022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.05467224121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019687272142618895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723018765449524,
      "backward_entropy": 0.09887093305587769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.29470825195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002062231535091996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722777366638184,
      "backward_entropy": 0.09881780828748431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.70578002929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002155337017029524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372252106666565,
      "backward_entropy": 0.09881989445005145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.0683898925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002248045289888978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722243905067444,
      "backward_entropy": 0.09882189546312604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.31622314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002343151718378067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372193992137909,
      "backward_entropy": 0.09887221881321498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.97637939453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002439824864268303,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721612095832825,
      "backward_entropy": 0.09895467758178711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.3878173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025363867171108723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372126042842865,
      "backward_entropy": 0.09882819652557373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.90509033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026304731145501137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720908761024475,
      "backward_entropy": 0.09887308733803886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.87014770507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027247988618910313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720545172691345,
      "backward_entropy": 0.0988318920135498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1110076904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00281934579834342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720163702964783,
      "backward_entropy": 0.09887338536126274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.13885498046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002912450348958373,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719788193702698,
      "backward_entropy": 0.09887346199580602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.27305603027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003002854762598872,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371939778327942,
      "backward_entropy": 0.0989675521850586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.5771942138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003092603525146842,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718989491462708,
      "backward_entropy": 0.09887324912207467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.08438110351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003181564388796687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371857225894928,
      "backward_entropy": 0.09883941071374076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.902587890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032687627244740725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371816247701645,
      "backward_entropy": 0.09887291703905378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.93328857421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003357882844284177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717734813690186,
      "backward_entropy": 0.09887276376996722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.93997192382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003446246264502406,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13717299699783325,
      "backward_entropy": 0.09897564138684954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.8926544189453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035365764051675797,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716842234134674,
      "backward_entropy": 0.09897718259266444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.16912841796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036275917664170265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716372847557068,
      "backward_entropy": 0.09897875785827637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.81906127929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003716958686709404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715903460979462,
      "backward_entropy": 0.09887208257402692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.56475830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003806719556450844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13715410232543945,
      "backward_entropy": 0.09884703159332275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.75546264648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003896542591974139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714908063411713,
      "backward_entropy": 0.09887160573686872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.16812133789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00398511067032814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371438056230545,
      "backward_entropy": 0.09887124810900007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.2473907470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004074141848832369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713836669921875,
      "backward_entropy": 0.09887087345123291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.8743896484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0041637541726231575,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371326446533203,
      "backward_entropy": 0.09898694923945836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.60739135742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004254578147083521,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13712674379348755,
      "backward_entropy": 0.09898817539215088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.9501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004347297362983227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712060451507568,
      "backward_entropy": 0.0988516126360212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.72828674316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00443823030218482,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711440563201904,
      "backward_entropy": 0.0989903552191598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.43243408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004525455180555582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13710828125476837,
      "backward_entropy": 0.09885262591498238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.60994720458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00461206678301096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371021866798401,
      "backward_entropy": 0.09885298354285103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.55226135253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00469332467764616,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709624111652374,
      "backward_entropy": 0.09899279049464635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1934051513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0047766841016709805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370900720357895,
      "backward_entropy": 0.09885327305112566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.7322540283203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004857184365391731,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370839625597,
      "backward_entropy": 0.09899425506591797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.19769287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004939021077007055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707758486270905,
      "backward_entropy": 0.09885341780526298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.87155151367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005023852922022343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707095384597778,
      "backward_entropy": 0.09886460644858223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.58999633789062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005106668453663588,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706429302692413,
      "backward_entropy": 0.09899636677333287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.52764892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00518865417689085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705754280090332,
      "backward_entropy": 0.09885357958929879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.68275451660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0052712163887917995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705050945281982,
      "backward_entropy": 0.098853485924857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.53529357910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005351845175027847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704350590705872,
      "backward_entropy": 0.09885317938668388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.2361297607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005433924030512571,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370362937450409,
      "backward_entropy": 0.09885282175881523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.31187438964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005518243182450533,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370287835597992,
      "backward_entropy": 0.09899930443082537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 292.5220947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005604736506938934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702094554901123,
      "backward_entropy": 0.0988521831376212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.27630615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005696421023458242,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137012779712677,
      "backward_entropy": 0.09885893549237933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.4097900390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00578621681779623,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700464367866516,
      "backward_entropy": 0.09885835647583008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.4925537109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005873162765055895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13699661195278168,
      "backward_entropy": 0.09900162901197161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.1662292480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005961758084595203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698828220367432,
      "backward_entropy": 0.09885080371584211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.31410217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006054584868252277,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13697953522205353,
      "backward_entropy": 0.09885661091123309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.43641662597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0061462800949811935,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697072863578796,
      "backward_entropy": 0.0990032468523298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.05191040039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0062378342263400555,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13696184754371643,
      "backward_entropy": 0.09900375774928502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.56130981445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006326809525489807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695289194583893,
      "backward_entropy": 0.09885458435331072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.7804260253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006418250966817141,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13694360852241516,
      "backward_entropy": 0.09885379246303014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.4482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006512862164527178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693375885486603,
      "backward_entropy": 0.0988484535898481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.3637237548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00660236831754446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369241327047348,
      "backward_entropy": 0.09884801932743617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.4906005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006692157126963139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691432774066925,
      "backward_entropy": 0.09885111025401525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.84580993652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006780351512134075,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13690437376499176,
      "backward_entropy": 0.09900639738355364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.67430114746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006869081407785416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368941366672516,
      "backward_entropy": 0.09884658030101232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.76976013183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006957418750971556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13688379526138306,
      "backward_entropy": 0.09884815556662423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.26451110839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0070463004522025585,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136873260140419,
      "backward_entropy": 0.09900757244655065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.88726806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007128217723220587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136863112449646,
      "backward_entropy": 0.09884590762002128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.26693725585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0072094714269042015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685278594493866,
      "backward_entropy": 0.0988445622580392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.12177276611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00728769414126873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368425488471985,
      "backward_entropy": 0.0988431487764631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.90972900390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00736222742125392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683246076107025,
      "backward_entropy": 0.09884167569024223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.76361083984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00743709085509181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13682204484939575,
      "backward_entropy": 0.09884051765714373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.27476501464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007512078154832125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13681136071681976,
      "backward_entropy": 0.09883935110909599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1525421142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007585658226162195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368006467819214,
      "backward_entropy": 0.09883677959442139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.45155334472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0076586720533668995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367896944284439,
      "backward_entropy": 0.09883499145507812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.6411895751953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007733291946351528,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13677829504013062,
      "backward_entropy": 0.09900930949619838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1780242919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007808132097125053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676665723323822,
      "backward_entropy": 0.09883131299700056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.10272216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00788084976375103,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13675503432750702,
      "backward_entropy": 0.0988293034689767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.10552978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007957239635288715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13674281537532806,
      "backward_entropy": 0.09882737909044538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.6318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008033808320760727,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13673032820224762,
      "backward_entropy": 0.09882536956242152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.27493286132812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008110650815069675,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367175281047821,
      "backward_entropy": 0.09900980336325509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.5836639404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00818804930895567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670434057712555,
      "backward_entropy": 0.09882773671831403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.4212188720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008269717916846275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366906464099884,
      "backward_entropy": 0.09881932394845146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.52955627441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008355004712939262,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366765946149826,
      "backward_entropy": 0.09901012693132673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.80909729003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00844297744333744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13666199147701263,
      "backward_entropy": 0.09882448400769915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.3223114013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008533068932592869,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13664691150188446,
      "backward_entropy": 0.0988142830984933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.1585693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008625146932899952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13663136959075928,
      "backward_entropy": 0.0988227299281529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.80335998535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008718813769519329,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13661542534828186,
      "backward_entropy": 0.09881115811211723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.01995849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008807525038719177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659974932670593,
      "backward_entropy": 0.09882082257952009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.78285217285156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008893935941159725,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365841031074524,
      "backward_entropy": 0.09901109763554164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.03546142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008980506099760532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656818866729736,
      "backward_entropy": 0.09881830215454102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3082733154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009068557992577553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13655178248882294,
      "backward_entropy": 0.09881715263639178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.00531005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009153309278190136,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13653552532196045,
      "backward_entropy": 0.0988031370299203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.30194091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009236383251845837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365191638469696,
      "backward_entropy": 0.09880140849522182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.3487548828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009320298209786415,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13650238513946533,
      "backward_entropy": 0.09901154892785209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.30726623535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00940687395632267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364850401878357,
      "backward_entropy": 0.09879813875470843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.0261993408203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009493252262473106,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13646750152111053,
      "backward_entropy": 0.09901175328663417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.00714111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009578988887369633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13644973933696747,
      "backward_entropy": 0.0987949115889413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.86236572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009661476127803326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13643214106559753,
      "backward_entropy": 0.09880900382995605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.3546905517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00974451843649149,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13641420006752014,
      "backward_entropy": 0.09901189804077148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.60098266601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00982719101011753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13639602065086365,
      "backward_entropy": 0.09878880637032646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.69459533691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009911884553730488,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363772302865982,
      "backward_entropy": 0.09901195764541626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.59779357910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009999539703130722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635769486427307,
      "backward_entropy": 0.09880339247839791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.08058166503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010086966678500175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363377571105957,
      "backward_entropy": 0.09878179856709071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.72930908203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010173395276069641,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13631770014762878,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6321258544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010260216891765594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362972855567932,
      "backward_entropy": 0.09879962035587855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.4490509033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010343501344323158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13627716898918152,
      "backward_entropy": 0.0987979599407741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.48789978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010431844741106033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13625597953796387,
      "backward_entropy": 0.09879657200404576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.43545532226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010516210459172726,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13623499870300293,
      "backward_entropy": 0.09901220457894462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.94212341308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010601001791656017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13621366024017334,
      "backward_entropy": 0.09901220457894462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.81292724609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010687261819839478,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13619180023670197,
      "backward_entropy": 0.09901222160884313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.3190155029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010771678760647774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13616988062858582,
      "backward_entropy": 0.0987609795161656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.51927185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01085555087774992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13614772260189056,
      "backward_entropy": 0.09878805705479213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.94151306152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010939352214336395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13612517714500427,
      "backward_entropy": 0.09878626040049962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.101806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011027103289961815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13610167801380157,
      "backward_entropy": 0.09878461701529366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.33016967773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011112775653600693,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13607817888259888,
      "backward_entropy": 0.09901222160884313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.4633331298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011200178414583206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13605402410030365,
      "backward_entropy": 0.09878100667681013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.42420959472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011285442858934402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360299289226532,
      "backward_entropy": 0.0987790482384818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.82461547851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01136879064142704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13600583374500275,
      "backward_entropy": 0.09877688544137138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.71160888671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011450318619608879,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13598167896270752,
      "backward_entropy": 0.09901211942945208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.81756591796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011528980918228626,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359577625989914,
      "backward_entropy": 0.09901201725006104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.24651336669922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011607542634010315,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13593348860740662,
      "backward_entropy": 0.09901191507066999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.10550689697266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011680291034281254,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13590994477272034,
      "backward_entropy": 0.09901174477168492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.13217163085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01174990925937891,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13588666915893555,
      "backward_entropy": 0.09872141906193324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.46307373046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011820274405181408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13586291670799255,
      "backward_entropy": 0.09875905513763428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.39996337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011892247013747692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13583852350711823,
      "backward_entropy": 0.09875552994864327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.71563720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01196763664484024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13581304252147675,
      "backward_entropy": 0.09870895317622594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.95012664794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012041248381137848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13578751683235168,
      "backward_entropy": 0.09870465312685285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.60433959960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012111671268939972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357622891664505,
      "backward_entropy": 0.09874525240489415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.25961303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01217955444008112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13573719561100006,
      "backward_entropy": 0.09874139513288226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.7025146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012245486490428448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13571211695671082,
      "backward_entropy": 0.09869010959352766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.92140197753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012310843914747238,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1356867551803589,
      "backward_entropy": 0.09900954791477748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.71524047851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012372776865959167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13566210865974426,
      "backward_entropy": 0.0986792870930263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.40350341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012439917773008347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13563694059848785,
      "backward_entropy": 0.09872494425092425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.6749725341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012508504092693329,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13561075925827026,
      "backward_entropy": 0.09866892439978463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.75653076171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012578076682984829,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13558343052864075,
      "backward_entropy": 0.099008389881679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.1497802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012648765929043293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355552077293396,
      "backward_entropy": 0.09865888527461461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.6937255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012720361351966858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13552621006965637,
      "backward_entropy": 0.0987086466380528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.73602294921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012796657159924507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354956328868866,
      "backward_entropy": 0.09864932298660278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.01150512695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012871074490249157,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13546496629714966,
      "backward_entropy": 0.09900777680533272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.09127807617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012948566116392612,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13543309271335602,
      "backward_entropy": 0.09900772571563721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.49180603027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013025246560573578,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354008913040161,
      "backward_entropy": 0.09863534995487758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.97901916503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013099807314574718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1353687196969986,
      "backward_entropy": 0.09863034316471644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.71339416503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01317642256617546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1353355497121811,
      "backward_entropy": 0.09862535340445382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.24874877929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013247452676296234,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13530327379703522,
      "backward_entropy": 0.09900714669908796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.89401245117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01332457922399044,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13526901602745056,
      "backward_entropy": 0.09900706154959542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.01605224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013399668037891388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352347731590271,
      "backward_entropy": 0.09860891103744507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.46771240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013478979468345642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13519898056983948,
      "backward_entropy": 0.09866734913417272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.52548217773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013557665050029755,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1351628303527832,
      "backward_entropy": 0.09900684016091484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.63882446289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013637805357575417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13512581586837769,
      "backward_entropy": 0.09859342234475273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.06964111328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013718202710151672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13508814573287964,
      "backward_entropy": 0.09865471294948033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.6084442138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01379744429141283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13505032658576965,
      "backward_entropy": 0.0986501659665789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.1082000732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01387854851782322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350114643573761,
      "backward_entropy": 0.09864580631256104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.73822784423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013961942866444588,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.134971484541893,
      "backward_entropy": 0.09900670392172677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.20636749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014041625894606113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349320411682129,
      "backward_entropy": 0.09863655907767159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.5533905029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014113632962107658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13489431142807007,
      "backward_entropy": 0.09855888571058001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.9836883544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014187723398208618,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13485532999038696,
      "backward_entropy": 0.09855214187077113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.83811950683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014265083707869053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13481482863426208,
      "backward_entropy": 0.09854561941964286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.10498046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014346644282341003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13477247953414917,
      "backward_entropy": 0.09861368792397636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.09706115722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014424800872802734,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347302943468094,
      "backward_entropy": 0.09900563955307007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.8125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014503478072583675,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13468626141548157,
      "backward_entropy": 0.09900539261954171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.2818603515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014583699405193329,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13464057445526123,
      "backward_entropy": 0.0990051201411656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.2457275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014660319313406944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345951110124588,
      "backward_entropy": 0.09851247923714775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.82345581054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014738823287189007,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13454806804656982,
      "backward_entropy": 0.09900435379573277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.1895294189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014821359887719154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13449883460998535,
      "backward_entropy": 0.09857560907091413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.60104370117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014908866956830025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1344470977783203,
      "backward_entropy": 0.09849292891366142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.26608276367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014997247606515884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13439422845840454,
      "backward_entropy": 0.0984870195388794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.42929077148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01508746575564146,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13433994352817535,
      "backward_entropy": 0.09900377477918353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.7937469482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015172981657087803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13428646326065063,
      "backward_entropy": 0.0984745877129691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.46743774414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015257229097187519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13423259556293488,
      "backward_entropy": 0.09854374613080706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.07647705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015339890494942665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341785341501236,
      "backward_entropy": 0.0985360997063773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.74815368652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015425234101712704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13412266969680786,
      "backward_entropy": 0.09852882793971471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.179443359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01551030296832323,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13406610488891602,
      "backward_entropy": 0.09844596045357841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.56671142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015598971396684647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13400739431381226,
      "backward_entropy": 0.0984392421586173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.7866973876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015688538551330566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13394752144813538,
      "backward_entropy": 0.0984324642590114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.2731170654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01577858068048954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13388662040233612,
      "backward_entropy": 0.09842557566506523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.99942016601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01586916483938694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1338246464729309,
      "backward_entropy": 0.0984938655580793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.97430419921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01596151292324066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13376113772392273,
      "backward_entropy": 0.0984870535986764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.2519073486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016053946688771248,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13369670510292053,
      "backward_entropy": 0.09840568474360875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.13999938964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01614784449338913,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13363081216812134,
      "backward_entropy": 0.09900171416146415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.16156005859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0162355899810791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1335666924715042,
      "backward_entropy": 0.0984647274017334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.86605834960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016321299597620964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1335025429725647,
      "backward_entropy": 0.09845596551895142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.26095581054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01640648953616619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13343773782253265,
      "backward_entropy": 0.09844681194850377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.84884643554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016492852941155434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13337154686450958,
      "backward_entropy": 0.09836618389402117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.8953857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01657886430621147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13330486416816711,
      "backward_entropy": 0.09842867510659355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.12144470214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016659507527947426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13323988020420074,
      "backward_entropy": 0.09834757872990199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.49940490722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016735780984163284,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13317617774009705,
      "backward_entropy": 0.09899829115186419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.6844482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016814282163977623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13311058282852173,
      "backward_entropy": 0.09839694840567452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.17425537109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016893481835722923,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1330438256263733,
      "backward_entropy": 0.09899686064038958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.84449768066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016971655189990997,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13297662138938904,
      "backward_entropy": 0.09830632380076818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.17559051513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017053913325071335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13290631771087646,
      "backward_entropy": 0.09829717023032052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.80140686035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017132295295596123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328369826078415,
      "backward_entropy": 0.09828698635101318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.72515869140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017212266102433205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13276582956314087,
      "backward_entropy": 0.09834155866077968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.64434814453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017292698845267296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13269348442554474,
      "backward_entropy": 0.09826381717409406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.7646484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017373552545905113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326199322938919,
      "backward_entropy": 0.09831854275294713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.66322326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01745225302875042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325465738773346,
      "backward_entropy": 0.098306485584804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.34800720214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017530009150505066,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13247260451316833,
      "backward_entropy": 0.09899074690682548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.18614196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01760546676814556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13239885866641998,
      "backward_entropy": 0.0982802425112043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.1799774169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017678452655673027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13232557475566864,
      "backward_entropy": 0.09819788592202323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.3650665283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017753636464476585,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13225004076957703,
      "backward_entropy": 0.09818402358463832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.35443115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017828254029154778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13217377662658691,
      "backward_entropy": 0.09823848520006452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.98452758789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01790658012032509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13209447264671326,
      "backward_entropy": 0.09815694604601179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.09808349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01798478700220585,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13201406598091125,
      "backward_entropy": 0.09814314331327166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.956787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01806514337658882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13193151354789734,
      "backward_entropy": 0.09812911919185094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.51463317871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018146226182579994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13184815645217896,
      "backward_entropy": 0.09818454299654279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.1481475830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018230486661195755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13176265358924866,
      "backward_entropy": 0.09810153075626918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.52247619628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01831253431737423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1316775679588318,
      "backward_entropy": 0.09815985815865653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.52738189697266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018393700942397118,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13159199059009552,
      "backward_entropy": 0.09898265770503453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.495361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01846853829920292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13150927424430847,
      "backward_entropy": 0.09813122238431658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.41864013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018542643636465073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1314258575439453,
      "backward_entropy": 0.09811481407710484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.32571411132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018614862114191055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13134248554706573,
      "backward_entropy": 0.0980185866355896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.12078857421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018689896911382675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13125641644001007,
      "backward_entropy": 0.09800124168395996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.6700439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018764786422252655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13116945326328278,
      "backward_entropy": 0.09806421824863978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.84681701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01883719488978386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1310831755399704,
      "backward_entropy": 0.0979650786944798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.8863525390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018913406878709793,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13099341094493866,
      "backward_entropy": 0.09794836384909493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.32113647460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018993264064192772,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1309019923210144,
      "backward_entropy": 0.09897489207131523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.21527099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019069915637373924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13081176578998566,
      "backward_entropy": 0.09799981117248535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.11329650878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01914762705564499,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13071981072425842,
      "backward_entropy": 0.0989734445299421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.45123291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019223595038056374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13062793016433716,
      "backward_entropy": 0.09796656029564994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.35537719726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019300589337944984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1305343210697174,
      "backward_entropy": 0.09794941118785314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.35614013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019378511235117912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13043901324272156,
      "backward_entropy": 0.0979322109903608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.2673797607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019456040114164352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13034293055534363,
      "backward_entropy": 0.09791472128459386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.3681182861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019533220678567886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13024494051933289,
      "backward_entropy": 0.09789703573499407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.38128662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01961243897676468,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13014335930347443,
      "backward_entropy": 0.09780293703079224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.66433715820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01969226263463497,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1300395131111145,
      "backward_entropy": 0.09778632436479841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.7532958984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019767414778470993,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1299375742673874,
      "backward_entropy": 0.0989678246634347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.0710906982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01983860321342945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1298372745513916,
      "backward_entropy": 0.0978215251650129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.2967987060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019909748807549477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12973546981811523,
      "backward_entropy": 0.0977993266923087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.88320922851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019979853183031082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12963315844535828,
      "backward_entropy": 0.09777649811335973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.10118103027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020050035789608955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12952926754951477,
      "backward_entropy": 0.09775277546473912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.11264038085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020120777189731598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1294238120317459,
      "backward_entropy": 0.09772908687591553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.11180114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020191427320241928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12931688129901886,
      "backward_entropy": 0.09763870920453753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.96363830566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02026134915649891,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12920701503753662,
      "backward_entropy": 0.0976796065058027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.61341857910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020334487780928612,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12909278273582458,
      "backward_entropy": 0.09759466988699776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.94036865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020406173542141914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.128977969288826,
      "backward_entropy": 0.09763320854731969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.92178344726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020476436242461205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1288626343011856,
      "backward_entropy": 0.09760671002524239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.49578857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02054716646671295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12874551117420197,
      "backward_entropy": 0.09757988793509347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.12225341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020617840811610222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12862680852413177,
      "backward_entropy": 0.09749984741210938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.69775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020689725875854492,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12850546836853027,
      "backward_entropy": 0.0974754776273455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.57801818847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02076132781803608,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1283828169107437,
      "backward_entropy": 0.09745093754359654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.20545959472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020827339962124825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12826381623744965,
      "backward_entropy": 0.09742295742034912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.733154296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02089666947722435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12814055383205414,
      "backward_entropy": 0.09739696979522705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.16612243652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020963815972208977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12801817059516907,
      "backward_entropy": 0.09739841733660017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.8904266357422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021031785756349564,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12789393961429596,
      "backward_entropy": 0.09894081524440221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.70518493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021100258454680443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12776796519756317,
      "backward_entropy": 0.09733613899775914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.79398345947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021168041974306107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12764157354831696,
      "backward_entropy": 0.09728516851152692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.75879669189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02123369090259075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12751606106758118,
      "backward_entropy": 0.09726968833378383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.61293029785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02129237912595272,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.127396821975708,
      "backward_entropy": 0.09893029928207397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.6726837158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021352771669626236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1272747665643692,
      "backward_entropy": 0.09719310488019671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.239501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021414954215288162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1271500289440155,
      "backward_entropy": 0.09715700149536133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.00994110107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021479407325387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1270217001438141,
      "backward_entropy": 0.097121034349714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.48971557617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021540412679314613,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12689554691314697,
      "backward_entropy": 0.09891753537314278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.8809814453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021605705842375755,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12676432728767395,
      "backward_entropy": 0.09891498940331596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.76449584960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021671824157238007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12663094699382782,
      "backward_entropy": 0.09700792176382882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.8967742919922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021734336391091347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12650005519390106,
      "backward_entropy": 0.09890913963317871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.76962280273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021800758317112923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12636421620845795,
      "backward_entropy": 0.09692916699818202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.85977935791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021863799542188644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1262308657169342,
      "backward_entropy": 0.09688775879996163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.70059204101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021924050524830818,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12609967589378357,
      "backward_entropy": 0.09687326635633196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.99317932128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02198553830385208,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12596598267555237,
      "backward_entropy": 0.09889604364122663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.0232162475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022048022598028183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12582993507385254,
      "backward_entropy": 0.0967972023146493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.70396423339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022107655182480812,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12569613754749298,
      "backward_entropy": 0.09888836315699986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.396240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022165101021528244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12556412816047668,
      "backward_entropy": 0.0966598732130868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.66123962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022224344313144684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1254291534423828,
      "backward_entropy": 0.0966127599988665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.3839569091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022287121042609215,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12528976798057556,
      "backward_entropy": 0.09663447311946324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.6195526123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022350795567035675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12514811754226685,
      "backward_entropy": 0.09652760199138097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.91075134277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02241719514131546,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12500274181365967,
      "backward_entropy": 0.09887167385646276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.81568908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022481674328446388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12485852837562561,
      "backward_entropy": 0.09652045794895717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.08920288085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022546645253896713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12471243739128113,
      "backward_entropy": 0.09639757020132882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.64118957519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02261841855943203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12455832958221436,
      "backward_entropy": 0.09644905158451625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.75050354003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022686315700411797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1244078204035759,
      "backward_entropy": 0.0963193689073835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.78089904785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022760096937417984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12424979358911514,
      "backward_entropy": 0.09638089793069023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.08180236816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022831102833151817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12409409135580063,
      "backward_entropy": 0.09634550980159215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.81642150878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022905634716153145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12393394112586975,
      "backward_entropy": 0.09631311893463135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.27108001708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022979242727160454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12377441674470901,
      "backward_entropy": 0.09627951894487653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.00811767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02304736338555813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12362059950828552,
      "backward_entropy": 0.09612249476569039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.84353637695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023114454001188278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1234668716788292,
      "backward_entropy": 0.09619603838239398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.39097595214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02318473905324936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12330831587314606,
      "backward_entropy": 0.09615441731044225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.79507446289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023257242515683174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12314675003290176,
      "backward_entropy": 0.09598310504640852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.06906127929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023326857015490532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12298762798309326,
      "backward_entropy": 0.09606786285127912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.70669555664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023398764431476593,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12282539159059525,
      "backward_entropy": 0.0960230997630528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.00204467773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02347516268491745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12265728414058685,
      "backward_entropy": 0.09598180225917272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.85751342773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023549048230051994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12249192595481873,
      "backward_entropy": 0.09578682695116315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.12550354003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02362171933054924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12232741713523865,
      "backward_entropy": 0.09573333603995186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.92860412597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023693174123764038,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12216363847255707,
      "backward_entropy": 0.095838691507067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.7514190673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023768557235598564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12199407815933228,
      "backward_entropy": 0.09579117809023176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.08834838867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023844124749302864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12182394415140152,
      "backward_entropy": 0.09556618758610316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.543853759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023913349956274033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12166191637516022,
      "backward_entropy": 0.09550385815756661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.5055389404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02397502027451992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12150926142930984,
      "backward_entropy": 0.0954312767301287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.73526000976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024037880823016167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12135417014360428,
      "backward_entropy": 0.09535797153200422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0465545654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024096712470054626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12120337784290314,
      "backward_entropy": 0.09527871438435145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.53042602539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02415871061384678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12104691565036774,
      "backward_entropy": 0.09520317826952253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.12071228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02422625944018364,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12088248133659363,
      "backward_entropy": 0.09534287452697754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.14633178710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024297254160046577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12071283161640167,
      "backward_entropy": 0.09506899969918388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.58119201660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02436838671565056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12054216861724854,
      "backward_entropy": 0.0952236567224775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.81272888183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024439774453639984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12037048488855362,
      "backward_entropy": 0.09492972918919154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.58644104003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024511903524398804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1201973408460617,
      "backward_entropy": 0.0951014586857387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.83208465576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024585992097854614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12002120912075043,
      "backward_entropy": 0.09504207542964391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.50012969970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024658214300870895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1198476105928421,
      "backward_entropy": 0.09472718409129552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.19339752197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02472785860300064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11967679858207703,
      "backward_entropy": 0.09491021292550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.4393310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024792687967419624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11951220035552979,
      "backward_entropy": 0.09456752027784075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.50872039794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02485593780875206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11934920400381088,
      "backward_entropy": 0.09447957788194929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.94760131835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02491738088428974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11918789148330688,
      "backward_entropy": 0.09466685567583356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.40859985351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024976402521133423,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11902961134910583,
      "backward_entropy": 0.09457756791796003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.33292388916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025031140074133873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1188766211271286,
      "backward_entropy": 0.0944826432636806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.44473266601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02508426085114479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11872565746307373,
      "backward_entropy": 0.09406788008553642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.41146850585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025133011862635612,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11858069151639938,
      "backward_entropy": 0.0942791189466204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.2593994140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02518562786281109,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11842945218086243,
      "backward_entropy": 0.09383510691779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.24047088623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025235522538423538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1182820200920105,
      "backward_entropy": 0.0940748964037214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.07941436767578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02528509497642517,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11813433468341827,
      "backward_entropy": 0.09870329924992152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.88888549804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0253322534263134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11799006909132004,
      "backward_entropy": 0.09385883808135986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.08389282226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02537817507982254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784705519676208,
      "backward_entropy": 0.09333971568516322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.85250854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025424450635910034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11770305037498474,
      "backward_entropy": 0.09320884091513497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.42311096191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02547263912856579,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11755603551864624,
      "backward_entropy": 0.09351716722760882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.89887237548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025516429916024208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11741499602794647,
      "backward_entropy": 0.09339481592178345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.70614624023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025560403242707253,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1172730028629303,
      "backward_entropy": 0.09861724717276436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.80418395996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02560918964445591,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11712390929460526,
      "backward_entropy": 0.09315439632960729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.7534942626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0256548672914505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11697892844676971,
      "backward_entropy": 0.0930312190737043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.43135833740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025703875347971916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11682911962270737,
      "backward_entropy": 0.09238340173448835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.46920013427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025750158354640007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.116683229804039,
      "backward_entropy": 0.09223738738468715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.46875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025798531249165535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11653447151184082,
      "backward_entropy": 0.09209694181169782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.8175048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025842634961009026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11639183759689331,
      "backward_entropy": 0.09194486481802804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.60499572753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025887323543429375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11624819785356522,
      "backward_entropy": 0.09240879331316267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.89691162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02592918835580349,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1161082535982132,
      "backward_entropy": 0.09162875584193639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.93814849853516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025978920981287956,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11595725268125534,
      "backward_entropy": 0.0984938314982823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.29417419433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02602735161781311,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11580830812454224,
      "backward_entropy": 0.09133427483694893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.70753479003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02608008123934269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11565335094928741,
      "backward_entropy": 0.09190661566598075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.49774169921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026136809960007668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11549311876296997,
      "backward_entropy": 0.09105687482016427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.03987121582031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02620328590273857,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11532099545001984,
      "backward_entropy": 0.09847663981573922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.67878723144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02626693621277809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11515353620052338,
      "backward_entropy": 0.09084030560084752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.91044616699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026329239830374718,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11498835682868958,
      "backward_entropy": 0.09071993827819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.93994140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026390202343463898,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11482538282871246,
      "backward_entropy": 0.09848054817744664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.69597625732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02645168825984001,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11466223001480103,
      "backward_entropy": 0.09129577875137329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.59105682373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026512980461120605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11449944972991943,
      "backward_entropy": 0.09032479354313441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.87452697753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026572242379188538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433908343315125,
      "backward_entropy": 0.09106716087886266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.73226928710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026636306196451187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11417165398597717,
      "backward_entropy": 0.09095734357833862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.47209167480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026698995381593704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11400611698627472,
      "backward_entropy": 0.08991268702915736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.01126861572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02675764262676239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11384650319814682,
      "backward_entropy": 0.08976043973650251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.79312133789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026816656813025475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11368633061647415,
      "backward_entropy": 0.08960357734135219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.42477416992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026877066120505333,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11352410912513733,
      "backward_entropy": 0.09044413907187325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.74947357177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026943620294332504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11335442215204239,
      "backward_entropy": 0.08929916790553502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.46947479248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027007227763533592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11318960785865784,
      "backward_entropy": 0.08914509841373988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.64002990722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027066843584179878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11303113400936127,
      "backward_entropy": 0.08897730282374791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.01405334472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027122046798467636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11287900805473328,
      "backward_entropy": 0.0887884157044547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.52389526367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027177566662430763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11272653192281723,
      "backward_entropy": 0.0897355249949864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.39669799804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027237243950366974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1125694140791893,
      "backward_entropy": 0.08958472524370466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.682098388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02729453146457672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11241630464792252,
      "backward_entropy": 0.08942622797829765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.10832214355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027343731373548508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11227530986070633,
      "backward_entropy": 0.0892457365989685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.7790069580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027392925694584846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11213468015193939,
      "backward_entropy": 0.08778105463300433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.43368530273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027452461421489716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11198163032531738,
      "backward_entropy": 0.08890828064509801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.27819061279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027509761974215508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11183249950408936,
      "backward_entropy": 0.08874566214425224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.89216613769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027562784031033516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11169042438268661,
      "backward_entropy": 0.08720346008028303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.80958557128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02761394903063774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11155133694410324,
      "backward_entropy": 0.08838592256818499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.07762145996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027669323608279228,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11140739917755127,
      "backward_entropy": 0.08821020807538714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.06553649902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027726104483008385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11126270890235901,
      "backward_entropy": 0.08803663083485194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.26311492919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0277808029204607,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11112156510353088,
      "backward_entropy": 0.08785571370806013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.15890121459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0278309416025877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11098739504814148,
      "backward_entropy": 0.0861586502620152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.38397216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027876975014805794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1108594685792923,
      "backward_entropy": 0.08591869047709874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.2827911376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02792748436331749,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11072617024183273,
      "backward_entropy": 0.08725406442369733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.68267822265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027983209118247032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11058685183525085,
      "backward_entropy": 0.08546088423047747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.79368591308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028038445860147476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11044914275407791,
      "backward_entropy": 0.08688093934740339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.02084350585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028095228597521782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11031007766723633,
      "backward_entropy": 0.08499678543635777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.68118286132812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028155548498034477,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11016774922609329,
      "backward_entropy": 0.09816372394561768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.83621215820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02821667492389679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11002594232559204,
      "backward_entropy": 0.08455727781568255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.86390686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028278391808271408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1098848208785057,
      "backward_entropy": 0.08434322902134486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.8128662109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028337426483631134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1097482293844223,
      "backward_entropy": 0.08411602463041033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.28955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028395935893058777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10961367189884186,
      "backward_entropy": 0.08574931110654559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.6182098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02844982035458088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10948622226715088,
      "backward_entropy": 0.08363531317029681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.43255615234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028512807562947273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1093493178486824,
      "backward_entropy": 0.08341152327401298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.40907287597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028578981757164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10921019315719604,
      "backward_entropy": 0.08319986718041557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.0379638671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028643783181905746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10907420516014099,
      "backward_entropy": 0.08494898251124791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.59011840820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028706658631563187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1089416891336441,
      "backward_entropy": 0.08474139656339373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.66310501098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028765270486474037,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10881547629833221,
      "backward_entropy": 0.08451615912573678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.83304595947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028818843886256218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10869644582271576,
      "backward_entropy": 0.08427279336111886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.32794952392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02887294813990593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1085776835680008,
      "backward_entropy": 0.08191555738449097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.06197357177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028919916599988937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10846863687038422,
      "backward_entropy": 0.08375847339630127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.35492706298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028966747224330902,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1083604171872139,
      "backward_entropy": 0.0834858843258449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.138084411621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02900632470846176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1082615852355957,
      "backward_entropy": 0.0809287258556911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.13380432128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02904127910733223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10816895961761475,
      "backward_entropy": 0.08055914299828666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.34394073486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0290836151689291,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10806882381439209,
      "backward_entropy": 0.08022229160581316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.89625549316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029126297682523727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10796894133090973,
      "backward_entropy": 0.07987901142665318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.97677612304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02917160838842392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10786718130111694,
      "backward_entropy": 0.08202514478138515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.36141967773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02921634539961815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10776709765195847,
      "backward_entropy": 0.07922324112483434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.21379852294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029261767864227295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1076672226190567,
      "backward_entropy": 0.08145928382873535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.09209442138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029302170500159264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10757392644882202,
      "backward_entropy": 0.0811549084527152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.99787139892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029335858300328255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10748879611492157,
      "backward_entropy": 0.08082389831542969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.60452270507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029370293021202087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10740362107753754,
      "backward_entropy": 0.0804944464138576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.35005950927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029406888410449028,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10731694102287292,
      "backward_entropy": 0.07742266144071307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.36197662353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029447410255670547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10722682625055313,
      "backward_entropy": 0.07706846509660993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.41737365722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02949042059481144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10713502764701843,
      "backward_entropy": 0.07672253676823207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.94599914550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02953462116420269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1070430725812912,
      "backward_entropy": 0.07927088226590838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.40272521972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029577860608696938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1069529727101326,
      "backward_entropy": 0.07897207566670009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.64234161376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02961946465075016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10686565190553665,
      "backward_entropy": 0.07866438797542027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.06879425048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029659956693649292,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10678055882453918,
      "backward_entropy": 0.07834777661732265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.159507751464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029700441285967827,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10669642686843872,
      "backward_entropy": 0.09726531164986747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.57540130615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0297364704310894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10661767423152924,
      "backward_entropy": 0.07769722597939628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.86354446411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029775207862257957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10653641074895859,
      "backward_entropy": 0.07737265314374651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.04813003540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029810599982738495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1064595952630043,
      "backward_entropy": 0.07379255975995745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.94444274902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02984369359910488,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10638603568077087,
      "backward_entropy": 0.07668102639062065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029883192852139473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1063072457909584,
      "backward_entropy": 0.07301799740110125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.48946380615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02992134913802147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1062307208776474,
      "backward_entropy": 0.07603544848305839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.85655212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029957881197333336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10615655779838562,
      "backward_entropy": 0.07225348268236433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.3697509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02999979257583618,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10607831180095673,
      "backward_entropy": 0.07537987402507237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.48921966552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03003717213869095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10600526630878448,
      "backward_entropy": 0.07148470197405134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.90470886230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030075712129473686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1059320792555809,
      "backward_entropy": 0.0710879819733756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.04547119140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03011304698884487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1058608889579773,
      "backward_entropy": 0.07068712796483721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.29342269897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030144695192575455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10579606890678406,
      "backward_entropy": 0.07397714682987758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.10318756103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03017435222864151,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10573381185531616,
      "backward_entropy": 0.07359445095062256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.69710540771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03020668588578701,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10566937923431396,
      "backward_entropy": 0.06940351213727679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.36674499511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03023875504732132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10560575127601624,
      "backward_entropy": 0.06899246147700719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.44918823242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030275046825408936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10553974658250809,
      "backward_entropy": 0.06861258404595512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.33370590209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030314579606056213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10547186434268951,
      "backward_entropy": 0.06824897016797747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.49652862548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03035110794007778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10540743172168732,
      "backward_entropy": 0.06786041600363595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.39584350585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030389534309506416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10534226149320602,
      "backward_entropy": 0.07151442766189575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.74315643310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03042762726545334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10527819395065308,
      "backward_entropy": 0.06708515116146632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.04981994628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030464088544249535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10521635413169861,
      "backward_entropy": 0.07080926639693123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.60090637207031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03050396218895912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1051526889204979,
      "backward_entropy": 0.07046709741864886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.04943084716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030543958768248558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10508997738361359,
      "backward_entropy": 0.07012259108679635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.06768798828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030583789572119713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10502836108207703,
      "backward_entropy": 0.06547977243150983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.40685272216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030628962442278862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10496371239423752,
      "backward_entropy": 0.06509144817079816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.2205810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030675094574689865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10490000247955322,
      "backward_entropy": 0.06911320345742362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.65664672851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030725041404366493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10483421385288239,
      "backward_entropy": 0.0688091516494751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.89505767822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03077562525868416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10476887226104736,
      "backward_entropy": 0.06850542340959821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.14520263671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030824121087789536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10470607131719589,
      "backward_entropy": 0.0636110816683088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.95177459716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030874883756041527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10464261472225189,
      "backward_entropy": 0.06325717908995492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.55342864990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030923839658498764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10458190739154816,
      "backward_entropy": 0.06289889131273542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.82004165649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030974604189395905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10452111810445786,
      "backward_entropy": 0.06254165513174874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.66361999511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031020184978842735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10446487367153168,
      "backward_entropy": 0.062151151044028144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.7987289428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031063927337527275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10441071540117264,
      "backward_entropy": 0.06174728274345398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.19281005859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031105877831578255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10435859858989716,
      "backward_entropy": 0.09626319578715734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.87519073486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031149180606007576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10430657863616943,
      "backward_entropy": 0.06580545221056257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.72248077392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031191043555736542,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10425616800785065,
      "backward_entropy": 0.06543278694152832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.82675170898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03123783878982067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10420319437980652,
      "backward_entropy": 0.06508582404681615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.27586364746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03128671273589134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10415029525756836,
      "backward_entropy": 0.0647450600351606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.193115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0313318595290184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10410070419311523,
      "backward_entropy": 0.06437920672552926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.71115112304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03138190880417824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10404898971319199,
      "backward_entropy": 0.06403738686016627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.31787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031432125717401505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10399821400642395,
      "backward_entropy": 0.06368914246559143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.94510650634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03148306906223297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10394805669784546,
      "backward_entropy": 0.06334159203938075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.0967025756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031532496213912964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10389994084835052,
      "backward_entropy": 0.0576371465410505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.11177825927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031584348529577255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10385169833898544,
      "backward_entropy": 0.06263072150094169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.88722229003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0316382497549057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1038026213645935,
      "backward_entropy": 0.06229901739529201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.05216217041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03169923275709152,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10375091433525085,
      "backward_entropy": 0.06200227567127773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.3336067199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03175772726535797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10370197892189026,
      "backward_entropy": 0.061681496245520454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.59442901611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031810734421014786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10365710407495499,
      "backward_entropy": 0.061329194477626255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.81417846679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031866006553173065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1036120057106018,
      "backward_entropy": 0.055309023175920756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.10762023925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03191966563463211,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10356853902339935,
      "backward_entropy": 0.0606216447693961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.0538787841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03196938708424568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10352791845798492,
      "backward_entropy": 0.05443874001502991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.13748168945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032025739550590515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10348473489284515,
      "backward_entropy": 0.054052378450121195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.65640258789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03208358213305473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10344204306602478,
      "backward_entropy": 0.053679747240883965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.87004852294922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03214234486222267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10339988768100739,
      "backward_entropy": 0.09605057750429426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.64289093017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032199613749980927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10335935652256012,
      "backward_entropy": 0.05291324853897095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.5858383178711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032255541533231735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10332033038139343,
      "backward_entropy": 0.05251650299344744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.09300994873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03231474384665489,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10328063368797302,
      "backward_entropy": 0.05214386326926095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.451908111572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03237345069646835,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10324219614267349,
      "backward_entropy": 0.057937907321112495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.47607421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032426487654447556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10320733487606049,
      "backward_entropy": 0.051343415464673726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.5953598022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032478779554367065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10317344218492508,
      "backward_entropy": 0.05719521215983799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.3508415222168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032529134303331375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10314146429300308,
      "backward_entropy": 0.0568048357963562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.53602600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03257397189736366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1031128466129303,
      "backward_entropy": 0.050015802894319804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.75348663330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03262137249112129,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10308369994163513,
      "backward_entropy": 0.055981414658682685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.8348274230957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03267137333750725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10305382311344147,
      "backward_entropy": 0.05560121365955898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.82579803466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032717958092689514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10302583873271942,
      "backward_entropy": 0.05520478316715786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.87455368041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032765526324510574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10299798846244812,
      "backward_entropy": 0.0482443060193743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.26104736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03281167522072792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1029711589217186,
      "backward_entropy": 0.04780474730900356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.24762725830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03285757824778557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10294501483440399,
      "backward_entropy": 0.047365239688328335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.85211944580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032901830971241,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10292022675275803,
      "backward_entropy": 0.053618013858795166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.84988403320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0329473502933979,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10289546847343445,
      "backward_entropy": 0.05321990592139108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.77339172363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03299387916922569,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10287098586559296,
      "backward_entropy": 0.05282592347690037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.4122543334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03303614258766174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10284870862960815,
      "backward_entropy": 0.05240755421774728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.09156608581543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0330803282558918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1028260588645935,
      "backward_entropy": 0.05200306858335223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.504066467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03311893343925476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10280615091323853,
      "backward_entropy": 0.05156870399202619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.89736938476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03315526619553566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10278746485710144,
      "backward_entropy": 0.051124670675822666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.069053649902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03319345787167549,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10276853293180466,
      "backward_entropy": 0.05069311601775033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.66716003417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03322773799300194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10275166481733322,
      "backward_entropy": 0.050241683210645406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.74527740478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03326752781867981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10273332893848419,
      "backward_entropy": 0.042805067130497525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.91483688354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03331030160188675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1027144342660904,
      "backward_entropy": 0.0423696722303118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.56116485595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03335276246070862,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10269570350646973,
      "backward_entropy": 0.049053847789764404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.10166931152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033395539969205856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10267727077007294,
      "backward_entropy": 0.048670368535178046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.12907028198242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03344542533159256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10265704989433289,
      "backward_entropy": 0.04833132454327175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.04661560058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03349321335554123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10263821482658386,
      "backward_entropy": 0.047976442745753696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.52952575683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03353697434067726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10262103378772736,
      "backward_entropy": 0.04760083556175232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.04215240478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03357941657304764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10260479897260666,
      "backward_entropy": 0.04721525737217495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.6517333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03362352401018143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10258852690458298,
      "backward_entropy": 0.03947154113224575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.12593460083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033671826124191284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10257155448198318,
      "backward_entropy": 0.0464966424873897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.677146911621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03371896222233772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10255524516105652,
      "backward_entropy": 0.038693436554500034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.45748901367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03376364707946777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10254000127315521,
      "backward_entropy": 0.0382982747895377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.97174835205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03380954638123512,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10252495110034943,
      "backward_entropy": 0.037903938974652975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.50513458251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033851176500320435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10251149535179138,
      "backward_entropy": 0.045060813426971436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.56201171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03389856591820717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10249687731266022,
      "backward_entropy": 0.044716102736336846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.64997100830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03394622355699539,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10248255729675293,
      "backward_entropy": 0.04437731845038278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.97797393798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034001413732767105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10246701538562775,
      "backward_entropy": 0.044079946620123725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.06643676757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03405696526169777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10245180130004883,
      "backward_entropy": 0.036003249032156806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.16456985473633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0341118648648262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1024370789527893,
      "backward_entropy": 0.04347798654011318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.751041412353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03416311368346214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10242383927106857,
      "backward_entropy": 0.04315025891576495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.22846221923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03421054035425186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10241207480430603,
      "backward_entropy": 0.04279427868979318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.282470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03425690531730652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10240080952644348,
      "backward_entropy": 0.034467769520623345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.75302124023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034304846078157425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1023893654346466,
      "backward_entropy": 0.042102890355246406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.16908264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03435574099421501,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10237748920917511,
      "backward_entropy": 0.04179258005959647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.001155853271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03440694138407707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10236592590808868,
      "backward_entropy": 0.04149468455995832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.755327224731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03445635363459587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10235509276390076,
      "backward_entropy": 0.03304630517959595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.739070892333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034502483904361725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10234507918357849,
      "backward_entropy": 0.032700498189244954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.11553955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03454804793000221,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10233524441719055,
      "backward_entropy": 0.04055889163698469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.56898498535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03458908200263977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10232660174369812,
      "backward_entropy": 0.03201004649911608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.40166473388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0346299484372139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1023181676864624,
      "backward_entropy": 0.03990294252123151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.75721740722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03467068076133728,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10231001675128937,
      "backward_entropy": 0.03958226101739066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.87367248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034712016582489014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1023022010922432,
      "backward_entropy": 0.030985010521752492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.29859924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034755557775497437,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10229428112506866,
      "backward_entropy": 0.03895951168877738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.30298614501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03479544445872307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10228735208511353,
      "backward_entropy": 0.030308755380766734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.23420715332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034835927188396454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10228055715560913,
      "backward_entropy": 0.029954405767577037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.534210205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03488259017467499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10227276384830475,
      "backward_entropy": 0.03802305885723659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.30771255493164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03492850810289383,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1022653728723526,
      "backward_entropy": 0.037738923515592306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.46578979492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034971993416547775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10225865244865417,
      "backward_entropy": 0.028990977576800754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.22439575195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035017553716897964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10225171595811844,
      "backward_entropy": 0.02867335081100464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.3912992477417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03506499528884888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10224469006061554,
      "backward_entropy": 0.03687139068331037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.829065322875977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03510592132806778,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1022391989827156,
      "backward_entropy": 0.03655900274004255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.24658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035143181681632996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10223457217216492,
      "backward_entropy": 0.027695796319416592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.67268753051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03517923131585121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10223045200109482,
      "backward_entropy": 0.0273578017950058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.97305297851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.035214614123106,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.102226123213768,
      "backward_entropy": 0.0943660991532462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.10592651367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03525310754776001,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10222096741199493,
      "backward_entropy": 0.03532875009945461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.38465118408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03529807925224304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10221539437770844,
      "backward_entropy": 0.02644996557916914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.81586456298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03534373641014099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1022099032998085,
      "backward_entropy": 0.026179658515112742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.24689483642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03539259731769562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10220411419868469,
      "backward_entropy": 0.03461289831570217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.177541732788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03543933853507042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10219885408878326,
      "backward_entropy": 0.025660917162895203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.44526672363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03548256680369377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10219427943229675,
      "backward_entropy": 0.03412488315786634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.67714309692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03552831709384918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1021895483136177,
      "backward_entropy": 0.03389093492712293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.52974319458008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03557243570685387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10218513011932373,
      "backward_entropy": 0.03365473662103925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.14300537109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03561701253056526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10218112170696259,
      "backward_entropy": 0.03341636274542127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.99413299560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03566361963748932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10217681527137756,
      "backward_entropy": 0.03319155318396432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.56344604492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03570881858468056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10217262804508209,
      "backward_entropy": 0.024089417287281582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.482776641845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03575747460126877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1021682545542717,
      "backward_entropy": 0.02385937741824559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.79239654541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035802122205495834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10216446220874786,
      "backward_entropy": 0.03256036128316607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.19361877441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03585055097937584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10216023027896881,
      "backward_entropy": 0.023413334574018205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.77437210083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03589770570397377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10215623676776886,
      "backward_entropy": 0.03219731577805111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.50315856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03594294190406799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10215261578559875,
      "backward_entropy": 0.03200808380331312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.874324798583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035989005118608475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10214902460575104,
      "backward_entropy": 0.022787115403584073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.00786209106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03603513538837433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1021454781293869,
      "backward_entropy": 0.03164242420877729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.44292068481445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036079879850149155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10214224457740784,
      "backward_entropy": 0.03146328244890485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.84327697753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03612274304032326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10213939845561981,
      "backward_entropy": 0.03127115326268332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.680580139160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0361655130982399,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10213666409254074,
      "backward_entropy": 0.031079432794025967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.57345581054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03620821237564087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10213406383991241,
      "backward_entropy": 0.030888783080237254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.305822372436523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036255888640880585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10213097184896469,
      "backward_entropy": 0.021544794951166426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.42201614379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03629905357956886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212861001491547,
      "backward_entropy": 0.03053313067981175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.229286193847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036340948194265366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212637484073639,
      "backward_entropy": 0.03033944751535143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.25855255126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036382656544446945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212413966655731,
      "backward_entropy": 0.03014343125479562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.08157730102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03642314672470093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10212214291095734,
      "backward_entropy": 0.02067114838532039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.94479370117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0364597886800766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10212065279483795,
      "backward_entropy": 0.020432753222329274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.48292541503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036502063274383545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10211887955665588,
      "backward_entropy": 0.020220228603907993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.54155731201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036544300615787506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.102117158472538,
      "backward_entropy": 0.020011092935289656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.33518981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03658752143383026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1021152138710022,
      "backward_entropy": 0.019822840179715837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.45619583129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036632321774959564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10211324691772461,
      "backward_entropy": 0.019644034760338918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.37174987792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03667568787932396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10211138427257538,
      "backward_entropy": 0.028889915772846768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.567840576171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036721937358379364,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210918635129929,
      "backward_entropy": 0.028750549469675337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.158205032348633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03676793724298477,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1021072044968605,
      "backward_entropy": 0.02860876279217856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.66181182861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03681006282567978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210558772087097,
      "backward_entropy": 0.028450801968574524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.28573608398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036853548139333725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10210390388965607,
      "backward_entropy": 0.018753534981182644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.00067901611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03690226748585701,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10210197418928146,
      "backward_entropy": 0.018596568277903965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.247074127197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03695041313767433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210011899471283,
      "backward_entropy": 0.02804809170109885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.84573364257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036997243762016296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209839791059494,
      "backward_entropy": 0.027921697923115323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.528654098510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03704836964607239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209652781486511,
      "backward_entropy": 0.01812499761581421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.76972770690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037095438688993454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209497809410095,
      "backward_entropy": 0.027679651975631714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66344928741455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03713991865515709,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209356248378754,
      "backward_entropy": 0.027546620794704983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.06730270385742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0371791310608387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209254175424576,
      "backward_entropy": 0.02738790214061737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.77580642700195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03721724450588226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209159553050995,
      "backward_entropy": 0.02722224806036268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.78110122680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03725743293762207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209043323993683,
      "backward_entropy": 0.017256076846803938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.54985046386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03729786351323128,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10208925604820251,
      "backward_entropy": 0.026932265077318465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.23532104492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03733864426612854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10208811610937119,
      "backward_entropy": 0.016910986176558902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.199710845947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03738381713628769,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10208678245544434,
      "backward_entropy": 0.016761147550174167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.59516906738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037430163472890854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020854115486145,
      "backward_entropy": 0.026568023221833364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.66027069091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03748057782649994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10208383947610855,
      "backward_entropy": 0.02648205203669412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.61906623840332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037531886249780655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020822674036026,
      "backward_entropy": 0.026400825807026455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.58587646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03758055344223976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10208083689212799,
      "backward_entropy": 0.02631630003452301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.69032096862793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0376267284154892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10207954049110413,
      "backward_entropy": 0.016114707503999983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.000572204589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0376703180372715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10207836329936981,
      "backward_entropy": 0.015977340085165843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.429241180419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03770997375249863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207733511924744,
      "backward_entropy": 0.025998030390058244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.530311584472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037747833877801895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10207635164260864,
      "backward_entropy": 0.01566446146794728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.62025833129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03778374567627907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10207539796829224,
      "backward_entropy": 0.015500359237194061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.30046081542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037820905447006226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207436978816986,
      "backward_entropy": 0.02560346041406904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.25227355957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03786022961139679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207323729991913,
      "backward_entropy": 0.02549016901424953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.9556770324707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03790128231048584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10207201540470123,
      "backward_entropy": 0.015060755823339735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.777727127075195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03794412687420845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207071900367737,
      "backward_entropy": 0.025282353162765503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.42619705200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03798563778400421,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020694375038147,
      "backward_entropy": 0.025170390095029558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.167747497558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038029249757528305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10206808149814606,
      "backward_entropy": 0.014653775308813368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.00588035583496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03806942701339722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020667627453804,
      "backward_entropy": 0.014517529734543391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.39142608642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03810935840010643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10206542909145355,
      "backward_entropy": 0.02488275510924203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.74451446533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03815563768148422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10206396877765656,
      "backward_entropy": 0.014273364629064287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.6361083984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03820592164993286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10206243395805359,
      "backward_entropy": 0.014174232525484902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.960968017578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03825722634792328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10206090658903122,
      "backward_entropy": 0.02471200908933367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.189386367797852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0383104607462883,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10205936431884766,
      "backward_entropy": 0.024668553045817783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.557990074157715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03835846111178398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205786675214767,
      "backward_entropy": 0.013884512441498893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.87139892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03840288519859314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205636918544769,
      "backward_entropy": 0.013774701527186803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.95103454589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03844522312283516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205484926700592,
      "backward_entropy": 0.0136601488505091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.60981750488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03849071264266968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205328464508057,
      "backward_entropy": 0.013557997133050646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.42451095581055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03853749856352806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205170512199402,
      "backward_entropy": 0.013457117336136954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.01601028442383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03858545050024986,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10205008089542389,
      "backward_entropy": 0.024299762078693936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.04733657836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038633234798908234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204844176769257,
      "backward_entropy": 0.013259305485657282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.39988899230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03868208825588226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204677283763885,
      "backward_entropy": 0.013162393655095781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.62419128417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03872979059815407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204511135816574,
      "backward_entropy": 0.01306735404900142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.497802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03877715393900871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204334557056427,
      "backward_entropy": 0.01296930227960859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.983814239501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03882705420255661,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020415648818016,
      "backward_entropy": 0.024046199662344798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.10170364379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038874395191669464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10203971713781357,
      "backward_entropy": 0.012789365436349596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.923906326293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038922857493162155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203786194324493,
      "backward_entropy": 0.0239570609160832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.647977828979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03896981477737427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020359992980957,
      "backward_entropy": 0.012604652770927973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.54375076293945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039014626294374466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020340770483017,
      "backward_entropy": 0.0125086743916784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.138790130615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039063017815351486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10203219950199127,
      "backward_entropy": 0.012419052422046661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.506440281867981,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03911503031849861,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203032195568085,
      "backward_entropy": 0.02378082914011819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.203445434570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03916120529174805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202839225530624,
      "backward_entropy": 0.012257522770336695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.397866249084473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039206329733133316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202637314796448,
      "backward_entropy": 0.023706423384802684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.298090934753418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03924811631441116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202421247959137,
      "backward_entropy": 0.01207904304776873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.20526123046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039287008345127106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202191770076752,
      "backward_entropy": 0.011981582002980369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.87405776977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03932986408472061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020195409655571,
      "backward_entropy": 0.011888153851032257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.03789234161377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03937658295035362,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201716423034668,
      "backward_entropy": 0.023500210472515652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.819412231445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03942014276981354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020146906375885,
      "backward_entropy": 0.02345475128718785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.133365631103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039461664855480194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201214253902435,
      "backward_entropy": 0.011621326208114624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.52206802368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039503637701272964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10200950503349304,
      "backward_entropy": 0.023343262927872793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.351036071777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03954758495092392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020069420337677,
      "backward_entropy": 0.02329810176576887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.756372451782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03959331288933754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10200440138578415,
      "backward_entropy": 0.02326736492770059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.52172088623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039635926485061646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10200169682502747,
      "backward_entropy": 0.023230448365211487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.962981700897217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039678994566202164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10199891030788422,
      "backward_entropy": 0.023192575999668667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.18940734863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03971842676401138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10199591517448425,
      "backward_entropy": 0.011126794985362462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.51585865020752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03976135328412056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10199315845966339,
      "backward_entropy": 0.011058724352291651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.908845901489258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039801474660634995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019902229309082,
      "backward_entropy": 0.02311376588685172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.993452072143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03984034061431885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10198715329170227,
      "backward_entropy": 0.010916737573487418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.832746505737305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03987753018736839,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10198386013507843,
      "backward_entropy": 0.010838348950658525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.70337677001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039913490414619446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10198038816452026,
      "backward_entropy": 0.023009745138032094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.17848205566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039948537945747375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10197679698467255,
      "backward_entropy": 0.010677228016512734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.062721252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03998741880059242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10197338461875916,
      "backward_entropy": 0.010607523577553886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.543272018432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0400257334113121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10196979343891144,
      "backward_entropy": 0.010531568101474218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.36769104003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04006265476346016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10196609795093536,
      "backward_entropy": 0.02285899647644588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.898094177246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04010197892785072,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019623875617981,
      "backward_entropy": 0.022825106978416443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.812156677246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040142402052879333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10195870697498322,
      "backward_entropy": 0.01031337252685002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.0324592590332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04018364101648331,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10195507854223251,
      "backward_entropy": 0.022787879620279585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.51765251159668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04022633284330368,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10195133835077286,
      "backward_entropy": 0.02276458059038435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.356855392456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040269702672958374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10194754600524902,
      "backward_entropy": 0.010121531784534454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.018978118896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04031376913189888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10194379091262817,
      "backward_entropy": 0.02273328389440264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.909149169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040362436324357986,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10194019228219986,
      "backward_entropy": 0.022723676902907237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.91529655456543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040410205721855164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10193654894828796,
      "backward_entropy": 0.00995086772101266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.805795669555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04045822471380234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10193288326263428,
      "backward_entropy": 0.02271521942956107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.72447204589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04050629958510399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10192917287349701,
      "backward_entropy": 0.009846067854336329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.54082489013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040555473417043686,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10192537307739258,
      "backward_entropy": 0.022712222167423794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.345272064208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04060320183634758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10192136466503143,
      "backward_entropy": 0.009739885372774941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.145668029785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04065213352441788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10191738605499268,
      "backward_entropy": 0.009687255535806929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.114614486694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040702227503061295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10191360861063004,
      "backward_entropy": 0.022697014468056814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.91374969482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040751028805971146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1019095629453659,
      "backward_entropy": 0.009588820593697684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.31367492675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040799710899591446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1019054651260376,
      "backward_entropy": 0.009538180061749049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.67186737060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040852516889572144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10190161317586899,
      "backward_entropy": 0.009491985397679465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.376190185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04090407118201256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10189768671989441,
      "backward_entropy": 0.009448559156485967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.654539108276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04095552861690521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10189390182495117,
      "backward_entropy": 0.009408087602683477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.416343688964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041004665195941925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10188981890678406,
      "backward_entropy": 0.009366966784000397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.019916534423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04105687513947487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10188587754964828,
      "backward_entropy": 0.0093281056199755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.10672950744629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04110446199774742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10188159346580505,
      "backward_entropy": 0.022748700210026333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.639246940612793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04115106165409088,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10187716037034988,
      "backward_entropy": 0.02275497998510088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.48545837402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04119462892413139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1018725261092186,
      "backward_entropy": 0.02275505236216954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.856935501098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04124186187982559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10186801850795746,
      "backward_entropy": 0.02276171956743513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.08013153076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04128768667578697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10186320543289185,
      "backward_entropy": 0.009104111364909582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.258689880371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041331518441438675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185817629098892,
      "backward_entropy": 0.009052300027438573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.373270988464355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04137786850333214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185346007347107,
      "backward_entropy": 0.009003910635198866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.302254676818848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041421081870794296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10184839367866516,
      "backward_entropy": 0.00895159798009055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.25743865966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04146154969930649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10184302926063538,
      "backward_entropy": 0.008897555725915092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.10298728942871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041501518338918686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1018374115228653,
      "backward_entropy": 0.008842601307800837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.93879699707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04154132679104805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10183171927928925,
      "backward_entropy": 0.008790309407881327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.970617294311523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04158281534910202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10182610154151917,
      "backward_entropy": 0.008738180888550622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.40385437011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04162357375025749,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10182027518749237,
      "backward_entropy": 0.008683289800371443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.763105392456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04166807234287262,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10181468725204468,
      "backward_entropy": 0.00863155722618103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.9973087310791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041711483150720596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10180868953466415,
      "backward_entropy": 0.008576005697250366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.495216369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04175492748618126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10180272161960602,
      "backward_entropy": 0.008517933743340629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.40635871887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04179767146706581,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10179679095745087,
      "backward_entropy": 0.022472824369158064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.25752830505371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04183965548872948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10179053246974945,
      "backward_entropy": 0.008401920752865928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.870729446411133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04188122972846031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10178422927856445,
      "backward_entropy": 0.008345832782132285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.86911392211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0419217012822628,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10177783668041229,
      "backward_entropy": 0.008295314120394843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.51404571533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04196065664291382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1017712727189064,
      "backward_entropy": 0.02234498517853873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.711824417114258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042002636939287186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10176482796669006,
      "backward_entropy": 0.022328579000064304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.14237594604492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04204295948147774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10175830125808716,
      "backward_entropy": 0.022306497607912337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.392228126525879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04208628833293915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10175196081399918,
      "backward_entropy": 0.008105654801641191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.465944290161133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042127158492803574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10174544155597687,
      "backward_entropy": 0.02229103446006775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.71816635131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04216655716300011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10173866897821426,
      "backward_entropy": 0.008021970412560872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.279887199401855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042209770530462265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10173209011554718,
      "backward_entropy": 0.022275790572166443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.209895133972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04225153475999832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10172544419765472,
      "backward_entropy": 0.007943528571299143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.14909839630127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04229193180799484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10171866416931152,
      "backward_entropy": 0.022273830005100796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.089728355407715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04233097285032272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10171177983283997,
      "backward_entropy": 0.022272678358214244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.790523529052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042368676513433456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10170476138591766,
      "backward_entropy": 0.007828668824263982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.91583251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042409349232912064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10169762372970581,
      "backward_entropy": 0.022267694984163557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.64713478088379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04244876652956009,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10169048607349396,
      "backward_entropy": 0.02227016431944711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.61614227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04248901456594467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10168325155973434,
      "backward_entropy": 0.007723103144339153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.247047424316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04252931848168373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10167625546455383,
      "backward_entropy": 0.007694189569779805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.284896850585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04257144778966904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10166925191879272,
      "backward_entropy": 0.007667798016752515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.550941467285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04261406511068344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10166220366954803,
      "backward_entropy": 0.0076411621911185125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.260541915893555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04266025498509407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10165554285049438,
      "backward_entropy": 0.022358583552496775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.878929138183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04270537570118904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10164856910705566,
      "backward_entropy": 0.022377716643469676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.846848964691162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042746782302856445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10164135694503784,
      "backward_entropy": 0.00756351330450603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.352882385253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04278489947319031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10163386166095734,
      "backward_entropy": 0.007535327758107867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.167501449584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042824894189834595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10162635147571564,
      "backward_entropy": 0.007508820721081325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.063058853149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042863622307777405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016187071800232,
      "backward_entropy": 0.02244515929903303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.23297882080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042904261499643326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10161124169826508,
      "backward_entropy": 0.022467206631387984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.547237396240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04294810816645622,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10160385072231293,
      "backward_entropy": 0.02248035158429827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.622236251831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04299136623740196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10159625858068466,
      "backward_entropy": 0.00740523317030498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.784069061279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043035950511693954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10158887505531311,
      "backward_entropy": 0.02251258705343519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.305801391601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04307885095477104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10158132761716843,
      "backward_entropy": 0.022529137986046926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.112825393676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04312320053577423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10157383978366852,
      "backward_entropy": 0.007332817252193179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.51802635192871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04316714033484459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10156649351119995,
      "backward_entropy": 0.007313426584005356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.470185279846191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043211400508880615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10155898332595825,
      "backward_entropy": 0.007294602692127228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.70256233215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04325404390692711,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10155145823955536,
      "backward_entropy": 0.007275677153042385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.33952522277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04329806566238403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10154387354850769,
      "backward_entropy": 0.007257627589362008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.627092361450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04334023594856262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1015361100435257,
      "backward_entropy": 0.022684904081480845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.53022003173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04338197037577629,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10152831673622131,
      "backward_entropy": 0.02270850113459996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.43445587158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04342330992221832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10152047872543335,
      "backward_entropy": 0.0071973832590239385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.04313850402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043464284390211105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10151263326406479,
      "backward_entropy": 0.007179120289427894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.27069091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04350374639034271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10150448977947235,
      "backward_entropy": 0.007158631192786353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.911734580993652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043542735278606415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10149633139371872,
      "backward_entropy": 0.022797235420772007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.56336784362793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043580312281847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10148797929286957,
      "backward_entropy": 0.02280322994504656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.436391830444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0436197929084301,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10147963464260101,
      "backward_entropy": 0.007087282304252897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.474350929260254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04366084188222885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10147131234407425,
      "backward_entropy": 0.022829975400652205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.622696876525879,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04369965195655823,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10146281123161316,
      "backward_entropy": 0.09812366110937935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38387680053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043737199157476425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1014542430639267,
      "backward_entropy": 0.007020767245973859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.49949836730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043772853910923004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10144534707069397,
      "backward_entropy": 0.022869910512651716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.54436683654785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04380746930837631,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1014365404844284,
      "backward_entropy": 0.022877180150577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.66652488708496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04384225234389305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1014280840754509,
      "backward_entropy": 0.022885069251060486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.3852596282959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0438789427280426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10141939669847488,
      "backward_entropy": 0.022891397987093245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.41554832458496,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043915461748838425,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10141073167324066,
      "backward_entropy": 0.0981682538986206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.179844856262207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04395362362265587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10140185058116913,
      "backward_entropy": 0.00687988315309797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.089882850646973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04399045929312706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10139288008213043,
      "backward_entropy": 0.022883613194738115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.008420944213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04402534291148186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10138370096683502,
      "backward_entropy": 0.022876990692956106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.043230056762695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04406313970685005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10137487947940826,
      "backward_entropy": 0.006800707961831774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.82155990600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04409777745604515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10136586427688599,
      "backward_entropy": 0.006773612328938076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.703140258789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04413331672549248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10135632753372192,
      "backward_entropy": 0.006746672093868256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.505807876586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04416989907622337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10134671628475189,
      "backward_entropy": 0.006722227803298405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.259864807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04420832172036171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10133769363164902,
      "backward_entropy": 0.022849919540541514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.82549285888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04424930363893509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10132864117622375,
      "backward_entropy": 0.006680774901594434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.574823379516602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044294342398643494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10131964087486267,
      "backward_entropy": 0.02286535927227565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.674837112426758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044337376952171326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10131043195724487,
      "backward_entropy": 0.022868780153138295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.585865020751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044377926737070084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10130119323730469,
      "backward_entropy": 0.006622393748589924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.57501745223999,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044420696794986725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10129223763942719,
      "backward_entropy": 0.006604096719196865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.025811195373535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044461071491241455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10128317773342133,
      "backward_entropy": 0.022895329764911106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.211345672607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04450090229511261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10127396136522293,
      "backward_entropy": 0.006569860236985343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.444890975952148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04453938081860542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10126462578773499,
      "backward_entropy": 0.006552149142537799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.759628295898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04457574337720871,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10125528275966644,
      "backward_entropy": 0.0229231949363436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.97321319580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04461205005645752,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1012459397315979,
      "backward_entropy": 0.02293299777167184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.227697372436523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044652774930000305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10123655200004578,
      "backward_entropy": 0.022946149110794067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.884347915649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04469374939799309,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10122718662023544,
      "backward_entropy": 0.0229564436844417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.36307144165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04473317414522171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10121771693229675,
      "backward_entropy": 0.022964021989277432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.741011619567871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04477661848068237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10120831429958344,
      "backward_entropy": 0.006453785513128553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.124726295471191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044818323105573654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10119900852441788,
      "backward_entropy": 0.022984234350068227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.649572372436523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044857610017061234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10118955373764038,
      "backward_entropy": 0.02299500150339944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.53495216369629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04489731416106224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10117977857589722,
      "backward_entropy": 0.023005696279661998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.42759132385254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044937483966350555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10117024183273315,
      "backward_entropy": 0.006394309124776295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.950908184051514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04497793689370155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10116064548492432,
      "backward_entropy": 0.023033101643834795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4715576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04501590132713318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10115093737840652,
      "backward_entropy": 0.006364290203366961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.689701080322266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045050784945487976,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10114115476608276,
      "backward_entropy": 0.09837662322180611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.010515213012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045085739344358444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1011313945055008,
      "backward_entropy": 0.006330816873482296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.160655975341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04512152820825577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10112161934375763,
      "backward_entropy": 0.023055372493607656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.38686203956604,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045156244188547134,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10111177712678909,
      "backward_entropy": 0.09839309964861188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3682186603546143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0451882965862751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10110192000865936,
      "backward_entropy": 0.006284395498888833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.28473663330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045217953622341156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10109201073646545,
      "backward_entropy": 0.006268483187471118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.15715789794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04525072127580643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10108213126659393,
      "backward_entropy": 0.006254665553569794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.87743091583252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045286279171705246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10107219219207764,
      "backward_entropy": 0.006241969232048307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.822807312011719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04532096907496452,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10106232762336731,
      "backward_entropy": 0.09841789518083845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.015789031982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04535476490855217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10105250775814056,
      "backward_entropy": 0.0062196217477321625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02298704907298088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04538855329155922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1010424792766571,
      "backward_entropy": 0.006208247372082302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.08363914489746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04541897028684616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.101032555103302,
      "backward_entropy": 0.023143636328833445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.806012153625488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545065760612488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10102254897356033,
      "backward_entropy": 0.0061864182353019714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.729281425476074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04548245295882225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10101264715194702,
      "backward_entropy": 0.023171603679656982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.300762176513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04551459103822708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10100267827510834,
      "backward_entropy": 0.023188450506755283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.725341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045550387352705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10099256038665771,
      "backward_entropy": 0.02320904391152518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.62496566772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045586809515953064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10098253190517426,
      "backward_entropy": 0.006148253700562886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.323108673095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04562383145093918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1009722650051117,
      "backward_entropy": 0.023246369191578457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.342317581176758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045659661293029785,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10096205770969391,
      "backward_entropy": 0.02326347359589168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021764056757092476,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045695409178733826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10095198452472687,
      "backward_entropy": 0.006124093064240047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.108521461486816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045727428048849106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1009419709444046,
      "backward_entropy": 0.0232995514358793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.075613021850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045757900923490524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10093209147453308,
      "backward_entropy": 0.0233130476304463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.068944931030273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04578695073723793,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10092227905988693,
      "backward_entropy": 0.02332469608102526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.003179550170898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04581643268465996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10091234743595123,
      "backward_entropy": 0.006085010511534554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.900421142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0458463579416275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10090237855911255,
      "backward_entropy": 0.023350255829947337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.87051010131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0458783358335495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10089229792356491,
      "backward_entropy": 0.0060678912060601374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.748724937438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04591043293476105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10088220983743668,
      "backward_entropy": 0.0060597195156982964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.728419303894043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04594341665506363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10087203979492188,
      "backward_entropy": 0.00605108163186482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.659407615661621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04597646743059158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10086192190647125,
      "backward_entropy": 0.023408223475728716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.589502334594727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04600946977734566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10085168480873108,
      "backward_entropy": 0.023421038474355425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.518306732177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046042364090681076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10084158182144165,
      "backward_entropy": 0.006025105182613645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.30302906036377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04607515409588814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10083124786615372,
      "backward_entropy": 0.023434790117400035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.212752342224121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046108778566122055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10082095116376877,
      "backward_entropy": 0.006004763501031058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.584096908569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04614312946796417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10081055760383606,
      "backward_entropy": 0.023446557777268544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.218204498291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04618063196539879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10080002248287201,
      "backward_entropy": 0.005986854434013367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.919341087341309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04621764272451401,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10078948736190796,
      "backward_entropy": 0.02346434337752206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.05855941772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04625510424375534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10077882558107376,
      "backward_entropy": 0.005971241210188184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.72388744354248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04629209637641907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10076828300952911,
      "backward_entropy": 0.00596422648855618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.06911277770996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04632939025759697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10075783729553223,
      "backward_entropy": 0.023498641593115672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.520854949951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046368636190891266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10074714571237564,
      "backward_entropy": 0.005949589290789196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.053396224975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04640795290470123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1007363349199295,
      "backward_entropy": 0.02352053565638406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.994359970092773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04644576460123062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1007256954908371,
      "backward_entropy": 0.005935547075101307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.580026626586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04648216441273689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10071512311697006,
      "backward_entropy": 0.00592808797955513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008254846557974815,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046518027782440186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10070456564426422,
      "backward_entropy": 0.02354533757482256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.435747146606445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04655031859874725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10069434344768524,
      "backward_entropy": 0.023550908480371748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.776250839233398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04658248648047447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10068397969007492,
      "backward_entropy": 0.023554105843816484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.299958229064941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04661386087536812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10067397356033325,
      "backward_entropy": 0.023559693779264177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.905431747436523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04664529860019684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10066374391317368,
      "backward_entropy": 0.005886890526328768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.703393936157227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04667907580733299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10065323114395142,
      "backward_entropy": 0.0058796389826706475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.655113220214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04671337082982063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10064267367124557,
      "backward_entropy": 0.005872104316949844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.518441200256348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04674975201487541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10063181817531586,
      "backward_entropy": 0.0235830226114818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.422428131103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046786386519670486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10062098503112793,
      "backward_entropy": 0.005857824214867183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.934345722198486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046823278069496155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10061018913984299,
      "backward_entropy": 0.005850560963153839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.344169616699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0468580462038517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10059965401887894,
      "backward_entropy": 0.005843485040324075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.291980266571045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04689168184995651,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10058906674385071,
      "backward_entropy": 0.02360156604221889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.06464958190918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046924278140068054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10057863593101501,
      "backward_entropy": 0.023607254028320312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.584371566772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04695751890540123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10056819021701813,
      "backward_entropy": 0.023614423615591868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.27236270904541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0469905361533165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10055769979953766,
      "backward_entropy": 0.005819385605198997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.085428237915039,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04702485725283623,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1005469560623169,
      "backward_entropy": 0.09866796221051898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.034826755523682,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047058071941137314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10053649544715881,
      "backward_entropy": 0.005809283150093896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.331662178039551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047090232372283936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10052607953548431,
      "backward_entropy": 0.023649643574442183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.875003814697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04711991548538208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10051596909761429,
      "backward_entropy": 0.005798273852893284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.186748504638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0471511147916317,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10050565004348755,
      "backward_entropy": 0.005791784397193364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.843154430389404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04718223214149475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10049530863761902,
      "backward_entropy": 0.02366283323083605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.532862663269043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047212518751621246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10048507153987885,
      "backward_entropy": 0.0057793110609054565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2532200813293457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047241244465112686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.100475013256073,
      "backward_entropy": 0.005772751356874194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.711618900299072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0472678616642952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.100465327501297,
      "backward_entropy": 0.023671284317970276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.116859436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04729408025741577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10045569390058517,
      "backward_entropy": 0.02367387499128069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.838279724121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04732143133878708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10044603049755096,
      "backward_entropy": 0.005754275513546807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.977113723754883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04734906554222107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10043612122535706,
      "backward_entropy": 0.02368088279451643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.904557228088379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04737766832113266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10042595863342285,
      "backward_entropy": 0.005743977746793202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031412930693477392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047407131642103195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10041579604148865,
      "backward_entropy": 0.02368835891996111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.154594659805298,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04743361845612526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10040609538555145,
      "backward_entropy": 0.023690398250307356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026427083648741245,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047458216547966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1003967672586441,
      "backward_entropy": 0.02369295060634613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.772984504699707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047480348497629166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10038785636425018,
      "backward_entropy": 0.02369502399648939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.350925922393799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047504715621471405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1003786027431488,
      "backward_entropy": 0.005717945950371879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.314383506774902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04752885550260544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10036925971508026,
      "backward_entropy": 0.0057131413902555194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.370062828063965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047552790492773056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10036005079746246,
      "backward_entropy": 0.005708349602563041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.400897979736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04757728800177574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10035056620836258,
      "backward_entropy": 0.005703888833522797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.202520847320557,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04760297015309334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10034117102622986,
      "backward_entropy": 0.02371032748903547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.38116455078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04762827977538109,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10033169388771057,
      "backward_entropy": 0.005694584654910224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.203027725219727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04765615239739418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1003217026591301,
      "backward_entropy": 0.005690000419105802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.079748630523682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04768487438559532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1003115251660347,
      "backward_entropy": 0.023717411926814487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0374298095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047712862491607666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10030154138803482,
      "backward_entropy": 0.02371790792260851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.993167877197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04774023965001106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10029155015945435,
      "backward_entropy": 0.005676146064485822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.891590118408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04776850342750549,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1002814769744873,
      "backward_entropy": 0.023721186178071157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.878278732299805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047798991203308105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10027091950178146,
      "backward_entropy": 0.005668015884501594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.818294048309326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04782931134104729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10026031732559204,
      "backward_entropy": 0.0056641942688397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.698274612426758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04785947501659393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10024981945753098,
      "backward_entropy": 0.023728915623256137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.395610809326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04789018630981445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10023921728134155,
      "backward_entropy": 0.0056566234145845684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.725088119506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047923509031534195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10022808611392975,
      "backward_entropy": 0.005652854485171182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.24683666229248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04795561730861664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1002170741558075,
      "backward_entropy": 0.005649106843130929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8767776489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04798946529626846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10020559281110764,
      "backward_entropy": 0.005645745034728732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8613972663879395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0480206273496151,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10019482672214508,
      "backward_entropy": 0.005642078284706388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.540736675262451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048049405217170715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10018463432788849,
      "backward_entropy": 0.023737375225339617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.499811172485352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04807738959789276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10017451643943787,
      "backward_entropy": 0.005635066756180355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8206146955490112,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04810468479990959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10016465187072754,
      "backward_entropy": 0.0056316352316311425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6158692836761475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048129938542842865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10015519708395004,
      "backward_entropy": 0.023740534271512712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.77628231048584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048154059797525406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1001460999250412,
      "backward_entropy": 0.023740955761500766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91788387298584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04817991331219673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10013655573129654,
      "backward_entropy": 0.005620513643537249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.312322616577148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048206642270088196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.100126713514328,
      "backward_entropy": 0.005616941622325352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5165867805480957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04823277145624161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10011705756187439,
      "backward_entropy": 0.005613421222993306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.238725185394287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04825766384601593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10010775923728943,
      "backward_entropy": 0.005609877407550812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7347980737686157,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04828212410211563,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10009853541851044,
      "backward_entropy": 0.023742052061217173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4473884105682373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048304829746484756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10008978843688965,
      "backward_entropy": 0.0056028813123703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.852621078491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048326630145311356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10008129477500916,
      "backward_entropy": 0.0055993859257016864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.917070388793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04834897816181183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10007263720035553,
      "backward_entropy": 0.005596006555216653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.071991443634033,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04837384819984436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1000632494688034,
      "backward_entropy": 0.023741213338715688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6792080402374268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048398252576589584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10005401819944382,
      "backward_entropy": 0.023740261793136597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.341153144836426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04842090606689453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10004532337188721,
      "backward_entropy": 0.005586173385381699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6571433544158936,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04844465106725693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10003629326820374,
      "backward_entropy": 0.0055828871471541265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.586071014404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04846670478582382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10002777725458145,
      "backward_entropy": 0.02373711551938738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2718162536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04848923906683922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10001906752586365,
      "backward_entropy": 0.0055766744273049495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.753767013549805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04851086065173149,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1000106930732727,
      "backward_entropy": 0.023734567420823232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6146979331970215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04853431507945061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1000017523765564,
      "backward_entropy": 0.005570599011012486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.417290210723877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048556096851825714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09999332576990128,
      "backward_entropy": 0.005567634212119239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.969248294830322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04857835918664932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09998463839292526,
      "backward_entropy": 0.023729601076671054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.497333526611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04860170930624008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09997577965259552,
      "backward_entropy": 0.005562448075839451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.856006145477295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04862668365240097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09996630251407623,
      "backward_entropy": 0.005559931908335004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.677512168884277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04865246266126633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09995664656162262,
      "backward_entropy": 0.0237258608852114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.642307758331299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04867764189839363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09994713962078094,
      "backward_entropy": 0.023724257946014404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0719785690307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04870227351784706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.099937804043293,
      "backward_entropy": 0.005552329655204501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.050175666809082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048725761473178864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0999288558959961,
      "backward_entropy": 0.02372088815484728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5147018432617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04874822124838829,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09992025792598724,
      "backward_entropy": 0.005547844405685153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.020124435424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04876909777522087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09991218894720078,
      "backward_entropy": 0.02371856995991298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.495181918144226,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04879048839211464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09990392625331879,
      "backward_entropy": 0.005543894001415798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.429964542388916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04881040379405022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09989619255065918,
      "backward_entropy": 0.0055421314069202966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.381345748901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04883155599236488,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09988804161548615,
      "backward_entropy": 0.023715496063232422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.330286026000977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04885381460189819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09987950325012207,
      "backward_entropy": 0.02371420817715781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9108290672302246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048877060413360596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09987059235572815,
      "backward_entropy": 0.005537149629422596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.226296424865723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04889927804470062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09986203908920288,
      "backward_entropy": 0.005535755838666644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.60809326171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048922471702098846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09985314309597015,
      "backward_entropy": 0.005534351404224124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.270341873168945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04894716665148735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09984369575977325,
      "backward_entropy": 0.005532972514629364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7893697733816225e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04897131025791168,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09983444213867188,
      "backward_entropy": 0.02370836692196982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8052923679351807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0489930622279644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09982609003782272,
      "backward_entropy": 0.005530569170202527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9198160973464837e-06,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04901391640305519,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09981806576251984,
      "backward_entropy": 0.09879786627633232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.154288291931152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049032703042030334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09981079399585724,
      "backward_entropy": 0.0055287884814398626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.881519794464111,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04905150458216667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09980353713035583,
      "backward_entropy": 0.0237057272877012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7345826625823975,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04907156154513359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09979579597711563,
      "backward_entropy": 0.0055271754307406286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0758819580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049090877175331116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0997883677482605,
      "backward_entropy": 0.005526411214045116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.749998569488525,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04911014065146446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09978092461824417,
      "backward_entropy": 0.0055256906364645276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3408663272857666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04913059249520302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0997731015086174,
      "backward_entropy": 0.023700514010020664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.99415397644043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049149639904499054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09976578503847122,
      "backward_entropy": 0.005524437342371259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2922797203063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049170494079589844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0997576117515564,
      "backward_entropy": 0.02369773175035204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.56810998916626,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919173941016197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09974939376115799,
      "backward_entropy": 0.005523468766893659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.82260799407959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049213945865631104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09974078088998795,
      "backward_entropy": 0.005522957337754113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8798723220825195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923761636018753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09973156452178955,
      "backward_entropy": 0.005522462406328746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4153242111206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04926076903939247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09972252696752548,
      "backward_entropy": 0.02368799490588052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5451087951660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928465932607651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09971321374177933,
      "backward_entropy": 0.005521499684878758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5753021240234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04930739849805832,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09970428794622421,
      "backward_entropy": 0.02368150438581194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.259946823120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04933149740099907,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09969489276409149,
      "backward_entropy": 0.023677193692752292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4824106693267822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935620725154877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0996851921081543,
      "backward_entropy": 0.005519889295101166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.847620010375977,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04937967285513878,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0996759757399559,
      "backward_entropy": 0.0988183787890843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4394283294677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04940557852387428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09966571629047394,
      "backward_entropy": 0.005518749356269836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.25437593460083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049430109560489655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09965599328279495,
      "backward_entropy": 0.005518227815628052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.791944980621338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049455758184194565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09964577853679657,
      "backward_entropy": 0.005517632833548954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.187068223953247,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04948123171925545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09963561594486237,
      "backward_entropy": 0.005517162382602692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5307483673095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04950476810336113,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09962625801563263,
      "backward_entropy": 0.02363849537713187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.835313320159912,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049527738243341446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09961716085672379,
      "backward_entropy": 0.005516671708651951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1570693254470825,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0495513491332531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0996076911687851,
      "backward_entropy": 0.023626676627567837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.44307279586792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04957320913672447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0995989590883255,
      "backward_entropy": 0.023620831114905223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.277188301086426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04959464445710182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09959055483341217,
      "backward_entropy": 0.00551634920494897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.129997968673706,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04961511120200157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0995824933052063,
      "backward_entropy": 0.005516275763511658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.487447738647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04963413625955582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09957510232925415,
      "backward_entropy": 0.005516446594681058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.022865295410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049653567373752594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09956745058298111,
      "backward_entropy": 0.0055164918303489685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.104230523109436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049676232039928436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0995582640171051,
      "backward_entropy": 0.023586188043866838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2859597206115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049697231501340866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09954983741044998,
      "backward_entropy": 0.023579061031341553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1734213829040527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04971785843372345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.099541574716568,
      "backward_entropy": 0.005516453513077327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2353553771972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04973757639527321,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09953370690345764,
      "backward_entropy": 0.09883553641183036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1407532691955566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04975704103708267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09952586889266968,
      "backward_entropy": 0.005516863827194486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.250279426574707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04977571964263916,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09951849281787872,
      "backward_entropy": 0.02355054020881653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1093990802764893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049794793128967285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09951084852218628,
      "backward_entropy": 0.005517782377345222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.18834114074707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049813106656074524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0995035320520401,
      "backward_entropy": 0.023536929062434604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0787556171417236,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049831852316856384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09949599951505661,
      "backward_entropy": 0.005518824394260134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0958006381988525,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04984985664486885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.099488765001297,
      "backward_entropy": 0.0055193549820355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.073763608932495,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049867745488882065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09948156774044037,
      "backward_entropy": 0.023516003574643816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.051868200302124,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988553375005722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09947440028190613,
      "backward_entropy": 0.005520419350692204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.050095081329346,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049903225153684616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09946726262569427,
      "backward_entropy": 0.005521073937416077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.004892587661743,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049921914935112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09945955872535706,
      "backward_entropy": 0.005521491169929504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.975325107574463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049939874559640884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09945221245288849,
      "backward_entropy": 0.005522192588874272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.949490785598755,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04995880275964737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09944430738687515,
      "backward_entropy": 0.02348120723451887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.877317428588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04997804015874863,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09943622350692749,
      "backward_entropy": 0.005523326141493661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9137277603149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04999863728880882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09942746162414551,
      "backward_entropy": 0.005523580525602613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7783427238464355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050018828362226486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09941873699426651,
      "backward_entropy": 0.005523974342005593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.772139072418213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050040267407894135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09940937906503677,
      "backward_entropy": 0.005524251077856336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.836853504180908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050062280148267746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09939968585968018,
      "backward_entropy": 0.02344084850379399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.874112844467163,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05008373409509659,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09939020872116089,
      "backward_entropy": 0.09885083777563912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9290327429771423,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050104133784770966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09938129782676697,
      "backward_entropy": 0.0055253564247063226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.528076648712158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05012305825948715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09937314689159393,
      "backward_entropy": 0.023417783635003225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7400572299957275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05014330521225929,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09936416149139404,
      "backward_entropy": 0.02341043097632272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.527439594268799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050163138657808304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09935551136732101,
      "backward_entropy": 0.005527280271053314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7949191331863403,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050183650106191635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0993463322520256,
      "backward_entropy": 0.0055277954254831585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.227997303009033,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05020318180322647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09933768212795258,
      "backward_entropy": 0.02338718090738569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7629305124282837,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05022444576025009,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09932805597782135,
      "backward_entropy": 0.02337848927293505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.620591402053833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050244659185409546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09931889176368713,
      "backward_entropy": 0.023370432002203807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7317906618118286,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05026443302631378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09931008517742157,
      "backward_entropy": 0.005530027938740594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.292428970336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05028330907225609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09930161386728287,
      "backward_entropy": 0.005531122109719685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.552839517593384,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0503028929233551,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09929271042346954,
      "backward_entropy": 0.023349238293511525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.530604124069214,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05032208934426308,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09928404539823532,
      "backward_entropy": 0.02334220920290266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.181318283081055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0503409206867218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09927548468112946,
      "backward_entropy": 0.005533810704946518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4864776134490967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050360433757305145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09926648437976837,
      "backward_entropy": 0.005534440279006958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.107342720031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05037956312298775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.099257692694664,
      "backward_entropy": 0.023319463644708906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.069673538208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05039933696389198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09924846887588501,
      "backward_entropy": 0.005536260349409921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6124987602233887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05041969567537308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09923885762691498,
      "backward_entropy": 0.005537223070859909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7990424633026123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05043903365731239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09922981262207031,
      "backward_entropy": 0.005538118737084525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.584357738494873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05045695602893829,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09922154247760773,
      "backward_entropy": 0.023290306329727173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1426327228546143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05047411099076271,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09921370446681976,
      "backward_entropy": 0.023283138871192932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.674550533294678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050491563975811005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09920567274093628,
      "backward_entropy": 0.023275703191757202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.544319748878479,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05051027610898018,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09919679164886475,
      "backward_entropy": 0.005541962704488209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3579230308532715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052812770009041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0991884246468544,
      "backward_entropy": 0.005542876464979989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.823188304901123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05054767057299614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09917895495891571,
      "backward_entropy": 0.005543748182909829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.999737739562988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050569694489240646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09916789084672928,
      "backward_entropy": 0.005544330924749374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9649498462677,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05059344321489334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09915564209222794,
      "backward_entropy": 0.02323570421763829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1980013847351074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050616804510354996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09914370626211166,
      "backward_entropy": 0.005545109510421753,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 4.085703554620888,
    "avg_log_Z": -0.049608814530074596,
    "success_rate": 1.0,
    "avg_reward": 57.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.36,
      "2": 0.6
    },
    "avg_forward_entropy": 0.09957733504474163,
    "avg_backward_entropy": 0.015746708464409623,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}