{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.0624119910326871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062411687590859154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.8331756591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143773714701335,
      "backward_entropy": 0.062481056560169564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.35885620117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144121408462524,
      "backward_entropy": 0.06241727417165583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.86367797851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0002000251697609201,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144462148348491,
      "backward_entropy": 0.06243351914665916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003003077581524849,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144792954126994,
      "backward_entropy": 0.06249923055822199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.15237426757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00039959981222637,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145118792851765,
      "backward_entropy": 0.06250499595295299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.7067108154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004989631706848741,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914543867111206,
      "backward_entropy": 0.06243923577395352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.0375213623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005977695109322667,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145752588907878,
      "backward_entropy": 0.0625161582773382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.97862243652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006950918468646705,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146058559417725,
      "backward_entropy": 0.062485033815557305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.02980041503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007922473014332354,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146360556284587,
      "backward_entropy": 0.062494738535447555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.11163330078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008901172550395131,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914665659268697,
      "backward_entropy": 0.062459468841552734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.37196350097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0009860103018581867,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146942694981892,
      "backward_entropy": 0.06251376325433905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.58041381835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010834188433364034,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914722482363383,
      "backward_entropy": 0.06246904893354936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.77587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011800023494288325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147496024767558,
      "backward_entropy": 0.06254645911130038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.87820434570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012789180036634207,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914776623249054,
      "backward_entropy": 0.062478721141815186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.04339599609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013781213201582432,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148029486338298,
      "backward_entropy": 0.06248366832733154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.81787109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001474000047892332,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148281812667847,
      "backward_entropy": 0.06255948543548584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.91282653808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015706784324720502,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148528178532918,
      "backward_entropy": 0.06249284202402288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.813232421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016694976948201656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148769577344258,
      "backward_entropy": 0.06257156350395897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.2852325439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017678241711109877,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149004022280376,
      "backward_entropy": 0.06257659738714044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.63262939453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018647941760718822,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149231513341267,
      "backward_entropy": 0.06259387189691717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.412841796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00196437886916101,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149457017580669,
      "backward_entropy": 0.06251152537085793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.88308715820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0020615949761122465,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149672587712605,
      "backward_entropy": 0.06261051784862172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.16505432128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002157762413844466,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149879217147827,
      "backward_entropy": 0.06261849403381348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.20455932617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022546483669430017,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150081872940063,
      "backward_entropy": 0.06252406402067705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.20306396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002351335482671857,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0915027658144633,
      "backward_entropy": 0.06252790039235895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.47357177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002445826306939125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150465329488118,
      "backward_entropy": 0.0625314712524414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.19813537597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0025402132887393236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150650103886922,
      "backward_entropy": 0.0625349608334628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.1727752685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002633840311318636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09150828917821248,
      "backward_entropy": 0.06261771375482733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.625732421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027268107514828444,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09150998791058858,
      "backward_entropy": 0.06266376647082242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.0741424560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028202417306602,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151161710421245,
      "backward_entropy": 0.06262595003301447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.2146759033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029150547925382853,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151318669319153,
      "backward_entropy": 0.06254790045998314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.42457580566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0030092555098235607,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151466687520345,
      "backward_entropy": 0.06263446807861328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.92726135253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00310362596064806,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151609738667806,
      "backward_entropy": 0.06269149888645519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.83599853515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0031971002463251352,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151746829350789,
      "backward_entropy": 0.06269813125783746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.7597961425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003291869070380926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151877959569295,
      "backward_entropy": 0.06264696337959984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.96791076660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033905296586453915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152002135912578,
      "backward_entropy": 0.0626514499837702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.18417358398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034879217855632305,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152117371559143,
      "backward_entropy": 0.06271833723241632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.57598876953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035860028583556414,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152228633562724,
      "backward_entropy": 0.06272502378983931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.03347778320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036819542292505503,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152330954869588,
      "backward_entropy": 0.06273145567287099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.2093963623047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003780695144087076,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152427315711975,
      "backward_entropy": 0.06273769248615611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.94984436035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038801163900643587,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152516722679138,
      "backward_entropy": 0.06274388053200462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.2479705810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003980869427323341,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152600169181824,
      "backward_entropy": 0.06258352236314253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.21444702148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004079969134181738,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0915267566839854,
      "backward_entropy": 0.06258677352558482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.07798767089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0041763815097510815,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152746200561523,
      "backward_entropy": 0.06258978085084395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.72840881347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0042726267129182816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152808785438538,
      "backward_entropy": 0.0626856034452265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.69960021972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004368993919342756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152862429618835,
      "backward_entropy": 0.06268901174718683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.9868927001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004464287310838699,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152908126513164,
      "backward_entropy": 0.06269225207242099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.38978576660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004560719709843397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152946869532268,
      "backward_entropy": 0.06269550323486328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.9717102050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004659187514334917,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152975678443909,
      "backward_entropy": 0.06269888444380327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.3190155029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004762035328894854,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152997533480327,
      "backward_entropy": 0.06279489127072421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.87973022460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0048660775646567345,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09153008460998535,
      "backward_entropy": 0.06261034987189552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.96148681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004967838060110807,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09153014421463013,
      "backward_entropy": 0.06270945072174072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.20986938476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00507366331294179,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09153008460998535,
      "backward_entropy": 0.06261653249913995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.17442321777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005180263426154852,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152993559837341,
      "backward_entropy": 0.0626197403127497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.01507568359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005283564794808626,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152969717979431,
      "backward_entropy": 0.06262272596359253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.00033569335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0053877620957791805,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152936935424805,
      "backward_entropy": 0.0628270994533192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.26513671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005488699302077293,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06283199245279486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.03994750976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005587664898484945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152851502100627,
      "backward_entropy": 0.06272919611497359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.46168518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005685332231223583,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152793884277344,
      "backward_entropy": 0.06263346021825617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.02220153808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005783508066087961,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152726332346599,
      "backward_entropy": 0.06263588775287975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.58750915527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005881038960069418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152650833129883,
      "backward_entropy": 0.06273732402107933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.11866760253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005976863205432892,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152568380037944,
      "backward_entropy": 0.06285367228768089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.19769287109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0060712601989507675,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152476986249287,
      "backward_entropy": 0.0626427097754045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.05825805664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00616998178884387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152369697888692,
      "backward_entropy": 0.0627449479970065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.07508850097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006266942247748375,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152261416117351,
      "backward_entropy": 0.06286583163521507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.21702575683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006361058913171291,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152148167292277,
      "backward_entropy": 0.06286953254179521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.25338745117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006456097587943077,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152025977770488,
      "backward_entropy": 0.06287305463444103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.992919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006553324870765209,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151888887087505,
      "backward_entropy": 0.06275454434481534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.85247802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006647668778896332,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151745835940044,
      "backward_entropy": 0.06265540556474165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.44036865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006741970311850309,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151591857274373,
      "backward_entropy": 0.0627588846466758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.0480651855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00683507788926363,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151428937911987,
      "backward_entropy": 0.06265884095972235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.19175720214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006932341493666172,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151251117388408,
      "backward_entropy": 0.0628895867954601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.5210876464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007029145024716854,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151062369346619,
      "backward_entropy": 0.06266239014538852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.56492614746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007129744626581669,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09150855739911397,
      "backward_entropy": 0.06276738101785834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.16151428222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007228827569633722,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150636196136475,
      "backward_entropy": 0.06266600435430353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.80743408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007325979880988598,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09150409698486328,
      "backward_entropy": 0.06277151541276411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.86239624023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007422287482768297,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09150175253550212,
      "backward_entropy": 0.06290497563102028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.78477478027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007515960838645697,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149932861328125,
      "backward_entropy": 0.06267031756314365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.267822265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0076106153428554535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149678548177083,
      "backward_entropy": 0.06277650052850897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.8954162597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0077047995291650295,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149413307507832,
      "backward_entropy": 0.06291275132786144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.67356872558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0078034233301877975,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149126211802165,
      "backward_entropy": 0.06277949701655995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.03744506835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007902474142611027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148826201756795,
      "backward_entropy": 0.0626749883998524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.68531036376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008000372909009457,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148518244425456,
      "backward_entropy": 0.0626760558648543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.3354797363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008091075345873833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148210287094116,
      "backward_entropy": 0.06278342550451105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.3184356689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008186078630387783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147882461547852,
      "backward_entropy": 0.06278459050438621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.61615753173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008278834633529186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147544701894124,
      "backward_entropy": 0.06278567964380438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.11199951171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008367105387151241,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147202968597412,
      "backward_entropy": 0.06292924014004794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.18560791015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008452078327536583,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.091468612353007,
      "backward_entropy": 0.0629311583258889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.280517578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008536472916603088,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146508574485779,
      "backward_entropy": 0.0629329031163996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.59718322753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00862056389451027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146143992741902,
      "backward_entropy": 0.06267929077148438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.21817016601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008701895363628864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145776430765788,
      "backward_entropy": 0.0626793232831088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.03064727783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008783266879618168,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145393967628479,
      "backward_entropy": 0.0627887790853327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.029296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008859788067638874,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145014484723409,
      "backward_entropy": 0.06293935125524347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.93052673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008936665020883083,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144622087478638,
      "backward_entropy": 0.06267889521338722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.71656799316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009011427871882915,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144224723180135,
      "backward_entropy": 0.06267858635295522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 291.9814147949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00908791646361351,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143811464309692,
      "backward_entropy": 0.06278865987604315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.56900024414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00917301420122385,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914335548877716,
      "backward_entropy": 0.06294523044065996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.25509643554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009262326173484325,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914287269115448,
      "backward_entropy": 0.06267872723666104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.82785034179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00934973917901516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142379959424336,
      "backward_entropy": 0.06267888979478316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.952880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009437935426831245,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141867359479268,
      "backward_entropy": 0.06267906860871748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.18856811523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009529341012239456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141324957211812,
      "backward_entropy": 0.0626793232831088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.23609924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009621012024581432,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140766660372417,
      "backward_entropy": 0.06267952919006348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.83892822265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009708325378596783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140206376711528,
      "backward_entropy": 0.06279182434082031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.3817596435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009797470644116402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139626224835713,
      "backward_entropy": 0.06279204108498314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.16282653808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009886834770441055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139029184977214,
      "backward_entropy": 0.06279212778264825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.99908447265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009974525310099125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138421217600505,
      "backward_entropy": 0.06279209527102383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.37673950195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010062912479043007,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137795368830363,
      "backward_entropy": 0.06296021288091486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.18212890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010150996036827564,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137151638666789,
      "backward_entropy": 0.0629614916714755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.38094329833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010243283584713936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136473139127095,
      "backward_entropy": 0.06279211694544012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.8164825439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01032830961048603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135811527570088,
      "backward_entropy": 0.06279175931757147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.6742401123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010416671633720398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135117133458455,
      "backward_entropy": 0.0627914612943476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.36944580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010505461134016514,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134402871131897,
      "backward_entropy": 0.06279107657345859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.64195251464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01059254165738821,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09133680661519368,
      "backward_entropy": 0.06296734376387163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.17735290527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010676916688680649,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913295050462087,
      "backward_entropy": 0.06267541105096991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.76415252685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010758970864117146,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913221538066864,
      "backward_entropy": 0.06278943473642523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.97813415527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010837417095899582,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131480256716411,
      "backward_entropy": 0.06278860569000244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.63986206054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01091989316046238,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130707383155823,
      "backward_entropy": 0.06297092546116222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.49351501464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011001231148838997,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129921595255534,
      "backward_entropy": 0.0626714446327903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.87216186523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011080469004809856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129129846890767,
      "backward_entropy": 0.06278620524839922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.97592163085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011154040694236755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09128351012865703,
      "backward_entropy": 0.06266883286562833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.74415588378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01122729666531086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127557277679443,
      "backward_entropy": 0.06266732107509267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.47650146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011301700957119465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126738707224528,
      "backward_entropy": 0.06266582012176514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.9981231689453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01137583889067173,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125903248786926,
      "backward_entropy": 0.06297509236769243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.0482635498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011453434824943542,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125027060508728,
      "backward_entropy": 0.06297573718157681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.83969116210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011535187251865864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124107162157695,
      "backward_entropy": 0.0626615123315291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.34002685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011612167581915855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09123196204503377,
      "backward_entropy": 0.06277712366797707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.47019958496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01168864592909813,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09122270345687866,
      "backward_entropy": 0.06297760659998114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.83578491210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011769546195864677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09121293822924297,
      "backward_entropy": 0.06265681440179999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.10121154785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011849666945636272,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120301405588786,
      "backward_entropy": 0.06265524300661954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.46315002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011928768828511238,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119296073913574,
      "backward_entropy": 0.06265357407656583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.49679565429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012007624842226505,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09118269880612691,
      "backward_entropy": 0.06297990408810702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.45765686035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012087369337677956,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09117241700490315,
      "backward_entropy": 0.06298044594851407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.54302978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012167922221124172,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09116193652153015,
      "backward_entropy": 0.06264826384457675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.00326538085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012251378037035465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115103880564372,
      "backward_entropy": 0.06264654072848233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.63665771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012336468324065208,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113980333010356,
      "backward_entropy": 0.06276359883221713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.16180419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012421508319675922,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112833937009175,
      "backward_entropy": 0.0626430023800243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.937232971191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012506620027124882,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111665685971577,
      "backward_entropy": 0.06264113296161998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.30233764648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012581315822899342,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09110557039578755,
      "backward_entropy": 0.06263874877582896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.43258666992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012659558095037937,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09109397729237874,
      "backward_entropy": 0.06298387050628662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.48616027832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012737354263663292,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108219544092815,
      "backward_entropy": 0.06263405626470392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6236572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012811938300728798,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910704533259074,
      "backward_entropy": 0.06275143406607887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.23399353027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012885002419352531,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105860193570454,
      "backward_entropy": 0.06274877895008434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.79354858398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012954761274158955,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09104682008425395,
      "backward_entropy": 0.06262581998651678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.52330017089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013030089437961578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09103432297706604,
      "backward_entropy": 0.06274358250878075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.27500915527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013103840872645378,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09102167685826619,
      "backward_entropy": 0.06274092197418213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.01992797851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013183945789933205,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09100814660390218,
      "backward_entropy": 0.06298563697121361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.8370361328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013262111693620682,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099441766738892,
      "backward_entropy": 0.06261489608071068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.38348388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013337170705199242,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09098047018051147,
      "backward_entropy": 0.06261156905781139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.90567016601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013411836698651314,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096617499987285,
      "backward_entropy": 0.06273000890558417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.72975158691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013483986258506775,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09095179041226704,
      "backward_entropy": 0.06298634138974277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.77066040039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01355594489723444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09093706806500752,
      "backward_entropy": 0.06260047175667503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.6002655029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013634336180984974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09092135230700175,
      "backward_entropy": 0.06272002241828224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.83804321289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01371494960039854,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09090505043665568,
      "backward_entropy": 0.062593167478388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.684326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01379722822457552,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09088821212450664,
      "backward_entropy": 0.06258950450203636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.18051147460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013878535479307175,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0908711055914561,
      "backward_entropy": 0.06258573315360329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.72792053222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013960221782326698,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09085359175999959,
      "backward_entropy": 0.06258193471214989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.9695587158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014041239395737648,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09083579977353413,
      "backward_entropy": 0.06298742511055687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.73194885253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014121322892606258,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09081773956616719,
      "backward_entropy": 0.06257393143393776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.96658325195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014202279038727283,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907991627852122,
      "backward_entropy": 0.06298763101751154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.28623962402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014283686876296997,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09078013896942139,
      "backward_entropy": 0.06256561929529364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.25083923339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014367310330271721,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09076046943664551,
      "backward_entropy": 0.06298786943609064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.94252014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014449303969740868,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09074066082636516,
      "backward_entropy": 0.0625570687380704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.44676208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014531892724335194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09072036544481914,
      "backward_entropy": 0.0626809922131625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.25611877441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014612623490393162,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09069992105166118,
      "backward_entropy": 0.06254797632044012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.56443786621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014688892289996147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09067968527475993,
      "backward_entropy": 0.0626730051907626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.84768676757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014764761552214622,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09065906206766765,
      "backward_entropy": 0.06298819997093895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.72014617919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014844614081084728,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09063750505447388,
      "backward_entropy": 0.06266440044749867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.64630126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014920217916369438,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09061618645985921,
      "backward_entropy": 0.0625275427644903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.88157653808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014994578436017036,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09059462944666545,
      "backward_entropy": 0.06298811869187788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.3182830810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015067478641867638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905728538831075,
      "backward_entropy": 0.06251612576571378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.90647888183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015141173265874386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09055060148239136,
      "backward_entropy": 0.06264532696117055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.34762573242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015217665582895279,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0905274748802185,
      "backward_entropy": 0.06264055858958852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.64895629882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015294021926820278,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09050393104553223,
      "backward_entropy": 0.06298754431984642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.26385498046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015373492613434792,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09047951300938924,
      "backward_entropy": 0.062492679465900765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.20301818847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015453927218914032,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09045446912447612,
      "backward_entropy": 0.0629871975291859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.10643768310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015535234473645687,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09042882919311523,
      "backward_entropy": 0.06248099153692072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.67373657226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015612538903951645,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0904034674167633,
      "backward_entropy": 0.0624747709794478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.4470977783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015693919733166695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09037697315216064,
      "backward_entropy": 0.06261153654618697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.68194580078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015777358785271645,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09034963448842366,
      "backward_entropy": 0.06298657980832187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.89041137695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015860343351960182,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09032189846038818,
      "backward_entropy": 0.06260198896581476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015943970531225204,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09029354651769002,
      "backward_entropy": 0.06298635222695091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.1114044189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016025736927986145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09026507536570232,
      "backward_entropy": 0.06244379823858088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.7172393798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01611362397670746,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09023497502009074,
      "backward_entropy": 0.06243764812296087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.83795166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016200266778469086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09020453691482544,
      "backward_entropy": 0.06243131377480247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.81848907470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016284631565213203,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09017403920491536,
      "backward_entropy": 0.06242471391504461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.95594787597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01636553555727005,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09014368057250977,
      "backward_entropy": 0.06298575618050316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.14314270019531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01644580438733101,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09011288483937581,
      "backward_entropy": 0.06298551776192406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.92681884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016522912308573723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09008181095123291,
      "backward_entropy": 0.06255883520299738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.50341796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016599196940660477,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09005038936932881,
      "backward_entropy": 0.06298487836664374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.29637908935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016675693914294243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09001846114794414,
      "backward_entropy": 0.06254618818109686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.49221801757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01674445904791355,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08998772501945496,
      "backward_entropy": 0.06298408183184537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.01893615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01681361347436905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08995614449183147,
      "backward_entropy": 0.06253186681053856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.20211791992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016889328137040138,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08992257714271545,
      "backward_entropy": 0.06236057931726629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.0174102783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01696755550801754,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08988771835962932,
      "backward_entropy": 0.06235228343443437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.9989013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017048625275492668,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08985191583633423,
      "backward_entropy": 0.06234422597018155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.85992431640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017126118764281273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08981629212697347,
      "backward_entropy": 0.06233572959899902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.32007598876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017206545919179916,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08977943658828735,
      "backward_entropy": 0.062327341599897904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.3479461669922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017281662672758102,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08974336584409077,
      "backward_entropy": 0.06298163804140958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.70108032226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017357032746076584,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0897066096464793,
      "backward_entropy": 0.06230915676463734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.17855834960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017432520166039467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08966914812723796,
      "backward_entropy": 0.0624751015142961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.17599487304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017506567761301994,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08963135878245036,
      "backward_entropy": 0.06229023499922319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.681640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017582662403583527,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08959235747655232,
      "backward_entropy": 0.06297986615787853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.91343688964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01766072027385235,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08955226341883342,
      "backward_entropy": 0.06227108565243808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.13773345947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01773347146809101,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08951300382614136,
      "backward_entropy": 0.06244293668053367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.64013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017802782356739044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08947405219078064,
      "backward_entropy": 0.062250126491893425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.12694549560547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017875248566269875,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08943343162536621,
      "backward_entropy": 0.0629777962511236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.06414794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01794540137052536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08939272165298462,
      "backward_entropy": 0.06241568652066318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.8336944580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018015176057815552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08935150504112244,
      "backward_entropy": 0.062406149777499115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.81558227539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01808437518775463,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08930975198745728,
      "backward_entropy": 0.06220599738034335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.34242248535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018155833706259727,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08926659822463989,
      "backward_entropy": 0.0629751140421087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.3216094970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018227769061923027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08922254045804341,
      "backward_entropy": 0.06218312003395774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.35708618164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018308274447917938,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08917523423830669,
      "backward_entropy": 0.062172434546730736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.52098083496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018388578668236732,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0891272524992625,
      "backward_entropy": 0.06235811927101829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.996826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018468346446752548,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08907860517501831,
      "backward_entropy": 0.06215044585141269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.28675842285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01855049468576908,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08902840813000996,
      "backward_entropy": 0.06213941899212924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.50504302978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01863252930343151,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08897760510444641,
      "backward_entropy": 0.06232839280908758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.62281799316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018711334094405174,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08892707029978435,
      "backward_entropy": 0.06211616776206277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.77134704589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01879534125328064,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08887406190236409,
      "backward_entropy": 0.06210469115864147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.80181884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01888154447078705,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08881953358650208,
      "backward_entropy": 0.06209333376450972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.72470092773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018965914845466614,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08876500527064006,
      "backward_entropy": 0.06208102269606157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.01547241210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019048642367124557,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08871037761370341,
      "backward_entropy": 0.062276970256458626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.6968994140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019130857661366463,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08865582942962646,
      "backward_entropy": 0.062266295606439766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.66552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019212977960705757,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08860063552856445,
      "backward_entropy": 0.06204158609563654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.5241241455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0192974004894495,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08854377269744873,
      "backward_entropy": 0.062028299678455696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.7467498779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019381511956453323,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08848632375399272,
      "backward_entropy": 0.06223445588892156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.5288848876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019463904201984406,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08842877546946208,
      "backward_entropy": 0.06200065396048806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.25917053222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019548824056982994,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0883695383866628,
      "backward_entropy": 0.06296859546141191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.80210876464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019633393734693527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08830966552098592,
      "backward_entropy": 0.06220258365977894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.58804321289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019717171788215637,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08824905753135681,
      "backward_entropy": 0.0619581937789917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.66720581054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019801324233412743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08818606535593669,
      "backward_entropy": 0.06218021566217596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.932861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01988605596125126,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08812177181243896,
      "backward_entropy": 0.06216882575641979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.31710815429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01997178979218006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08805611729621887,
      "backward_entropy": 0.06191441687670621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.69778442382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02005261741578579,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08799145619074504,
      "backward_entropy": 0.061898654157465156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.19659423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02013353258371353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08792589108149211,
      "backward_entropy": 0.06213382157412442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.71144104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02021465264260769,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08785943190256755,
      "backward_entropy": 0.06212190064516934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.4324493408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020292803645133972,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08779329061508179,
      "backward_entropy": 0.06210896101864902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.47470092773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0203707255423069,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08772603670756023,
      "backward_entropy": 0.06183165853673762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.6170196533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02045193687081337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0876565972963969,
      "backward_entropy": 0.06181443279439753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.27045440673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02053309977054596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08758628368377686,
      "backward_entropy": 0.06207014213908802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.07415771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020608341321349144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08751771847407024,
      "backward_entropy": 0.06205566362901167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.03913116455078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02068231999874115,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0874485969543457,
      "backward_entropy": 0.06296356157823042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.41761779785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02075381390750408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08737960457801819,
      "backward_entropy": 0.06202357465570623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.15291595458984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020822210237383842,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08731143673261006,
      "backward_entropy": 0.06296153502030806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.00459289550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020887572318315506,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08724393447240193,
      "backward_entropy": 0.061693635853854095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.00707244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020950952544808388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08717610438664754,
      "backward_entropy": 0.06196833740581165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.44320678710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021008795127272606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08711029092470805,
      "backward_entropy": 0.06194709647785534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.00991821289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021069133654236794,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08704253037770589,
      "backward_entropy": 0.06295509771867232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.12034606933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021135760471224785,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08697078625361125,
      "backward_entropy": 0.06295386769554832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.40596008300781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021204741671681404,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0868966778119405,
      "backward_entropy": 0.06295275688171387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.38284301757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02127177268266678,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08682261904080708,
      "backward_entropy": 0.06186789274215698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.5171661376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02133866772055626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08674778540929158,
      "backward_entropy": 0.06184732913970947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.37928771972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02141217142343521,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08666847149531047,
      "backward_entropy": 0.061827778816223145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.09840393066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021492181345820427,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08658518393834432,
      "backward_entropy": 0.06147727641192349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.60504150390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02157173492014408,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08650098244349162,
      "backward_entropy": 0.06145406853068958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.901123046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021652590483427048,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08641517162322998,
      "backward_entropy": 0.06294765255667946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.73883056640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02173253893852234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08632952968279521,
      "backward_entropy": 0.06175211342898282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.48109436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021815212443470955,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0862414538860321,
      "backward_entropy": 0.06138309565457431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.61206817626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02189655601978302,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08615355690320332,
      "backward_entropy": 0.061713473363356156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.70278930664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021975353360176086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08606657385826111,
      "backward_entropy": 0.061333114450628105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.16404724121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022056885063648224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08597695827484131,
      "backward_entropy": 0.06167304515838623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.83663940429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022140992805361748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08588491876920064,
      "backward_entropy": 0.06128248301419345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.15133666992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022223392501473427,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08579244216283162,
      "backward_entropy": 0.06125618652863936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.0067596435547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022299664095044136,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08570186297098796,
      "backward_entropy": 0.0629436427896673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.80393981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022374896332621574,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08561064799626668,
      "backward_entropy": 0.061585155400362884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.0046844482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022450800985097885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08551801244417827,
      "backward_entropy": 0.06156110763549805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.6724090576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022525958716869354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0854249397913615,
      "backward_entropy": 0.06153669682416049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.82135009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02260020188987255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08533133069674174,
      "backward_entropy": 0.06110996549779719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.67217254638672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022675110027194023,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08523627122243245,
      "backward_entropy": 0.06293770399960605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.02188110351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022743377834558487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08514466881752014,
      "backward_entropy": 0.06104679541154341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.772216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02281341329216957,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08505127827326457,
      "backward_entropy": 0.06143331527709961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.67070007324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022882571443915367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08495694398880005,
      "backward_entropy": 0.06140578334981745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.57278442382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022949693724513054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08486267924308777,
      "backward_entropy": 0.06094517491080544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.83799743652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02302241139113903,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08476376533508301,
      "backward_entropy": 0.06292921846563165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.43850708007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02309572882950306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0846633513768514,
      "backward_entropy": 0.06087713891809637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.34237670898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023172421380877495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08455959955851237,
      "backward_entropy": 0.06128815629265525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.18807983398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023250916972756386,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08445380131403606,
      "backward_entropy": 0.060811671343716706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.38052368164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023331034928560257,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08434605598449707,
      "backward_entropy": 0.06122922897338867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.13256072998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023409776389598846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08423848946889241,
      "backward_entropy": 0.06119801781394265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.03627014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023485789075493813,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08413199583689372,
      "backward_entropy": 0.060710701075467194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.80978393554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02356807142496109,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08402057488759358,
      "backward_entropy": 0.060677138241854583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.72850799560547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02364577166736126,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08391156792640686,
      "backward_entropy": 0.06292055953632701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.78634643554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02371845953166485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08380600810050964,
      "backward_entropy": 0.06060310927304355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.76361083984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023786259815096855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08370337883631389,
      "backward_entropy": 0.060561971230940384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.86473083496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023858385160565376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08359688520431519,
      "backward_entropy": 0.060985023325139824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.49221801757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02392982505261898,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08348991473515828,
      "backward_entropy": 0.06094649705019864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.22086334228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02400040440261364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08338236808776855,
      "backward_entropy": 0.06090567870573564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.97589874267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024069085717201233,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08327546715736389,
      "backward_entropy": 0.060391827063127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.83407592773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024136431515216827,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0831691970427831,
      "backward_entropy": 0.06081899729642001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.43276977539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024204596877098083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08306088050206502,
      "backward_entropy": 0.06077330762689764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.28646850585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02427424117922783,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08295093476772308,
      "backward_entropy": 0.06025377728722312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.3231658935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024345219135284424,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08283946414788564,
      "backward_entropy": 0.06020741029219194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.31382751464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02442171983420849,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08272334933280945,
      "backward_entropy": 0.06063937057148327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.20065307617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024497617036104202,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08260746796925862,
      "backward_entropy": 0.06011765653436834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.56141662597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024574097245931625,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08249049385388692,
      "backward_entropy": 0.06007151170210405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.14344024658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024652712047100067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08237143357594807,
      "backward_entropy": 0.060025323521007194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.12083435058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024727514013648033,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0822551151116689,
      "backward_entropy": 0.05997600338675759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.08296203613281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0247996486723423,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08213972051938374,
      "backward_entropy": 0.0599239631132646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.38951873779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0248671006411314,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08202783266703288,
      "backward_entropy": 0.06289432265541771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.15357971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024933120235800743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0819165011246999,
      "backward_entropy": 0.06030119549144398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.71253204345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02500397153198719,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08180105686187744,
      "backward_entropy": 0.0628898794000799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.83795166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025071417912840843,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08168765902519226,
      "backward_entropy": 0.059696668928319756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.88957977294922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025141457095742226,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08157111704349518,
      "backward_entropy": 0.06288534944707697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.46444702148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02520981803536415,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08145532011985779,
      "backward_entropy": 0.0595771616155451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.83026123046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02527894452214241,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08133698006470998,
      "backward_entropy": 0.05951508608731357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.37661743164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025347506627440453,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08121793468793233,
      "backward_entropy": 0.059934729879552666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.76837158203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025420544669032097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.081094890832901,
      "backward_entropy": 0.059870784932916817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.40016174316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025494622066617012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08097062508265178,
      "backward_entropy": 0.05980658531188965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.09127044677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02556409314274788,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08085055152575175,
      "backward_entropy": 0.05925398523157293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.20388793945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02563195861876011,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08073142170906067,
      "backward_entropy": 0.05918254635550759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.45968627929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025695836171507835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08061618606249492,
      "backward_entropy": 0.05959254503250122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9950714111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025762952864170074,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08049747347831726,
      "backward_entropy": 0.0595185865055431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.91294860839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025832736864686012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08037552237510681,
      "backward_entropy": 0.05944393439726396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.94578552246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025900771841406822,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0802545150121053,
      "backward_entropy": 0.06285434419458563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.34635925292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025970257818698883,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08013192812601726,
      "backward_entropy": 0.05928698453036221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.3284912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026036759838461876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0800117552280426,
      "backward_entropy": 0.05920460549267856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.678829193115234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026103613898158073,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07989108562469482,
      "backward_entropy": 0.06284384835850108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.50523376464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026161352172493935,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07977786660194397,
      "backward_entropy": 0.05855376612056385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.23065948486328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026218805462121964,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07966469724973042,
      "backward_entropy": 0.06283142349936745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.72401428222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02627740614116192,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07955018679300944,
      "backward_entropy": 0.058364001187411224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.44955444335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026337167248129845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07943452894687653,
      "backward_entropy": 0.05874315717003562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.69806671142578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02640659548342228,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0793103277683258,
      "backward_entropy": 0.06281747601249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.53890991210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026471659541130066,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07919012506802876,
      "backward_entropy": 0.05808588591488925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.36943817138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02653748355805874,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07906965414683025,
      "backward_entropy": 0.05799074606461958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.22335815429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02660198323428631,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07894978920618693,
      "backward_entropy": 0.0628047531301325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.58567810058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026665296405553818,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07883048554261525,
      "backward_entropy": 0.05779144980690696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.66183471679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02672307752072811,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07871585587660472,
      "backward_entropy": 0.057683451609178024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.91412353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02678338997066021,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07859859863917033,
      "backward_entropy": 0.057576130736957894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.93971252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026850003749132156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07847500840822856,
      "backward_entropy": 0.05796275355599143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.52424621582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026915481314063072,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07835262020428975,
      "backward_entropy": 0.05785920403220437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.8748321533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026979319751262665,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07823088765144348,
      "backward_entropy": 0.05775141716003418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.55329895019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02704761177301407,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07810460527737935,
      "backward_entropy": 0.057645808566700325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.85381317138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027112960815429688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07798109948635101,
      "backward_entropy": 0.057535323229703034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.74678802490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027173884212970734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0778612494468689,
      "backward_entropy": 0.05692458152770996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.81639099121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02723565325140953,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07774085799853007,
      "backward_entropy": 0.06274055350910533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.59005737304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027299335226416588,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07761843999226888,
      "backward_entropy": 0.05717403238469904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.37947082519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02736511081457138,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07749453683694203,
      "backward_entropy": 0.05656763098456643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.86163330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02742961421608925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773718257745107,
      "backward_entropy": 0.05693061243404041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.52305603027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027498658746480942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07724488774935405,
      "backward_entropy": 0.0568106933073564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.51823425292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027567505836486816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07711818317572276,
      "backward_entropy": 0.056686780669472435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.36254119873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02763056568801403,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07699718077977498,
      "backward_entropy": 0.05607429417696866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.54931640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0276931319385767,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0768772264321645,
      "backward_entropy": 0.06269613179293546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.21426391601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027754763141274452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07675792276859283,
      "backward_entropy": 0.056282964619723236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.88434600830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027820231392979622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07663557926813762,
      "backward_entropy": 0.05615057728507302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.06349182128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027884235605597496,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07651414473851521,
      "backward_entropy": 0.05553638393228704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.49819946289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027947958558797836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07639190057913463,
      "backward_entropy": 0.0558646483854814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.96495056152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028019441291689873,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07626319428284963,
      "backward_entropy": 0.055730884725397285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.9546661376953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028092382475733757,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07613423466682434,
      "backward_entropy": 0.06266125765713779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.74806213378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028168784454464912,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07600208123524983,
      "backward_entropy": 0.05500449917533181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.98512268066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028247160837054253,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07586854696273804,
      "backward_entropy": 0.05533334883776578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.75491333007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02832012251019478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07574054102102916,
      "backward_entropy": 0.05518798936497082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.80459594726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02839665859937668,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07560952007770538,
      "backward_entropy": 0.05504517663608898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.37123107910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028476640582084656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07547620435555775,
      "backward_entropy": 0.054906184023076836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.92642974853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028549280017614365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07534963885943095,
      "backward_entropy": 0.05475118485364047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.15065002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02861946076154709,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07522749900817871,
      "backward_entropy": 0.05416400324214588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.21542358398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028687968850135803,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0751072069009145,
      "backward_entropy": 0.06263406710191206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.82876586914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028759129345417023,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07498468955357869,
      "backward_entropy": 0.053850379857149994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.86080932617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028829913586378098,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07486286262671153,
      "backward_entropy": 0.05369148471138694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.11854553222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02889745682477951,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.074744313955307,
      "backward_entropy": 0.06261970780112526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.20799255371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028970619663596153,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0746212253967921,
      "backward_entropy": 0.05377819321372292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.86715698242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029043573886156082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0744996468226115,
      "backward_entropy": 0.05319904197346081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.34490203857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029120463877916336,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07437547047932942,
      "backward_entropy": 0.053039258176630195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.70127868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02919616736471653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07425241669019063,
      "backward_entropy": 0.05327293005856601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.13072204589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029266512021422386,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07413434982299805,
      "backward_entropy": 0.052694754167036575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.15953063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02933795377612114,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0740158458550771,
      "backward_entropy": 0.0525146560235457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.10123443603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029407620429992676,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07389957706133525,
      "backward_entropy": 0.052328288555145264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.67611694335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029476959258317947,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07378409802913666,
      "backward_entropy": 0.052138686180114746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.94967651367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02954738587141037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0736679236094157,
      "backward_entropy": 0.05228351462971081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.81581115722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02962064929306507,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07355056206385295,
      "backward_entropy": 0.05208554592999545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.22899627685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029690096154808998,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0734365185101827,
      "backward_entropy": 0.051874502138658005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.74382019042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029759611934423447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07332361737887065,
      "backward_entropy": 0.0516631928357211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.26968383789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02982715331017971,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07321508725484212,
      "backward_entropy": 0.05116637186570601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.19407653808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029890188947319984,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07311038672924042,
      "backward_entropy": 0.05095167593522505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.90619659423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02995244413614273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07300718625386556,
      "backward_entropy": 0.05073304609818892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.5983123779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030013641342520714,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07290473580360413,
      "backward_entropy": 0.05050877549431541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.89012145996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030078399926424026,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0727999210357666,
      "backward_entropy": 0.05028892647136341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.7686767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030147729441523552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07269012928009033,
      "backward_entropy": 0.050299427726052025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.36094284057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03020985797047615,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07258713245391846,
      "backward_entropy": 0.04984682256525213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.14113235473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030265623703598976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07249029477437337,
      "backward_entropy": 0.04979518868706443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.654296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03031608648598194,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07239638765652974,
      "backward_entropy": 0.062432050704956055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.80128479003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03036869317293167,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07230168581008911,
      "backward_entropy": 0.04924533583901145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.686344146728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030427366495132446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07220279177029927,
      "backward_entropy": 0.048855234276164665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.98303985595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030478164553642273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07211046914259593,
      "backward_entropy": 0.04859833825718273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.93183135986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03053222969174385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0720160702864329,
      "backward_entropy": 0.048441074111244896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.39297485351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03058761917054653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192081212997437,
      "backward_entropy": 0.04816893555901267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.39375305175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030650408938527107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07182123263676961,
      "backward_entropy": 0.04791852560910312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.47468566894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030712999403476715,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07172372937202454,
      "backward_entropy": 0.047624403780156914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.13296127319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03077445924282074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07162692149480183,
      "backward_entropy": 0.04737956957383589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.36455535888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0308308657258749,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07153446972370148,
      "backward_entropy": 0.04712783206592907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.09263610839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030885988846421242,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0714442531267802,
      "backward_entropy": 0.046847673979672516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.95059585571289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03094547800719738,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07135135928789775,
      "backward_entropy": 0.046605299819599495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.62650299072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030995583161711693,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07126576701800029,
      "backward_entropy": 0.04632903770966963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.71438980102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031049074605107307,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07117795944213867,
      "backward_entropy": 0.045989172025160355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.26177215576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031098229810595512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07109348972638448,
      "backward_entropy": 0.04568403417413885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.47759246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03114938922226429,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07100796699523926,
      "backward_entropy": 0.04538290609012951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.52632141113281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03120260126888752,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07092191775639851,
      "backward_entropy": 0.04508778181943027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.92161560058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03125569969415665,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07083573937416077,
      "backward_entropy": 0.044940731742165306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.85730743408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03131306543946266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07074671983718872,
      "backward_entropy": 0.044485596093264496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.76199340820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031372785568237305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07065604130427043,
      "backward_entropy": 0.044395387172698975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.68555450439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03143635019659996,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07056371370951335,
      "backward_entropy": 0.04412913864309138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.97763061523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031494662165641785,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0704757422208786,
      "backward_entropy": 0.04358970035206188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.75927734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03155435621738434,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07038798928260803,
      "backward_entropy": 0.0435636043548584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.56710052490234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031618379056453705,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0702989399433136,
      "backward_entropy": 0.0621006272055886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.30294036865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031681858003139496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07021153966585796,
      "backward_entropy": 0.04270029609853571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.34696960449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03174746781587601,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0701235830783844,
      "backward_entropy": 0.0427529053254561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.38837432861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03181227296590805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0700373003880183,
      "backward_entropy": 0.042122131044214424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.85963439941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03187796100974083,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06995188693205516,
      "backward_entropy": 0.06208607283505527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.60675811767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03194285184144974,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06986793875694275,
      "backward_entropy": 0.04193320599469272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.78453063964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03200828284025192,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0697841743628184,
      "backward_entropy": 0.041246571324088356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.36835479736328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0320756770670414,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06969992319742839,
      "backward_entropy": 0.06207959218458696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.51994323730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03214201331138611,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06961712737878163,
      "backward_entropy": 0.04109977050261064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.72595977783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03220934420824051,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06953547398249309,
      "backward_entropy": 0.040822419253262604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.51353454589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032276879996061325,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06945384542147319,
      "backward_entropy": 0.04054053263230757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.77496337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03234177455306053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06937422355016072,
      "backward_entropy": 0.039752033623782074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.93887329101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032410070300102234,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06929309169451396,
      "backward_entropy": 0.03996226462450894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.09872436523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03248165175318718,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06921123464902242,
      "backward_entropy": 0.03915294733914462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.68712615966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03255056217312813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06913214425245921,
      "backward_entropy": 0.03884921019727534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.41255187988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0326123982667923,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06905743976434071,
      "backward_entropy": 0.038518325849012894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.296142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03267638757824898,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06898147861162822,
      "backward_entropy": 0.03818914565173062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.57161712646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03273961693048477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06890634695688884,
      "backward_entropy": 0.03847918185320767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.97952270507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03280240297317505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06883243719736735,
      "backward_entropy": 0.03752024878155102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.14688110351562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032863449305295944,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06876059373219807,
      "backward_entropy": 0.062019927935166794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.17412567138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03293122723698616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06868565082550049,
      "backward_entropy": 0.03686888109553944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.09658813476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03300238400697708,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06861001749833424,
      "backward_entropy": 0.036573827266693115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.06942749023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033074021339416504,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06853571037451427,
      "backward_entropy": 0.03698527812957764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.67915725708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03315260633826256,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06845850745836894,
      "backward_entropy": 0.03671569715846668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.30496597290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03322511166334152,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06838587919871013,
      "backward_entropy": 0.03642691807313399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.10916900634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03328797221183777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06831990679105122,
      "backward_entropy": 0.03537610986016013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.58766174316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0333501435816288,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06825405359268188,
      "backward_entropy": 0.035794889385049995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.21709442138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03342055156826973,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06818484763304393,
      "backward_entropy": 0.03473082455721768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.08653259277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03348563238978386,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06811894476413727,
      "backward_entropy": 0.03519042513587258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.47441864013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03355579450726509,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06805128852526347,
      "backward_entropy": 0.03410257263617082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.50037384033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033623021095991135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06798487901687622,
      "backward_entropy": 0.03378022529862144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.65149688720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03369060903787613,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06791849434375763,
      "backward_entropy": 0.034283039244738495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.11982727050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033757541328668594,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06785349051157634,
      "backward_entropy": 0.03397585316137834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.53749084472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033822234719991684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06779000163078308,
      "backward_entropy": 0.03279961510138078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.49020385742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03389185294508934,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06772435704867046,
      "backward_entropy": 0.032483138821341774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.52928161621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03396327793598175,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06765857835610707,
      "backward_entropy": 0.033066009933298286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.04135131835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03403785824775696,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06759221355120341,
      "backward_entropy": 0.03188118880445307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.75984954833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03411244601011276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06752660870552063,
      "backward_entropy": 0.03158537366173484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.359188079833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034189872443675995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06746073563893636,
      "backward_entropy": 0.031299032948233864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.86099243164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034263089299201965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06739817063013713,
      "backward_entropy": 0.03192722797393799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.31684112548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03433603048324585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06733530263106029,
      "backward_entropy": 0.03069381280378862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.49494934082031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034406114369630814,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06727367639541626,
      "backward_entropy": 0.031332907351580536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.90625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0344739630818367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06721370915571849,
      "backward_entropy": 0.030047422105615788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.16773223876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034542106091976166,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06715329488118489,
      "backward_entropy": 0.029721330512653698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.18198013305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034612368792295456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0670927365620931,
      "backward_entropy": 0.030422273007306187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.22959899902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03467757999897003,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06703502933184306,
      "backward_entropy": 0.030111171982505104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.74485778808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034743815660476685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06697733700275421,
      "backward_entropy": 0.02875784852287986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.66743469238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03481109067797661,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06691992779572804,
      "backward_entropy": 0.0284440354867415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.18601989746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03487519174814224,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06686469415823619,
      "backward_entropy": 0.02919420599937439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.91454315185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03494294360280037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06680765748023987,
      "backward_entropy": 0.02781203118237582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.91606903076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035008594393730164,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06675159931182861,
      "backward_entropy": 0.028592050075531006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.90666198730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03507807105779648,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06669429937998454,
      "backward_entropy": 0.02830263701352206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.22874450683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03514562174677849,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0666386882464091,
      "backward_entropy": 0.028010159730911255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.08999633789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035211898386478424,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06658220787843068,
      "backward_entropy": 0.02770908312364058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.15547180175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03527681529521942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06652788817882538,
      "backward_entropy": 0.026258858767422764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.328243255615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03534107282757759,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06647308667500813,
      "backward_entropy": 0.027108658443797718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.88216018676758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03540237993001938,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0664196362098058,
      "backward_entropy": 0.026802220127799294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.28424072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035459861159324646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06636842091878255,
      "backward_entropy": 0.025279042395678433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.07154083251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03551553189754486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06631901363531749,
      "backward_entropy": 0.026179037310860374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.99754333496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035571541637182236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06626701354980469,
      "backward_entropy": 0.025869388471950184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.90584182739258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035632237792015076,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.066214253505071,
      "backward_entropy": 0.02558003772388805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.34626770019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035689469426870346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0661644736925761,
      "backward_entropy": 0.024006540125066585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.75878143310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03574318438768387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06611633797486623,
      "backward_entropy": 0.023690749298442493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.17350006103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03579889237880707,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06606658299763997,
      "backward_entropy": 0.024696117097681217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.52622604370117,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.035856615751981735,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06601528326670329,
      "backward_entropy": 0.06168121641332453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.98969268798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03591223433613777,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06596483786900838,
      "backward_entropy": 0.024121002717451615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.81690216064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03596736118197441,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06591470042864482,
      "backward_entropy": 0.02383876930583607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.93333053588867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03602313622832298,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06586375832557678,
      "backward_entropy": 0.023563666777177292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.32434844970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03607706353068352,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06581349174181621,
      "backward_entropy": 0.021874563260511917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.58478927612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03613357990980148,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06576244036356609,
      "backward_entropy": 0.02159214968031103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.90190887451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036185357719659805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06571302811304729,
      "backward_entropy": 0.02129441499710083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.78407287597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0362398698925972,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06566290060679118,
      "backward_entropy": 0.022488209334286777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.05494689941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03629498556256294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06561167538166046,
      "backward_entropy": 0.02222796326333826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.26142883300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036353692412376404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0655587762594223,
      "backward_entropy": 0.020458386702971024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.28109741210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03640998899936676,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06550583740075429,
      "backward_entropy": 0.021726923910054294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.82856750488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03646988421678543,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06545161704222362,
      "backward_entropy": 0.021484633738344364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.04293060302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03653312474489212,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06539630889892578,
      "backward_entropy": 0.01966484839265997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.71572875976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03660216182470322,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0653392771879832,
      "backward_entropy": 0.06155220486901023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.12931060791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036672383546829224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06528226534525554,
      "backward_entropy": 0.019223870201544327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.60786819458008,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.036744628101587296,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06522412101427714,
      "backward_entropy": 0.061591928655450996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.78584289550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03681197389960289,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06516711910565694,
      "backward_entropy": 0.020422292026606472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.2807846069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03687916323542595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06510970989863078,
      "backward_entropy": 0.01854677227410403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.203147888183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03694641962647438,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06505328416824341,
      "backward_entropy": 0.01833201132037423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.06497573852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037012115120887756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06499641140302022,
      "backward_entropy": 0.01811301437291232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.43849563598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037076324224472046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06493935982386272,
      "backward_entropy": 0.017887498844753612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.53248596191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037138164043426514,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06488342086474101,
      "backward_entropy": 0.01765920492735776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.132530212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03720169886946678,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06482639908790588,
      "backward_entropy": 0.017440890724008732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.75684356689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037262871861457825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06477014223734538,
      "backward_entropy": 0.01721747084097429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.453369140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0373246930539608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06471391518910725,
      "backward_entropy": 0.016999625346877358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.52016067504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037389662116765976,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06465618312358856,
      "backward_entropy": 0.01859724521636963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.218017578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037450943142175674,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06459983189900716,
      "backward_entropy": 0.06167966669256037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.704463958740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03751025348901749,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06454376379648845,
      "backward_entropy": 0.018196734515103428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.43834686279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03756362944841385,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06448982656002045,
      "backward_entropy": 0.061671235344626686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.33493041992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037619639188051224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06443366905053456,
      "backward_entropy": 0.015916554765267807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.78155517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03767784684896469,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06437671184539795,
      "backward_entropy": 0.01570657437497919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.26253890991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03773201256990433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06432194511095683,
      "backward_entropy": 0.015493119304830378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.79304504394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037785016000270844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06426751613616943,
      "backward_entropy": 0.01718757911161943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.410573959350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03783925995230675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06421199937661488,
      "backward_entropy": 0.01507331837307323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.84619903564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03788992762565613,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06415857871373494,
      "backward_entropy": 0.014863347465341742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.08884811401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03794350475072861,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06410311162471771,
      "backward_entropy": 0.014661347324197943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.90803527832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03799457475543022,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06404808163642883,
      "backward_entropy": 0.016412575136531483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.32530212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03804899379611015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06399240096410115,
      "backward_entropy": 0.014267916029149836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.12874984741211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03810486942529678,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0639352301756541,
      "backward_entropy": 0.014085768298669294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.53723907470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038159385323524475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06387835741043091,
      "backward_entropy": 0.013901493766091087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.53748321533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03821573406457901,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06382059057553609,
      "backward_entropy": 0.013730269941416655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.33858489990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0382709801197052,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06376362840334575,
      "backward_entropy": 0.01556700197133151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.17323303222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0383276641368866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06370521585146587,
      "backward_entropy": 0.013396428389982744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.92506408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03838324546813965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06364771227041881,
      "backward_entropy": 0.015256368301131508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.21055221557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038437940180301666,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06359046200911204,
      "backward_entropy": 0.015104911544106224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.130680084228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03849296644330025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06353265047073364,
      "backward_entropy": 0.012921215458349749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.79086685180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03854813799262047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06347389022509257,
      "backward_entropy": 0.012766407294706865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.78269958496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03860362619161606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06341461340586345,
      "backward_entropy": 0.012616087089885365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.53995895385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03866417706012726,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06335162619749705,
      "backward_entropy": 0.012475361878221685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.14097595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038724277168512344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06328771511713664,
      "backward_entropy": 0.01233236627145247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03878270834684372,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06322396794954936,
      "backward_entropy": 0.012184707955880598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.95841217041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03884633257985115,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06315826872984569,
      "backward_entropy": 0.014137400822205977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.80423736572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03891193866729736,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06309088567892711,
      "backward_entropy": 0.014019525863907555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.05428123474121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038977738469839096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06302205721537273,
      "backward_entropy": 0.011796925555575977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.10594940185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03903914988040924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06295579671859741,
      "backward_entropy": 0.011661954901435158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.76212310791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03910144045948982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06288839379946391,
      "backward_entropy": 0.011531518264250322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.77098083496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03916586562991142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06281900405883789,
      "backward_entropy": 0.011407353661277077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.32110595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03922710940241814,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0627507468064626,
      "backward_entropy": 0.011277735233306885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.72827911376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03929036483168602,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06268076598644257,
      "backward_entropy": 0.011152343993837183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.89824676513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039349090307950974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06261221567789714,
      "backward_entropy": 0.011016641828146849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.79140853881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0394088476896286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06254222492376964,
      "backward_entropy": 0.010882482609965584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.294551849365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03946838155388832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06247178713480631,
      "backward_entropy": 0.010749380696903576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.212581634521484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03952904790639877,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06240094701449076,
      "backward_entropy": 0.061963796615600586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.03450393676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03958965837955475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06232957045237223,
      "backward_entropy": 0.010497424412857403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.18376159667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03965015336871147,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06225781639417013,
      "backward_entropy": 0.012618541717529297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.75811767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039709240198135376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.062186350425084434,
      "backward_entropy": 0.010255089537663893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.563480377197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03976752609014511,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06211577355861664,
      "backward_entropy": 0.010140777988867327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.14164733886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03982225060462952,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06204709907372793,
      "backward_entropy": 0.01002387431534854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.73519897460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03987479954957962,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06197907030582428,
      "backward_entropy": 0.01219669526273554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.28976058959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039931561797857285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0619078129529953,
      "backward_entropy": 0.012095349756154146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.080196380615234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0399898886680603,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.061834817131360374,
      "backward_entropy": 0.06205219572240656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.27587127685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040049560368061066,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061760117610295616,
      "backward_entropy": 0.009575149552388624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.751461029052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04010721296072006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06168738007545471,
      "backward_entropy": 0.011816886338320646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.448768615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04016385227441788,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06161474188168844,
      "backward_entropy": 0.011727127161892977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.760536193847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040219880640506744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061542252699534096,
      "backward_entropy": 0.009274862706661224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.162412643432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04027630016207695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06146911780039469,
      "backward_entropy": 0.009179189801216125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.68223190307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04032842069864273,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06139912704626719,
      "backward_entropy": 0.009080101143230091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.443355560302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040379125624895096,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0613300104935964,
      "backward_entropy": 0.011382944204590538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.06364440917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040431998670101166,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061258514722188316,
      "backward_entropy": 0.008889408274130388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.3854751586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04048541933298111,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0611855685710907,
      "backward_entropy": 0.011218994855880737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.1119384765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040543220937252045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06110836068789164,
      "backward_entropy": 0.008709835735234346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.36351013183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040603235363960266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06102820237477621,
      "backward_entropy": 0.008622281930663368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.64053344726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04066331312060356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060947333772977196,
      "backward_entropy": 0.0085354745388031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.00328826904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04072808846831322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060861602425575256,
      "backward_entropy": 0.008454887704415754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.46725082397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04079503193497658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06077446540196737,
      "backward_entropy": 0.008380270817063072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.39329147338867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040856774896383286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06069142619768778,
      "backward_entropy": 0.00830183516849171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.258487701416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04091986268758774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060607537627220154,
      "backward_entropy": 0.008228507231582294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.947853088378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04097941145300865,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06052642563978831,
      "backward_entropy": 0.008154858242381702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.15493392944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04104139283299446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06044224898020426,
      "backward_entropy": 0.010631584985689684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.43961715698242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041098713874816895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060361847281455994,
      "backward_entropy": 0.008010258728807623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.687358856201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04115857183933258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06027840574582418,
      "backward_entropy": 0.007937920364466581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.03248977661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04121636971831322,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.060196653008461,
      "backward_entropy": 0.010456133295189251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.96446228027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041275665163993835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060112337271372475,
      "backward_entropy": 0.007797566327181729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.77661895751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041335318237543106,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06002784768740336,
      "backward_entropy": 0.010349461300806566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.131317138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04139523580670357,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05994288126627604,
      "backward_entropy": 0.010299906134605408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.40314483642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04145311191678047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05985920627911886,
      "backward_entropy": 0.00760382278399034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.155540466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04151131957769394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059774686892827354,
      "backward_entropy": 0.010201958092776213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.01430892944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04156999662518501,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05968919893105825,
      "backward_entropy": 0.010156036100604317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.183753967285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0416288785636425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059602578481038414,
      "backward_entropy": 0.007420917803590948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.119773864746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041686952114105225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05951640506585439,
      "backward_entropy": 0.007361759516325864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.81993865966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041746608912944794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05942790706952413,
      "backward_entropy": 0.007305988533930345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.204014778137207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041803017258644104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0593420018752416,
      "backward_entropy": 0.007247506217523055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.10673713684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04185545817017555,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05926010012626648,
      "backward_entropy": 0.007187719372185794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.935148239135742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041906438767910004,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059179271260897316,
      "backward_entropy": 0.009880559688264673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.42782974243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04195632040500641,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05909936626752218,
      "backward_entropy": 0.007068639451807196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.52669143676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04200980067253113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05901584525903066,
      "backward_entropy": 0.007016278803348541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.947208404541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04206383600831032,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05892983078956604,
      "backward_entropy": 0.006961265748197382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.773685455322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04212099686264992,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0588399072488149,
      "backward_entropy": 0.009715390476313505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.46135711669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042177457362413406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0587502121925354,
      "backward_entropy": 0.006857399913397702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.47921752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04223664849996567,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05865659316380819,
      "backward_entropy": 0.00680619478225708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.065624237060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04229923337697983,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05855788787206014,
      "backward_entropy": 0.006755062802271409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.43108367919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042359359562397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05846149722735087,
      "backward_entropy": 0.006702307273041119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.07553482055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04242084175348282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05836371580759684,
      "backward_entropy": 0.006653149696913632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.75235366821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04248224198818207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05826537807782491,
      "backward_entropy": 0.006603664972565391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.452068328857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04254244640469551,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.058167467514673867,
      "backward_entropy": 0.009441833604465832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.340486526489258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042600709944963455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05807158350944519,
      "backward_entropy": 0.006503905762325634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.218719482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04265710338950157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05797733863194784,
      "backward_entropy": 0.006455057723955674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.05751037597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0427129752933979,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05788358052571615,
      "backward_entropy": 0.006407720121470365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.981468200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0427694171667099,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05778829256693522,
      "backward_entropy": 0.006361407312479886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.763999938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04282398149371147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05769461393356323,
      "backward_entropy": 0.00631352039900693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.29319763183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042878057807683945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05760127305984497,
      "backward_entropy": 0.006265633485533975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.551401138305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042934976518154144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05750340223312378,
      "backward_entropy": 0.006219256330620159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.10741424560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04299026355147362,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05740706125895182,
      "backward_entropy": 0.006174678152257746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.71511459350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043046142905950546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057309508323669434,
      "backward_entropy": 0.0061311505057594995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.157428741455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0431036502122879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05720961093902588,
      "backward_entropy": 0.006088762120767074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.01449966430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04315950721502304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057111447056134544,
      "backward_entropy": 0.006048139523376118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.43651580810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0432179793715477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057008941968282066,
      "backward_entropy": 0.006007693707942963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.79188537597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043280020356178284,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05690115690231323,
      "backward_entropy": 0.008988791568712755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.18429946899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04334302246570587,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056791216135025024,
      "backward_entropy": 0.005931321870196949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.49831008911133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04340793564915657,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056678324937820435,
      "backward_entropy": 0.005893592130054127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.193078994750977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04347560182213783,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.056560839215914406,
      "backward_entropy": 0.008901975371620872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.85642623901367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04353839531540871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05645002921422323,
      "backward_entropy": 0.005820921198888259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.050111770629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043604038655757904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05633471409479777,
      "backward_entropy": 0.0057849240573969755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.89206886291504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04366699606180191,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05622246861457825,
      "backward_entropy": 0.005747740241614255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.18550109863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043727677315473557,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05611305435498556,
      "backward_entropy": 0.005711507390845905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.01211929321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04378732666373253,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05600479245185852,
      "backward_entropy": 0.008759367195042696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.21910858154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04384610056877136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055897653102874756,
      "backward_entropy": 0.005642203783447092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.98894500732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04390501230955124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055789401133855186,
      "backward_entropy": 0.005608352070504969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.503143310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0439673513174057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05567509929339091,
      "backward_entropy": 0.005576827986673875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.34136199951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04402858018875122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05556263526280721,
      "backward_entropy": 0.005546987056732178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.39549255371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044088706374168396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055451671282450356,
      "backward_entropy": 0.005517510189251466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.788841247558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04414893686771393,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055339932441711426,
      "backward_entropy": 0.005489362573081797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.30998992919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0442122183740139,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05522282918294271,
      "backward_entropy": 0.005461140112443404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.400510787963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04427725076675415,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05510211984316508,
      "backward_entropy": 0.008568751541050997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.74575424194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04433872923254967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05498690406481425,
      "backward_entropy": 0.0054050104861909695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.138289451599121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04440217465162277,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.054867888490358986,
      "backward_entropy": 0.00852514464746822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.094905853271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04446115717291832,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05475593606630961,
      "backward_entropy": 0.00850290060043335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.991518020629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044517144560813904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05464840432008108,
      "backward_entropy": 0.005324048074808988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.832000732421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04457147791981697,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05454327662785848,
      "backward_entropy": 0.005296986888755451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.474361419677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044625334441661835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05443844199180603,
      "backward_entropy": 0.005270075052976608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.221290588378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044681865721940994,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05432849625746409,
      "backward_entropy": 0.008408974517475475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.357074737548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04474082589149475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05421383182207743,
      "backward_entropy": 0.0052195746790279045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.21646118164062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04479888454079628,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05410038431485494,
      "backward_entropy": 0.0628411119634455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.62462615966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044862162321805954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05397785703341166,
      "backward_entropy": 0.005174115300178528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.1485595703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044926125556230545,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05385343233744303,
      "backward_entropy": 0.0628516294739463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.590843200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04499164968729019,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05372577408949534,
      "backward_entropy": 0.005132273516871713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.093093872070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04505959153175354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05359351634979248,
      "backward_entropy": 0.005111663517626849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.60122299194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04512365907430649,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05346787969271342,
      "backward_entropy": 0.005090980705889789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.49715805053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04519124701619148,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.053335572282473244,
      "backward_entropy": 0.008251843804662878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.11953353881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04525602236390114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05320807298024496,
      "backward_entropy": 0.005050799386067824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.87319564819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04532121121883392,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05307893455028534,
      "backward_entropy": 0.005030943250114267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.17084503173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04538671672344208,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05294918020566305,
      "backward_entropy": 0.00819111547686837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.360130310058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545547440648079,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05281287928422292,
      "backward_entropy": 0.004991245540705594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.33167266845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04552419111132622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05267604688803355,
      "backward_entropy": 0.004971616308797489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.66606140136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045588910579681396,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05254643162091573,
      "backward_entropy": 0.0081259317018769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.856708526611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04565592110157013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05241175492604574,
      "backward_entropy": 0.008102601902051405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.01494598388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04572106897830963,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.052280341585477196,
      "backward_entropy": 0.008079064840620214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.006778717041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045785509049892426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052149961392084755,
      "backward_entropy": 0.004895046692002903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.64034652709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04585316404700279,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05201284090677897,
      "backward_entropy": 0.004876711829142137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.905975341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045923683792352676,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05186966061592102,
      "backward_entropy": 0.0048580010506239805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.89590835571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0459909662604332,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05173227687676748,
      "backward_entropy": 0.004839052530852231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.911760330200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04606110230088234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05158879359563192,
      "backward_entropy": 0.004820333285765214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.345935821533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046129949390888214,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05144744118054708,
      "backward_entropy": 0.004801833832805807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.796993255615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04619474336504936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051314075787862144,
      "backward_entropy": 0.0047838284888050775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.260215759277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04626256227493286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051174263159434,
      "backward_entropy": 0.00476613776250319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.03012466430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046329278498888016,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05103625853856405,
      "backward_entropy": 0.007851269434798847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.865161895751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046393100172281265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0509037176767985,
      "backward_entropy": 0.00473171743479642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.759553909301758,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0464552566409111,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05077405273914337,
      "backward_entropy": 0.062929706139998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.629905700683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046514932066202164,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05064937472343445,
      "backward_entropy": 0.004698696461590854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.630300521850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04657239094376564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05052897334098816,
      "backward_entropy": 0.00468274476853284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.541512489318848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046626895666122437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05041445791721344,
      "backward_entropy": 0.004667307165536014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.093585968017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04667874798178673,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05030520757039388,
      "backward_entropy": 0.004652498797936873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.16411018371582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04673008993268013,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050196513533592224,
      "backward_entropy": 0.0046380558474497366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.87260437011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04678003117442131,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050090531508127846,
      "backward_entropy": 0.0046241754157976675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.207866668701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046833336353302,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04997678101062775,
      "backward_entropy": 0.004610143940557133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.123747825622559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046884045004844666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04986858864625295,
      "backward_entropy": 0.0045961815525184975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.44609832763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04693247005343437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04976508021354675,
      "backward_entropy": 0.004582913084463639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.22451400756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04698348790407181,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04965528845787048,
      "backward_entropy": 0.004570579325610941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.498804092407227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047036826610565186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04953972498575846,
      "backward_entropy": 0.004558515480973504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.364830017089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04708855226635933,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04942747950553894,
      "backward_entropy": 0.004547175358642231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.531517028808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047143399715423584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04930775364240011,
      "backward_entropy": 0.004535836252299222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.147615432739258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04720013961195946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04918336868286133,
      "backward_entropy": 0.004524819552898407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.53352165222168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047254838049411774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.049063478906949363,
      "backward_entropy": 0.004513842138377103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.864683151245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04730867221951485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04894523819287618,
      "backward_entropy": 0.004503615877845071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.47831344604492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04736262187361717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048826505740483604,
      "backward_entropy": 0.004493974149227142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0072394972667098045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047420285642147064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048698753118515015,
      "backward_entropy": 0.0044844997200098905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.111656188964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047472257167100906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048584366838137306,
      "backward_entropy": 0.004476579414172606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.520977020263672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04752630740404129,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04846471051375071,
      "backward_entropy": 0.06294886090538719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.66926097869873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04758129268884659,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048342580596605934,
      "backward_entropy": 0.004461092705076391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.820199966430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047632571309804916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04822924236456553,
      "backward_entropy": 0.0044536431404677305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.285746097564697,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04768412932753563,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04811472694079081,
      "backward_entropy": 0.004446272145618092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.00383758544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0477314218878746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04801061749458313,
      "backward_entropy": 0.004439402371644974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.682621002197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04777764901518822,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04790910085042318,
      "backward_entropy": 0.004433694210919467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.410320281982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04782195761799812,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047811796267827354,
      "backward_entropy": 0.00442850725217299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.07524299621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04786372184753418,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04772043228149414,
      "backward_entropy": 0.007137555290352215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.936338424682617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04790671169757843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04762562115987142,
      "backward_entropy": 0.004421146078543229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.797513961791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04795083403587341,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04752756158510844,
      "backward_entropy": 0.004418301311406222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.546092987060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04799583554267883,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04742714762687683,
      "backward_entropy": 0.004414704712954434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.26216983795166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048040762543678284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047326733668645225,
      "backward_entropy": 0.00441087240522558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.074607849121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0480838306248188,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04723090926806132,
      "backward_entropy": 0.004406877539374612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.202573776245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048123497515916824,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047143628199895225,
      "backward_entropy": 0.004403473978692835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.096290588378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048163652420043945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04705481727917989,
      "backward_entropy": 0.004400577734817158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.993775367736816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04820418357849121,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04696481426556905,
      "backward_entropy": 0.004397361454638568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.880613327026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048244159668684006,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04687611758708954,
      "backward_entropy": 0.004393895241347226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.52373504638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048284489661455154,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.046786328156789146,
      "backward_entropy": 0.006931982257149436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.87236213684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04832955449819565,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046684240301450096,
      "backward_entropy": 0.004385656592520801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.538480758666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048371829092502594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04658934473991394,
      "backward_entropy": 0.0043813250958919525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.18625831604004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04841415956616402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04649426539738973,
      "backward_entropy": 0.004376161843538284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.015857696533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04845824092626572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04639464616775513,
      "backward_entropy": 0.004369892518628727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.517972946166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0485040619969368,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04629016915957133,
      "backward_entropy": 0.00436431271108714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.636577129364014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048547856509685516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04619102676709493,
      "backward_entropy": 0.0043586865067481995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.524202346801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048589084297418594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04609844088554382,
      "backward_entropy": 0.004354544661261819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7835142612457275,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04863223433494568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04600058992703756,
      "backward_entropy": 0.00435037606141784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.728837966918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04867203161120415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04591150085131327,
      "backward_entropy": 0.004347870295697992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.461549758911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04871220886707306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.045821170012156166,
      "backward_entropy": 0.006684879010373896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.822887420654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048750169575214386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04573655128479004,
      "backward_entropy": 0.004345031624490564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.060526847839355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048787716776132584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04565300544102987,
      "backward_entropy": 0.004343593323772604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.32272720336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882416874170303,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04557213683923086,
      "backward_entropy": 0.004343242130496285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.307489395141602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0488613024353981,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04548915227254232,
      "backward_entropy": 0.0043432824313640594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.265469551086426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04889631271362305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04541207353274027,
      "backward_entropy": 0.004342098127711903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.04245376586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04892963171005249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04533936580022176,
      "backward_entropy": 0.004342311146584424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.781824111938477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048963870853185654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04526399075984955,
      "backward_entropy": 0.004342304034666581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.42913818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048997197300195694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04519101480642954,
      "backward_entropy": 0.004341890527443452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.316566467285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04903228208422661,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04511303702990214,
      "backward_entropy": 0.004341310059482401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.729740142822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04906894639134407,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04503060380617777,
      "backward_entropy": 0.006478543308648196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.057622909545898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049107763916254044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04494227965672811,
      "backward_entropy": 0.004338536411523819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.925241470336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049146123230457306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044855087995529175,
      "backward_entropy": 0.004337117753245614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.423898696899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04918739199638367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04475974043210348,
      "backward_entropy": 0.00433561849323186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.69664764404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0492270402610302,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.044668808579444885,
      "backward_entropy": 0.00639155236157504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.67278289794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049267545342445374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04457587003707886,
      "backward_entropy": 0.004330343820831992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.622934341430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04931313544511795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04446906844774882,
      "backward_entropy": 0.004326281222430142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.524648666381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935738816857338,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04436613122622172,
      "backward_entropy": 0.004321577196771448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.385009527206421,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04940059408545494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044265965620676674,
      "backward_entropy": 0.004317877306179566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.68096160888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0494401715695858,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04417611161867777,
      "backward_entropy": 0.0043131946162744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.263866424560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04947981983423233,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044086078802744545,
      "backward_entropy": 0.004307658834890885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.90289306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049518831074237823,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04399767518043518,
      "backward_entropy": 0.004302978854287754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.349241256713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049562208354473114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04389702280362447,
      "backward_entropy": 0.00429879907857288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.204221725463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049605537205934525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04379621148109436,
      "backward_entropy": 0.004297051917422901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.682541847229004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04965178668498993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04368730386098226,
      "backward_entropy": 0.004293915900317105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.80760669708252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04969591647386551,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0435845156510671,
      "backward_entropy": 0.004291883923790671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.057661056518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04973886162042618,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04348498582839966,
      "backward_entropy": 0.004289718514139002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.918691635131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04978233948349953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043383960922559105,
      "backward_entropy": 0.0042871751568534155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.532551765441895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04982634261250496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04328141609827677,
      "backward_entropy": 0.00428515842015093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.443355560302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049869176000356674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04318218926588694,
      "backward_entropy": 0.004283365539529107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.59374237060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04991091415286064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04308601220448812,
      "backward_entropy": 0.004281420260667801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.659095764160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04995402693748474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04298606514930725,
      "backward_entropy": 0.004278710619969802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.19455337524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05000158026814461,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0428737203280131,
      "backward_entropy": 0.004275450313633139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.08163833618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05004844069480896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04276323815186819,
      "backward_entropy": 0.004273352975195105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.860525131225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500953383743763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0426528255144755,
      "backward_entropy": 0.0042707889594815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.59973907470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050145477056503296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04253332316875458,
      "backward_entropy": 0.0042684562504291534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.685766220092773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05019846931099892,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04240601261456808,
      "backward_entropy": 0.004265937276861884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.747182846069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050250034779310226,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04228301843007406,
      "backward_entropy": 0.004263009198687293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.548285484313965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05029884725809097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04216789205869039,
      "backward_entropy": 0.0042611255564472894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.152198791503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05034593120217323,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04205771287282308,
      "backward_entropy": 0.004259826107458634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.354852676391602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05039305239915848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041947394609451294,
      "backward_entropy": 0.004259739748456262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.475650787353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05043858662247658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041841636101404824,
      "backward_entropy": 0.004260046238248999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.936928749084473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05048573762178421,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04173127810160319,
      "backward_entropy": 0.0042601021176034756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.316150665283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050532266497612,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04162237048149109,
      "backward_entropy": 0.005699754438617013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.98255729675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05057644844055176,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04152032981316248,
      "backward_entropy": 0.0042659318582578135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4754815101623535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05061924457550049,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04142239689826965,
      "backward_entropy": 0.004268344830382954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.199689865112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05065922811627388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04133275896310806,
      "backward_entropy": 0.004270202734253623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.732462882995605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050699613988399506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04124218225479126,
      "backward_entropy": 0.004270139065655795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.952859878540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05073895677924156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04115462303161621,
      "backward_entropy": 0.004270106892694126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.826380729675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05077880993485451,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041065538922945656,
      "backward_entropy": 0.004269138317216526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.09656810760498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05081922188401222,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04097483307123184,
      "backward_entropy": 0.004268816926262595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.395299911499023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050859324634075165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040884993970394135,
      "backward_entropy": 0.004268501969900998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.32967472076416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050898678600788116,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04079683621724447,
      "backward_entropy": 0.004271573302420703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.346001625061035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050937000662088394,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04071178287267685,
      "backward_entropy": 0.0042736344039440155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.701654434204102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05097593739628792,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0406249463558197,
      "backward_entropy": 0.004275382242419503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.618518829345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05101461708545685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04053894430398941,
      "backward_entropy": 0.004276273264126344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.523913860321045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05105460062623024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04044904808203379,
      "backward_entropy": 0.004276992922479456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.936501502990723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05109277367591858,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04036460071802139,
      "backward_entropy": 0.005401084030216391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.410097599029541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0511300154030323,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04028290510177612,
      "backward_entropy": 0.0042780542915517635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.647180557250977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05116570368409157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040205818911393486,
      "backward_entropy": 0.004278291355479847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.891753196716309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051202304661273956,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04012579222520193,
      "backward_entropy": 0.004279700192538175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.049854278564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05123657360672951,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04005292554696401,
      "backward_entropy": 0.0042798522521149025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4355268478393555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05127084627747536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039980217814445496,
      "backward_entropy": 0.00427766279740767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.243865966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0513024739921093,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0399152934551239,
      "backward_entropy": 0.004276938736438751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.139537811279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051335129886865616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039847383896509804,
      "backward_entropy": 0.004274659197438847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.716872215270996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051368825137615204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03977632522583008,
      "backward_entropy": 0.004272478886625983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.310647010803223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05140062794089317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03971074024836222,
      "backward_entropy": 0.004271479492837732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.245691299438477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05143218860030174,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0396456370751063,
      "backward_entropy": 0.004271775822747837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.471151351928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051463570445775986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039580787221590676,
      "backward_entropy": 0.004273732954805548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.121332168579102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051495347172021866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0395147850116094,
      "backward_entropy": 0.004275353117422624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.063732147216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051526863127946854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039449344078699745,
      "backward_entropy": 0.0042780383744023065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.709837913513184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05155801400542259,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03938499093055725,
      "backward_entropy": 0.0050716559317978945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.802757263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05159087851643562,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039315737783908844,
      "backward_entropy": 0.004280720922079953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.869609832763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051626235246658325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039238775769869484,
      "backward_entropy": 0.004282807423309846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.604410171508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05166437104344368,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0391536479194959,
      "backward_entropy": 0.004284547133879228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.884477615356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05170085281133652,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03907338778177897,
      "backward_entropy": 0.0049895061687989664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.355600833892822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05173709988594055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03899413843949636,
      "backward_entropy": 0.0042888288470831785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.193776845932007,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05177106708288193,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0389217883348465,
      "backward_entropy": 0.004290267486463894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.862931251525879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05180226266384125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03885786235332489,
      "backward_entropy": 0.004291267896240408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2536821365356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051835089921951294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03878917545080185,
      "backward_entropy": 0.004902433942664753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.479635238647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051866088062524796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038725823163986206,
      "backward_entropy": 0.004292183301665566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1299898624420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05189730226993561,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03866196175416311,
      "backward_entropy": 0.0042918778278610925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.21291446685791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05192605406045914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03860546896855036,
      "backward_entropy": 0.004291889342394742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.25441837310791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051954157650470734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03855054577191671,
      "backward_entropy": 0.00429451736536893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0860676765441895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051982950419187546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03849331041177114,
      "backward_entropy": 0.00429815257137472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.150898933410645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05200955644249916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038442631562550865,
      "backward_entropy": 0.004302302544767206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.046126365661621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05203820392489433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03838586062192917,
      "backward_entropy": 0.0043055547231977635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.976385116577148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05206884443759918,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038322831193606056,
      "backward_entropy": 0.004310014573010531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9975509643554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05209987983107567,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038258522748947144,
      "backward_entropy": 0.004315276376225732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.795190811157227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05212918296456337,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03819935768842697,
      "backward_entropy": 0.0043207569555802775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.645075798034668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05215946584939957,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03813749551773071,
      "backward_entropy": 0.00469672984697602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.46762752532959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0521913506090641,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03807090719540914,
      "backward_entropy": 0.004326812922954559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.692261695861816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05222521722316742,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037998780608177185,
      "backward_entropy": 0.004326780411330136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7411627769470215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052258413285017014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03792850921551386,
      "backward_entropy": 0.0043277178298343315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.08871841430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05229023098945618,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03786257406075796,
      "backward_entropy": 0.004328498447483236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.370711326599121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05232394114136696,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03779114782810211,
      "backward_entropy": 0.004326428540728309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.752729892730713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05235747620463371,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03772061069806417,
      "backward_entropy": 0.004323884844779968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.860994338989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05238894745707512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03765637675921122,
      "backward_entropy": 0.0043219595470211725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.318665504455566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05242200940847397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03758703172206879,
      "backward_entropy": 0.004322531209750609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052358627319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05245434492826462,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0375199168920517,
      "backward_entropy": 0.004323008724234321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.539250373840332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052486732602119446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037452518939971924,
      "backward_entropy": 0.0043241368098692464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.442595481872559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05252048373222351,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037380993366241455,
      "backward_entropy": 0.004326206039298664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.817693710327148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0525551401078701,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03730732202529907,
      "backward_entropy": 0.004325239495797591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722476959228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052592091262340546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037226974964141846,
      "backward_entropy": 0.004324234344742515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4932262897491455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05262866988778114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03714761634667715,
      "backward_entropy": 0.004325199872255325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.27328872680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0526629276573658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03707514703273773,
      "backward_entropy": 0.004327449270270087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.483011245727539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052697353065013885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03700266281763712,
      "backward_entropy": 0.004326887767423283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4047751426696777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052731484174728394,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03693112482627233,
      "backward_entropy": 0.004326587373560125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.984879493713379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05276338756084442,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036866401632626854,
      "backward_entropy": 0.004325858571312644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.978909015655518,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05279577895998955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03680038948853811,
      "backward_entropy": 0.004324365068565716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.546010971069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05282679945230484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03673844039440155,
      "backward_entropy": 0.004323466257615523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.907291889190674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052857447415590286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03667716681957245,
      "backward_entropy": 0.004326281222430142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.444730758666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052886608988046646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03662082552909851,
      "backward_entropy": 0.0043256045742468404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.988450050354004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052915386855602264,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0365654652317365,
      "backward_entropy": 0.00422507185827602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.043275833129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0529441274702549,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03651061902443568,
      "backward_entropy": 0.0043239678171547976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.396677017211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05297436937689781,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03645112613836924,
      "backward_entropy": 0.004323269155892459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.846627235412598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05300522595643997,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.036389817794164024,
      "backward_entropy": 0.004160444844852795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1630425453186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05303734540939331,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036324734489123024,
      "backward_entropy": 0.004323498091914437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.669270515441895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05306883528828621,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03626127044359843,
      "backward_entropy": 0.004326832565394315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.051923751831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05310264974832535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03619103133678436,
      "backward_entropy": 0.004330302503975955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.45017147064209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053135503083467484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0361236979564031,
      "backward_entropy": 0.004334102977405895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.465163230895996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053169023245573044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03605500360329946,
      "backward_entropy": 0.004334402355280789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.87264347076416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05320101976394653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03599073986212412,
      "backward_entropy": 0.0043355162170800295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.692243576049805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05323224887251854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03592865665753683,
      "backward_entropy": 0.004337724298238754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.190157890319824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053263962268829346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0358651727437973,
      "backward_entropy": 0.004340757700529965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.357789993286133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05329538881778717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.035802689691384636,
      "backward_entropy": 0.004343024031682448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.858917236328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05332813784480095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03573680420716604,
      "backward_entropy": 0.004342104900966991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.979193687438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053358789533376694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.035677055517832436,
      "backward_entropy": 0.004341991448944265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.537642955780029,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05338922142982483,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03561818599700928,
      "backward_entropy": 0.06298565864562988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835793495178223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05341898277401924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03556110461552938,
      "backward_entropy": 0.004342250187288631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11313247680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05344878137111664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03550372024377187,
      "backward_entropy": 0.004344985227693211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.382513999938965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0534791462123394,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03544453779856364,
      "backward_entropy": 0.004349068145860325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.695237159729004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05350876972079277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03538758307695389,
      "backward_entropy": 0.004353215409950776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.883913993835449,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05353666841983795,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.035335553189118706,
      "backward_entropy": 0.06298742511055687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.525935173034668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05356527492403984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03528130054473877,
      "backward_entropy": 0.004365317862142216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6357271671295166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053593821823596954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.035227338473002114,
      "backward_entropy": 0.004371146248145537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.675804615020752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053620487451553345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03517915556828181,
      "backward_entropy": 0.004374947060238232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5723483562469482,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05364779755473137,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03512917707363764,
      "backward_entropy": 0.004377943886951966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.281984806060791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053673624992370605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03508330633242925,
      "backward_entropy": 0.004383019425652244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0001726150512695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053699806332588196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.035036069651444755,
      "backward_entropy": 0.004390114410357041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7266924381256104,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05372561886906624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.034989818930625916,
      "backward_entropy": 0.004397393966262991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.335294246673584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0537506528198719,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03494556248188019,
      "backward_entropy": 0.004406474530696869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.070548057556152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053776562213897705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03489867349465688,
      "backward_entropy": 0.004415782337838953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.632405996322632,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053802669048309326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03485115120808283,
      "backward_entropy": 0.004425024783069437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6295623779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053827885538339615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03480606029431025,
      "backward_entropy": 0.0044348839331756935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.919500350952148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053851861506700516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03476525843143463,
      "backward_entropy": 0.0044390775940634985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.342473983764648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05387609079480171,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03472367922465006,
      "backward_entropy": 0.0044420862739736385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.532332181930542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053902238607406616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.034676591555277504,
      "backward_entropy": 0.004444726488806985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.618056297302246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392708256840706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03463392456372579,
      "backward_entropy": 0.004443291913379322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.440972328186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05395159497857094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03459194799264272,
      "backward_entropy": 0.004442487928000363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.78513765335083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05397538095712662,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.034551734725634255,
      "backward_entropy": 0.004443941129879518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.033048629760742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05399981141090393,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03450991213321686,
      "backward_entropy": 0.004442979327657006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.454085350036621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05402662232518196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.034461175402005516,
      "backward_entropy": 0.004442832348021594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.485524654388428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05405283346772194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03441418210665385,
      "backward_entropy": 0.004442613233219494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2845675945281982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05407918617129326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03436644375324249,
      "backward_entropy": 0.004444503310051831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.313192844390869,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05410455912351608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03432131807009379,
      "backward_entropy": 0.004447744989937002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.216522455215454,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05412963405251503,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.034276689092318215,
      "backward_entropy": 0.004453060640530152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.199617624282837,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0541539303958416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03423397243022919,
      "backward_entropy": 0.00446058064699173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.27837610244751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05417732894420624,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.034193972746531166,
      "backward_entropy": 0.0035047134892507033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2331414222717285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05420144274830818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03415209551652273,
      "backward_entropy": 0.004472940144213763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.180946350097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054225996136665344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.034109639624754585,
      "backward_entropy": 0.004474712366407568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.101224899291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05425156652927399,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03406436244646708,
      "backward_entropy": 0.004474502056837082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0399980545043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0542769655585289,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03401977817217509,
      "backward_entropy": 0.004472089084711942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.947227478027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05430234596133232,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03397523363431295,
      "backward_entropy": 0.004469868811694058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.990058422088623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05432915315032005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03392678747574488,
      "backward_entropy": 0.004466628147797151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74319076538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0543547198176384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033881994585196175,
      "backward_entropy": 0.0044632726772265005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.889150381088257,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054382141679525375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0338321179151535,
      "backward_entropy": 0.004459066485816782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.771672248840332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054408591240644455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03378542512655258,
      "backward_entropy": 0.004452616653659127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.654783248901367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054434917867183685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03373895585536957,
      "backward_entropy": 0.0044477476992390375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7469189167022705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05446155369281769,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03369161983331045,
      "backward_entropy": 0.004443471743301911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6148600578308105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05448751524090767,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033646141489346824,
      "backward_entropy": 0.004440440372987227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.670957088470459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05451337620615959,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03360079973936081,
      "backward_entropy": 0.0044386779720133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6370861530303955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054538529366254807,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03355748454729716,
      "backward_entropy": 0.004436354068192569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.480733871459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054562944918870926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03351666281620661,
      "backward_entropy": 0.004432223737239838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.692739725112915,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05458714812994003,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033476799726486206,
      "backward_entropy": 0.004425978796048598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5130386352539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05461014434695244,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03344075381755829,
      "backward_entropy": 0.003193552182479338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4750242233276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05463279411196709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03340548276901245,
      "backward_entropy": 0.004410934719172391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5965707302093506,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05465518310666084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033370574315389,
      "backward_entropy": 0.004406976767561652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7406470775604248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054676830768585205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03333763778209686,
      "backward_entropy": 0.00440526008605957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.715478777885437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05469721555709839,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03330829242865244,
      "backward_entropy": 0.0031204643574627962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.177770614624023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054716650396585464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033281284073988594,
      "backward_entropy": 0.004405402663079175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6918367147445679,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05473637953400612,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03325364241997401,
      "backward_entropy": 0.004405803639780392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.675101399421692,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0547550804913044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033228752513726555,
      "backward_entropy": 0.0044068260626359415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.866178512573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05477290228009224,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03320616980393728,
      "backward_entropy": 0.003062403676184741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.031157493591309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05479174107313156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03318067888418833,
      "backward_entropy": 0.004411752928387035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2094779014587402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05481100454926491,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03315397103627523,
      "backward_entropy": 0.00441454215483232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.404130458831787,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0548301562666893,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03312752892573675,
      "backward_entropy": 0.00441710583188317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.384965658187866,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054848670959472656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03310299416383108,
      "backward_entropy": 0.004418347369540821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1220338344573975,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05486656725406647,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033080274860064186,
      "backward_entropy": 0.004417758096348156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0951831340789795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05488456413149834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.033056979378064476,
      "backward_entropy": 0.004418804902922024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.581948757171631,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05490265041589737,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0330333411693573,
      "backward_entropy": 0.004421324215152047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.303858518600464,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05492153391242027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0330076664686203,
      "backward_entropy": 0.0044225125827572565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7521045207977295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05493970960378647,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03298411021629969,
      "backward_entropy": 0.004421543668616901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2519946098327637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05495841056108475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03295874843994776,
      "backward_entropy": 0.004422789270227606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9622957706451416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054976686835289,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032934377590815224,
      "backward_entropy": 0.004426091909408569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.09440279006958,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05499490723013878,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03291006634632746,
      "backward_entropy": 0.004429645159027793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.193643569946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05501443147659302,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03288207948207855,
      "backward_entropy": 0.004433346065607938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.287536144256592,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05503334105014801,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03285569449265798,
      "backward_entropy": 0.004437352784655311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.146841287612915,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05505312979221344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032826729118824005,
      "backward_entropy": 0.004443275657567111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.816241979598999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055072396993637085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0327988862991333,
      "backward_entropy": 0.0028549913655627856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7425155639648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05509169027209282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03277067840099335,
      "backward_entropy": 0.004461763257330114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7273897528648376,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05510940030217171,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032746948301792145,
      "backward_entropy": 0.004470445215702057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3978981971740723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055125899612903595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03272629529237747,
      "backward_entropy": 0.004480727016925812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.394164562225342,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055141668766736984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03270754714806875,
      "backward_entropy": 0.0044913061640479346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3696067333221436,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05515804886817932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03268694877624512,
      "backward_entropy": 0.00450154495510188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6783201694488525,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05517382547259331,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032667686541875206,
      "backward_entropy": 0.004513929174704986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.000850200653076,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0551898218691349,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03264755507310232,
      "backward_entropy": 0.004526643590493636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.573364734649658,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05520563945174217,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03262763222058614,
      "backward_entropy": 0.06299348310990767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2646915912628174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05522303655743599,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.032603119810422264,
      "backward_entropy": 0.002800420265306126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6745198965072632,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05524064972996712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03257827957471212,
      "backward_entropy": 0.004567430777983232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9300073385238647,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055257078260183334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03255623082319895,
      "backward_entropy": 0.004580570554191416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.295651912689209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055273279547691345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03253448009490967,
      "backward_entropy": 0.00459519705989144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.524041175842285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05528869479894638,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03251482049624125,
      "backward_entropy": 0.004608743231404911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2769678831100464,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05530427768826485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03249447047710419,
      "backward_entropy": 0.004621643573045731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.876484990119934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05531907454133034,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03247635066509247,
      "backward_entropy": 0.004632472991943359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.283525466918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05533359572291374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03245892872413,
      "backward_entropy": 0.004641755738041617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6443372964859009,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055349577218294144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032437349359194435,
      "backward_entropy": 0.004650196568532424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0229666233062744,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05536431446671486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032419110337893166,
      "backward_entropy": 0.004657536406408657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.999871253967285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05537959188222885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03239932656288147,
      "backward_entropy": 0.0046635476702993565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7951886653900146,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05539530888199806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03237836807966232,
      "backward_entropy": 0.0046678141436793585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.375236749649048,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055410705506801605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032358020544052124,
      "backward_entropy": 0.004672500558874824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.76863431930542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055425964295864105,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03233837087949117,
      "backward_entropy": 0.004673340103842996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7577471733093262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055440861731767654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03231964260339737,
      "backward_entropy": 0.004673593084920536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.435410737991333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05545535311102867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032302044332027435,
      "backward_entropy": 0.004672036252238534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8506827354431152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055470794439315796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03228171169757843,
      "backward_entropy": 0.004670414396307685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7004374265670776,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05548654869198799,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03226066132386526,
      "backward_entropy": 0.004666655578396537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6809806823730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05550200492143631,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032240102688471474,
      "backward_entropy": 0.004664792255921798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.212494134902954,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05551726743578911,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03221956888834635,
      "backward_entropy": 0.004665988412770358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7532899379730225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055532731115818024,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03219809134801229,
      "backward_entropy": 0.0026317994025620546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6428838968276978,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05554836988449097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03217673301696777,
      "backward_entropy": 0.004668369550596584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.216963529586792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055563632398843765,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032156129678090416,
      "backward_entropy": 0.004667560146613555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1346561908721924,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05557979643344879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03213292360305786,
      "backward_entropy": 0.004668042063713074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.111999034881592,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05559597909450531,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0321094940106074,
      "backward_entropy": 0.004669797014106403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0894696712493896,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05561220645904541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.032085647185643516,
      "backward_entropy": 0.004673198542811654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5377320051193237,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05562850460410118,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03206131855646769,
      "backward_entropy": 0.004678722809661518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0539358854293823,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0556437112390995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03203956286112467,
      "backward_entropy": 0.004686417904767123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0356009006500244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055657994002103806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03202069799105326,
      "backward_entropy": 0.0046905008229342375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5168378353118896,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05567244067788124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03200122465689977,
      "backward_entropy": 0.004695096476511521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.493640899658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05568735674023628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03198042015234629,
      "backward_entropy": 0.004699358547275717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.497286319732666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570268630981445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031958463291327156,
      "backward_entropy": 0.0047032968564467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.965042233467102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055717576295137405,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03193772087494532,
      "backward_entropy": 0.004706383428790353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4730587005615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05573246628046036,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03191697597503662,
      "backward_entropy": 0.002523128112608736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9248875379562378,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05574687942862511,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031897621850172676,
      "backward_entropy": 0.004709795456040989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4475651979446411,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05576140433549881,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031877756118774414,
      "backward_entropy": 0.004711496897719123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8929272890090942,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05577544495463371,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031859504679838814,
      "backward_entropy": 0.0047107193280350075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8770639896392822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05578954890370369,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031841019789377846,
      "backward_entropy": 0.00470989468422803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.766946315765381,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05580367147922516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03182253738244375,
      "backward_entropy": 0.004708404229445891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.383442759513855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05581866204738617,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031801496942838035,
      "backward_entropy": 0.004708196629177441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.373290777206421,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05583333224058151,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03178109725316366,
      "backward_entropy": 0.004709547893567519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3650877475738525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055847637355327606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03176164130369822,
      "backward_entropy": 0.0024474281817674637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9093847870826721,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05586150288581848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031743456919988,
      "backward_entropy": 0.004710867662321438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.075133800506592,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055874694138765335,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03172698120276133,
      "backward_entropy": 0.06300164352763783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8861904144287109,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05588911473751068,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03170724709828695,
      "backward_entropy": 0.0047110664573582735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.737160563468933,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05590294674038887,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03168880691130956,
      "backward_entropy": 0.004713890227404508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.71915864944458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05591682344675064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03167019784450531,
      "backward_entropy": 0.004716303199529648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1204004287719727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05593077093362808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03165131558974584,
      "backward_entropy": 0.0047190985219045115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4406528174877167,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055945154279470444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03163118908802668,
      "backward_entropy": 0.004722499373284253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6732834577560425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055958524346351624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0316135436296463,
      "backward_entropy": 0.004727086898955432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8429051041603088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05597192421555519,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031595962742964424,
      "backward_entropy": 0.004730331626805392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6458008289337158,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05598467215895653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03158002346754074,
      "backward_entropy": 0.00473324412649328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43350711464881897,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05599743500351906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0315642183025678,
      "backward_entropy": 0.004734190011566336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6139754056930542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05600913241505623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03155139833688736,
      "backward_entropy": 0.004733485931699926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3878142833709717,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056021008640527725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03153806428114573,
      "backward_entropy": 0.004732687364925037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8016942739486694,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056033674627542496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03152281045913696,
      "backward_entropy": 0.0047303658317435875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9567452669143677,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05604586377739906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0315085252126058,
      "backward_entropy": 0.004730216481468894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1670608520507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05605850741267204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03149303297201792,
      "backward_entropy": 0.004729281772266735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.158793330192566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056071069091558456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03147745132446289,
      "backward_entropy": 0.004731219600547443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2784557342529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05608348548412323,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.031462046007315315,
      "backward_entropy": 0.002299951728094708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.765151858329773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0560966394841671,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031444733341534935,
      "backward_entropy": 0.004736664281650023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7616519331932068,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05610925704240799,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03142864257097244,
      "backward_entropy": 0.00474034690044143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4837056398391724,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05612128973007202,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03141408662001292,
      "backward_entropy": 0.004743736237287521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38732415437698364,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056133463978767395,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03139916559060415,
      "backward_entropy": 0.004746892574158582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02643396146595478,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05614473670721054,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03138653437296549,
      "backward_entropy": 0.004749655384909023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3807796239852905,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05615484341979027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03137692312399546,
      "backward_entropy": 0.004751951179721139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7903460264205933,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05616425350308418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.031369104981422424,
      "backward_entropy": 0.004754131829196756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.778519868850708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05617433786392212,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03135954091946284,
      "backward_entropy": 0.0022444134070114656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7149187922477722,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05618496239185333,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03134860098361969,
      "backward_entropy": 0.00475525517355312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4001593589782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05619528517127037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03133825212717056,
      "backward_entropy": 0.00475716387683695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3884849548339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056205932050943375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03132684528827667,
      "backward_entropy": 0.004759952087293972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.376587152481079,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05621686205267906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0313145766655604,
      "backward_entropy": 0.004763339392163537,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.0395848073251543,
    "avg_log_Z": -0.05553225088864565,
    "success_rate": 1.0,
    "avg_reward": 81.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.08,
      "2": 0.9
    },
    "avg_forward_entropy": 0.03219267581899961,
    "avg_backward_entropy": 0.005631661997600036,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}