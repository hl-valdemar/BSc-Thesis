{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07688377963172065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07669360770119561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.0797576904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098109245300293,
      "backward_entropy": 0.07679702175988092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.1763153076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981078147888183,
      "backward_entropy": 0.07679873042636448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.27845764160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00019924051593989134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981045961380005,
      "backward_entropy": 0.07680030663808186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.67666625976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0002969694323837757,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098099708557129,
      "backward_entropy": 0.07680184973610772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.06964111328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003953833074774593,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980935096740722,
      "backward_entropy": 0.07672924465603298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.03945922851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004947734996676445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980859994888306,
      "backward_entropy": 0.07680512799157037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.45338439941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005948289763182402,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980769395828247,
      "backward_entropy": 0.0767465697394477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.97882080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006953029078431427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098067045211792,
      "backward_entropy": 0.07689558135138617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.1352081298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007961353985592723,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980556011199952,
      "backward_entropy": 0.07689735624525282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.51097106933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008976462413556874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980439186096191,
      "backward_entropy": 0.07689914438459608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.07884216308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000998295028693974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980308055877686,
      "backward_entropy": 0.07681469122568767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.16612243652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010970255825668573,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980172157287597,
      "backward_entropy": 0.07681649261050755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.94088745117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011944263242185116,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980025529861451,
      "backward_entropy": 0.076794875992669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.9585418701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012929383665323257,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979869365692138,
      "backward_entropy": 0.07690560817718506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.6580047607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001391273457556963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979700088500977,
      "backward_entropy": 0.07690713140699598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.1245574951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014902559341862798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979523658752441,
      "backward_entropy": 0.0769086546368069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.98741912841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015884875319898129,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979349613189697,
      "backward_entropy": 0.07691011163923475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.78770446777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001683608046732843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979180335998535,
      "backward_entropy": 0.07682586378521389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.4282684326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017816177569329739,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979008674621582,
      "backward_entropy": 0.07682748635609944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.16233825683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018801079131662846,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978832244873046,
      "backward_entropy": 0.07684195703930324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9491729736328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019808660726994276,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978643894195557,
      "backward_entropy": 0.07684826850891113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.46957397460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0020798256155103445,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978443622589111,
      "backward_entropy": 0.07685436142815484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.353515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021817535161972046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097822904586792,
      "backward_entropy": 0.07691855563057794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.72232055664062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002284696325659752,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978000164031983,
      "backward_entropy": 0.07686645454830593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.99468994140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002387121319770813,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977768898010254,
      "backward_entropy": 0.07692141665352716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.32200622558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024882087018340826,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977529287338257,
      "backward_entropy": 0.07687771320343018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.19223022460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002592002972960472,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977277755737305,
      "backward_entropy": 0.07692411210801867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.91554260253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026951751206070185,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977020263671874,
      "backward_entropy": 0.07684442732069227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.46231079101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027968077920377254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097675919532776,
      "backward_entropy": 0.07692668173048231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.8632354736328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028977959882467985,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976502895355225,
      "backward_entropy": 0.07689865430196126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.0769805908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002997497096657753,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976239442825317,
      "backward_entropy": 0.07690344916449653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.01670837402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003097096225246787,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975968837738037,
      "backward_entropy": 0.07690812481774224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.16241455078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003194345161318779,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097569465637207,
      "backward_entropy": 0.076931013001336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.5712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003293995512649417,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975404977798461,
      "backward_entropy": 0.07685547404819065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.65386962890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0033956195693463087,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975099802017212,
      "backward_entropy": 0.07692136367162068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.50413513183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034991130232810974,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974781513214112,
      "backward_entropy": 0.07692564858330621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.70899963378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036040330305695534,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974452495574952,
      "backward_entropy": 0.07686135503980848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.53836059570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037121919449418783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974105596542358,
      "backward_entropy": 0.07693627145555285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.74554443359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038177971728146076,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973756313323975,
      "backward_entropy": 0.07686511675516765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.38478088378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003921545576304197,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973398685455323,
      "backward_entropy": 0.07686668634414673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.23707580566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004029080271720886,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973014831542968,
      "backward_entropy": 0.07686833540598552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.64263916015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0041366200894117355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972620248794555,
      "backward_entropy": 0.07694036430782741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.96636962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0042425841093063354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972223281860352,
      "backward_entropy": 0.07694131135940552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.8506088256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004347749520093203,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971816778182983,
      "backward_entropy": 0.07687286535898845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.06793975830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004448044579476118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971415042877197,
      "backward_entropy": 0.07694297366672093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.76502990722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004542607348412275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097102165222168,
      "backward_entropy": 0.07694354322221544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.61924743652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004637455567717552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970616340637207,
      "backward_entropy": 0.07687585883670384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.39654541015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0047323498874902725,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970206260681152,
      "backward_entropy": 0.07696623272365993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1790008544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004826187156140804,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096979022026062,
      "backward_entropy": 0.07696857717302111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.65635681152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004917935002595186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969364643096924,
      "backward_entropy": 0.07694543070263332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.99034118652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005010333843529224,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968919992446899,
      "backward_entropy": 0.07694579495324029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.43162536621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005106939934194088,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968449115753173,
      "backward_entropy": 0.07687969340218438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.13255310058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005200785119086504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967977046966552,
      "backward_entropy": 0.07694654994540745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.20416259765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005295141134411097,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967490673065186,
      "backward_entropy": 0.07697888877656725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.69297790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0053931949660182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966982841491699,
      "backward_entropy": 0.0769472254647149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.89743041992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00549223180860281,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096646785736084,
      "backward_entropy": 0.07698255115085179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.45973205566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005588332656770945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965952873229981,
      "backward_entropy": 0.0769477751519945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.85113525390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005684561096131802,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965425968170166,
      "backward_entropy": 0.07694798045688206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.8744659423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0057781413197517395,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964899063110352,
      "backward_entropy": 0.07694808642069499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.10049438476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0058768559247255325,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964342355728149,
      "backward_entropy": 0.07688426309161717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.62440490722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005976574029773474,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963771343231202,
      "backward_entropy": 0.07699007458157009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.03758239746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006074745673686266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963194370269776,
      "backward_entropy": 0.07694855001237658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.45068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0061714225448668,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962612628936767,
      "backward_entropy": 0.07694858974880642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.27081298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00626665074378252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962026119232178,
      "backward_entropy": 0.0768854816754659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.11135864257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00635940209031105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961438417434692,
      "backward_entropy": 0.07694843742582533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.10191345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006452414207160473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960839986801148,
      "backward_entropy": 0.07694827185736762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.639892578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006542940158396959,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960241556167602,
      "backward_entropy": 0.0769964059193929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.58816528320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006631362717598677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959641933441162,
      "backward_entropy": 0.07694767581091987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.22909545898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006720671430230141,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959028005599976,
      "backward_entropy": 0.07688472006056044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.35426330566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006814592983573675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958384275436402,
      "backward_entropy": 0.07694696055518256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.15513610839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006910271476954222,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095771074295044,
      "backward_entropy": 0.07694662941826715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.78521728515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007009789813309908,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10957005023956298,
      "backward_entropy": 0.077000273598565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.4397735595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00710860313847661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10956287384033203,
      "backward_entropy": 0.07694594727622138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.21687316894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007207135204225779,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955555438995361,
      "backward_entropy": 0.07694553004370795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.0644073486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0073012192733585835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10954828262329101,
      "backward_entropy": 0.0768833491537306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.83900451660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007396806962788105,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10954079627990723,
      "backward_entropy": 0.0770028101073371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.3154296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0074951839633286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10953304767608643,
      "backward_entropy": 0.07688236236572266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.51597595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007593320682644844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10952528715133666,
      "backward_entropy": 0.07694347037209405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.88954162597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00769351189956069,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951731204986573,
      "backward_entropy": 0.07700440618726942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.09617614746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007791613694280386,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950928926467896,
      "backward_entropy": 0.07700487640168932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.0545654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00788926612585783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10950114727020263,
      "backward_entropy": 0.0768800179163615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.28541564941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007982517592608929,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109493088722229,
      "backward_entropy": 0.07694104644987318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.46368408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0080763204023242,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948483943939209,
      "backward_entropy": 0.07687832249535455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.2809295654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00816906988620758,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947656631469727,
      "backward_entropy": 0.07687734895282322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.50303649902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0082616051658988,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946822166442871,
      "backward_entropy": 0.076938443713718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.12469482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008354435674846172,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945972204208373,
      "backward_entropy": 0.0768752892812093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.26240539550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008445842191576958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10945117473602295,
      "backward_entropy": 0.07693631119198269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.61782836914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008532057516276836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10944273471832275,
      "backward_entropy": 0.07693506611718072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.94216918945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00862360093742609,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943384170532226,
      "backward_entropy": 0.07687152756585015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.05638122558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008715670555830002,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942509174346923,
      "backward_entropy": 0.07700807518429226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0316619873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00880539882928133,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10941665172576905,
      "backward_entropy": 0.07686860031551784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.95404052734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008893031626939774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10940818786621094,
      "backward_entropy": 0.07686690489451091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.90943145751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008979791775345802,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939964056015014,
      "backward_entropy": 0.07686515649159749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.69927978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009063496254384518,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10939111709594726,
      "backward_entropy": 0.07692688703536987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.1716537475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009145229123532772,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938256978988647,
      "backward_entropy": 0.0768612093395657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.84449768066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009224030189216137,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093740463256836,
      "backward_entropy": 0.07700885004467434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.09007263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009302918799221516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936539173126221,
      "backward_entropy": 0.07692139678531223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.4851531982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009386739693582058,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935646295547485,
      "backward_entropy": 0.07685475216971503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.39842224121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009470519609749317,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934748649597167,
      "backward_entropy": 0.07685253355238172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.72198486328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009557380340993404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933818817138671,
      "backward_entropy": 0.0768503016895718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.1169204711914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009647833183407784,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093285322189331,
      "backward_entropy": 0.0770091281996833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.29888916015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009733445942401886,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10931909084320068,
      "backward_entropy": 0.07700916131337483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.95562744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009821952320635319,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10930933952331542,
      "backward_entropy": 0.07684336768256293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.61656188964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009911322966217995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10929938554763793,
      "backward_entropy": 0.07690772745344374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.28677368164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009999716654419899,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10928933620452881,
      "backward_entropy": 0.07683846023347643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.05192565917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010087624192237854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10927923917770385,
      "backward_entropy": 0.07690335644616021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.59557342529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010172264650464058,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10926920175552368,
      "backward_entropy": 0.07690101861953735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.7676239013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010254100896418095,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925921201705932,
      "backward_entropy": 0.07683047983381483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.33387756347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010336289182305336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10924911499023438,
      "backward_entropy": 0.07689613103866577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.84893798828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010420208796858788,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923894643783569,
      "backward_entropy": 0.07700924078623454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.9365463256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010502335615456104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10922873020172119,
      "backward_entropy": 0.07689098517100017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.6919403076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010581801645457745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10921852588653565,
      "backward_entropy": 0.07688821686638726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.36892700195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010664472356438637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10920794010162353,
      "backward_entropy": 0.07681539323594835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.99933624267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010748231783509254,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10919711589813233,
      "backward_entropy": 0.0770090553495619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.28343200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010825796984136105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10918654203414917,
      "backward_entropy": 0.07687933577431573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.11947631835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01090590562671423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10917561054229737,
      "backward_entropy": 0.07687621646457249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.3691864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01098451018333435,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10916458368301392,
      "backward_entropy": 0.07680179675420125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.4653778076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011069606058299541,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091529130935669,
      "backward_entropy": 0.0770087440808614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.72596740722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01115946751087904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10914072990417481,
      "backward_entropy": 0.07679502169291179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.5378875732422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011249428614974022,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10912832021713256,
      "backward_entropy": 0.07700867123074001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.79576110839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011343007907271385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10911543369293213,
      "backward_entropy": 0.0768609709209866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.39922332763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01143819559365511,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10910223722457886,
      "backward_entropy": 0.07678486241234674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.76519775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011527552269399166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10908925533294678,
      "backward_entropy": 0.07678121990627712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.44798278808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011615115217864513,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10907621383666992,
      "backward_entropy": 0.077008499039544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.75823974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011701466515660286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10906306505203248,
      "backward_entropy": 0.07684777842627631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.491943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011791737750172615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904937982559204,
      "backward_entropy": 0.07676962349149916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.35423278808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01188972219824791,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1090348482131958,
      "backward_entropy": 0.07684079806009929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.08584594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011991879902780056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10901974439620972,
      "backward_entropy": 0.07676251729329427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.079345703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01209481805562973,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10900431871414185,
      "backward_entropy": 0.07675899399651422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.28619384765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012197205796837807,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10898869037628174,
      "backward_entropy": 0.0770084195666843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.7050552368164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012300834059715271,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10897269248962402,
      "backward_entropy": 0.0770084195666843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.48341369628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01240012887865305,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10895681381225586,
      "backward_entropy": 0.0767476028866238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.116455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012496568262577057,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10894088745117188,
      "backward_entropy": 0.07674335108862983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.93479919433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012592118233442307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10892475843429565,
      "backward_entropy": 0.07673892709943983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.57858276367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012686619535088539,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10890837907791137,
      "backward_entropy": 0.07673434416453044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.7146453857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012776789255440235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10889186859130859,
      "backward_entropy": 0.07680612140231663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.34336853027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012866215780377388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10887501239776612,
      "backward_entropy": 0.0768013662762112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.1358184814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012959430925548077,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10885738134384156,
      "backward_entropy": 0.07679663764105903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.7503662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013050157576799393,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10883963108062744,
      "backward_entropy": 0.07700785001118977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.69134521484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013137462548911572,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10882186889648438,
      "backward_entropy": 0.07678653134240045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.35507202148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01323016732931137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10880317687988281,
      "backward_entropy": 0.07678144507937962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.48077392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013324430212378502,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10878394842147827,
      "backward_entropy": 0.07669888602362739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.21771240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013417529873549938,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10876448154449463,
      "backward_entropy": 0.07677103413475884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.50692749023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013518385589122772,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10874382257461548,
      "backward_entropy": 0.07668977313571507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.8270034790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013620398938655853,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10872266292572022,
      "backward_entropy": 0.07676102055443658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.07422637939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01371743530035019,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10870171785354614,
      "backward_entropy": 0.07675561639997694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.8238754272461,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013805017806589603,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10868154764175415,
      "backward_entropy": 0.07700721422831218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.69248962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013886104337871075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10866183042526245,
      "backward_entropy": 0.07674309942457411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.45944213867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013968771323561668,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10864152908325195,
      "backward_entropy": 0.07673640383614434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1470489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014050380326807499,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10862100124359131,
      "backward_entropy": 0.07665863964292738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.770751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014132102020084858,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1086000680923462,
      "backward_entropy": 0.07665285136964586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.29785919189453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014218691736459732,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10857815742492676,
      "backward_entropy": 0.07700619432661268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.39447021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014300642535090446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10855649709701538,
      "backward_entropy": 0.07670871416727702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.94088745117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014389938674867153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10853348970413208,
      "backward_entropy": 0.07663265864054362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.22451782226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01447539497166872,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10851095914840699,
      "backward_entropy": 0.07662512858708699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.07650756835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014563286677002907,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10848785638809204,
      "backward_entropy": 0.07668668693966335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.0018310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014655501581728458,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1084637999534607,
      "backward_entropy": 0.07661010159386529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.37515258789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014746995642781258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10843944549560547,
      "backward_entropy": 0.07667181226942274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.48951721191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014836150221526623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10841500759124756,
      "backward_entropy": 0.07659426000383165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.61965942382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014926588162779808,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10839000940322877,
      "backward_entropy": 0.07700481017430623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.67054748535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015013737604022026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1083651065826416,
      "backward_entropy": 0.07657747798495823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.0482177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015098867937922478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10834006071090699,
      "backward_entropy": 0.07663956615659925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.94927215576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015182056464254856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10831489562988281,
      "backward_entropy": 0.07655926545461018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.2884292602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015260948799550533,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1082899808883667,
      "backward_entropy": 0.07654943731096056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.442626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01533323060721159,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10826579332351685,
      "backward_entropy": 0.07661141951878865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.17086791992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015404065139591694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10824147462844849,
      "backward_entropy": 0.07660139931572808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.18146896362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015468113124370575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10821781158447266,
      "backward_entropy": 0.07651656203799778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.24449157714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01552435290068388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10819501876831054,
      "backward_entropy": 0.0765041775173611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.6914520263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015588167123496532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10817058086395263,
      "backward_entropy": 0.0765672657224867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.88868713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015661975368857384,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10814416408538818,
      "backward_entropy": 0.0765564971499973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.68690490722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01573936827480793,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10811690092086793,
      "backward_entropy": 0.07700023386213514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.13937377929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015815624967217445,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10808932781219482,
      "backward_entropy": 0.07699983649783665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.56153869628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015886502340435982,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10806210041046142,
      "backward_entropy": 0.07652380731370714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.84817504882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0159644465893507,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10803298950195313,
      "backward_entropy": 0.07643351289961073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3404541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016044270247220993,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10800293684005738,
      "backward_entropy": 0.07650041580200195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.2189178466797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01612245850265026,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10797253847122193,
      "backward_entropy": 0.07699799537658691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.6659164428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016199849545955658,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10794178247451783,
      "backward_entropy": 0.07647502422332764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.55442810058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01627381332218647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10791127681732178,
      "backward_entropy": 0.07646185159683228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.82872009277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016350766643881798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10787967443466187,
      "backward_entropy": 0.07644881804784139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.68251037597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01643185317516327,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10784677267074586,
      "backward_entropy": 0.0769953793949551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.74591064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01651480793952942,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10781292915344239,
      "backward_entropy": 0.07642306221856011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.40707397460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016596907749772072,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10777878761291504,
      "backward_entropy": 0.0769941012064616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.08499145507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01667320728302002,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10774528980255127,
      "backward_entropy": 0.0769933197233412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.94937133789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016743043437600136,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10771230459213257,
      "backward_entropy": 0.07629943556255764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.60810089111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016811328008770943,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10767910480499268,
      "backward_entropy": 0.0769912666744656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.45368957519531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01687670685350895,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10764600038528442,
      "backward_entropy": 0.07699012094073826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.16851806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01694113202393055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10761278867721558,
      "backward_entropy": 0.07625224855211046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.06373596191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017007997259497643,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10757853984832763,
      "backward_entropy": 0.0762360625796848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.22766876220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017075156792998314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10754362344741822,
      "backward_entropy": 0.07621965143415663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.19761657714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01713995635509491,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10750881433486939,
      "backward_entropy": 0.07620265086491902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.29306030273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017209649085998535,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10747219324111938,
      "backward_entropy": 0.07618590858247545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.35682678222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017275063320994377,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10743610858917237,
      "backward_entropy": 0.07616833183500502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.29965209960938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017342062667012215,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10739887952804565,
      "backward_entropy": 0.07698251141442193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.54087829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01741049811244011,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10736054182052612,
      "backward_entropy": 0.07621514797210693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.4278335571289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017479531466960907,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10732157230377197,
      "backward_entropy": 0.07698052459292942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.28781127929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017547858878970146,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10728241205215454,
      "backward_entropy": 0.07609688573413426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.5443344116211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01761035993695259,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10724424123764038,
      "backward_entropy": 0.07697845167583889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.15260314941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01767045073211193,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10720603466033936,
      "backward_entropy": 0.07605735460917155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.83187866210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017731748521327972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10716689825057983,
      "backward_entropy": 0.0761235687467787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.52838134765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017789343371987343,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10712816715240478,
      "backward_entropy": 0.07697468996047974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.9743881225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017856530845165253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10708643198013305,
      "backward_entropy": 0.07608469327290852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.14045715332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017920996993780136,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10704478025436401,
      "backward_entropy": 0.07597523265414768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.0941925048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017984572798013687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10700271129608155,
      "backward_entropy": 0.07604504293865627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.04157257080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018053745850920677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10695844888687134,
      "backward_entropy": 0.07602546612421672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.20594787597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018121568486094475,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1069138765335083,
      "backward_entropy": 0.07591196563508776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.3354949951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018185202032327652,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10686995983123779,
      "backward_entropy": 0.0758894681930542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.3226089477539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018249191343784332,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10682502985000611,
      "backward_entropy": 0.07696788840823704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.78369140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018310250714421272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10678008794784546,
      "backward_entropy": 0.07584269841512044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.78836059570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018374046310782433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10673366785049439,
      "backward_entropy": 0.07591574721866184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.37842559814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018437067046761513,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10668680667877198,
      "backward_entropy": 0.0758920709292094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.14784240722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01849755086004734,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10663995742797852,
      "backward_entropy": 0.07696289486355251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.43152618408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01856227219104767,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10659103393554688,
      "backward_entropy": 0.07584281100167169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.49327850341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01862587220966816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10654165744781494,
      "backward_entropy": 0.07581760485967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.589111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018685871735215187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10649298429489136,
      "backward_entropy": 0.07569115691714817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.9990692138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01874421536922455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10644432306289672,
      "backward_entropy": 0.0756633612844679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.84563446044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01880381442606449,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.106394362449646,
      "backward_entropy": 0.07573799954520331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.37348937988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0188580509275198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10634547472000122,
      "backward_entropy": 0.07560553815629747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.50426483154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018913233652710915,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10629591941833497,
      "backward_entropy": 0.07695206668641832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.24109649658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01896815560758114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10624563694000244,
      "backward_entropy": 0.07565161916944715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.0196075439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01901964843273163,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10619577169418334,
      "backward_entropy": 0.07562094264560276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.63739013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019075699150562286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10614397525787353,
      "backward_entropy": 0.07548118299908108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.57431030273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019133301451802254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10609076023101807,
      "backward_entropy": 0.07556116580963135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.95318603515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01919230818748474,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10603617429733277,
      "backward_entropy": 0.07694278823004828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.83489227294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01925758272409439,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10597853660583496,
      "backward_entropy": 0.0753859281539917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.65957641601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019318854436278343,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10592172145843506,
      "backward_entropy": 0.0754686262872484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.14991760253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01938812993466854,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10586137771606445,
      "backward_entropy": 0.07693895366456774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.08756256103516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0194589514285326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10579935312271119,
      "backward_entropy": 0.07693800661298963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.0680694580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019525090232491493,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10573834180831909,
      "backward_entropy": 0.07693668206532796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.2728271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019595371559262276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10567501783370972,
      "backward_entropy": 0.07522191603978474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.52931213378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01966451294720173,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10561141967773438,
      "backward_entropy": 0.07693448331620958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.80517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019739195704460144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10554496049880982,
      "backward_entropy": 0.07527731524573432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.2467269897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019817158579826355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10547641515731812,
      "backward_entropy": 0.07524530755148993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.6248016357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019892804324626923,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1054077386856079,
      "backward_entropy": 0.07508532868491279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.70693969726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01997624710202217,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1053350806236267,
      "backward_entropy": 0.07505214214324951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.08476257324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020058540627360344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10526186227798462,
      "backward_entropy": 0.07501778999964397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.35365295410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020138783380389214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1051889181137085,
      "backward_entropy": 0.0751114288965861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.65240478515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02022019401192665,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10511466264724731,
      "backward_entropy": 0.07494570149315728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.62351989746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02030252106487751,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10503909587860108,
      "backward_entropy": 0.07490893205006917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.1403045654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020386358723044395,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10496242046356201,
      "backward_entropy": 0.0750075446234809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.5567398071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020473700016736984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10488295555114746,
      "backward_entropy": 0.07497286134295994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.35081481933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020556636154651642,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1048046350479126,
      "backward_entropy": 0.07479608058929443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.41607666015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020638776943087578,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10472573041915893,
      "backward_entropy": 0.0769309467739529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.4637451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020722052082419395,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10464550256729126,
      "backward_entropy": 0.07486002312766181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.414306640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020808175206184387,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.104563307762146,
      "backward_entropy": 0.07467365264892578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.48402404785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020897988229990005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10447834730148316,
      "backward_entropy": 0.07463343275917901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.67303466796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020990237593650818,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10439177751541137,
      "backward_entropy": 0.0747520923614502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.4569091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021087178960442543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10430192947387695,
      "backward_entropy": 0.07471740245819092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.30079650878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021178625524044037,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1042136788368225,
      "backward_entropy": 0.07451042864057753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.84080505371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021271925419569016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10412365198135376,
      "backward_entropy": 0.07464141978157891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.45884704589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02135835960507393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10403592586517334,
      "backward_entropy": 0.07442029317220052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.49988555908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02144702896475792,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10394606590270997,
      "backward_entropy": 0.0769311719470554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.79461669921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021531999111175537,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1038578987121582,
      "backward_entropy": 0.0743238131205241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.69400024414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021617675200104713,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1037682294845581,
      "backward_entropy": 0.07447408967547947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.5007095336914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021709855645895004,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10367364883422851,
      "backward_entropy": 0.07692970169915093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.4555892944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021798323839902878,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10357956886291504,
      "backward_entropy": 0.07417391406165229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.16997528076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021880412474274635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10348782539367676,
      "backward_entropy": 0.07411928309334649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.11005401611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021958351135253906,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10339715480804443,
      "backward_entropy": 0.07428592443466187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.293212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022034427151083946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10330649614334106,
      "backward_entropy": 0.07423284318712023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.31568908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02210986614227295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1032145857810974,
      "backward_entropy": 0.07394289308124119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.13337707519531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022185426205396652,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10312172174453735,
      "backward_entropy": 0.07691903909047444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.85736083984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022255895659327507,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10303075313568115,
      "backward_entropy": 0.07381781604554918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.34765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022328581660985947,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10293753147125244,
      "backward_entropy": 0.07400541835361057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.02296447753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022398218512535095,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10284513235092163,
      "backward_entropy": 0.07368659973144531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.68423461914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022470034658908844,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10275033712387086,
      "backward_entropy": 0.07361961735619439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.3731689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022546816617250443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10265126228332519,
      "backward_entropy": 0.07382220692104763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.9963836669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022623755037784576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10255143642425538,
      "backward_entropy": 0.07376090023252699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.69945526123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022703848779201508,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10244872570037841,
      "backward_entropy": 0.0734196040365431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.31138610839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02277989499270916,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10234721899032592,
      "backward_entropy": 0.07689974043104383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.15025329589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022862570360302925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10224088430404663,
      "backward_entropy": 0.07328075170516968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.5993194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022939614951610565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10213725566864014,
      "backward_entropy": 0.0735068056318495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.730712890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023017968982458115,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10203166007995605,
      "backward_entropy": 0.0734400749206543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.75303649902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023099210113286972,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10192315578460694,
      "backward_entropy": 0.07306130727132161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.95680236816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023179763928055763,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10181398391723633,
      "backward_entropy": 0.07298643721474542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.68206024169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023264942690730095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10170115232467651,
      "backward_entropy": 0.07323575019836426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.05255126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023344673216342926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10159157514572144,
      "backward_entropy": 0.07283445199330647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.01860046386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02342401258647442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10148124694824219,
      "backward_entropy": 0.07309085792965359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.00997924804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023498984053730965,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1013720154762268,
      "backward_entropy": 0.07266864511701795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.08840942382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023571137338876724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10126430988311767,
      "backward_entropy": 0.07293269369337294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.18248748779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02364354394376278,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10115532875061035,
      "backward_entropy": 0.07249016894234551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.43878173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02371431142091751,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10104609727859497,
      "backward_entropy": 0.07239754994710286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.67291259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02378920093178749,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10093331336975098,
      "backward_entropy": 0.07230607668558757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.39335632324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023858066648244858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1008247971534729,
      "backward_entropy": 0.07259684138827854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.63384246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023924047127366066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10071698427200318,
      "backward_entropy": 0.07250634829203288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.25331115722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02398446574807167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10061253309249878,
      "backward_entropy": 0.07241155041588677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.87977600097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024047819897532463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10050449371337891,
      "backward_entropy": 0.07189485761854383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.0417251586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024117808789014816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10039116144180298,
      "backward_entropy": 0.07222387525770399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.23448944091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0241848211735487,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10027874708175659,
      "backward_entropy": 0.07212571965323554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.9052734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02424943633377552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10016723871231079,
      "backward_entropy": 0.07156390613979763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.082908630371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02431553788483143,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10005397796630859,
      "backward_entropy": 0.07144843207465278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.35981750488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024372946470975876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09994616508483886,
      "backward_entropy": 0.07182039154900445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.90487670898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024430548772215843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09983693361282349,
      "backward_entropy": 0.07120400667190552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.1591567993164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024488473311066628,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0997263252735138,
      "backward_entropy": 0.07682083050409953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.05415344238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024546558037400246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09961434602737426,
      "backward_entropy": 0.07149934768676758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.8948974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02460302971303463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09950238466262817,
      "backward_entropy": 0.07138721148173015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.1017608642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024660244584083557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09938932657241821,
      "backward_entropy": 0.07068892319997151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.4317398071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02472628839313984,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09926866292953491,
      "backward_entropy": 0.07056378655963474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.62500762939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02478695660829544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09915188550949097,
      "backward_entropy": 0.07043218612670898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.70648193359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024846196174621582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09903556108474731,
      "backward_entropy": 0.0702965259552002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.62567138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024910617619752884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09891412854194641,
      "backward_entropy": 0.07016263405481975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.06902313232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02497795782983303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09878922700881958,
      "backward_entropy": 0.07002944416469997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.98456573486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025041591376066208,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0986670970916748,
      "backward_entropy": 0.07059313191307916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.3813705444336,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02510189078748226,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09854741096496582,
      "backward_entropy": 0.07677630583445232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.49749755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025162456557154655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09842679500579835,
      "backward_entropy": 0.06960086027781169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.49819946289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025224894285202026,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09830379486083984,
      "backward_entropy": 0.07022159629397923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.15557098388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025283008813858032,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09818229675292969,
      "backward_entropy": 0.0693022542529636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.62263488769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025340279564261436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09806160926818848,
      "backward_entropy": 0.06995216343137953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.99411010742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025397874414920807,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09793958067893982,
      "backward_entropy": 0.06981419854693943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.65716552734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025457678362727165,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09781497716903687,
      "backward_entropy": 0.07674788104163276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.3863754272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02552458643913269,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09768379926681518,
      "backward_entropy": 0.06954025559955174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.08432006835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02559291198849678,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09755102396011353,
      "backward_entropy": 0.06852173805236816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.35711669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02566344290971756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09741470813751221,
      "backward_entropy": 0.069264464908176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.40631866455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025737842544913292,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09727393388748169,
      "backward_entropy": 0.06820857524871826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.58490753173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025810234248638153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09713602066040039,
      "backward_entropy": 0.06898307800292969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.27033233642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025878213346004486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09700142741203308,
      "backward_entropy": 0.06883574856652154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.7778091430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025946050882339478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09686699509620667,
      "backward_entropy": 0.06868644555409749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.7093734741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02601143904030323,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0967336893081665,
      "backward_entropy": 0.06753299633661906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.56391906738281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02607584558427334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09659933447837829,
      "backward_entropy": 0.06836908393436009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.09146881103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02614021487534046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09646475315093994,
      "backward_entropy": 0.06820556852552626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.00331115722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026200996711850166,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09633288383483887,
      "backward_entropy": 0.06803592046101888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.20907592773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026256052777171135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09620445966720581,
      "backward_entropy": 0.06785519917805989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.68124389648438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026310810819268227,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09607701301574707,
      "backward_entropy": 0.07670405838224623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.6016845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026367472484707832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09594601392745972,
      "backward_entropy": 0.06748833921220568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.1811294555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026425058022141457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09581420421600342,
      "backward_entropy": 0.066176884704166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.90758514404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026480717584490776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09568229913711548,
      "backward_entropy": 0.067109657658471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.32920837402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026538362726569176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09554728269577026,
      "backward_entropy": 0.06691371070014106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.69381713867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026599576696753502,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09540795087814331,
      "backward_entropy": 0.06554888354407416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.50621795654297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02666017971932888,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09526752233505249,
      "backward_entropy": 0.07666714986165364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.7489013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026717498898506165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09513011574745178,
      "backward_entropy": 0.06630451811684503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.77835845947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0267721526324749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09499545097351074,
      "backward_entropy": 0.0660919878217909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.83244323730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026822324842214584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0948647141456604,
      "backward_entropy": 0.06587245729234484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.14565658569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026873590424656868,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09473232030868531,
      "backward_entropy": 0.06441573301951091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.4879608154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02691933885216713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09460570216178894,
      "backward_entropy": 0.06416877773072985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.36759948730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026974180713295937,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09447105526924134,
      "backward_entropy": 0.06393241882324219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.20527648925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027028582990169525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09433742761611938,
      "backward_entropy": 0.06498344739278157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.10288619995117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027075937017798424,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09421210885047912,
      "backward_entropy": 0.06344593895806207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.53196716308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02711651846766472,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09409379363059997,
      "backward_entropy": 0.06452306111653645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.88410186767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02716401405632496,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0939669132232666,
      "backward_entropy": 0.06293352444966634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.43035125732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02721293270587921,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09383774995803833,
      "backward_entropy": 0.0626777211825053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.97612762451172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027263285592198372,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09370659589767456,
      "backward_entropy": 0.07655841774410671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.05845642089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027315082028508186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09357393383979798,
      "backward_entropy": 0.062162439028422035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.00452423095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02736416645348072,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09344269037246704,
      "backward_entropy": 0.061897582477993436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.20281982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027414707466959953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09330962896347046,
      "backward_entropy": 0.06306544939676921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.85061645507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027470286935567856,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.093171888589859,
      "backward_entropy": 0.07652683390511407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.4485626220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027521708980202675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09303854703903199,
      "backward_entropy": 0.06256160471174452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.85108184814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027579737827181816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09289886951446533,
      "backward_entropy": 0.06082232793172201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.18386840820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027634771540760994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0927617073059082,
      "backward_entropy": 0.06054633855819702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.54615020751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027695097029209137,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09261751174926758,
      "backward_entropy": 0.060275899039374456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.00018310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02775416150689125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09247485399246216,
      "backward_entropy": 0.05999800893995497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.68073272705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027817046269774437,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09232821464538574,
      "backward_entropy": 0.06126001808378431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.20613098144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027882011607289314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09218009710311889,
      "backward_entropy": 0.05944720241758558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.36254119873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027946658432483673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09203177690505981,
      "backward_entropy": 0.060720086097717285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.65631103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028009936213493347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09188574552536011,
      "backward_entropy": 0.06044316954082913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.52720642089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028069913387298584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09174297451972961,
      "backward_entropy": 0.07648251454035442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.94928741455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028126930817961693,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09160317182540893,
      "backward_entropy": 0.05827107694413927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.96990966796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028186123818159103,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09146047830581665,
      "backward_entropy": 0.05796266926659478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.14959716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028250839561223984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.091312175989151,
      "backward_entropy": 0.05927389197879367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.41726684570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028320791199803352,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09115934371948242,
      "backward_entropy": 0.05898565053939819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.1893310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02839028090238571,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09100734591484069,
      "backward_entropy": 0.057059923807779946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.67063903808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028457576408982277,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09085763692855835,
      "backward_entropy": 0.056750602192348905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.73009490966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028534553945064545,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09069883823394775,
      "backward_entropy": 0.05645129415724012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.8220443725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028609970584511757,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0905413269996643,
      "backward_entropy": 0.05614293946160211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.87338638305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0286838561296463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09038490056991577,
      "backward_entropy": 0.0575088726149665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.16407012939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028751423582434654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09023436307907104,
      "backward_entropy": 0.05719137191772461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.609130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0288193691521883,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09008468985557556,
      "backward_entropy": 0.05687716272142199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.57525634765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02889253944158554,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08993090391159057,
      "backward_entropy": 0.05484543244043986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.28463745117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02896811068058014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08977445363998413,
      "backward_entropy": 0.054521143436431885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.38794708251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02904246188700199,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08961960077285766,
      "backward_entropy": 0.05594687329398261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.73015594482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029114361852407455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08946784734725952,
      "backward_entropy": 0.05562474330266317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.747459411621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029187200590968132,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08931528329849243,
      "backward_entropy": 0.05529793765809801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.3963737487793,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02925502508878708,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08917000293731689,
      "backward_entropy": 0.07644853989283244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.56462097167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029314054176211357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08903350830078124,
      "backward_entropy": 0.05279593997531467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.41790771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029369592666625977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08889862298965454,
      "backward_entropy": 0.05426065789328681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.15419006347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029431290924549103,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08875800371170044,
      "backward_entropy": 0.0520556370417277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.46227264404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02949691005051136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08861401081085205,
      "backward_entropy": 0.05355610450108846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.1752700805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02956416830420494,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08846868872642517,
      "backward_entropy": 0.05320372184117635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.10935974121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029633458703756332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08832293748855591,
      "backward_entropy": 0.0528543922636244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.75434875488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029706604778766632,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08817580938339234,
      "backward_entropy": 0.05061506231625875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.1743049621582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029775915667414665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.088033127784729,
      "backward_entropy": 0.0521655711862776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.82604217529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029840419068932533,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08789693713188171,
      "backward_entropy": 0.049858682685428195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.12567901611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02990700677037239,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08775888681411743,
      "backward_entropy": 0.05145663022994995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.23106384277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02997521311044693,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08761883974075317,
      "backward_entropy": 0.0491029421488444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.87173843383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030041636899113655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08748055696487426,
      "backward_entropy": 0.04872089624404907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.76042556762695,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030101405456662178,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0873491644859314,
      "backward_entropy": 0.07635939121246338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.50322723388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03015519678592682,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08722370862960815,
      "backward_entropy": 0.04997296134630839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.28058624267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03021181747317314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08709483742713928,
      "backward_entropy": 0.049587653742896184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.63320922851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030270054936408997,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08696582913398743,
      "backward_entropy": 0.049206657542122736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.85730743408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030325952917337418,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08683938980102539,
      "backward_entropy": 0.04882032341427273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.01050567626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03038506582379341,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08671056628227233,
      "backward_entropy": 0.048439853721194796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.84294509887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030443426221609116,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08658255338668823,
      "backward_entropy": 0.04592793848779467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.47718811035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030496204271912575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08646044731140137,
      "backward_entropy": 0.047660880618625216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.49205780029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030546439811587334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08633880019187927,
      "backward_entropy": 0.047253936529159546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.71127319335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03060026466846466,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08621392250061036,
      "backward_entropy": 0.0468507276640998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.86886596679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030652306973934174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08609105348587036,
      "backward_entropy": 0.04427107175191244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.92652893066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030708473175764084,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08596619367599487,
      "backward_entropy": 0.07622557878494263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.61784362792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030762940645217896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08584355115890503,
      "backward_entropy": 0.043450123733944364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.6732406616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03082064911723137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08571770787239075,
      "backward_entropy": 0.045258916086620755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.45487213134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03088303655385971,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08558813333511353,
      "backward_entropy": 0.044870204395718045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.45092010498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030943168327212334,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08546149730682373,
      "backward_entropy": 0.042243391275405884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.91777420043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031002510339021683,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08533408641815185,
      "backward_entropy": 0.041838384336895414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.20372772216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0310581736266613,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08521095514297486,
      "backward_entropy": 0.04142583078808255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.27017974853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031112177297472954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0850901484489441,
      "backward_entropy": 0.043277362982432045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.18395233154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03116457536816597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08497127294540405,
      "backward_entropy": 0.04287097520298428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.16863250732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031222306191921234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08484712839126587,
      "backward_entropy": 0.04247486591339111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.22211456298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03127796947956085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08472436666488647,
      "backward_entropy": 0.042074991597069636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.850341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031331658363342285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08460233807563781,
      "backward_entropy": 0.04167107409901089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.75459289550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03138616681098938,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08448188304901123,
      "backward_entropy": 0.04127907090716892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.029563903808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031443726271390915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0843574047088623,
      "backward_entropy": 0.04088761740260654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.88896179199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031497836112976074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08423783779144287,
      "backward_entropy": 0.04048841529422336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.541255950927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03154886141419411,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08412147760391235,
      "backward_entropy": 0.04008484880129496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.19890594482422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03159726783633232,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0840082585811615,
      "backward_entropy": 0.07604589727189806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.61917114257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03164983540773392,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08389110565185547,
      "backward_entropy": 0.03695600893762377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.43445587158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031702931970357895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08377380967140198,
      "backward_entropy": 0.03887905346022712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.24191284179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031756531447172165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08365623950958252,
      "backward_entropy": 0.03848083151711358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.4763946533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03181504085659981,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08353224992752076,
      "backward_entropy": 0.0380849474006229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.1291732788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03188062831759453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08340452313423156,
      "backward_entropy": 0.03770899772644043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.73281860351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03194700554013252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08327597975730897,
      "backward_entropy": 0.03503319952223036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.85900115966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032015182077884674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08314388394355773,
      "backward_entropy": 0.03694524698787265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.6551742553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03208285570144653,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08301457166671752,
      "backward_entropy": 0.03430020478036669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.05432891845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03215328976511955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08288538455963135,
      "backward_entropy": 0.036199616061316595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.25499725341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03222103416919708,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08275930881500244,
      "backward_entropy": 0.03357591562800937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.593162536621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03228837996721268,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08263541460037231,
      "backward_entropy": 0.033214191595713295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.18448257446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032351914793252945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08251751661300659,
      "backward_entropy": 0.03509225779109531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.4504165649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03241150826215744,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08240281343460083,
      "backward_entropy": 0.03247055742475721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.47675132751465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03247252479195595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0822853684425354,
      "backward_entropy": 0.034339686234792076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.2879409790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03252720460295677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08217533826828002,
      "backward_entropy": 0.03396088547176785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.04545593261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032585833221673965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08206143379211425,
      "backward_entropy": 0.033589561780293785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.42942810058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032648030668497086,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08194405436515809,
      "backward_entropy": 0.031000216801961262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.63774871826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03270655497908592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08182910084724426,
      "backward_entropy": 0.0328526861137814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.50037384033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032767243683338165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08171292543411254,
      "backward_entropy": 0.032490558094448514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.85533142089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032822173088788986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08160510063171386,
      "backward_entropy": 0.032130675183402166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.66520690917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03287782147526741,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0814960241317749,
      "backward_entropy": 0.03177268637551202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.3267593383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032934144139289856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08138625621795655,
      "backward_entropy": 0.0292233493593004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.44587707519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03298911079764366,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0812771201133728,
      "backward_entropy": 0.028870383898417156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.31336975097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03304474428296089,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08116730451583862,
      "backward_entropy": 0.030698736508687336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.33623504638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03309634327888489,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08106234073638915,
      "backward_entropy": 0.030336081981658936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.197265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03314753249287605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08095840215682984,
      "backward_entropy": 0.02997591429286533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.43120193481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03320484980940819,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0808484673500061,
      "backward_entropy": 0.0296298795276218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.50861167907715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03325766697525978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08074193596839904,
      "backward_entropy": 0.02927812933921814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.83511352539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03330511972308159,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08064125776290894,
      "backward_entropy": 0.028925369183222454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.8763656616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0333525575697422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08054035305976867,
      "backward_entropy": 0.028575738271077473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.5047378540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033406853675842285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0804332137107849,
      "backward_entropy": 0.028240780035654705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.2797622680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03346354141831398,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08032292127609253,
      "backward_entropy": 0.02790743112564087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.65151596069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033522408455610275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08021028637886048,
      "backward_entropy": 0.02757743000984192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.27359008789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03357787802815437,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08009927272796631,
      "backward_entropy": 0.02723497814602322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.49897384643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033632420003414154,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07998870611190796,
      "backward_entropy": 0.02689109245936076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.67399597167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033684831112623215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0798807442188263,
      "backward_entropy": 0.02448267075750563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.0191535949707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033741530030965805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0797682523727417,
      "backward_entropy": 0.0241665028863483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.56648254394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03379517421126366,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07965676784515381,
      "backward_entropy": 0.023846526940663654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.34343719482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033852651715278625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0795408308506012,
      "backward_entropy": 0.025531581706470914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.32583618164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033910974860191345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0794245719909668,
      "backward_entropy": 0.023233251439200506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.40782928466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03397165238857269,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07930604219436646,
      "backward_entropy": 0.02488184968630473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.563579559326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03403757885098457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07918376326560975,
      "backward_entropy": 0.02265962792767419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.46340942382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03409692645072937,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07906781435012818,
      "backward_entropy": 0.02236972749233246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.43905639648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034160394221544266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0789491891860962,
      "backward_entropy": 0.02208994494544135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.76136779785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03422733396291733,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07882784605026245,
      "backward_entropy": 0.023643786708513897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.478275299072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03429624065756798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07870608568191528,
      "backward_entropy": 0.02335104511843787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.51070404052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03436228632926941,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07858884334564209,
      "backward_entropy": 0.021287527349260118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.08744812011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034430183470249176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07847032546997071,
      "backward_entropy": 0.02278104755613539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.03276062011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03449847176671028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07835299968719482,
      "backward_entropy": 0.022504942284690008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.210079193115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03456292673945427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07823778390884399,
      "backward_entropy": 0.02221964134110345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.9952621459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034623268991708755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0781273901462555,
      "backward_entropy": 0.021936848759651184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.292110443115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03468814864754677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07801421880722045,
      "backward_entropy": 0.020007467932171293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.777326583862305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034748561680316925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0779049277305603,
      "backward_entropy": 0.019758822189437017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.66671752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034802936017513275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07779977917671203,
      "backward_entropy": 0.02111511594719357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6694283485412598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03486202657222748,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07768958806991577,
      "backward_entropy": 0.0192632128794988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.4768295288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034912653267383575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07758835554122925,
      "backward_entropy": 0.019016752640406292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.0201416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0349680557847023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0774812638759613,
      "backward_entropy": 0.02030722631348504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.04228210449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03502329811453819,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07737401127815247,
      "backward_entropy": 0.018546448813544378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.52236938476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03507818654179573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07726610898971557,
      "backward_entropy": 0.01978282630443573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.76412963867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035134319216012955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07715587615966797,
      "backward_entropy": 0.019522882170147367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.06549835205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035193365067243576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07704236507415771,
      "backward_entropy": 0.017867687675688002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.5223274230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035249050706624985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07693278789520264,
      "backward_entropy": 0.01901677085293664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.84303283691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035303276032209396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07682507038116455,
      "backward_entropy": 0.017428677943017747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.59952163696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03535786643624306,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0767173409461975,
      "backward_entropy": 0.017217314905590482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.60831069946289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03541292995214462,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0766098976135254,
      "backward_entropy": 0.07591128349304199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.224937438964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03546598181128502,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07650250196456909,
      "backward_entropy": 0.018057897686958313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.339698791503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035517603158950806,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07639585137367248,
      "backward_entropy": 0.01782176560825772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.39505004882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03556689992547035,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07629278898239136,
      "backward_entropy": 0.0759052832921346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.58780288696289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03561883419752121,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0761878490447998,
      "backward_entropy": 0.017371477352248296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.03917694091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0356677807867527,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07608466148376465,
      "backward_entropy": 0.016027895940674677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.90673065185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035714760422706604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07598418593406678,
      "backward_entropy": 0.016930432783232793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.76636505126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035767149180173874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07587660551071167,
      "backward_entropy": 0.016717213723394606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.248598098754883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035826265811920166,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07576209306716919,
      "backward_entropy": 0.016511912147204082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.58010864257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03588130697607994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07565390467643737,
      "backward_entropy": 0.015329352683491178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.91718292236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035940054804086685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07554229497909545,
      "backward_entropy": 0.016120543082555134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.81072998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036003097891807556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07542536854743957,
      "backward_entropy": 0.015928382674853008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.72703552246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0360659584403038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07530891299247741,
      "backward_entropy": 0.015741295284695096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.5557861328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036126721650362015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07519375085830689,
      "backward_entropy": 0.014712967806392245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.168611526489258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036189187318086624,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07507789134979248,
      "backward_entropy": 0.01457055409749349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.0545539855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036246731877326965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07496705055236816,
      "backward_entropy": 0.015194881293508742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.28569030761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03630160167813301,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07485898733139038,
      "backward_entropy": 0.01428616378042433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.8533935546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03635827824473381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07474762201309204,
      "backward_entropy": 0.014843122826682197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.969852447509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03641241788864136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07463884353637695,
      "backward_entropy": 0.014670353796746995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.67877960205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03646687790751457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07452847957611083,
      "backward_entropy": 0.013876180681917403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.65343475341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03652336448431015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07441537380218506,
      "backward_entropy": 0.014328602287504408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.069302558898926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03657859191298485,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07430267333984375,
      "backward_entropy": 0.014159810211923387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.40924072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036627545952796936,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07419528365135193,
      "backward_entropy": 0.013476826250553131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.0994873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03667474910616875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07408996820449829,
      "backward_entropy": 0.013810551828808255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.73611450195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0367233045399189,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07398254871368408,
      "backward_entropy": 0.013641672001944648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.38287353515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03678262233734131,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07386466264724731,
      "backward_entropy": 0.01348521974351671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.013797760009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03684411942958832,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07374520301818847,
      "backward_entropy": 0.012987821466392942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.05531311035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036902714520692825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07362909317016601,
      "backward_entropy": 0.013191444178422293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.53022003173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03696348890662193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0735107421875,
      "backward_entropy": 0.013052172131008573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.13621520996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03702868893742561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07338666319847106,
      "backward_entropy": 0.012686766684055328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.005821228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037093549966812134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07326242923736573,
      "backward_entropy": 0.012588630947801802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.3961181640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03715802729129791,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07313822507858277,
      "backward_entropy": 0.0126339809762107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.058902740478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037223849445581436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07301217317581177,
      "backward_entropy": 0.012499117188983493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.46676635742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037287745624780655,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07288782596588135,
      "backward_entropy": 0.01236482047372394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.744503021240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037354834377765656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07275974750518799,
      "backward_entropy": 0.012236331899960836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.74136734008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03742000460624695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0726337492465973,
      "backward_entropy": 0.012107190158632066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.46937561035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0374830886721611,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07250918745994568,
      "backward_entropy": 0.011973730391926236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.882513999938965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03754753991961479,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07238240242004394,
      "backward_entropy": 0.011844426393508911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.176002502441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037606243044137955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07226313352584839,
      "backward_entropy": 0.011840066976017423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.35856628417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037664033472537994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07214486598968506,
      "backward_entropy": 0.011753835611873202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.80619812011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037722766399383545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07202534079551696,
      "backward_entropy": 0.011480692360136244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.12609100341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037783101201057434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07190249562263488,
      "backward_entropy": 0.011361396147145165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.23526382446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037848349660634995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0717737078666687,
      "backward_entropy": 0.011245815290345086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.709388732910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03790852800011635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07164980173110962,
      "backward_entropy": 0.01143286128838857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.18132972717285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037969548255205154,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07152564525604248,
      "backward_entropy": 0.011014352242151896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.158008575439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03802797198295593,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07140436172485351,
      "backward_entropy": 0.010905548930168152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.967369079589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03808381035923958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0712852954864502,
      "backward_entropy": 0.010794384611977471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.18193817138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03813768923282623,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0711686372756958,
      "backward_entropy": 0.01068633132510715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.016971588134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03819077089428902,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07105172872543335,
      "backward_entropy": 0.01105324923992157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.97169494628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038243331015110016,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07093459367752075,
      "backward_entropy": 0.010973999897638956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.668458938598633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03829707205295563,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07081539630889892,
      "backward_entropy": 0.010897604955567254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.582401275634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038348887115716934,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07069859504699708,
      "backward_entropy": 0.010822346640957726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.524864196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03840070217847824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0705816388130188,
      "backward_entropy": 0.010147507819864485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.29927444458008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03845391049981117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07046234607696533,
      "backward_entropy": 0.010683455400996737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.155433654785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03850725665688515,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07034329771995544,
      "backward_entropy": 0.07641608185238308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.08481216430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038563646376132965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07022028565406799,
      "backward_entropy": 0.009864084422588348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.03053665161133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038622308522462845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07009348273277283,
      "backward_entropy": 0.009773770968119303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.5253677368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03868020698428154,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06996730566024781,
      "backward_entropy": 0.009683955046865676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.732913970947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03874313458800316,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06983393430709839,
      "backward_entropy": 0.009594312972492643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.040267944335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03880512714385986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06970155239105225,
      "backward_entropy": 0.009508330788877275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.527809143066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03886277973651886,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06957451701164245,
      "backward_entropy": 0.010276579194598727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.19150161743164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03891982510685921,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06944766640663147,
      "backward_entropy": 0.010219994518491957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.234622955322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038977786898612976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06931946277618409,
      "backward_entropy": 0.009247831172413297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.54862976074219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.039035432040691376,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0691918134689331,
      "backward_entropy": 0.07650148868560791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.98252868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03909582644701004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06906051635742187,
      "backward_entropy": 0.009092450141906738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.55551528930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0391557514667511,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06892998218536377,
      "backward_entropy": 0.010031977461444007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.79509735107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03921655938029289,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0687980055809021,
      "backward_entropy": 0.008953630096382566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.265357971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03927651792764664,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06866679787635803,
      "backward_entropy": 0.008883896801206801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.965700149536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933729976415634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06853413581848145,
      "backward_entropy": 0.008814860549237993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.948246002197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03939581289887428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06840455532073975,
      "backward_entropy": 0.00987783239947425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.291358947753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03945544362068176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06827301979064941,
      "backward_entropy": 0.008682305614153544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.681982040405273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039514511823654175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06814206838607788,
      "backward_entropy": 0.0086188738544782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.15562629699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03957158327102661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06801385879516601,
      "backward_entropy": 0.008556795616944632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.30110168457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03962516412138939,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06789043545722961,
      "backward_entropy": 0.008494139545493655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.83024597167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03968298062682152,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0677599310874939,
      "backward_entropy": 0.008432638314035203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.926063537597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03974044695496559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06762975454330444,
      "backward_entropy": 0.008372571733262803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.6034049987793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03979479521512985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06750440001487731,
      "backward_entropy": 0.009643795589605967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.844276428222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03984915465116501,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06737885475158692,
      "backward_entropy": 0.008258008294635348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.095905303955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039904844015836716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06725060939788818,
      "backward_entropy": 0.009584373897976346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.70442199707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03995875269174576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06712470054626465,
      "backward_entropy": 0.008144288427299924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.16219329833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04001973196864128,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06698732376098633,
      "backward_entropy": 0.008086943791972266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.02324295043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0400858148932457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06684129238128662,
      "backward_entropy": 0.00803130285607444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.51466941833496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040150705724954605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06669702529907226,
      "backward_entropy": 0.007976675199137794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.78852844238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040211621671915054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06655927896499633,
      "backward_entropy": 0.007922546731101142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.18569946289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040271710604429245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06642245650291442,
      "backward_entropy": 0.007867527504762014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.415210723876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04033692926168442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06627697348594666,
      "backward_entropy": 0.007813311285442777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.23851203918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0403996966779232,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06613539457321167,
      "backward_entropy": 0.009339641365740035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.31739807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040458936244249344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0659999668598175,
      "backward_entropy": 0.009314638872941336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.173744201660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04051921144127846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06586273908615112,
      "backward_entropy": 0.00766550170050727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.04304885864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04057876020669937,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06572595834732056,
      "backward_entropy": 0.00761806137031979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.85862731933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04063780605792999,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06558958292007447,
      "backward_entropy": 0.00757112271255917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.80721664428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04069903865456581,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06544893980026245,
      "backward_entropy": 0.0075220805075433515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.673301696777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04075956344604492,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06530925035476684,
      "backward_entropy": 0.0074742742710643345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.949027061462402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04081963747739792,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06517029404640198,
      "backward_entropy": 0.007428838147057427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.45330810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04087492451071739,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06503989696502685,
      "backward_entropy": 0.007385358214378357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.160831451416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04093015566468239,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06490925550460816,
      "backward_entropy": 0.007342795530954997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.82197189331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04098675027489662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0647757887840271,
      "backward_entropy": 0.00730127924018436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.357830047607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04104581102728844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06463732719421386,
      "backward_entropy": 0.00725857416788737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.45915222167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04110291600227356,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06450207233428955,
      "backward_entropy": 0.007215705182817247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.87905502319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041162725538015366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06436171531677246,
      "backward_entropy": 0.007174864411354065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.45860290527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041222043335437775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06422203779220581,
      "backward_entropy": 0.0071347885661655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.628074645996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0412866584956646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06407254934310913,
      "backward_entropy": 0.007095660600397322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.901636123657227,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041350413113832474,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06392457485198974,
      "backward_entropy": 0.07681010166803996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.8096866607666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041411738842725754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06378100514411926,
      "backward_entropy": 0.0070197855432828265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.717235565185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041470881551504135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06364113092422485,
      "backward_entropy": 0.006981539229551951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.27411651611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041528135538101196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06350462436676026,
      "backward_entropy": 0.006944124483399921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.02977752685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04159066453576088,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06335770487785339,
      "backward_entropy": 0.008866151173909506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.976526260375977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04165250062942505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06321194171905517,
      "backward_entropy": 0.006869109968344371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.67475891113281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04171079397201538,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06307305097579956,
      "backward_entropy": 0.006833608779642317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.853633880615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0417715385556221,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06292895078659058,
      "backward_entropy": 0.008800528115696378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.18047523498535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04182891547679901,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0627911388874054,
      "backward_entropy": 0.008779538174470266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.93181610107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04188460484147072,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06265650987625122,
      "backward_entropy": 0.006730142566892836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.997129440307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04195002093911171,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06250314712524414,
      "backward_entropy": 0.006696263121234046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.07662582397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042013030499219894,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06235431432723999,
      "backward_entropy": 0.006663960715134938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.85466003417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04207942634820938,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.062198424339294435,
      "backward_entropy": 0.00869496249490314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.61642074584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04214875400066376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06203669309616089,
      "backward_entropy": 0.008672825164265104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.98666763305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04222080856561661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06186950206756592,
      "backward_entropy": 0.006567522469494078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.97296142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04229254275560379,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06170281171798706,
      "backward_entropy": 0.006536031348837746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.762088775634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04236532747745514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061533880233764646,
      "backward_entropy": 0.00860644794172711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.72474670410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0424390509724617,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061362826824188234,
      "backward_entropy": 0.00858375844028261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.16993522644043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04251638799905777,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.061184585094451904,
      "backward_entropy": 0.006442366788784663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.08131408691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04259007051587105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06101380586624146,
      "backward_entropy": 0.00641225278377533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.886253356933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04266176000237465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060846847295761106,
      "backward_entropy": 0.006382037368085649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.687965393066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042735833674669266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060674774646759036,
      "backward_entropy": 0.006352090173297458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.828640937805176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042810749262571335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06050090193748474,
      "backward_entropy": 0.006323168675104777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.02350997924805,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04288095608353615,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06033707857131958,
      "backward_entropy": 0.07690078682369655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.691445350646973,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04295502230525017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06016498804092407,
      "backward_entropy": 0.07690419753392537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.04651641845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043024323880672455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06000290513038635,
      "backward_entropy": 0.006242040544748306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.6537971496582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043093491345644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05984086990356445,
      "backward_entropy": 0.006215645621220271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.96782875061035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04316389188170433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05967589616775513,
      "backward_entropy": 0.006189586387740241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.957252502441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04323268681764603,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05951427221298218,
      "backward_entropy": 0.006164345062441296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029635957907885313,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04330408200621605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05934677720069885,
      "backward_entropy": 0.006139149268468221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.4984130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04336833581328392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.059195584058761595,
      "backward_entropy": 0.006115693185064528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.440595626831055,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043435584753751755,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.059036928415298465,
      "backward_entropy": 0.07692159546746148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.579293727874756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04350152239203453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058881241083145144,
      "backward_entropy": 0.006069271100891961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.839115142822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04356222227215767,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05873743891716003,
      "backward_entropy": 0.006047745545705159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.0699520111084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043626271188259125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058585834503173825,
      "backward_entropy": 0.006025961703724331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.37936401367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043689291924238205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058436250686645506,
      "backward_entropy": 0.008185101879967583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.813274383544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04375806078314781,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058273696899414064,
      "backward_entropy": 0.008162248465749953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.102813720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04382532089948654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058114361763000486,
      "backward_entropy": 0.005961557229359944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.16354751586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043892551213502884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05795488357543945,
      "backward_entropy": 0.0059404778811666704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.137760162353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04395708441734314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05780153274536133,
      "backward_entropy": 0.00592019905646642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.97224235534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04402318224310875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05764439105987549,
      "backward_entropy": 0.005899871389071147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.879188537597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04408669471740723,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.057493042945861814,
      "backward_entropy": 0.005880361629856957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.3153076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04414787515997887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05734708309173584,
      "backward_entropy": 0.00586155719227261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.931121826171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04420960322022438,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0571996808052063,
      "backward_entropy": 0.005842830571863387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.81157875061035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04427051171660423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05705389976501465,
      "backward_entropy": 0.005824721107880275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.520658493041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04433068260550499,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05690964460372925,
      "backward_entropy": 0.005807217624452379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.157405853271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04438882693648338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05677021741867065,
      "backward_entropy": 0.005790285766124725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.25056457519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04445173963904381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05661931037902832,
      "backward_entropy": 0.005772643619113498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.552635192871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044522810727357864,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0564497172832489,
      "backward_entropy": 0.07694340414471096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.130271911621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044596001505851746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0562752366065979,
      "backward_entropy": 0.005734470983346303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.04537582397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04466589540243149,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056108671426773074,
      "backward_entropy": 0.005716648780637317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.823734283447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044735390692949295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05594313144683838,
      "backward_entropy": 0.005699151506026586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.760345458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04480713605880737,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05577217936515808,
      "backward_entropy": 0.005682042075528039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.24283218383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04487698897719383,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05560579299926758,
      "backward_entropy": 0.005665642519791921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.34906768798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044950321316719055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.055431270599365236,
      "backward_entropy": 0.007730022072792053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.505186080932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045022886246442795,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05525866746902466,
      "backward_entropy": 0.005632677012019687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.198753356933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0450921505689621,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05509417057037354,
      "backward_entropy": 0.0076778191659185625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.82108688354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04516614228487015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054918473958969115,
      "backward_entropy": 0.0056012823349899715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.187664031982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04523925110697746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05474506020545959,
      "backward_entropy": 0.005585514008998871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.700667858123779,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045309048146009445,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05457979440689087,
      "backward_entropy": 0.07695289452870686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.65332794189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04537324979901314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05442857146263123,
      "backward_entropy": 0.005558749867810143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.89927864074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045436225831508636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05428034067153931,
      "backward_entropy": 0.005546545402871238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.61203384399414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0454968698322773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05413784980773926,
      "backward_entropy": 0.005535492052634557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.99681854248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045559123158454895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05399121046066284,
      "backward_entropy": 0.005523552911149131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.622604370117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04562414437532425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05383761525154114,
      "backward_entropy": 0.005511181635989083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.03849983215332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04568665847182274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05369027853012085,
      "backward_entropy": 0.007447629339165158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.39340591430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04574805498123169,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05354573726654053,
      "backward_entropy": 0.007422146697839101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.905035018920898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04580971226096153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05340050458908081,
      "backward_entropy": 0.007395821313063304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.681215286254883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04586782306432724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05326435565948486,
      "backward_entropy": 0.0054690200421545244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.567461013793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04592525213956833,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053129905462265016,
      "backward_entropy": 0.005459272199206882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.735306739807129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045982081443071365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05299688577651977,
      "backward_entropy": 0.005449851353963216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.346797943115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04603588581085205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0528717577457428,
      "backward_entropy": 0.005441795620653365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.93067169189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04609322547912598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05273727178573608,
      "backward_entropy": 0.005433244837654961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.5717134475708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04614870622754097,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05260764360427857,
      "backward_entropy": 0.0054253290096918745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.768774032592773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04620126634836197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05248562097549438,
      "backward_entropy": 0.005418470750252406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.244946002960205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04625256359577179,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05236674547195434,
      "backward_entropy": 0.0071955107980304295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.62445068359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04630007594823837,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05225793123245239,
      "backward_entropy": 0.007174141705036163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.732637405395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04634666442871094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05215139389038086,
      "backward_entropy": 0.005405167738596599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.638795852661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04639371111989021,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05204353332519531,
      "backward_entropy": 0.007129992875787947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.154287338256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04644119367003441,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05193438529968262,
      "backward_entropy": 0.00539739512734943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.566808700561523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04648518189787865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.051834714412689206,
      "backward_entropy": 0.00539370874563853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.450439453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04653105139732361,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05172985792160034,
      "backward_entropy": 0.007060782776938545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.147427558898926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04657872021198273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.051620036363601685,
      "backward_entropy": 0.005385004811816745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.25480651855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04662419110536575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0515161395072937,
      "backward_entropy": 0.005381445917818282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.096385955810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04667280241847038,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05140366554260254,
      "backward_entropy": 0.006991184420055813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.969444274902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046722859144210815,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05128727555274963,
      "backward_entropy": 0.0053751882579591535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.843416213989258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04677429795265198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05116703510284424,
      "backward_entropy": 0.006946111718813579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.84050178527832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0468267947435379,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05104420781135559,
      "backward_entropy": 0.005368328756756253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.851731300354004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04687763750553131,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050926172733306886,
      "backward_entropy": 0.005362535930342144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.4620361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04692582041025162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05081552267074585,
      "backward_entropy": 0.005356254263056649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.611295700073242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04697529599070549,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05070149898529053,
      "backward_entropy": 0.006832643101612727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.703451156616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047023650258779526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05059053897857666,
      "backward_entropy": 0.00534182083275583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.28185272216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047069650143384933,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0504860520362854,
      "backward_entropy": 0.005335324340396457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.186479568481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04711602255702019,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05038058161735535,
      "backward_entropy": 0.005328729748725891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.85663414001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04716278985142708,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0502739667892456,
      "backward_entropy": 0.005322732445266511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.253883361816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047211118042469025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0501630425453186,
      "backward_entropy": 0.005316831999354892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.749109745025635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04725833237171173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050055259466171266,
      "backward_entropy": 0.005311006473170387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.89051818847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04730211943387985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04995706081390381,
      "backward_entropy": 0.005306147038936615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.716365814208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04735008254647255,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04984751045703888,
      "backward_entropy": 0.005299832257959578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.604034423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04740196093916893,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04972734749317169,
      "backward_entropy": 0.005293885038958656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.500703811645508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047453656792640686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04960775375366211,
      "backward_entropy": 0.005288615408870909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.216133117675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04750504344701767,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04948925673961639,
      "backward_entropy": 0.005282658669683669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.600413799285889,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04755375161767006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04937829375267029,
      "backward_entropy": 0.005277028514279259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.662612915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0475989505648613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04927709400653839,
      "backward_entropy": 0.005273157109816869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.076343536376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0476432740688324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04917841851711273,
      "backward_entropy": 0.005268926007880105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.031391143798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04768557846546173,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04908546209335327,
      "backward_entropy": 0.0063843511872821385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.370426177978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04772620275616646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04899714589118957,
      "backward_entropy": 0.00526137070523368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.490939617156982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0477714017033577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04889605641365051,
      "backward_entropy": 0.006328683760431077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.06003189086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04781344160437584,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04880383014678955,
      "backward_entropy": 0.006303226782215966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.261693954467773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04785978049039841,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048699766397476196,
      "backward_entropy": 0.0052547939121723175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.576618194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04790528863668442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048598045110702516,
      "backward_entropy": 0.005253702402114868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.48415756225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047951266169548035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04849494099617004,
      "backward_entropy": 0.0052537090248531764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.06477355957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04799757897853851,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048390886187553404,
      "backward_entropy": 0.005253984696335263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.978957176208496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04804657772183418,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04827951192855835,
      "backward_entropy": 0.006186013420422872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.193191528320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04809434339404106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048171818256378174,
      "backward_entropy": 0.005253700746430291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.096961975097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048142243176698685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.048063811659812924,
      "backward_entropy": 0.006140880286693573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.99664306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048190176486968994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04795606136322021,
      "backward_entropy": 0.005253233843379551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.755733489990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04823828488588333,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04784775078296662,
      "backward_entropy": 0.00525365024805069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.604947090148926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04829123988747597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04772632122039795,
      "backward_entropy": 0.005253440803951687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.848081588745117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04834260791540146,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04760948419570923,
      "backward_entropy": 0.006051535407702128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1786603927612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04839489981532097,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047490251064300534,
      "backward_entropy": 0.0060299394859208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.59381103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048443324863910675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04738195836544037,
      "backward_entropy": 0.006009846097893185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049349311739206314,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04849286377429962,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04727076292037964,
      "backward_entropy": 0.005257263365719054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.289125442504883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0485374741256237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04717370867729187,
      "backward_entropy": 0.005258457528220283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.35599136352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048582565039396286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04707525074481964,
      "backward_entropy": 0.005260729127460056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.066429138183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048632510006427765,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04696373045444489,
      "backward_entropy": 0.005260282920466529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.9932804107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048678550869226456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046863535046577455,
      "backward_entropy": 0.005258831712934706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.87323570251465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04872596636414528,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04675952792167663,
      "backward_entropy": 0.005257444663180245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.807771682739258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04877456650137901,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04665242433547974,
      "backward_entropy": 0.0052557144727971815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.703975677490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048823121935129166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04654557108879089,
      "backward_entropy": 0.005819821109374364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.397319793701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04887180030345917,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04643819034099579,
      "backward_entropy": 0.005255694604582257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.377643585205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04892241954803467,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04632601737976074,
      "backward_entropy": 0.005771706915564007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.404638290405273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04897363856434822,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046212786436080934,
      "backward_entropy": 0.0052488818764686584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.73183822631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04902438074350357,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04610108733177185,
      "backward_entropy": 0.005244021614392598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.971942901611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049078162759542465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045981448888778684,
      "backward_entropy": 0.0052382441030608285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.611812591552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049132369458675385,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04586101770401001,
      "backward_entropy": 0.005654614004823897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.78359317779541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919245094060898,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04572572112083435,
      "backward_entropy": 0.0052225035097863935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.137627601623535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04924771562218666,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04560416340827942,
      "backward_entropy": 0.005213956452078289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.394553184509277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049301207065582275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04548721313476563,
      "backward_entropy": 0.005208919445673625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.348807334899902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935174807906151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045378726720809934,
      "backward_entropy": 0.005205014513598548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.30032730102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04939943552017212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04527848660945892,
      "backward_entropy": 0.005200256490045124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.436769485473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04944454878568649,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045185649394989015,
      "backward_entropy": 0.00519472567571534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6387104988098145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04948975518345833,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04509263038635254,
      "backward_entropy": 0.005189455217785305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.619926929473877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049531470984220505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04500961899757385,
      "backward_entropy": 0.00518361810180876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.648096084594727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04956994578242302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04493589699268341,
      "backward_entropy": 0.005176343851619297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.590291976928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04960810765624046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044862869381904605,
      "backward_entropy": 0.005343608558177948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.04085922241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049645937979221344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04479069113731384,
      "backward_entropy": 0.005313193218575584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.47344970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04968241602182388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04472205638885498,
      "backward_entropy": 0.005285213390986125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.324682235717773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04971882700920105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04465345740318298,
      "backward_entropy": 0.005162465075651805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.361837387084961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049757275730371475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04457924962043762,
      "backward_entropy": 0.005161246077881919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.301262855529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04979530721902847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044506224989891055,
      "backward_entropy": 0.005160310202174717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.4259033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049833059310913086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04443391561508179,
      "backward_entropy": 0.005160429411464267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.184139251708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04987378790974617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04435352385044098,
      "backward_entropy": 0.005159609019756317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.1204195022583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049913808703422546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044275274872779845,
      "backward_entropy": 0.0051584334837065805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.06418514251709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049953289330005646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04419851303100586,
      "backward_entropy": 0.005157877587609821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.686982154846191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04999207705259323,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04412391185760498,
      "backward_entropy": 0.005155893249644173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654248237609863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05002939701080322,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044053304195404056,
      "backward_entropy": 0.005155626684427261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.893969535827637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05006514489650726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0439872145652771,
      "backward_entropy": 0.005154397338628769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06562841683626175,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05010046064853668,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043922591209411624,
      "backward_entropy": 0.005150814851125081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.781403541564941,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050132378935813904,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.043867334723472595,
      "backward_entropy": 0.07695070902506511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.623332977294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016464367508888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043810924887657164,
      "backward_entropy": 0.005149288309945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.676989555358887,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05020158365368843,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04374159574508667,
      "backward_entropy": 0.07695060968399048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.617749214172363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05023826286196709,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043672975897789,
      "backward_entropy": 0.005150560703542497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.06598663330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05027485266327858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043604490160942075,
      "backward_entropy": 0.005153563287523057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.504291534423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05031437799334526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04352813959121704,
      "backward_entropy": 0.005155167645878262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.697553634643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05035336688160896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043453389406204225,
      "backward_entropy": 0.0051571788887182874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.170085430145264,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05039400979876518,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04337431490421295,
      "backward_entropy": 0.00515860484706031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.323501586914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05043189972639084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04330276250839234,
      "backward_entropy": 0.005162016799052556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.334718704223633,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05046944320201874,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04323216378688812,
      "backward_entropy": 0.07695549726486206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.354888916015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05050768330693245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04315976500511169,
      "backward_entropy": 0.005169787340694004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.229448318481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05054856836795807,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04308052062988281,
      "backward_entropy": 0.005171012547281053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.082864761352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05059181898832321,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042995238304138185,
      "backward_entropy": 0.0051700116859542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.998185157775879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05063400790095329,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042913132905960084,
      "backward_entropy": 0.005168539368444019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.949145317077637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05067639425396919,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042830651998519896,
      "backward_entropy": 0.005167156871822145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.767057418823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05071794614195824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04275055527687073,
      "backward_entropy": 0.005166860090361701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0662837103009224,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05076074227690697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042667335271835326,
      "backward_entropy": 0.005165488355689579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.760763168334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05079954117536545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042594936490058896,
      "backward_entropy": 0.005167289740509457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.341211318969727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050837840884923935,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042523935437202454,
      "backward_entropy": 0.005169822937912411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7815165519714355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05087866634130478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042446523904800415,
      "backward_entropy": 0.005169879231188033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.09273910522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05091778561472893,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04237363338470459,
      "backward_entropy": 0.005171991470787261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.333319664001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05095947906374931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042294034361839296,
      "backward_entropy": 0.0051732514467504286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6542816162109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05100139603018761,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.042214015126228334,
      "backward_entropy": 0.07696167627970378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.709552764892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05104158818721771,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04213855564594269,
      "backward_entropy": 0.005179031855530209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.83552360534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05108441784977913,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04205605983734131,
      "backward_entropy": 0.005184432284699546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.529998779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05112830176949501,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041971176862716675,
      "backward_entropy": 0.005188416275713179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.201233863830566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05117012932896614,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04189189076423645,
      "backward_entropy": 0.005193745924366845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.828662872314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05121101811528206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04181532263755798,
      "backward_entropy": 0.005198629779948128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.412254333496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051252081990242004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0417385458946228,
      "backward_entropy": 0.005202484213643604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.661093711853027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051294367760419846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04165883064270019,
      "backward_entropy": 0.005205407324764464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.567523002624512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05133666470646858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041579368710517886,
      "backward_entropy": 0.005207344889640808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.494940757751465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05137918144464493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041499316692352295,
      "backward_entropy": 0.005210808995697234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.39639949798584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05142154544591904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04142010807991028,
      "backward_entropy": 0.005211990740564134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.86469268798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05146409943699837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04134039282798767,
      "backward_entropy": 0.005214804576502906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.2300443649292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051507994532585144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041257092356681825,
      "backward_entropy": 0.005220378438631694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5974817276000977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05155172944068909,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041174501180648804,
      "backward_entropy": 0.005225180751747555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.059525489807129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051592160016298294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041100960969924924,
      "backward_entropy": 0.00522962792052163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.986297607421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051632802933454514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04102702140808105,
      "backward_entropy": 0.005233946359819836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.894235610961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05167345702648163,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040953484177589414,
      "backward_entropy": 0.00523623451590538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.812414169311523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05171433836221695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04087942540645599,
      "backward_entropy": 0.005239088502195146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.926774501800537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05175540968775749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040804925560951236,
      "backward_entropy": 0.0052424950732125174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.845705032348633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05179411545395851,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04073740541934967,
      "backward_entropy": 0.005241738425360786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.57907772064209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05183602496981621,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04066208600997925,
      "backward_entropy": 0.005238456030686696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.49450969696045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05187775939702988,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04058756232261658,
      "backward_entropy": 0.005233919868866603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.741212844848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05191932991147041,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040513867139816286,
      "backward_entropy": 0.005228215207656224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.633176803588867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05196173116564751,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04043843150138855,
      "backward_entropy": 0.004134159949090745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.940311431884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052004873752593994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0403615415096283,
      "backward_entropy": 0.005212306148476071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.150531768798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05204688385128975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0402876079082489,
      "backward_entropy": 0.005205459064907498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.299339294433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052088674157857895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04021461009979248,
      "backward_entropy": 0.005197724948326747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.973690032958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05213147774338722,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.040139076113700864,
      "backward_entropy": 0.0040271538827154375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.887707710266113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05217408761382103,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040064293146133426,
      "backward_entropy": 0.005185619824462467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.617504119873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05221651494503021,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03999016284942627,
      "backward_entropy": 0.005180310871866014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.706109046936035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05225792154669762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03991867005825043,
      "backward_entropy": 0.005177334364917543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.496140480041504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05229955539107323,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03984643816947937,
      "backward_entropy": 0.0051779233747058446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.668349266052246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05234016850590706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03977693915367127,
      "backward_entropy": 0.005179602652788162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.567956924438477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05238184332847595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03970487117767334,
      "backward_entropy": 0.005181821270121468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.398499488830566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052424393594264984,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03963092565536499,
      "backward_entropy": 0.003885397066672643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.306365966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05246651545166969,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039558684825897215,
      "backward_entropy": 0.005183304763502545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.22037410736084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05250842496752739,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03948720693588257,
      "backward_entropy": 0.0051827629407246905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.121761322021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052550192922353745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039416301250457766,
      "backward_entropy": 0.005182817578315735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.064696311950684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05259093642234802,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03934803307056427,
      "backward_entropy": 0.005184608615107006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.932147979736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05263068526983261,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03928238451480866,
      "backward_entropy": 0.00518714470995797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.910204887390137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05267222970724106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03921276032924652,
      "backward_entropy": 0.005187395546171401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.686840057373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05271336808800697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039144736528396604,
      "backward_entropy": 0.005185234877798293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.909818649291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05275613069534302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03907317519187927,
      "backward_entropy": 0.005181252128548092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.763867378234863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052796728909015656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03900707960128784,
      "backward_entropy": 0.005179274413320754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.708778381347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05283623933792114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0389437198638916,
      "backward_entropy": 0.005178045895364549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.79677152633667,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287470296025276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03888325691223145,
      "backward_entropy": 0.005176440709167057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.435446739196777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05291134864091873,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03882741928100586,
      "backward_entropy": 0.005175891021887462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.169516563415527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05294807627797127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03877168893814087,
      "backward_entropy": 0.005173742357227538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.272676467895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05298599228262901,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03871317505836487,
      "backward_entropy": 0.005171926899088753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.419462203979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05302417278289795,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0386539101600647,
      "backward_entropy": 0.005172396699587504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.377782821655273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05306166410446167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03859621286392212,
      "backward_entropy": 0.005175388935539458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8460769653320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05309826508164406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03854095935821533,
      "backward_entropy": 0.00517757526702351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.994759559631348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05313209071755409,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038492798805236816,
      "backward_entropy": 0.005178655601210064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.644087791442871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05316641926765442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03844345211982727,
      "backward_entropy": 0.005180094391107559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.246355056762695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05320196971297264,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03839141726493835,
      "backward_entropy": 0.005179864664872487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098740577697754,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05323958024382591,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03833469450473785,
      "backward_entropy": 0.07696110010147095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.707317352294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05327664688229561,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038278961181640626,
      "backward_entropy": 0.005180967350800832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.645552635192871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05331398919224739,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03822252154350281,
      "backward_entropy": 0.00518531890379058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.964227676391602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05335136502981186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038166236877441403,
      "backward_entropy": 0.005188945680856705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.510613441467285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05338766425848007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03811301589012146,
      "backward_entropy": 0.005190146052175098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.433484077453613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05342394486069679,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03806021213531494,
      "backward_entropy": 0.005189381953742769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.352789878845215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05346033349633217,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03800730705261231,
      "backward_entropy": 0.005188410480817159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.186967372894287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053497012704610825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0379535973072052,
      "backward_entropy": 0.00518950406048033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.215056419372559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05353209748864174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037903624773025515,
      "backward_entropy": 0.005192819568845961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.165127754211426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05356758087873459,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03785261511802673,
      "backward_entropy": 0.005197695146004359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.104531288146973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053603071719408035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03780201077461243,
      "backward_entropy": 0.005200112859408061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.540526866912842,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05363842844963074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037752261757850646,
      "backward_entropy": 0.00519887109597524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.945068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053673043847084045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0377043604850769,
      "backward_entropy": 0.005197889275021023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.89583969116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053708065301179886,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03765538930892944,
      "backward_entropy": 0.005198952224519517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5341615676879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05374310538172722,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.037606722116470336,
      "backward_entropy": 0.0032466575503349304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.752453804016113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05377553403377533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03756434917449951,
      "backward_entropy": 0.005196618537108104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.299685478210449,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05380849167704582,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03752065896987915,
      "backward_entropy": 0.005196521265639199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.868372917175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05384085327386856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03747853636741638,
      "backward_entropy": 0.005195795247952144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.831907272338867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05387180298566818,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03743976354598999,
      "backward_entropy": 0.0051950646771325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.218216896057129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053901612758636475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0374035507440567,
      "backward_entropy": 0.005196057673957612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.458049774169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053934041410684586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037361109256744386,
      "backward_entropy": 0.0051987386412090724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.053913116455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05396683141589165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03731794953346253,
      "backward_entropy": 0.005200911313295364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.715608596801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05400151386857033,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03727088570594787,
      "backward_entropy": 0.005199931561946869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26107120513916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054034534841775894,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03722781240940094,
      "backward_entropy": 0.005199025902483199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.211264610290527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05406796559691429,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03718366622924805,
      "backward_entropy": 0.0051996418171458775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.617605209350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05410148575901985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03713961541652679,
      "backward_entropy": 0.005198332998487685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3536062240600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054133519530296326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03709906339645386,
      "backward_entropy": 0.005198002689414554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.716948509216309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054163094609975815,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03706440329551697,
      "backward_entropy": 0.005195873479048411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.608621597290039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05419591814279556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03702239394187927,
      "backward_entropy": 0.005193750891420577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.707559585571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05423165112733841,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03697389662265778,
      "backward_entropy": 0.005191790560881297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827013969421387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05426623672246933,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036928427219390866,
      "backward_entropy": 0.005187390579117669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.432708740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054300956428050995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03688265681266785,
      "backward_entropy": 0.0051844389074378544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.989328384399414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05433911457657814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03682951927185059,
      "backward_entropy": 0.005181054688162274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.746705055236816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0543786883354187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03677343726158142,
      "backward_entropy": 0.005178029338518779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4438629150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054418694227933884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03671659827232361,
      "backward_entropy": 0.005175787955522537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.277583122253418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05445709452033043,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03666382133960724,
      "backward_entropy": 0.0028719049361017016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.32994270324707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05449362471699715,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.036615106463432315,
      "backward_entropy": 0.0028546835399336284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329291343688965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452908203005791,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03656896948814392,
      "backward_entropy": 0.005170495973693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.314167976379395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05456465110182762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03652245998382568,
      "backward_entropy": 0.005172886368301179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.160017490386963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05460098385810852,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0364744246006012,
      "backward_entropy": 0.0051756298376454245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.190750122070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054635290056467056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036431151628494265,
      "backward_entropy": 0.005176909681823518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1116652488708496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05467280000448227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03638127744197846,
      "backward_entropy": 0.005176163382000393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.004498481750488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05470707640051842,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03633909821510315,
      "backward_entropy": 0.005171555611822341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.987189769744873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05474146082997322,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036296415328979495,
      "backward_entropy": 0.0051693788005246055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.984668016433716,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0547749325633049,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03625591397285462,
      "backward_entropy": 0.00516764157348209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.958247184753418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05480698496103287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03621830940246582,
      "backward_entropy": 0.005169423504008187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.852475166320801,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05483768880367279,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03618349432945252,
      "backward_entropy": 0.005173569752110375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720231533050537,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05486789345741272,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0361497700214386,
      "backward_entropy": 0.07694789436128405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.452568054199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05489835888147354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03611564040184021,
      "backward_entropy": 0.005182361437214745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8627545833587646,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05493055656552315,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03607809543609619,
      "backward_entropy": 0.005183697988589604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.412426948547363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054960962384939194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03604470491409302,
      "backward_entropy": 0.005182327495680915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7835533618927,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0549924336373806,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03600907623767853,
      "backward_entropy": 0.005181119673781925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.095693588256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055022723972797394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03597560524940491,
      "backward_entropy": 0.0051840730011463165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9214568138122559,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05505518242716789,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03593730926513672,
      "backward_entropy": 0.07694769567913479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.128719329833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05508517101407051,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03590443730354309,
      "backward_entropy": 0.005195354421933492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.86013126373291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05511635169386864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03586901426315307,
      "backward_entropy": 0.005201384425163269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.555941581726074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055149227380752563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03583015203475952,
      "backward_entropy": 0.005206153210666444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.200377464294434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05518431216478348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035787007212638854,
      "backward_entropy": 0.005208360652128856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.087716579437256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05522238835692406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035737726092338565,
      "backward_entropy": 0.005211071835623847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8219681978225708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05525976046919823,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03569023609161377,
      "backward_entropy": 0.0025031322406397927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.097439765930176,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05529434606432915,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03564858436584473,
      "backward_entropy": 0.07695257001452976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.87879753112793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05533107742667198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03560263812541962,
      "backward_entropy": 0.005218262059821023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.77809476852417,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0553676001727581,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.035556966066360475,
      "backward_entropy": 0.07695506016413371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.783419609069824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055401336401700974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0355171799659729,
      "backward_entropy": 0.005231306784682804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.709985733032227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055436957627534866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035473978519439696,
      "backward_entropy": 0.005234081298112869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.639463424682617,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05547209456562996,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0354320079088211,
      "backward_entropy": 0.07695768939124213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.579085826873779,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05550698563456535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0353905200958252,
      "backward_entropy": 0.005239081879456838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5194411277771,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05554164573550224,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03534948229789734,
      "backward_entropy": 0.005243817965189616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2692854404449463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055576078593730927,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03530888557434082,
      "backward_entropy": 0.005249696473280589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8449249267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055608898401260376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03527135848999023,
      "backward_entropy": 0.005258510096205605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.040892601013184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05564050376415253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035236743092536923,
      "backward_entropy": 0.005263111657566494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.852565288543701,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05567452684044838,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03519719839096069,
      "backward_entropy": 0.005269801451100243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.30354118347168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570891126990318,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03515709936618805,
      "backward_entropy": 0.0052751849095026655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.666728973388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05574459955096245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03511441946029663,
      "backward_entropy": 0.005282147477070491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.120862007141113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0557788722217083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03507488965988159,
      "backward_entropy": 0.005286712199449539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0833282470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0558127798140049,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035036152601242064,
      "backward_entropy": 0.005291329489813911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.96773624420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055844780057668686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03500136137008667,
      "backward_entropy": 0.005295216623279784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.491562843322754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05587809905409813,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.034964066743850705,
      "backward_entropy": 0.0022962453464667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.245052337646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05591033026576042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03492903709411621,
      "backward_entropy": 0.005302172154188156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.286413192749023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05594472587108612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034889665246009824,
      "backward_entropy": 0.005307479865021176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5085712671279907,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055979304015636444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034850218892097475,
      "backward_entropy": 0.005311096707979838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1448655128479,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0560113750398159,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03481552302837372,
      "backward_entropy": 0.005317019919554393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.484192848205566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05604389309883118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03478012681007385,
      "backward_entropy": 0.0053218259579605525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.608517169952393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056077346205711365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03474331498146057,
      "backward_entropy": 0.005323280890782674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30744457244873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05611066520214081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034706509113311766,
      "backward_entropy": 0.005328262845675151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.518641948699951,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05614500865340233,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034667912125587466,
      "backward_entropy": 0.005332525819540024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.467959880828857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0561787448823452,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034630709886550905,
      "backward_entropy": 0.005335344622532527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.721916675567627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05621185153722763,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034595006704330446,
      "backward_entropy": 0.00533606070611212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.658154487609863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056245408952236176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03455837368965149,
      "backward_entropy": 0.005338778926266564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6840760707855225,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05627928301692009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03452115058898926,
      "backward_entropy": 0.0053423212634192575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.969611167907715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056311409920454025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0344870924949646,
      "backward_entropy": 0.005348352508412467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.196011543273926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056342266499996185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03445577025413513,
      "backward_entropy": 0.005351067417197757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91843032836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05637285113334656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03442509770393372,
      "backward_entropy": 0.005353274858660168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.848318338394165,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05640551447868347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03439036011695862,
      "backward_entropy": 0.005358103662729263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753795623779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056436967104673386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03435806632041931,
      "backward_entropy": 0.005361570252312554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5458643436431885,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05647015571594238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0343227207660675,
      "backward_entropy": 0.005364418029785156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.307633876800537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05650139972567558,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03429111242294312,
      "backward_entropy": 0.005366582009527419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.898561954498291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05653023719787598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03426400125026703,
      "backward_entropy": 0.005368625124295552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.475799798965454,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056558918207883835,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034237274527549745,
      "backward_entropy": 0.005369887583785587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7925333976745605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05658608675003052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03421338796615601,
      "backward_entropy": 0.0053708429137865705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5936546325683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056613530963659286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03418871760368347,
      "backward_entropy": 0.07698071002960205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5853960514068604,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05664036050438881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03416513204574585,
      "backward_entropy": 0.0053796954452991486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.686403751373291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05666626617312431,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03414362072944641,
      "backward_entropy": 0.005380127165052626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.515005588531494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05669226124882698,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03412195742130279,
      "backward_entropy": 0.0053801557256115805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6237993240356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05671755224466324,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03410175740718842,
      "backward_entropy": 0.0020061807913912665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08128779381513596,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05674269422888756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03408217430114746,
      "backward_entropy": 0.005372613254520629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.514300346374512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056765537708997726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034066444635391234,
      "backward_entropy": 0.005370342069201999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.404193878173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056789033114910126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03404920399188995,
      "backward_entropy": 0.0053719766438007355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.838920593261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05681199952960014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03403310179710388,
      "backward_entropy": 0.005370812283621894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.50309944152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05683773756027222,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03401235342025757,
      "backward_entropy": 0.005366523646646076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.222651481628418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056864164769649506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03399035632610321,
      "backward_entropy": 0.005361962649557326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.217912197113037,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05688949301838875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03397004306316376,
      "backward_entropy": 0.0053609054949548506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3684773445129395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056913554668426514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03395207226276398,
      "backward_entropy": 0.005359292858176761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.214923620223999,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05693824589252472,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03393322229385376,
      "backward_entropy": 0.005354837410979801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.237400531768799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056962549686431885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03391488790512085,
      "backward_entropy": 0.0053527123398251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.144577741622925,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056986838579177856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033896762132644656,
      "backward_entropy": 0.005348362856441074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1324760913848877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057009901851415634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03388091325759888,
      "backward_entropy": 0.005343162351184421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1003129482269287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057032737880945206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03386526107788086,
      "backward_entropy": 0.0053403108484215206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.086756706237793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057055503129959106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0338494211435318,
      "backward_entropy": 0.005341442508829964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0675556659698486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057077933102846146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03383415937423706,
      "backward_entropy": 0.0053430042333073085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.003871917724609,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05709945783019066,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03382043838500977,
      "backward_entropy": 0.001812725845310423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.965146541595459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057122085243463516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03380471765995026,
      "backward_entropy": 0.005349059071805742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9802350997924805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057145629078149796,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03378735780715943,
      "backward_entropy": 0.005352699094348484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.86577033996582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0571688711643219,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03377037048339844,
      "backward_entropy": 0.0053585001991854776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.869313955307007,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057193271815776825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033751028776168826,
      "backward_entropy": 0.005368354419867198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8424010276794434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05721811577677727,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0337305873632431,
      "backward_entropy": 0.00538209080696106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.871849536895752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057243142277002335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033709749579429626,
      "backward_entropy": 0.005396561490164863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.705348968505859,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05726773291826248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033689528703689575,
      "backward_entropy": 0.00541206987367736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9074901342391968,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05729294195771217,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0336683988571167,
      "backward_entropy": 0.0054255516992674935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8002126216888428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05731695517897606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033649271726608275,
      "backward_entropy": 0.005438569519254897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.663811445236206,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05734045431017876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0336310476064682,
      "backward_entropy": 0.005450620005528132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.853837251663208,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05736431106925011,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03361194133758545,
      "backward_entropy": 0.005464904010295868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.623623847961426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057387132197618484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03359451591968536,
      "backward_entropy": 0.00547931840022405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5850539207458496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05740988999605179,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033577510714530946,
      "backward_entropy": 0.005489019470082389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.93182772397995,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05743270739912987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0335604727268219,
      "backward_entropy": 0.005496233701705933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.509510040283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05745406076312065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03354572057723999,
      "backward_entropy": 0.005505493531624476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6094300746917725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057475846260786057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033529999852180484,
      "backward_entropy": 0.005515931795040767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.464867353439331,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05749770253896713,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03351360857486725,
      "backward_entropy": 0.005531439764632119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4352662563323975,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05751965567469597,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03349722623825073,
      "backward_entropy": 0.07699212763044569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.586592674255371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057541679590940475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03348089456558227,
      "backward_entropy": 0.005552326639493306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5603437423706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0575629398226738,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03346623480319977,
      "backward_entropy": 0.005555155790514416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.523421287536621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05758357420563698,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03345293402671814,
      "backward_entropy": 0.005553391658597522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.501828908920288,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05760389566421509,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03344005644321442,
      "backward_entropy": 0.005551300528976653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.282768487930298,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05762393772602081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03342758417129517,
      "backward_entropy": 0.005549158487055037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4691667556762695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05764433741569519,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033414417505264284,
      "backward_entropy": 0.005547545850276947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.437851667404175,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057664256542921066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03340223431587219,
      "backward_entropy": 0.005543480730719036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4232985973358154,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768393352627754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033390367031097413,
      "backward_entropy": 0.005540003793107139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.956535577774048,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05770326778292656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033379080891609195,
      "backward_entropy": 0.005535382363531325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1379523277282715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05772344022989273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03336639404296875,
      "backward_entropy": 0.005529833336671193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.350752115249634,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057744067162275314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033352631330490115,
      "backward_entropy": 0.0055275120668941075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.605679035186768,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0577644445002079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033339235186576846,
      "backward_entropy": 0.005526924298869239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.312832832336426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057786133140325546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033323663473129275,
      "backward_entropy": 0.0055258336166540785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0155179500579834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05780733749270439,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03330892324447632,
      "backward_entropy": 0.005524790949291653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7252347469329834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057829052209854126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033292928338050844,
      "backward_entropy": 0.005528914017809762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5124694108963013,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05785168334841728,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03327515423297882,
      "backward_entropy": 0.00553644738263554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.393152713775635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057873308658599854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03325892686843872,
      "backward_entropy": 0.005544969605074989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7687448859214783,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05789593234658241,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03324131369590759,
      "backward_entropy": 0.07698497507307264,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 4.562717016264796,
    "avg_log_Z": -0.05668785378336907,
    "success_rate": 1.0,
    "avg_reward": 81.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.06,
      "1": 0.04,
      "2": 0.9
    },
    "avg_forward_entropy": 0.034227889627218254,
    "avg_backward_entropy": 0.009550956311739155,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}