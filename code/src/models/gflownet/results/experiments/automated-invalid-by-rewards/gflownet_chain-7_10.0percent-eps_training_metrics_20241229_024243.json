{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09892090729304723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09878395284925189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.92796325683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369083970785141,
      "backward_entropy": 0.09890951429094587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.30931091308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13690465688705444,
      "backward_entropy": 0.098925062588283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.0713348388672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00019976275507360697,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369008719921112,
      "backward_entropy": 0.09892923491341728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.04861450195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0002995550457853824,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368969827890396,
      "backward_entropy": 0.09893344129834857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.2475128173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00039984771865420043,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13689298927783966,
      "backward_entropy": 0.09879006658281599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.61834716796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004997450159862638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13688892126083374,
      "backward_entropy": 0.09879170145307269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.8219451904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006002584123052657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688479363918304,
      "backward_entropy": 0.09891653060913086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.41460418701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007003250648267567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13688039779663086,
      "backward_entropy": 0.09879493713378906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.93588256835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007984392577782273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687579333782196,
      "backward_entropy": 0.09891898291451591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.52951049804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008976234821602702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687105476856232,
      "backward_entropy": 0.09892026015690394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.51039123535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009976866422221065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368662416934967,
      "backward_entropy": 0.09879887104034424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.82186126708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010971722658723593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686127960681915,
      "backward_entropy": 0.098922746522086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.47088623046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011873955372720957,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368563324213028,
      "backward_entropy": 0.09896583216530937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.4428253173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012786159059032798,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368512362241745,
      "backward_entropy": 0.09896859100886754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.18858337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013721506111323833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684603571891785,
      "backward_entropy": 0.09892480713980538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.16664123535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014673969708383083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684070110321045,
      "backward_entropy": 0.09892555645533971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.13052368164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001564056845381856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683518767356873,
      "backward_entropy": 0.09880454199654716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.77096557617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016630507307127118,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13682958483695984,
      "backward_entropy": 0.09897927727018084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.06446838378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017595478566363454,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13682380318641663,
      "backward_entropy": 0.09898169551576887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.9532470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018593640998005867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13681793212890625,
      "backward_entropy": 0.09892855371747698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.822998046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019615821074694395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13681183755397797,
      "backward_entropy": 0.09881017889295306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.16657257080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002059348626062274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368056833744049,
      "backward_entropy": 0.09881171158381871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.36854553222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021550313103944063,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13679948449134827,
      "backward_entropy": 0.09899069581712995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.96224975585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022530045825988054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13679321110248566,
      "backward_entropy": 0.09881429161344256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.73210906982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002352994168177247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13678717613220215,
      "backward_entropy": 0.09881563697542463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.50314331054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0024506684858351946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678118586540222,
      "backward_entropy": 0.09893153394971575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.89295959472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002551689278334379,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13677510619163513,
      "backward_entropy": 0.0988177912575858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.17446899414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002654231386259198,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676892220973969,
      "backward_entropy": 0.09899961948394775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.73658752441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002755295718088746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676264882087708,
      "backward_entropy": 0.09881983484540667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.16726684570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028497260063886642,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13675637543201447,
      "backward_entropy": 0.09900242941720146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.4188995361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029478222131729126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674995303153992,
      "backward_entropy": 0.09893223217555455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.61344146728516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0030478821136057377,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367434412240982,
      "backward_entropy": 0.0990049157823835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.13577270507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003145336639136076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673695921897888,
      "backward_entropy": 0.09893177236829485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.67807006835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003244660561904311,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13673031330108643,
      "backward_entropy": 0.0988220317023141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.08929443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003342854091897607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136723592877388,
      "backward_entropy": 0.09893075057438441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.35281372070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0034428350627422333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13671670854091644,
      "backward_entropy": 0.09893013749803815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.66159057617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035430314019322395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670971989631653,
      "backward_entropy": 0.09892942224230085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.65354919433594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036448570899665356,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13670261204242706,
      "backward_entropy": 0.09901033129010882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.99546813964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003743397770449519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669544458389282,
      "backward_entropy": 0.09892771925245013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.8865966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038436809554696083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668809831142426,
      "backward_entropy": 0.09892669745853969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.031494140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003944219555705786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366807073354721,
      "backward_entropy": 0.09882129090172904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.20277404785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0040474277921020985,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13667306303977966,
      "backward_entropy": 0.09901279211044312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.9006805419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004147241823375225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366654336452484,
      "backward_entropy": 0.09892308712005615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.24400329589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004248610232025385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665764033794403,
      "backward_entropy": 0.09892167363848005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.40771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004348210524767637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13664959371089935,
      "backward_entropy": 0.09892005579812187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.43971252441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004451015964150429,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13664135336875916,
      "backward_entropy": 0.09881830215454102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.8043670654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00454872427508235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13663314282894135,
      "backward_entropy": 0.0989166327885219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.23489379882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004645131528377533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13662481307983398,
      "backward_entropy": 0.0988161734172276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.93382263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004738369956612587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366163194179535,
      "backward_entropy": 0.09891234125409808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.72247314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004832843784242868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366078108549118,
      "backward_entropy": 0.09881326981953212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.96717834472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004932354670017958,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13659898936748505,
      "backward_entropy": 0.09901540619986397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.40431213378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005030565429478884,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365901529788971,
      "backward_entropy": 0.09901554243905204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.2263946533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005125619471073151,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658124208450317,
      "backward_entropy": 0.09890275342123848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.72080993652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005221543833613396,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657227158546448,
      "backward_entropy": 0.0990156957081386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.2871856689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0053090378642082214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656345009803772,
      "backward_entropy": 0.09889701434544154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.24766540527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005401004571467638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365543007850647,
      "backward_entropy": 0.09880282197679792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.1881561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0054923249408602715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365450918674469,
      "backward_entropy": 0.0988907984324864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.58685302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0055863214656710625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365356743335724,
      "backward_entropy": 0.09888761384146554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.60800170898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005683903582394123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13652589917182922,
      "backward_entropy": 0.09901570422308785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.92254638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005781543906778097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13651582598686218,
      "backward_entropy": 0.09888104030064174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.43011474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005877650808542967,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365056335926056,
      "backward_entropy": 0.0990156957081386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.53915405273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005974356085062027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13649535179138184,
      "backward_entropy": 0.0987897515296936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.07218170166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0060712313279509544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648483157157898,
      "backward_entropy": 0.0988701241356986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.5919647216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006165384314954281,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364743709564209,
      "backward_entropy": 0.0990155850137983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.7429656982422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006258123088628054,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364637166261673,
      "backward_entropy": 0.09901549134935651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.04156494140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006353188306093216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13645276427268982,
      "backward_entropy": 0.09885787963867188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.10250854492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006447257939726114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13644179701805115,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.30892944335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006536882370710373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13643090426921844,
      "backward_entropy": 0.09884896448680333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.12356567382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006630755495280027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364196240901947,
      "backward_entropy": 0.0987722533089774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.12289428710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0067248838022351265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13640806078910828,
      "backward_entropy": 0.09883965764726911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.20729064941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006823076866567135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13639622926712036,
      "backward_entropy": 0.09883502551487514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.312255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006923095788806677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13638417422771454,
      "backward_entropy": 0.09883035932268415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.2900390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007026677951216698,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363719403743744,
      "backward_entropy": 0.0990147590637207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.7467041015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007134667132049799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13635942339897156,
      "backward_entropy": 0.0987600599016462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.59039306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007243394386023283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363467127084732,
      "backward_entropy": 0.09881718669618879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.81336975097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007350762374699116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13633380830287933,
      "backward_entropy": 0.09881255456379481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.66046142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007448279764503241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13632115721702576,
      "backward_entropy": 0.09880735192980085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.88507080078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007547666784375906,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13630831241607666,
      "backward_entropy": 0.09901458876473564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.63143920898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007646535523235798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362951695919037,
      "backward_entropy": 0.09874730450766427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.84255981445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007740047760307789,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13628210127353668,
      "backward_entropy": 0.09901433331625802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.08993530273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007832156494259834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13626886904239655,
      "backward_entropy": 0.0987847021647862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.8275146484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007919021882116795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13625554740428925,
      "backward_entropy": 0.09877808604921613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.2018814086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008001986891031265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13624237477779388,
      "backward_entropy": 0.0987336550440107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.09320068359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00807963591068983,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13622944056987762,
      "backward_entropy": 0.09901326043265206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.47340393066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008161577396094799,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13621623814105988,
      "backward_entropy": 0.09901297092437744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.55799865722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008243082091212273,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13620270788669586,
      "backward_entropy": 0.09872151272637504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.60245513916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008326445706188679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13618890941143036,
      "backward_entropy": 0.09874246801648821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.43368530273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008405566215515137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361750215291977,
      "backward_entropy": 0.0987133298601423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.00599670410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008482947014272213,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13616099953651428,
      "backward_entropy": 0.09901162556239537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.90199279785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008560548536479473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361466944217682,
      "backward_entropy": 0.09871831962040492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.5472869873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008637141436338425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13613244891166687,
      "backward_entropy": 0.0987009150641305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.67567443847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008715818636119366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13611777126789093,
      "backward_entropy": 0.09870146002088274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.48636627197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008802231401205063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361026167869568,
      "backward_entropy": 0.09869351557322911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.51393127441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008884108625352383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13608741760253906,
      "backward_entropy": 0.09900999069213867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.2830810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00896019209176302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360723078250885,
      "backward_entropy": 0.09868466854095459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.94317626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009034870192408562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360570788383484,
      "backward_entropy": 0.09866682120731898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.68691635131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009106749668717384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13604190945625305,
      "backward_entropy": 0.09865765060697283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.3354263305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009169814176857471,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13602706789970398,
      "backward_entropy": 0.09867018461227417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.74183654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009229344315826893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13601242005825043,
      "backward_entropy": 0.09863795552934919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.1166534423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009286856278777122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13599750399589539,
      "backward_entropy": 0.09862757580620903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.41867065429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009346602484583855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13598214089870453,
      "backward_entropy": 0.09865346125194005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.52291870117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009406949393451214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13596664369106293,
      "backward_entropy": 0.09864789247512817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.05617904663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009471547789871693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13595066964626312,
      "backward_entropy": 0.09859614712851388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.72679138183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009525987319648266,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359352320432663,
      "backward_entropy": 0.09900462627410889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.634033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009581438265740871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13591955602169037,
      "backward_entropy": 0.09857365914753505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.31620025634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00964366365224123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359032392501831,
      "backward_entropy": 0.0985627429825919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.315185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009706287644803524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358867883682251,
      "backward_entropy": 0.09855173315320696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.00048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009774678386747837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13586965203285217,
      "backward_entropy": 0.09854091065270561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.7959747314453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009846702218055725,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13585209846496582,
      "backward_entropy": 0.09900248902184623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.85601806640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009920024313032627,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13583427667617798,
      "backward_entropy": 0.0990023102079119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.47996520996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009998145513236523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13581582903862,
      "backward_entropy": 0.09850897107805524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.98284912109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010076670907437801,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13579705357551575,
      "backward_entropy": 0.09859422274998256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8292694091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010156137868762016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13577815890312195,
      "backward_entropy": 0.09858935219900948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.76496124267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010243239812552929,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13575837016105652,
      "backward_entropy": 0.09858502660478864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.35566711425781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010328410193324089,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13573861122131348,
      "backward_entropy": 0.09900236129760742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.71676635742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010405243374407291,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357191801071167,
      "backward_entropy": 0.09857518332345146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.94900512695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010481190867722034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13569971919059753,
      "backward_entropy": 0.09856969969613212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.76759338378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010557932779192924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356799155473709,
      "backward_entropy": 0.09843095711299352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.64515686035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010633385740220547,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13565993309020996,
      "backward_entropy": 0.09900171416146415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.7476806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010708127170801163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13563990592956543,
      "backward_entropy": 0.09840614455086845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.52130126953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010785544291138649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13561929762363434,
      "backward_entropy": 0.0983936105455671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.1579818725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01087097730487585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13559766113758087,
      "backward_entropy": 0.09838134901864189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.2180404663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010952362790703773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13557611405849457,
      "backward_entropy": 0.0983682530266898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.87982940673828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01102576032280922,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13555455207824707,
      "backward_entropy": 0.09900093930108207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.13189697265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011094661429524422,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13553300499916077,
      "backward_entropy": 0.09900049652372088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.82322692871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0111674340441823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13551080226898193,
      "backward_entropy": 0.09832762820380074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.17214965820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011247029528021812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13548746705055237,
      "backward_entropy": 0.09851018020084926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.05391693115234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01132521964609623,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354639083147049,
      "backward_entropy": 0.09899999414171491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.1023406982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011402592994272709,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13544028997421265,
      "backward_entropy": 0.09828752279281616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.4866180419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01148847583681345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354169249534607,
      "backward_entropy": 0.09849119186401367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9366912841797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011580529622733593,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13539305329322815,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.71624755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011673993431031704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13536877930164337,
      "backward_entropy": 0.09825035503932408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.34315490722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011768031865358353,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13534387946128845,
      "backward_entropy": 0.09900116920471191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.94264221191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011865051463246346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13531842827796936,
      "backward_entropy": 0.09846895081656319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.37167358398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011964856646955013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13529250025749207,
      "backward_entropy": 0.09821238688060216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.0206298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012068857438862324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13526591658592224,
      "backward_entropy": 0.09820022753306798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.05062866210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012170911766588688,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1352391541004181,
      "backward_entropy": 0.09900293179920741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.30502319335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012265053577721119,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1352127194404602,
      "backward_entropy": 0.09900305952344622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.10946655273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012352346442639828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13518667221069336,
      "backward_entropy": 0.09843839917864118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.7107925415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012443308718502522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13515996932983398,
      "backward_entropy": 0.0981438500540597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.32457733154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012529642321169376,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13513335585594177,
      "backward_entropy": 0.0990028977394104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.29926300048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012611954472959042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351068913936615,
      "backward_entropy": 0.09811224256243024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.8755340576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012690648436546326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350805163383484,
      "backward_entropy": 0.09809516157422747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.51376342773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012769593857228756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13505353033542633,
      "backward_entropy": 0.09839567116328649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.38876342773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01285644806921482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13502517342567444,
      "backward_entropy": 0.0980597734451294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.77359008789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012950683943927288,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13499568402767181,
      "backward_entropy": 0.09837855611528669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.30313110351562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013043548911809921,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13496580719947815,
      "backward_entropy": 0.09900152683258057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.40878295898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013135747984051704,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13493579626083374,
      "backward_entropy": 0.09900140762329102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.53096771240234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013228900730609894,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13490521907806396,
      "backward_entropy": 0.09900128841400146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.08375549316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013319230638444424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348746418952942,
      "backward_entropy": 0.09797138827187675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.41389465332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01340513862669468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13484430313110352,
      "backward_entropy": 0.09795214448656354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.59974670410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013486920855939388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13481411337852478,
      "backward_entropy": 0.09832090990883964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.7163314819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013565718196332455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13478434085845947,
      "backward_entropy": 0.09791124718529838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.33230590820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013640958815813065,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347545087337494,
      "backward_entropy": 0.09899914264678955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.75955200195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013713146559894085,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347246766090393,
      "backward_entropy": 0.0989983422415597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.57395935058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013791004195809364,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13469398021697998,
      "backward_entropy": 0.09899774619511195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.17066955566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01387037057429552,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13466313481330872,
      "backward_entropy": 0.09899721826825823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.9930877685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013953682035207748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346309632062912,
      "backward_entropy": 0.09780287742614746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.90303802490234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014041349291801453,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13459792733192444,
      "backward_entropy": 0.09899663925170898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.3524169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014124447479844093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13456490635871887,
      "backward_entropy": 0.09822418008531843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.8419647216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014213326387107372,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13453051447868347,
      "backward_entropy": 0.09899625607899257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.66070556640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014304004609584808,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1344955861568451,
      "backward_entropy": 0.09820032119750977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.17417907714844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014405065216124058,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13445861637592316,
      "backward_entropy": 0.09899658816201347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.8271942138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01450604572892189,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13442100584506989,
      "backward_entropy": 0.09817816529955183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.0176544189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014604712836444378,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13438290357589722,
      "backward_entropy": 0.09816632952008929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.62786865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014702001586556435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343446671962738,
      "backward_entropy": 0.09815362521580287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.93222045898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014802087098360062,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13430577516555786,
      "backward_entropy": 0.09814076764242989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.26010131835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014904527924954891,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13426616787910461,
      "backward_entropy": 0.09758730445589338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.8497772216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015001046471297741,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1342269331216812,
      "backward_entropy": 0.09899767807551793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.75372314453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015107301063835621,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1341855674982071,
      "backward_entropy": 0.09899802718843732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.02642822265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015218876302242279,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13414280116558075,
      "backward_entropy": 0.09899855511529106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.08960723876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015331733971834183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13409949839115143,
      "backward_entropy": 0.09749628816332136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.37911987304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015436003915965557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1340571939945221,
      "backward_entropy": 0.09747188431876046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.9857635498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015541388653218746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13401371240615845,
      "backward_entropy": 0.09899951730455671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.1470947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015644462779164314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1339699923992157,
      "backward_entropy": 0.09742152690887451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.733154296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0157528817653656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13392475247383118,
      "backward_entropy": 0.09801828861236572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.97203063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015866141766309738,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13387815654277802,
      "backward_entropy": 0.09800433261053902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.79771423339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015985311940312386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13382995128631592,
      "backward_entropy": 0.09799090453556605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.9359893798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016102179884910583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13378185033798218,
      "backward_entropy": 0.09797675268990653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.82147979736328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016220929101109505,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13373276591300964,
      "backward_entropy": 0.09900177376610893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.58953857421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016332034021615982,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1336844116449356,
      "backward_entropy": 0.09900196960994176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.98086547851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016442034393548965,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13363569974899292,
      "backward_entropy": 0.09900215693882533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.1114959716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016556674614548683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1335856020450592,
      "backward_entropy": 0.09721497978482928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 267.912841796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01667875051498413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1335335522890091,
      "backward_entropy": 0.0978999308177403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.9757537841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016810255125164986,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13347886502742767,
      "backward_entropy": 0.09788644313812256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.07716369628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01693992130458355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13342368602752686,
      "backward_entropy": 0.09787206990378243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.74874877929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01707131415605545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13336728513240814,
      "backward_entropy": 0.09785735607147217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.53257751464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017202595248818398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13331009447574615,
      "backward_entropy": 0.09708615711757115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.8770294189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017330318689346313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13325285911560059,
      "backward_entropy": 0.09705783639635358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.41082763671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01745888777077198,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13319511711597443,
      "backward_entropy": 0.09900614193507604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.89545440673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017584146931767464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13313725590705872,
      "backward_entropy": 0.09700066702706474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.16749572753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01770300418138504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13308018445968628,
      "backward_entropy": 0.0977712529046195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.50140380859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01782134361565113,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13302239775657654,
      "backward_entropy": 0.0977514215878078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6151580810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017942851409316063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13296324014663696,
      "backward_entropy": 0.0977316073008946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.24734497070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01806015707552433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13290441036224365,
      "backward_entropy": 0.0977104902267456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.84130859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018173428252339363,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13284564018249512,
      "backward_entropy": 0.09900658471243722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.8773651123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018291497603058815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13278459012508392,
      "backward_entropy": 0.09680352892194476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.11170959472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018412433564662933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13272200524806976,
      "backward_entropy": 0.0967684303011213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 266.4082336425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01853613182902336,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13265809416770935,
      "backward_entropy": 0.09762313536235265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.45379638671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018668487668037415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1325911283493042,
      "backward_entropy": 0.09760257175990514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.0394744873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018800416961312294,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13252350687980652,
      "backward_entropy": 0.09900718075888497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.31353759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018928714096546173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13245612382888794,
      "backward_entropy": 0.09755877086094447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8855438232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019053619354963303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13238883018493652,
      "backward_entropy": 0.09753480979374476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.22520446777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01917596347630024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13232186436653137,
      "backward_entropy": 0.09751002277646746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.35169982910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019292041659355164,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13225579261779785,
      "backward_entropy": 0.09900687422071185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.56002807617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019401025027036667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1321912705898285,
      "backward_entropy": 0.09745551007134574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.85986328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019507404416799545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13212715089321136,
      "backward_entropy": 0.09742607389177595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.94268798828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019610941410064697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13206306099891663,
      "backward_entropy": 0.09739549670900617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.20025634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019719017669558525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1319969892501831,
      "backward_entropy": 0.096332848072052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.68643188476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019825618714094162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13193026185035706,
      "backward_entropy": 0.09733392511095319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.29083251953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019929340109229088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318635791540146,
      "backward_entropy": 0.09623529229845319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.37892150878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02003060095012188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13179689645767212,
      "backward_entropy": 0.09726829188210624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.74436950683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02013833448290825,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13172760605812073,
      "backward_entropy": 0.09900263377598353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.04443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020241616293787956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13165917992591858,
      "backward_entropy": 0.09608295134135655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.47610473632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02034718729555607,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13158872723579407,
      "backward_entropy": 0.0971682071685791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.9868927001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020451262593269348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1315174251794815,
      "backward_entropy": 0.09713329587663923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.66415405273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020553184673190117,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13144651055335999,
      "backward_entropy": 0.09709673268454415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.96827697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020654601976275444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1313750445842743,
      "backward_entropy": 0.09586068562098912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.47659301757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020746368914842606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13130594789981842,
      "backward_entropy": 0.09580048492976598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.27862548828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02083735726773739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13123692572116852,
      "backward_entropy": 0.09574076107570104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.19393920898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02093403972685337,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1311650425195694,
      "backward_entropy": 0.09899680955069405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.00302124023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021021798253059387,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13109564781188965,
      "backward_entropy": 0.09899563448769706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.24290466308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02111024223268032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13102497160434723,
      "backward_entropy": 0.09555337258747645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.9200897216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021197864785790443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13095393776893616,
      "backward_entropy": 0.09548865045819964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.8404998779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021289896219968796,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13088122010231018,
      "backward_entropy": 0.09899270534515381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.74607849121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021385863423347473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13080701231956482,
      "backward_entropy": 0.09535868678774152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.98474884033203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02148240990936756,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13073241710662842,
      "backward_entropy": 0.09899139404296875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.26148986816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021573523059487343,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13065889477729797,
      "backward_entropy": 0.09899045739855085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.87510681152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021666772663593292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1305835247039795,
      "backward_entropy": 0.09515810012817383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.19168090820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021758710965514183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1305079609155655,
      "backward_entropy": 0.09653892687388829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.10598754882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021844202652573586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13043436408042908,
      "backward_entropy": 0.09648973601205009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.40677642822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021929798647761345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13036078214645386,
      "backward_entropy": 0.0964394382068089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.2718963623047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02201118879020214,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13028797507286072,
      "backward_entropy": 0.09898562942232404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.26715850830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022091861814260483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1302138864994049,
      "backward_entropy": 0.09898436069488525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.50828552246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02217055670917034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13013966381549835,
      "backward_entropy": 0.0962799106325422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.06483459472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02224944904446602,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1300647109746933,
      "backward_entropy": 0.09898163591112409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.38414001464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022330356761813164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12998825311660767,
      "backward_entropy": 0.0961686202457973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.57907104492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022411249577999115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12991106510162354,
      "backward_entropy": 0.09611223425183978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.00584411621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022493718191981316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1298322230577469,
      "backward_entropy": 0.09438742910112653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.16851806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02257443405687809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1297536939382553,
      "backward_entropy": 0.09430285862513951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.0622100830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02265479788184166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1296740472316742,
      "backward_entropy": 0.09421604020254952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.27779388427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02274421788752079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12959006428718567,
      "backward_entropy": 0.0941321509225028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.333251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02282971329987049,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12950776517391205,
      "backward_entropy": 0.0958207334790911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.19046020507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022919556125998497,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12942206859588623,
      "backward_entropy": 0.09576114586421422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.53211975097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023015649989247322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12933304905891418,
      "backward_entropy": 0.0938734667641776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.52569580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02312062308192253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12923941016197205,
      "backward_entropy": 0.09379043749400548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.88897705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023226434364914894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1291443109512329,
      "backward_entropy": 0.0937063183103289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.0919647216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02333122119307518,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12904852628707886,
      "backward_entropy": 0.09553301334381104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.3021697998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023440459743142128,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12894994020462036,
      "backward_entropy": 0.09547415801456996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.34689331054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02355353534221649,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1288485825061798,
      "backward_entropy": 0.09541537931987218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.7275848388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02366841584444046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.128745436668396,
      "backward_entropy": 0.0933539697102138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.65380096435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023783165961503983,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12864145636558533,
      "backward_entropy": 0.09326323441096715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.53097534179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02389104850590229,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12854012846946716,
      "backward_entropy": 0.09522793974195208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.30824279785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023999515920877457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12843799591064453,
      "backward_entropy": 0.09516124214444842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.89665985107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024106984958052635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12833568453788757,
      "backward_entropy": 0.0929737857409886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.8634490966797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024209750816226006,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12823449075222015,
      "backward_entropy": 0.09898495674133301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.45562744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02431720308959484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12813019752502441,
      "backward_entropy": 0.09276875427791051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.44236755371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024425141513347626,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12802444398403168,
      "backward_entropy": 0.09898568902696882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.59622955322266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024535007774829865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12791617214679718,
      "backward_entropy": 0.09898613180433001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.39569091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02463991567492485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12780936062335968,
      "backward_entropy": 0.09244333846228463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.75389099121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02474392019212246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1277020126581192,
      "backward_entropy": 0.09464483601706368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.3115234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024842239916324615,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12759725749492645,
      "backward_entropy": 0.0989853824887957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.61558532714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02493639849126339,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1274929791688919,
      "backward_entropy": 0.09447296176637922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.62118530273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025035535916686058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1273844838142395,
      "backward_entropy": 0.09438674790518624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.68048095703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02513258159160614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12727613747119904,
      "backward_entropy": 0.09182905299322945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.66146087646484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025223784148693085,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12716934084892273,
      "backward_entropy": 0.09898137194769722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.4420928955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0253085158765316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.127065509557724,
      "backward_entropy": 0.0915517977305821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.10514068603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025396067649126053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12695902585983276,
      "backward_entropy": 0.09400832653045654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.91915893554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02547530271112919,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1268559992313385,
      "backward_entropy": 0.09126219579151698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.73834228515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025559576228260994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12674908339977264,
      "backward_entropy": 0.09380442755562919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.3885955810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025643032044172287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12664087116718292,
      "backward_entropy": 0.09370122637067523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.97451782226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02573120780289173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12652716040611267,
      "backward_entropy": 0.0936013034411839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.9572982788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02582032047212124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.126411572098732,
      "backward_entropy": 0.090659499168396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.88638305664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02590525522828102,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1262979805469513,
      "backward_entropy": 0.09339454344340734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.23243713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025986431166529655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12618613243103027,
      "backward_entropy": 0.09034711122512817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.10348510742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026074327528476715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1260688602924347,
      "backward_entropy": 0.09019160270690918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.56797790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026164492592215538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12594833970069885,
      "backward_entropy": 0.0900362389428275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.84544372558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026262015104293823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12582191824913025,
      "backward_entropy": 0.09296987737928118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026362650096416473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12569159269332886,
      "backward_entropy": 0.09286701679229736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.67991638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026459630578756332,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12556299567222595,
      "backward_entropy": 0.08956810406276158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.281494140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026549236848950386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12543770670890808,
      "backward_entropy": 0.08939846924373082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.02529907226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026637254282832146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12531131505966187,
      "backward_entropy": 0.09252704892839704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.10223388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026722412556409836,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12518548965454102,
      "backward_entropy": 0.0924053703035627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.9136505126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02680869959294796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12505798041820526,
      "backward_entropy": 0.08886000088282994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.68833923339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026897884905338287,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12492790818214417,
      "backward_entropy": 0.0886781896863665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.95094299316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026989318430423737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1247948482632637,
      "backward_entropy": 0.08849465847015381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.2332763671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027079708874225616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12466194480657578,
      "backward_entropy": 0.09191351277487618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.3687973022461,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027170468121767044,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12452735006809235,
      "backward_entropy": 0.09895731721605573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.04466247558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0272566769272089,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12439537048339844,
      "backward_entropy": 0.09165084362030029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.5581817626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0273355171084404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12427017092704773,
      "backward_entropy": 0.09151047468185425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.33358764648438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02741827443242073,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1241423562169075,
      "backward_entropy": 0.09895177398409162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.4785385131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027507800608873367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12400905042886734,
      "backward_entropy": 0.08733317681721278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.65390014648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027590859681367874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12387915700674057,
      "backward_entropy": 0.09109040669032506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.9837646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027676809579133987,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12374569475650787,
      "backward_entropy": 0.0909468446459089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.39759826660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02776193618774414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12361140549182892,
      "backward_entropy": 0.08671242850167411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.45497131347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027848338708281517,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12347552180290222,
      "backward_entropy": 0.09894646917070661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.0594482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02794078178703785,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1233341246843338,
      "backward_entropy": 0.09051152638026647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.78742980957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028031984344124794,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12319295853376389,
      "backward_entropy": 0.0903627702168056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.8345947265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028118504211306572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12305445969104767,
      "backward_entropy": 0.09020669119698661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.9627227783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028207572177052498,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12291261553764343,
      "backward_entropy": 0.0900496074131557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.77180480957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028301943093538284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12276476621627808,
      "backward_entropy": 0.0853888988494873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.44046783447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028392033651471138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1226210817694664,
      "backward_entropy": 0.08515741995402745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.82217025756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028479356318712234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12247880548238754,
      "backward_entropy": 0.0849211301122393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.81431579589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028556717559695244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1223430261015892,
      "backward_entropy": 0.08466947078704834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.41278076171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028634147718548775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12220585346221924,
      "backward_entropy": 0.0891939742224557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.47457122802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02871176414191723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12206767499446869,
      "backward_entropy": 0.08415628331048149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.74937438964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02878451906144619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12193325161933899,
      "backward_entropy": 0.0888150589806693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.1973876953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02885771356523037,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12179704010486603,
      "backward_entropy": 0.08861513648714338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.2303009033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02893107943236828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1216588169336319,
      "backward_entropy": 0.08335092238017491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.87955474853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02900981344282627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12151449918746948,
      "backward_entropy": 0.08821117026465279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.7879180908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029086854308843613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12137080729007721,
      "backward_entropy": 0.0880049637385777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.37448120117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029169350862503052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12122198194265366,
      "backward_entropy": 0.08252043383462089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.70393371582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029249904677271843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12107442319393158,
      "backward_entropy": 0.08223247528076172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.21443939208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029328953474760056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12092824280261993,
      "backward_entropy": 0.08194000380379814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.03276824951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02940855734050274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12078182399272919,
      "backward_entropy": 0.08715507813862391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.0703887939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029486533254384995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1206362396478653,
      "backward_entropy": 0.08135177407945905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.94610595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02956472523510456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.120489701628685,
      "backward_entropy": 0.08669699941362653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9680633544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02964654751121998,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12033924460411072,
      "backward_entropy": 0.098914521081107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.01744842529297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02973197214305401,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12018562853336334,
      "backward_entropy": 0.09891445296151298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.81354522705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029815446585416794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12003365904092789,
      "backward_entropy": 0.0801348260470799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.04983520507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029898490756750107,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11988094449043274,
      "backward_entropy": 0.09891389948981148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.46907043457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029979722574353218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11972950398921967,
      "backward_entropy": 0.08552706241607666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.86884307861328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030059101060032845,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1195802092552185,
      "backward_entropy": 0.09891257967267718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.44551849365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03013872168958187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11942857503890991,
      "backward_entropy": 0.0788549269948687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.23470306396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03021487221121788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927808821201324,
      "backward_entropy": 0.07852378913334437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.26336669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03028668649494648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1191331148147583,
      "backward_entropy": 0.07819113561085292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.58497619628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030364617705345154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11898186802864075,
      "backward_entropy": 0.07786014250346593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.016845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030439505353569984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11883313208818436,
      "backward_entropy": 0.07752272060939244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.87487030029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03050803951919079,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11868983507156372,
      "backward_entropy": 0.08370717934199742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.96685791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030575940385460854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11854593455791473,
      "backward_entropy": 0.07682205949510847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.8466567993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030643628910183907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11840194463729858,
      "backward_entropy": 0.07646409102848598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.23362731933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030711140483617783,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1182578057050705,
      "backward_entropy": 0.08284837859017509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.86705017089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030785279348492622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11810673773288727,
      "backward_entropy": 0.07574590614863805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.07130432128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03086382895708084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11795131862163544,
      "backward_entropy": 0.08228349685668945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.72384643554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030939225107431412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11779829859733582,
      "backward_entropy": 0.07502226318631854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.9001007080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031011447310447693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11764687299728394,
      "backward_entropy": 0.08170096363340106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.54891967773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031091246753931046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11748716235160828,
      "backward_entropy": 0.07426985672542027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.24087524414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031176751479506493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11732266843318939,
      "backward_entropy": 0.08112692832946777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.95132064819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031256530433893204,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11716292798519135,
      "backward_entropy": 0.0808294585772923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.07920837402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031327538192272186,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11701200902462006,
      "backward_entropy": 0.09888938495091029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.16746520996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03140154480934143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11685681343078613,
      "backward_entropy": 0.07273142678397042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.9064178466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031478144228458405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11669827997684479,
      "backward_entropy": 0.07989411694662911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.68655395507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031562644988298416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11653372645378113,
      "backward_entropy": 0.07195650679724556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.06497955322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03164156898856163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1163739264011383,
      "backward_entropy": 0.07927780491965157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.98786926269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03171525523066521,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1162179708480835,
      "backward_entropy": 0.07895493507385254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.0942153930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03178827092051506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11606290936470032,
      "backward_entropy": 0.07074628557477679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.47737884521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031860582530498505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1159084364771843,
      "backward_entropy": 0.07829301697867257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.15946197509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03192846104502678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11575737595558167,
      "backward_entropy": 0.06990966626576015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.85832977294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03199293091893196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11561043560504913,
      "backward_entropy": 0.06948338236127581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.38494873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032059043645858765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11546081304550171,
      "backward_entropy": 0.06905299425125122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.83615112304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03212830796837807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11530700325965881,
      "backward_entropy": 0.07689355100904192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.86260986328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03219406679272652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11515761911869049,
      "backward_entropy": 0.0681814295904977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.5889892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03226359933614731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11500553786754608,
      "backward_entropy": 0.0677479122366224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.44703674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03233509510755539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.114852175116539,
      "backward_entropy": 0.06732214774404253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.14058685302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032405924052000046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11469821631908417,
      "backward_entropy": 0.06689068249293736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.10050201416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03247672691941261,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11454537510871887,
      "backward_entropy": 0.07510619504111153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.92881774902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032545510679483414,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11439459025859833,
      "backward_entropy": 0.09886166027614049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.1906967163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03261738643050194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11423972249031067,
      "backward_entropy": 0.07436692714691162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.8909454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03268503025174141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408831179141998,
      "backward_entropy": 0.06513373340879168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.63372039794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03275623917579651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11393333971500397,
      "backward_entropy": 0.06468402062143598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.97982788085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032828785479068756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11377684026956558,
      "backward_entropy": 0.06423366921288627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.01580810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03290420398116112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11361926794052124,
      "backward_entropy": 0.06378141471317836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.45878601074219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032982103526592255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11345641314983368,
      "backward_entropy": 0.09885614258902413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.4607925415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033055804669857025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11329805850982666,
      "backward_entropy": 0.06287744215556554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.44525146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03312709182500839,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11314325034618378,
      "backward_entropy": 0.07170763186046056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.87803649902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.033201318234205246,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11298495531082153,
      "backward_entropy": 0.09885426078523908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.00344848632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033271871507167816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11283215135335922,
      "backward_entropy": 0.06149667501449585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.4754638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03334413841366768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11267775297164917,
      "backward_entropy": 0.06103920936584473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.49689865112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03341763839125633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1125214546918869,
      "backward_entropy": 0.060576217515128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.91787719726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033481400460004807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11237376928329468,
      "backward_entropy": 0.060094986643110006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.32560729980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03354738652706146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11222346127033234,
      "backward_entropy": 0.059614556176321845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.95594787597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03361004590988159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11207606643438339,
      "backward_entropy": 0.05912638562066214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.81339263916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03368034586310387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11192118376493454,
      "backward_entropy": 0.05864862033299038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.714599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03375203534960747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11176499724388123,
      "backward_entropy": 0.058166640145438056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.08389282226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0338236540555954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11161035299301147,
      "backward_entropy": 0.06762428368840899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.59380340576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03389313071966171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1114569753408432,
      "backward_entropy": 0.057201530252184184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.32774353027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033962689340114594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11130465567111969,
      "backward_entropy": 0.0567143304007394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.13034057617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03403596580028534,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11114910244941711,
      "backward_entropy": 0.06634080410003662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.8962631225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0341125912964344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11099092662334442,
      "backward_entropy": 0.0557674595287868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.53054809570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034188732504844666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11083459854125977,
      "backward_entropy": 0.06548782757350377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.42164611816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034269802272319794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11067409068346024,
      "backward_entropy": 0.05483769518988473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.75962829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034359805285930634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11050502955913544,
      "backward_entropy": 0.054383082049233575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.7127685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034447796642780304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11033840477466583,
      "backward_entropy": 0.053921375955854146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.16607666015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03453563153743744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11017199605703354,
      "backward_entropy": 0.05345446722848075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.7328338623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034629687666893005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10999882221221924,
      "backward_entropy": 0.0633998087474278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.99454498291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03472662344574928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10982412099838257,
      "backward_entropy": 0.052523480994360786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.70571899414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03481977805495262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10965562611818314,
      "backward_entropy": 0.06254517180579049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.47628021240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03490738198161125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10949381440877914,
      "backward_entropy": 0.06210397822516305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.89160919189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03499501943588257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10933289676904678,
      "backward_entropy": 0.05112217579569135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.70298767089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035081278532743454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10917437076568604,
      "backward_entropy": 0.05065473062651498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.80523681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035167939960956573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10901584476232529,
      "backward_entropy": 0.050190742526735575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.14653015136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03525799512863159,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10885380208492279,
      "backward_entropy": 0.06032534156526838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.10618591308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03534279018640518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10869733989238739,
      "backward_entropy": 0.04925655892917088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.67449188232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035424407571554184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10854392498731613,
      "backward_entropy": 0.048775170530591695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.76121520996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03549854829907417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10840042680501938,
      "backward_entropy": 0.048292151519230435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.66844177246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035575903952121735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10825300216674805,
      "backward_entropy": 0.04781578694071088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.73846435546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035654544830322266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1081053614616394,
      "backward_entropy": 0.04734058891023908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.75312042236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03574026748538017,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10794956982135773,
      "backward_entropy": 0.05755195873124259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.39656829833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035828255116939545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10779330134391785,
      "backward_entropy": 0.04639207465308053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.86492919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03591477498412132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10763950645923615,
      "backward_entropy": 0.04592039329665048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.17388916015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035999588668346405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10748695582151413,
      "backward_entropy": 0.045440690858023505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.40524291992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03608319163322449,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10733579099178314,
      "backward_entropy": 0.05572513171604702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.78436279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03616752848029137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10718540102243423,
      "backward_entropy": 0.04448971578053066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.68765258789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03625073656439781,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10703688114881516,
      "backward_entropy": 0.054807109492165704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.82296752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03633635491132736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10688664764165878,
      "backward_entropy": 0.04354700020381382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.35982513427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03642731532454491,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10673204064369202,
      "backward_entropy": 0.05390284742627825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.62245178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036519818007946014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10657677054405212,
      "backward_entropy": 0.04262476308005197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.46379089355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03660661727190018,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10642638802528381,
      "backward_entropy": 0.05300294501440866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.17057037353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03669031709432602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10627904534339905,
      "backward_entropy": 0.04167698962347848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.77780151367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03677662834525108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10613090544939041,
      "backward_entropy": 0.04121237141745431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.99326705932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036858804523944855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.105989009141922,
      "backward_entropy": 0.04075208732060024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.30767059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0369330532848835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1058541089296341,
      "backward_entropy": 0.04028099349566868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.7163314819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03700583055615425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1057213693857193,
      "backward_entropy": 0.03981576221329825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.81826782226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0370769202709198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1055895984172821,
      "backward_entropy": 0.050234479563576837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.22380828857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03715020418167114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1054573804140091,
      "backward_entropy": 0.04977332694189889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.45841217041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037226978689432144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10532280802726746,
      "backward_entropy": 0.04932214106832232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.13029479980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037300318479537964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1051923856139183,
      "backward_entropy": 0.03798208066395351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.29414367675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037366870790719986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10506780445575714,
      "backward_entropy": 0.03752033199582781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.529541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037430960685014725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10494597256183624,
      "backward_entropy": 0.03705909848213196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.02125549316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03749636560678482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10482387244701385,
      "backward_entropy": 0.036604689700262885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.6834716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03755757585167885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10470521450042725,
      "backward_entropy": 0.03614558918135507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.11834716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03761892765760422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1045883297920227,
      "backward_entropy": 0.03569545490401132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.93177795410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03768184781074524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1044706255197525,
      "backward_entropy": 0.046108250107084005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.23869323730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03774986043572426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10434950888156891,
      "backward_entropy": 0.04566723108291626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.28936767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03781372308731079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10423268377780914,
      "backward_entropy": 0.034398019313812256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.50460052490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03787737339735031,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10411709547042847,
      "backward_entropy": 0.04477380854742868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.0714340209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037942368537187576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10400030016899109,
      "backward_entropy": 0.03355090532984052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.2242431640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03801055625081062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10388217866420746,
      "backward_entropy": 0.03313917560236795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.19259643554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03808136284351349,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1037629097700119,
      "backward_entropy": 0.09879859004701887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.85955047607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03814994916319847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10364672541618347,
      "backward_entropy": 0.04305138758250645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.32626342773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03821592032909393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10353169590234756,
      "backward_entropy": 0.031918121235711236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.2122573852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03828330710530281,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10341665148735046,
      "backward_entropy": 0.042199896914618354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.62245178222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03834852948784828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1033046767115593,
      "backward_entropy": 0.04177574174744742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.85753631591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03841642662882805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10318924486637115,
      "backward_entropy": 0.041363030672073364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.33344268798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03847716376185417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10308106243610382,
      "backward_entropy": 0.030313747269766673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.44761657714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03854179382324219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10297086834907532,
      "backward_entropy": 0.029925146273204258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.663087844848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03861290588974953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10285570472478867,
      "backward_entropy": 0.02954653118337904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.14894104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038674939423799515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10274945199489594,
      "backward_entropy": 0.029161568198885237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.15753936767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038742005825042725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10263954848051071,
      "backward_entropy": 0.028786469783101763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.91986846923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038808710873126984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10253044962882996,
      "backward_entropy": 0.028412386775016785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.78104019165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03887827321887016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1024186760187149,
      "backward_entropy": 0.038545416934149604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.93211364746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038942690938711166,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10231287777423859,
      "backward_entropy": 0.09880522319248744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.51071166992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03901224210858345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10220441222190857,
      "backward_entropy": 0.027320384979248047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.10652160644531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03908659145236015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209384560585022,
      "backward_entropy": 0.026979203735079085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.11813354492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039160147309303284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10198470950126648,
      "backward_entropy": 0.026640581233160838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.787763595581055,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03923284262418747,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10187645256519318,
      "backward_entropy": 0.09882304498127528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.32046508789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03929828852415085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10177502036094666,
      "backward_entropy": 0.025957727006503513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.1020278930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03936556354165077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10167349874973297,
      "backward_entropy": 0.025620094367436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.30963897705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03943589702248573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10156835615634918,
      "backward_entropy": 0.03555223984377725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.90060424804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03951089084148407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10146093368530273,
      "backward_entropy": 0.024963142616408213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.54470443725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03959153592586517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10135075449943542,
      "backward_entropy": 0.034855780856949944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.90785217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03966771066188812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10124487429857254,
      "backward_entropy": 0.034509816340037754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.12428283691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03973937779664993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10114171355962753,
      "backward_entropy": 0.02401080940450941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.57728576660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03980892151594162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10104193538427353,
      "backward_entropy": 0.033809887511389594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.90353393554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03987700119614601,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10094401240348816,
      "backward_entropy": 0.02338097776685442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.75520324707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03994328901171684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10084696114063263,
      "backward_entropy": 0.023071105991091048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.43207550048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04000799357891083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10075148195028305,
      "backward_entropy": 0.022762281554085866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.09876251220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04006816819310188,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10066022723913193,
      "backward_entropy": 0.022455019610268728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.6572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040127839893102646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10056998580694199,
      "backward_entropy": 0.022154916610036577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.90195846557617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040188487619161606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10047949850559235,
      "backward_entropy": 0.021858340927532742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.34323120117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0402485616505146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10039044171571732,
      "backward_entropy": 0.031433939933776855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.18575286865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04030962660908699,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10030119121074677,
      "backward_entropy": 0.021282308867999485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.29945373535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0403716079890728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10021241009235382,
      "backward_entropy": 0.021000728011131287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.87238311767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04043108969926834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10012529790401459,
      "backward_entropy": 0.030477566378457204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.22900390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040491703897714615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1000375747680664,
      "backward_entropy": 0.020443435226167952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.30248260498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040551893413066864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09995181858539581,
      "backward_entropy": 0.029854559472629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.29510498046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04061637446284294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09986262023448944,
      "backward_entropy": 0.029552336250032698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.398284912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04068649560213089,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09977059066295624,
      "backward_entropy": 0.01965509993689401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.30302810668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04075384512543678,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09968245029449463,
      "backward_entropy": 0.028967146362577165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.03042602539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04081670567393303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09959761798381805,
      "backward_entropy": 0.01915407819407327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.40840148925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040880363434553146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0995124876499176,
      "backward_entropy": 0.028385907411575317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.06004333496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0409434475004673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0994284451007843,
      "backward_entropy": 0.018660634756088257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.0325698852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041004423052072525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09934639930725098,
      "backward_entropy": 0.01842032160077776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.712982177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04107144474983215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0992593988776207,
      "backward_entropy": 0.018187748534338816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.18426513671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041134316474199295,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09917588531970978,
      "backward_entropy": 0.09884501355034965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.2923355102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04119819030165672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09909267723560333,
      "backward_entropy": 0.027007283908980235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.30825805664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041266199201345444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09900706261396408,
      "backward_entropy": 0.01750168949365616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.63480377197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04134112223982811,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09891742467880249,
      "backward_entropy": 0.0264934173652104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.83868408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041417721658945084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09882733225822449,
      "backward_entropy": 0.02624754181929997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.19762420654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041501931846141815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09873258322477341,
      "backward_entropy": 0.016868329473904202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.14224624633789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04158531874418259,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09863947331905365,
      "backward_entropy": 0.02577096862452371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.82080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0416661761701107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09854890406131744,
      "backward_entropy": 0.01645960339478084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.53736114501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0417497456073761,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09845682978630066,
      "backward_entropy": 0.025304455842290605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.42838287353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041832827031612396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.098366878926754,
      "backward_entropy": 0.02508107466357095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.69685363769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041916850954294205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09827682375907898,
      "backward_entropy": 0.015889614820480347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.73953247070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04199663922190666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09818945825099945,
      "backward_entropy": 0.0246414201600211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.5650405883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04208368435502052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09809805452823639,
      "backward_entropy": 0.024427399039268494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.46792984008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04217307269573212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09800681471824646,
      "backward_entropy": 0.024219429918697903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.83143615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04225617274641991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09791946411132812,
      "backward_entropy": 0.015162732984338487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.24999237060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042337071150541306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09783416986465454,
      "backward_entropy": 0.014984396951539176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.6348991394043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04241914302110672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09774866700172424,
      "backward_entropy": 0.02359064987727574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.52202606201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04249786213040352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09766671806573868,
      "backward_entropy": 0.014640175870486669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.76107025146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04257969185709953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09758302569389343,
      "backward_entropy": 0.014476844242640905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.98948669433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042662445455789566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09749892354011536,
      "backward_entropy": 0.014313082609857832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.5335922241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04274899885058403,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09741221368312836,
      "backward_entropy": 0.022797954933983938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.35665893554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0428348071873188,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09732688218355179,
      "backward_entropy": 0.01398910688502448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.7542724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04291996359825134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0972428023815155,
      "backward_entropy": 0.013832399887698037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.85244750976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043006155639886856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09715885668992996,
      "backward_entropy": 0.013680280319281988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.44506072998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04309602826833725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09707285463809967,
      "backward_entropy": 0.022053484405790056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.10575485229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04318295046687126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0969889685511589,
      "backward_entropy": 0.013378582894802094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.99898529052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04326445981860161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09690887480974197,
      "backward_entropy": 0.013228942240987505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.26553344726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04334728792309761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09682817757129669,
      "backward_entropy": 0.013083829411438532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.12411499023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043435752391815186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0967445969581604,
      "backward_entropy": 0.012942288603101457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.11862182617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0435233898460865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09666265547275543,
      "backward_entropy": 0.012804229344640459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.28455352783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0436098612844944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09658020734786987,
      "backward_entropy": 0.012665561267307826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.8709602355957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043694451451301575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0965004712343216,
      "backward_entropy": 0.012533048433916909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.79986572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04377558454871178,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0964234322309494,
      "backward_entropy": 0.020706421562603543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.2886734008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043853502720594406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09634897112846375,
      "backward_entropy": 0.02055033189909799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.79618835449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043931666761636734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09627480804920197,
      "backward_entropy": 0.01214843669107982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.63311004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044008661061525345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09620146453380585,
      "backward_entropy": 0.012025874640260423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.324180603027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044088635593652725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0961257666349411,
      "backward_entropy": 0.011902110917227609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.69425201416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04416564479470253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09605226665735245,
      "backward_entropy": 0.011780292860099248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.912784576416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044242870062589645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09597870707511902,
      "backward_entropy": 0.011659234762191772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.68289184570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044315919280052185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09590768814086914,
      "backward_entropy": 0.011540489537375314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.05458450317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04439269006252289,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0958346426486969,
      "backward_entropy": 0.011424992765699114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.19673919677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04446829482913017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0957629531621933,
      "backward_entropy": 0.011311128735542297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.78017807006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04454571008682251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09568943083286285,
      "backward_entropy": 0.01119803637266159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.92928314208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04462192580103874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09561646729707718,
      "backward_entropy": 0.01108715044600623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.52301025390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044702962040901184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09554070234298706,
      "backward_entropy": 0.010977881295340402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.32794952392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04478728398680687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09546329081058502,
      "backward_entropy": 0.01087482167141778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.2026138305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04486830532550812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09538841247558594,
      "backward_entropy": 0.010772212275436946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.12346649169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04495213180780411,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0953119620680809,
      "backward_entropy": 0.01866858346121652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.85403442382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045031290501356125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09523829072713852,
      "backward_entropy": 0.010569767228194646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.069156646728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04511064663529396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0951647013425827,
      "backward_entropy": 0.010471169437680925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.73615646362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04518419876694679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.095095194876194,
      "backward_entropy": 0.01834183931350708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.677833557128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04525570943951607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09502732753753662,
      "backward_entropy": 0.010278503809656416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.408233642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04532518610358238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09496018290519714,
      "backward_entropy": 0.010184319955962045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.57012939453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04539434611797333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09489348530769348,
      "backward_entropy": 0.01009148359298706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.94937896728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04546071216464043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09482947736978531,
      "backward_entropy": 0.010003878601959773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.27416229248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0455285906791687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09476448595523834,
      "backward_entropy": 0.009917594492435455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.40666198730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04559486731886864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09470008313655853,
      "backward_entropy": 0.009832056505339486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.81010437011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045658376067876816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0946374386548996,
      "backward_entropy": 0.009748355618544988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.77191925048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04572219029068947,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09457448124885559,
      "backward_entropy": 0.01762008454118456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.20945358276367,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04579083248972893,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09450849145650864,
      "backward_entropy": 0.09897322314126152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.73101043701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04585637152194977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09444433450698853,
      "backward_entropy": 0.009502328932285309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.56757354736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04592515528202057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09437809884548187,
      "backward_entropy": 0.00942346453666687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.78550720214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04599681496620178,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09430995583534241,
      "backward_entropy": 0.09897616931370326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.48294448852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04606959596276283,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09424106776714325,
      "backward_entropy": 0.017261185816356113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.47349166870117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04614035785198212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09417349100112915,
      "backward_entropy": 0.01719512790441513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.8577880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04621239751577377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0941050723195076,
      "backward_entropy": 0.009120701679161616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.19152069091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046287015080451965,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09403524547815323,
      "backward_entropy": 0.09898247037615095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.49826049804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046365320682525635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09396214783191681,
      "backward_entropy": 0.008978783019951411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.83943557739258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04644544795155525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09388850629329681,
      "backward_entropy": 0.008908838033676147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.23102569580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04652584716677666,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09381459653377533,
      "backward_entropy": 0.09898848193032402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.7193603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04660516604781151,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0937415063381195,
      "backward_entropy": 0.008772585008825575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.71261596679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04668181389570236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09367014467716217,
      "backward_entropy": 0.008705455277647291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.47230911254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04676055163145065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09359736740589142,
      "backward_entropy": 0.016728833317756653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.3671760559082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04683694243431091,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09352633357048035,
      "backward_entropy": 0.016675845852919986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.9608154296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04691119119524956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09345685690641403,
      "backward_entropy": 0.00851539894938469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.16557312011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046982139348983765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09338971972465515,
      "backward_entropy": 0.016578653029033115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.062564849853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047051429748535156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09332350641489029,
      "backward_entropy": 0.016533508896827698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.41048049926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047119274735450745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09325841069221497,
      "backward_entropy": 0.008340601410184587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.46188354492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047188691794872284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0931921899318695,
      "backward_entropy": 0.016447454690933228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.26848602294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04726093262434006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09312407672405243,
      "backward_entropy": 0.008229381803955351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.802181243896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04733593389391899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09305383265018463,
      "backward_entropy": 0.008176497050694056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.3037052154541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04741036146879196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09298394620418549,
      "backward_entropy": 0.008124299347400665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.7401123046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047480013221502304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0929175466299057,
      "backward_entropy": 0.008073921714510237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.34481430053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047552477568387985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.092849001288414,
      "backward_entropy": 0.008023658501250404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.33917999267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047623202204704285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0927816703915596,
      "backward_entropy": 0.016232294695717946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.09513282775879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04769517481327057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09271331131458282,
      "backward_entropy": 0.01620004858289446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.03353118896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04776262119412422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09264827519655228,
      "backward_entropy": 0.007877882037843977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.8012924194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04783318191766739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0925808697938919,
      "backward_entropy": 0.00783085503748485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.772132873535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0479094423353672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09250914305448532,
      "backward_entropy": 0.007784952010427203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.48160552978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047985196113586426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09243777394294739,
      "backward_entropy": 0.007741169205733708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.715579986572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04806322231888771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0923650711774826,
      "backward_entropy": 0.007698199578693935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.37056350708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04813768342137337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09229475259780884,
      "backward_entropy": 0.0076576221202101025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.24161148071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04821173474192619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09222468733787537,
      "backward_entropy": 0.007617877530200141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.55624389648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04828530550003052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09215467423200607,
      "backward_entropy": 0.01601197783436094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.3337631225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04836263507604599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09208187460899353,
      "backward_entropy": 0.015988132783344815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.86754608154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048443496227264404,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09200632572174072,
      "backward_entropy": 0.0990099481173924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.94647979736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04852873831987381,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0919274091720581,
      "backward_entropy": 0.007455914680446897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.52982711791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048611052334308624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09185069054365158,
      "backward_entropy": 0.007416196167469025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.38520812988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04869214445352554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09177489578723907,
      "backward_entropy": 0.007377477096659797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.88679885864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048772186040878296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09169977903366089,
      "backward_entropy": 0.007340373205287116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.3309326171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04885268583893776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09162415564060211,
      "backward_entropy": 0.007304490676948002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.2998046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0489349402487278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09154702723026276,
      "backward_entropy": 0.015829894159521376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.68735694885254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04902142286300659,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09146653115749359,
      "backward_entropy": 0.007233399897813797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.59916114807129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04910349100828171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09138938784599304,
      "backward_entropy": 0.007199285817997796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.5126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049181584268808365,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09131529927253723,
      "backward_entropy": 0.015773590121950423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.89918518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04926165193319321,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09123970568180084,
      "backward_entropy": 0.0157576927116939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.90171241760254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04933926463127136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09116582572460175,
      "backward_entropy": 0.007103917854172843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.684059143066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04941197484731674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09109587222337723,
      "backward_entropy": 0.015729208077703203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.973812103271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04948306828737259,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09102702140808105,
      "backward_entropy": 0.01571932222161974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.84518814086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04955409839749336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09095796942710876,
      "backward_entropy": 0.007020062633923122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.39932250976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04962501302361488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09088878333568573,
      "backward_entropy": 0.006993575819901058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.2690544128418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04969855770468712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0908171534538269,
      "backward_entropy": 0.006966570126158851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.163185119628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049770332872867584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09074681252241135,
      "backward_entropy": 0.00694018229842186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.06245040893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04984045401215553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09067773073911667,
      "backward_entropy": 0.006913940821375165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.67586517333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049909185618162155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09060943126678467,
      "backward_entropy": 0.00688885897397995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.49217224121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0499807745218277,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0905386358499527,
      "backward_entropy": 0.0068636078919683185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.56121063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05005492642521858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09046553820371628,
      "backward_entropy": 0.006838206733976092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.80021667480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050125863403081894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09039495885372162,
      "backward_entropy": 0.0068140583378928045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.67293167114258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050196655094623566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09032455086708069,
      "backward_entropy": 0.006790569850376674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.86007690429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05026743561029434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.090253084897995,
      "backward_entropy": 0.0067687561469418666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.4031982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05034220591187477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0901784747838974,
      "backward_entropy": 0.006746579493795123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.263877868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050416529178619385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09010379761457443,
      "backward_entropy": 0.006725485835756574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.17621612548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05049039050936699,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09002937376499176,
      "backward_entropy": 0.006704857306821006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.97787857055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050566550344228745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08995260298252106,
      "backward_entropy": 0.006684090409960065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.840641021728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05064475163817406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08987380564212799,
      "backward_entropy": 0.0066631947244916645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.6986198425293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050722092390060425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08979560434818268,
      "backward_entropy": 0.006642848785434451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.644439697265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050798702985048294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08971773087978363,
      "backward_entropy": 0.015524979148592268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.415069580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05087326094508171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08964139223098755,
      "backward_entropy": 0.006605180246489388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.422325134277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05094730481505394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0895654559135437,
      "backward_entropy": 0.006587448929037366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.79757308959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051019538193941116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08949128538370132,
      "backward_entropy": 0.015503368207386561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.80287170410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051094185560941696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08941441774368286,
      "backward_entropy": 0.006553633404629571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.318662643432617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05116967484354973,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0893363431096077,
      "backward_entropy": 0.015485615602561406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.237285614013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05124187842011452,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08926123380661011,
      "backward_entropy": 0.015480252248900277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.158174514770508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05131112411618233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08918868005275726,
      "backward_entropy": 0.015478025589670454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.47010803222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051377683877944946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08911861479282379,
      "backward_entropy": 0.015477008053234645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.34389877319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05144451931118965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08904802054166794,
      "backward_entropy": 0.015475722295897347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.931617736816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05151159316301346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08897697925567627,
      "backward_entropy": 0.006472286369119372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.09503173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05157620087265968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08890808373689651,
      "backward_entropy": 0.006461665566478457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.37815856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05164126679301262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08883846551179886,
      "backward_entropy": 0.015472122601100377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.85009002685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051705408841371536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08876955509185791,
      "backward_entropy": 0.006441883742809296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.72722625732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051770053803920746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08869978785514832,
      "backward_entropy": 0.0064329249518258235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.56290626525879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05183514952659607,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08862926065921783,
      "backward_entropy": 0.015469038060733251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.47542190551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05189796909689903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08856090158224106,
      "backward_entropy": 0.006417023816279003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.29828643798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051964081823825836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08848869800567627,
      "backward_entropy": 0.0064093247056007385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.22455596923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05203314498066902,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0884130448102951,
      "backward_entropy": 0.01546365235533033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.09157180786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05210220441222191,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08833691477775574,
      "backward_entropy": 0.006393452308007649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.95887756347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0521712452173233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08826057612895966,
      "backward_entropy": 0.006386225244828633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.732099533081055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05224026367068291,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08818410336971283,
      "backward_entropy": 0.015452751091548375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.36116027832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05230526626110077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08811172842979431,
      "backward_entropy": 0.01545108003275735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.89189529418945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052369315177202225,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08803997933864594,
      "backward_entropy": 0.09901794365474156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.6070327758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052435148507356644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08796577900648117,
      "backward_entropy": 0.006364890507289341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.31135940551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05250652879476547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08788512647151947,
      "backward_entropy": 0.0063586921564170295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.64133071899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05257762223482132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08780454844236374,
      "backward_entropy": 0.01543824268238885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.44150161743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05265108123421669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08772093057632446,
      "backward_entropy": 0.006346752601010459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.88347625732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05272665619850159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08763465285301208,
      "backward_entropy": 0.006340715501989637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.737491607666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052801501005887985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08754885941743851,
      "backward_entropy": 0.015412627586296626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.946044921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287567898631096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08746352791786194,
      "backward_entropy": 0.006331115961074829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.44053268432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05295316129922867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08737405389547348,
      "backward_entropy": 0.006325738770621163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.29177474975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053029678761959076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.087285116314888,
      "backward_entropy": 0.015381510768617903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.17073440551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053105346858501434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08719691634178162,
      "backward_entropy": 0.006316778383084706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.98921203613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05318152904510498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0871075764298439,
      "backward_entropy": 0.0063127683741705755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.87302589416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053259462118148804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0870160162448883,
      "backward_entropy": 0.015347162527697427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.81602668762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05333506688475609,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08692672103643417,
      "backward_entropy": 0.015335899378572191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.7315673828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053407251834869385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08684112131595612,
      "backward_entropy": 0.006304606795310974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.29496765136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053476378321647644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08675892651081085,
      "backward_entropy": 0.015320097761494773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.71205997467041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053546641021966934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0866749957203865,
      "backward_entropy": 0.006305469466107232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.62670135498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053612709045410156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08659587800502777,
      "backward_entropy": 0.006307614701134818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.00476837158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05368276685476303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08651137351989746,
      "backward_entropy": 0.006308466728244509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.18269348144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05375254154205322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08642678707838058,
      "backward_entropy": 0.015291956918580192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.46341323852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053825899958610535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08633728325366974,
      "backward_entropy": 0.006310175039938518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.571983337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053899914026260376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0862465649843216,
      "backward_entropy": 0.006310563534498215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.056800842285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05397320166230202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08615626394748688,
      "backward_entropy": 0.006311119667121342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.62898063659668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0540432408452034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08606965839862823,
      "backward_entropy": 0.006312540067093713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.26071834564209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05411163344979286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08598466217517853,
      "backward_entropy": 0.0063142600868429455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.21053409576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054175928235054016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08590435981750488,
      "backward_entropy": 0.015228754707745143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.74028778076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05423657223582268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08582857251167297,
      "backward_entropy": 0.006320166268518993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.670724868774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05429520085453987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08575518429279327,
      "backward_entropy": 0.006324317838464465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.26292037963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0543520487844944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0856836587190628,
      "backward_entropy": 0.01520989409514836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.55642318725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05441366881132126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08560523390769958,
      "backward_entropy": 0.006332993507385254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.8926887512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054478295147418976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0855223685503006,
      "backward_entropy": 0.0063354335725307465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.82209587097168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054544366896152496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08543707430362701,
      "backward_entropy": 0.006337825208902359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.288829803466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05460914224386215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08535309135913849,
      "backward_entropy": 0.0063404882592814306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.420249938964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05467147380113602,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08527205884456635,
      "backward_entropy": 0.015150693910462516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.26396179199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05473539978265762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08518829941749573,
      "backward_entropy": 0.006346300776515689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.75356674194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05480076000094414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08510208129882812,
      "backward_entropy": 0.006347927664007459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.266536712646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05486612394452095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08501536399126053,
      "backward_entropy": 0.006349228322505951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.89078140258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0549340546131134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08492454886436462,
      "backward_entropy": 0.015080800013882774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.8829345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0549992136657238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08483728021383286,
      "backward_entropy": 0.00635192117520741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.727401733398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05506689473986626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08474594354629517,
      "backward_entropy": 0.006352544895240239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.07386779785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05513184145092964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0846581682562828,
      "backward_entropy": 0.006354961012090955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.566123962402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055196817964315414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08456987142562866,
      "backward_entropy": 0.015005387365818024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.648855209350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05525928735733032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0844847708940506,
      "backward_entropy": 0.006360609616552081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.819278717041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05532070994377136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08440066128969193,
      "backward_entropy": 0.006363571754523686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.443931579589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05538374185562134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08431366086006165,
      "backward_entropy": 0.0063659995794296265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.42502212524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05544571951031685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08422787487506866,
      "backward_entropy": 0.006369217698063169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.41050338745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05550801753997803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08414101600646973,
      "backward_entropy": 0.006372896156140736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.34331512451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05557306110858917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08404961973428726,
      "backward_entropy": 0.006375537919146674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.007537841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05564551800489426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08394689112901688,
      "backward_entropy": 0.006375727908951896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.867713928222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05571345239877701,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08385063707828522,
      "backward_entropy": 0.006377902946301869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.72512435913086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05578107759356499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08375437557697296,
      "backward_entropy": 0.014828803283827645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.753437042236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05584832280874252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08365802466869354,
      "backward_entropy": 0.0063830289457525525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.22783279418945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05591275170445442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08356570452451706,
      "backward_entropy": 0.014785179070064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.03221893310547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055979590862989426,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08346906304359436,
      "backward_entropy": 0.09901653017316546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.333621978759766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056048620492219925,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08336849510669708,
      "backward_entropy": 0.0990163939339774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.024742126464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056115880608558655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08327015489339828,
      "backward_entropy": 0.014706703169005257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.3335018157959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05618282034993172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0831717997789383,
      "backward_entropy": 0.006390790854181562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.50374698638916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05624700337648392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08307737112045288,
      "backward_entropy": 0.006394090929201671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.17605972290039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05630742758512497,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08298857510089874,
      "backward_entropy": 0.006398725190332958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.10226058959961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0563657209277153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08290274441242218,
      "backward_entropy": 0.006404380713190351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.030357360839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056422073394060135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08281955122947693,
      "backward_entropy": 0.014602123626640864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.613380432128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05647662281990051,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08273887634277344,
      "backward_entropy": 0.014583817550114222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.520328521728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056530822068452835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08265821635723114,
      "backward_entropy": 0.006423477615628924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.03577423095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05658457800745964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08257777988910675,
      "backward_entropy": 0.006428106554916927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.084476470947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05663924291729927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08249522745609283,
      "backward_entropy": 0.006432109645434788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.680870056152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05669718235731125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08240664750337601,
      "backward_entropy": 0.006434807819979531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.608694076538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056753214448690414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08232084661722183,
      "backward_entropy": 0.006438856678349631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.560306549072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05680748075246811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08223757147789001,
      "backward_entropy": 0.006443503711904798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.467809677124023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05686260387301445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08215231448411942,
      "backward_entropy": 0.006447821855545044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.86336326599121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05691598728299141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08206960558891296,
      "backward_entropy": 0.006451694028718131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.213279724121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056969042867422104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08198694884777069,
      "backward_entropy": 0.006455337362630027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.425788879394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05702301114797592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08190219849348068,
      "backward_entropy": 0.006458260118961334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.800090789794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057072993367910385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0818241760134697,
      "backward_entropy": 0.006463179630892617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.135257720947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05712052807211876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08175012469291687,
      "backward_entropy": 0.006468448255743299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.78650665283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05716709792613983,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08167736232280731,
      "backward_entropy": 0.006473894097975322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.346878051757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05721519887447357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08160130679607391,
      "backward_entropy": 0.014242797025612422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.263769149780273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05726339668035507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08152465522289276,
      "backward_entropy": 0.006481037608214787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.7653694152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0573117733001709,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08144724369049072,
      "backward_entropy": 0.006483936416251319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.820066452026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05736270546913147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08136464655399323,
      "backward_entropy": 0.006485721894672939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.00403594970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05741235986351967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08128394186496735,
      "backward_entropy": 0.006488701062543052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.59914779663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057462047785520554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08120278269052505,
      "backward_entropy": 0.00649189150759152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.43547821044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05751534923911095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08111442625522614,
      "backward_entropy": 0.014061440314565386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.26216506958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05757184699177742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08101984113454819,
      "backward_entropy": 0.014024668506213598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.313765525817871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057631250470876694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08091947436332703,
      "backward_entropy": 0.006490838314805712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.52227020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768722668290138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08082514256238937,
      "backward_entropy": 0.006489978837115424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.73688888549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057742610573768616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08073138445615768,
      "backward_entropy": 0.006490660565240043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.557220458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05780097842216492,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08063164353370667,
      "backward_entropy": 0.006490313581057957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.16305923461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05786203593015671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08052636682987213,
      "backward_entropy": 0.00648933755499976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.188385009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05792073905467987,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08042518049478531,
      "backward_entropy": 0.013810397258826665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.001365661621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05798208713531494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08031845092773438,
      "backward_entropy": 0.006489387048142297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.895145416259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05804334953427315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08021141588687897,
      "backward_entropy": 0.013739697635173798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.954250335693359,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05810339003801346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08010633289813995,
      "backward_entropy": 0.006488169942583356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.69191551208496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058158792555332184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08000990003347397,
      "backward_entropy": 0.006490146475178855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.491628646850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058213576674461365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0799141526222229,
      "backward_entropy": 0.006492912769317627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.625783920288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058268941938877106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07981675863265991,
      "backward_entropy": 0.006495279925210136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.706390380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058322515338659286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07972250133752823,
      "backward_entropy": 0.006499258535248893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.96586227416992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05837327986955643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07963338494300842,
      "backward_entropy": 0.006504981645515987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.220630645751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05842621996998787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07953938841819763,
      "backward_entropy": 0.006510230047362191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.127403259277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05847881734371185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0794454962015152,
      "backward_entropy": 0.0065168605319091254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.522294998168945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058531031012535095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07935194671154022,
      "backward_entropy": 0.006523662379809788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.1513557434082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058580536395311356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07926350831985474,
      "backward_entropy": 0.01346915534564427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.565128326416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058633431792259216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07916761934757233,
      "backward_entropy": 0.0065376923552581245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.758909225463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05868703871965408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07906980812549591,
      "backward_entropy": 0.006542975349085671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.3199348449707,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05874011293053627,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07897259294986725,
      "backward_entropy": 0.09901553392410278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.286299705505371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058797385543584824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07886624336242676,
      "backward_entropy": 0.006552654717649732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.466886520385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0588514544069767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07876615226268768,
      "backward_entropy": 0.006558949393885476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.96221351623535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058904968202114105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07866667211055756,
      "backward_entropy": 0.006565801267113004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.84190559387207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05895894393324852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07856591045856476,
      "backward_entropy": 0.006569802228893552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.093939781188965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05901339277625084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07846368104219437,
      "backward_entropy": 0.006572267306702477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.086103439331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059064831584692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07836749404668808,
      "backward_entropy": 0.006575496069022587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.49088478088379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05911596491932869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07827140390872955,
      "backward_entropy": 0.006579950451850891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.901714324951172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.059167880564928055,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07817313075065613,
      "backward_entropy": 0.09901588303702218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.25924301147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05921931192278862,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07807546108961105,
      "backward_entropy": 0.013122569237436568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.142053604125977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05927151441574097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07797559350728989,
      "backward_entropy": 0.006589102957929883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.21792221069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05932435020804405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07787390053272247,
      "backward_entropy": 0.006591148674488068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.287723541259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05937551334500313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07777540385723114,
      "backward_entropy": 0.013018870992319924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.077247619628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05942856892943382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07767220586538315,
      "backward_entropy": 0.012983655290944236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.340505599975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05947991833090782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.077572301030159,
      "backward_entropy": 0.006599958453859601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.86787986755371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05953081324696541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0774729773402214,
      "backward_entropy": 0.006602832249232701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.724857330322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05958358198404312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07736903429031372,
      "backward_entropy": 0.006604610809258052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.09930419921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059638042002916336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07726078480482101,
      "backward_entropy": 0.0066056980618408746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.714838981628418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0596962533891201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07714370638132095,
      "backward_entropy": 0.0066048987209796906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.1046142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05975212901830673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07703164219856262,
      "backward_entropy": 0.012758113443851471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.373798370361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05981387197971344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07690606266260147,
      "backward_entropy": 0.0066012729491506305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.63178062438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05987180396914482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07678878307342529,
      "backward_entropy": 0.006599493324756622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.658489227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0599285326898098,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07667383551597595,
      "backward_entropy": 0.0065976205681051526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.218844413757324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059985388070344925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07655802369117737,
      "backward_entropy": 0.0065968041973454615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.88508987426758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06003902480006218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07644925266504288,
      "backward_entropy": 0.006598892488649913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.219533920288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06009979173541069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0763237476348877,
      "backward_entropy": 0.006599404449973788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.112504959106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0601591132581234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07620113343000412,
      "backward_entropy": 0.006600480526685715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.008919715881348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06021708622574806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0760812759399414,
      "backward_entropy": 0.006601243146828243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.88126564025879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06027274951338768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07596628367900848,
      "backward_entropy": 0.012399254100663322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.75532341003418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06032855808734894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0758504867553711,
      "backward_entropy": 0.012362997446741377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.55234146118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06038452312350273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07573375105857849,
      "backward_entropy": 0.006607881081955773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.499927520751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06044173985719681,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07561343908309937,
      "backward_entropy": 0.006611202444349017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.75589656829834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060498952865600586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07549254596233368,
      "backward_entropy": 0.006615360932690757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.944210052490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06055285409092903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07537920773029327,
      "backward_entropy": 0.012234243963445936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.300504684448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06060928478837013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07525917887687683,
      "backward_entropy": 0.006627791162048068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.403828620910645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06066463887691498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07514125108718872,
      "backward_entropy": 0.006634369492530823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.785915851593018,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060717903077602386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07502797245979309,
      "backward_entropy": 0.006641557706253869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.514915466308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06076706573367119,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07492448389530182,
      "backward_entropy": 0.006650143436023167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.20275592803955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06081358343362808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.074827179312706,
      "backward_entropy": 0.006658682865755898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.431581497192383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06085886433720589,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0747324675321579,
      "backward_entropy": 0.006667400045054299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.08298110961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06090199947357178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07464258372783661,
      "backward_entropy": 0.006677830325705665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.697988510131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06094428151845932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07455432415008545,
      "backward_entropy": 0.006689231842756271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.92477798461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06098676845431328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0744650810956955,
      "backward_entropy": 0.006699215088571821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.803009033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06103171780705452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07436893880367279,
      "backward_entropy": 0.006708792809929166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.89654541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06107887253165245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07426661252975464,
      "backward_entropy": 0.011956094631126948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.948408126831055,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06113012880086899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07415343821048737,
      "backward_entropy": 0.0990168707711356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.267566680908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06118185818195343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07403848320245743,
      "backward_entropy": 0.0067325516470841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.176166534423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061232905834913254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07392475008964539,
      "backward_entropy": 0.006740432764802661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.602249145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06128324568271637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07381231337785721,
      "backward_entropy": 0.006747181394270488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.487245559692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061334073543548584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07369858026504517,
      "backward_entropy": 0.0067531125886099675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.78651428222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06138530373573303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07358315587043762,
      "backward_entropy": 0.011786151145185744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.353473663330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061440058052539825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07345837354660034,
      "backward_entropy": 0.011750240411077226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.282090187072754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06149262934923172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07333892583847046,
      "backward_entropy": 0.006763464638165065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.612262725830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06154320761561394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07322447001934052,
      "backward_entropy": 0.011675271604742323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.1445894241333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06159308925271034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07311135530471802,
      "backward_entropy": 0.006767210683652333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.78777313232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061641257256269455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07300247997045517,
      "backward_entropy": 0.006769004144838878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.67610168457031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0616900734603405,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07289129495620728,
      "backward_entropy": 0.09901544877461024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.17521858215332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06174255162477493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07277005910873413,
      "backward_entropy": 0.011517752494130815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.866293907165527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06179727986454964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0726424902677536,
      "backward_entropy": 0.006769924823726926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.792915344238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061849720776081085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07252088189125061,
      "backward_entropy": 0.006768294743129185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.43393898010254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06190020963549614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07240407168865204,
      "backward_entropy": 0.006767905184200832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.292129516601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06195208430290222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07228301465511322,
      "backward_entropy": 0.006767643349511283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.957557678222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0620051734149456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07215827703475952,
      "backward_entropy": 0.006766974393810544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.67119789123535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06205832585692406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0720328763127327,
      "backward_entropy": 0.006766972265073231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.437116622924805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062110535800457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07190939784049988,
      "backward_entropy": 0.011222895767007555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.48557472229004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06216071546077728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07179126143455505,
      "backward_entropy": 0.006770730018615723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.109479904174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062210164964199066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07167474925518036,
      "backward_entropy": 0.011146701872348785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.610877990722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062255848199129105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0715683102607727,
      "backward_entropy": 0.00677761435508728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.275747299194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06230533868074417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07145087420940399,
      "backward_entropy": 0.006780398211308888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.132081985473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06235507130622864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07133260369300842,
      "backward_entropy": 0.00678170844912529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.050724029541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06240405887365341,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07121607661247253,
      "backward_entropy": 0.0067834194217409405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983813762664795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062453318387269974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0710984617471695,
      "backward_entropy": 0.006783790354217801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.867372512817383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062499821186065674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07098830491304398,
      "backward_entropy": 0.006785719522408077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.900655269622803,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06254592537879944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07087872177362442,
      "backward_entropy": 0.006788897195032665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.473209381103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06258948147296906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07077626883983612,
      "backward_entropy": 0.006791463920048305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.3238525390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06263579428195953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07066580653190613,
      "backward_entropy": 0.006790727376937866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.288576126098633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06268464028835297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07054781913757324,
      "backward_entropy": 0.0067884038601602826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.583585739135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06273472309112549,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0704260841012001,
      "backward_entropy": 0.006784742431981223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.18238067626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06278286129236221,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07030963897705078,
      "backward_entropy": 0.010644727519580297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.261025428771973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06283146888017654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07019130885601044,
      "backward_entropy": 0.010599964431353978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.383750915527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06287937611341476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07007446885108948,
      "backward_entropy": 0.00677977768438203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.320667266845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06292565912008286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06996193528175354,
      "backward_entropy": 0.006781655762876783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.0064697265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06297045201063156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06985332071781158,
      "backward_entropy": 0.006784591291631971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.109073638916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06301499158143997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06974484026432037,
      "backward_entropy": 0.006789832775081907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.253257751464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06306222826242447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0696280226111412,
      "backward_entropy": 0.006794756544487817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.805084228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06311080604791641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06950704753398895,
      "backward_entropy": 0.00679845895086016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.338328838348389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06316154450178146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06937943398952484,
      "backward_entropy": 0.010336313928876604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.294432640075684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06320928037166595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06926053762435913,
      "backward_entropy": 0.010298373443739755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.25404167175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06325434893369675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0691492110490799,
      "backward_entropy": 0.006807320884295872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.81319808959961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06329696625471115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06904494017362595,
      "backward_entropy": 0.006812378231968198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.91901397705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.063338503241539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06894336640834808,
      "backward_entropy": 0.006819893739053181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.384817123413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06338094174861908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06883858144283295,
      "backward_entropy": 0.006827228835650853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.263809204101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06342513114213943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06872814893722534,
      "backward_entropy": 0.0068334851946149555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.098487854003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06347095966339111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06861241161823273,
      "backward_entropy": 0.006839496748788016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.517655372619629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06351625174283981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06849783658981323,
      "backward_entropy": 0.006845943629741669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.898048400878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06355998665094376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06838789582252502,
      "backward_entropy": 0.010042678032602583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.3167781829834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06360533088445663,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0682726502418518,
      "backward_entropy": 0.0068568385073116845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4559645652770996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06365102529525757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0681561529636383,
      "backward_entropy": 0.006860199251345226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.85630989074707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06369318813085556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06805039942264557,
      "backward_entropy": 0.009942584804126195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.829830169677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06373318284749985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06795093417167664,
      "backward_entropy": 0.006869780165808541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.928707122802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06377606838941574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06784218549728394,
      "backward_entropy": 0.006874612931694303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.46808910369873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06381963193416595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0677308514714241,
      "backward_entropy": 0.006879821419715881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.04704761505127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06386278569698334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06762062013149261,
      "backward_entropy": 0.009813718497753143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.990456581115723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06390457600355148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06751428544521332,
      "backward_entropy": 0.0068896811987672535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.241046905517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06394513696432114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06741160154342651,
      "backward_entropy": 0.006894523011786597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.593112468719482,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06398558616638184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06730884313583374,
      "backward_entropy": 0.006899656994002206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.556325912475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0640239492058754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06721241772174835,
      "backward_entropy": 0.00690475053020886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.54214096069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06406055390834808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06712105870246887,
      "backward_entropy": 0.006911975996834891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.963184356689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0640992745757103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06702280044555664,
      "backward_entropy": 0.006917644292116165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.892902374267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0641380324959755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06692397594451904,
      "backward_entropy": 0.006923721304961613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.620548248291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06417683511972427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06682462990283966,
      "backward_entropy": 0.006930661520787648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.758306503295898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06421475857496262,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06672761589288712,
      "backward_entropy": 0.006939069500991276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.024564743041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06425261497497559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06663088500499725,
      "backward_entropy": 0.006944462124790464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.615836143493652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06429235637187958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06652812659740448,
      "backward_entropy": 0.006947547197341919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.415584564208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06433195620775223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06642547249794006,
      "backward_entropy": 0.006950541798557554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.475668907165527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06437031924724579,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0663270577788353,
      "backward_entropy": 0.009398375238691057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.404733657836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06440862268209457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06622849404811859,
      "backward_entropy": 0.006949951606137412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0980498790740967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06444693356752396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06612961739301682,
      "backward_entropy": 0.0069503454225403926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.398202896118164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06448231637477875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06604039669036865,
      "backward_entropy": 0.009278432599135808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.297523498535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06451988965272903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06594346463680267,
      "backward_entropy": 0.009240108941282545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.07606840133667,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06455934792757034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06584013998508453,
      "backward_entropy": 0.0069513049508844104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.100738525390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06459668278694153,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06574377417564392,
      "backward_entropy": 0.0990099481173924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.97352409362793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06463684886693954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0656379759311676,
      "backward_entropy": 0.006949893065861293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.965275287628174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06467954814434052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06552363932132721,
      "backward_entropy": 0.00908044193472181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.799224853515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06471992284059525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06541669368743896,
      "backward_entropy": 0.006948679685592651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.520647048950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06476088613271713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0653076320886612,
      "backward_entropy": 0.0069481852863516125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.606162071228027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06480512022972107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06518805027008057,
      "backward_entropy": 0.00896257268530982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.50617504119873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0648496076464653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06506728380918503,
      "backward_entropy": 0.006944723427295685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.651448249816895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06489431858062744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0649455189704895,
      "backward_entropy": 0.006944462124790464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.451992988586426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06493731588125229,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06482931971549988,
      "backward_entropy": 0.006944012429033007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.696355819702148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0649796798825264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0647151917219162,
      "backward_entropy": 0.006943365825074059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.482392311096191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06501970440149307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06460849195718765,
      "backward_entropy": 0.006944003914083753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.255094528198242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06505850702524185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06450557708740234,
      "backward_entropy": 0.006945314151900155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.941839218139648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06510170549154282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06438785046339035,
      "backward_entropy": 0.006947377962725503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31385612487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06514523923397064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06426864117383957,
      "backward_entropy": 0.006951094738074711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.49884796142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06518726050853729,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06415413320064545,
      "backward_entropy": 0.008646077343395777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.474708080291748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06523064523935318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06403470039367676,
      "backward_entropy": 0.006963966680424554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.568907737731934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06527149677276611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06392373889684677,
      "backward_entropy": 0.00697050616145134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.093694686889648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06531272828578949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0638115257024765,
      "backward_entropy": 0.0069754815527370995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.715557098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06535255908966064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06370389461517334,
      "backward_entropy": 0.006980884820222855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.990581035614014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06539199501276016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06359751522541046,
      "backward_entropy": 0.006985817636762347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.219219207763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06543010473251343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06349559128284454,
      "backward_entropy": 0.006989506738526481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.134848594665527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06546884775161743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06339146196842194,
      "backward_entropy": 0.006992263453347343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.230281352996826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06550808250904083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06328561902046204,
      "backward_entropy": 0.006993186260972705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.197072505950928,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06554518640041351,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06318700313568115,
      "backward_entropy": 0.09901075703757149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.03380584716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06558039039373398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06309452652931213,
      "backward_entropy": 0.006996412362371173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.248885154724121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06561829894781113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06299261003732681,
      "backward_entropy": 0.006998940237930843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0982513427734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06565585732460022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06289185583591461,
      "backward_entropy": 0.0069995128682681495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.069005489349365,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06569153815507889,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0627971664071083,
      "backward_entropy": 0.007002874676670347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.567106246948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0657254159450531,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0627085343003273,
      "backward_entropy": 0.00700638975415911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.987834930419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06576038897037506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06261567026376724,
      "backward_entropy": 0.007011687649147851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.453665733337402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06579708307981491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06251673400402069,
      "backward_entropy": 0.007015790790319443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9451518058776855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06583282351493835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06242073327302933,
      "backward_entropy": 0.007021591599498477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.36433744430542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06586676090955734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06233084946870804,
      "backward_entropy": 0.007027632423809597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.887364387512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06589991599321365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0622434988617897,
      "backward_entropy": 0.007033130420105798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.70055103302002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06593148410320282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062161535024642944,
      "backward_entropy": 0.007038454924310956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.235563278198242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06596333533525467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.062078677117824554,
      "backward_entropy": 0.00804031640291214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4100277423858643,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06599472463130951,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06199698895215988,
      "backward_entropy": 0.0070509154881749836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.53921127319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06602393090724945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06192263588309288,
      "backward_entropy": 0.007994264364242554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49023723602295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06605368852615356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06184633448719978,
      "backward_entropy": 0.007068908640316555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.079645156860352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06608381867408752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06176871061325073,
      "backward_entropy": 0.007075358182191849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.042863845825195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06611360609531403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061691898852586746,
      "backward_entropy": 0.0070833489298820496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.322105407714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0661429911851883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061616308987140656,
      "backward_entropy": 0.007090988968099866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.911382675170898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06617534160614014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061530448496341705,
      "backward_entropy": 0.0070962022457804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.820125579833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06620940566062927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061438947916030884,
      "backward_entropy": 0.007097726953881127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.727169036865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06624510884284973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06134171783924103,
      "backward_entropy": 0.0070981042725699285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.62856674194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06628227978944778,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06123926863074303,
      "backward_entropy": 0.007783242102180209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.275055885314941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06632083654403687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0611317977309227,
      "backward_entropy": 0.007097674799816949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.957633972167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06635985523462296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06102243438363075,
      "backward_entropy": 0.007100054728133338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890857696533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06639838218688965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06091466173529625,
      "backward_entropy": 0.007103300520351955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82845401763916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06643648445606232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06080801784992218,
      "backward_entropy": 0.007107787898608616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.763505935668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0664740800857544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06070313602685928,
      "backward_entropy": 0.007111075201204845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3590192794799805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06651123613119125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06059988588094711,
      "backward_entropy": 0.007113698869943619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.641681671142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06654636561870575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06050362437963486,
      "backward_entropy": 0.007116756268909999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.58222770690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06658122688531876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06040848791599274,
      "backward_entropy": 0.007118108017104012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.268465042114258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06661582738161087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060314349830150604,
      "backward_entropy": 0.007117971245731626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1316282749176025,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0666486993432045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060225959867239,
      "backward_entropy": 0.00712020109806742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.216891765594482,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06667909771203995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06014634668827057,
      "backward_entropy": 0.007122910980667386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.624786376953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06670808792114258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06007164716720581,
      "backward_entropy": 0.007125844380685261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.163782596588135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06673981994390488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059987623244524,
      "backward_entropy": 0.007126587842191968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25660514831543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06677006930112839,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05990814045071602,
      "backward_entropy": 0.0071289220026561195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.158228874206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06680064648389816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.059826936572790146,
      "backward_entropy": 0.007381383329629898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.156600952148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06683068722486496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05974739417433739,
      "backward_entropy": 0.007139738116945539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.063024520874023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06686097383499146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059666894376277924,
      "backward_entropy": 0.007145574050290244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0287652015686035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06688984483480453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05959141254425049,
      "backward_entropy": 0.00715093154992376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.00843334197998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06691664457321167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05952326953411102,
      "backward_entropy": 0.007156440189906529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.959939956665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06694633513689041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05944490432739258,
      "backward_entropy": 0.007160033498491559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.939037799835205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06697635352611542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05936485528945923,
      "backward_entropy": 0.007165389401572091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.862751483917236,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06700576841831207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05928701162338257,
      "backward_entropy": 0.007170172674315316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.554258346557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06703544408082962,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05920805037021637,
      "backward_entropy": 0.007194289139338902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.756585121154785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06706935912370682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05911383777856827,
      "backward_entropy": 0.0071789467973368505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.779663562774658,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0671030580997467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05902034044265747,
      "backward_entropy": 0.0071829333901405334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.834219217300415,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06713578850030899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05893021821975708,
      "backward_entropy": 0.007187344133853912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.695139408111572,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0671667754650116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05884656682610512,
      "backward_entropy": 0.00719089646424566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.543467998504639,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06719721853733063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05876420810818672,
      "backward_entropy": 0.007198484880583627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7529475688934326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06722778081893921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05868123471736908,
      "backward_entropy": 0.007205755582877568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.588888645172119,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06725697219371796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058602768927812576,
      "backward_entropy": 0.007215049649987902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7100868225097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06728559732437134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05852629989385605,
      "backward_entropy": 0.007223659328051976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.023897171020508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06731288135051727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05845476686954498,
      "backward_entropy": 0.0072307804865496495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6627562046051025,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06734202057123184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058376774191856384,
      "backward_entropy": 0.007234967180660793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.074480056762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06736978888511658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.058303747326135635,
      "backward_entropy": 0.006959403731993267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.414231300354004,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06739851832389832,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.058227404952049255,
      "backward_entropy": 0.09901625769478935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.952295303344727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06742669641971588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058153048157691956,
      "backward_entropy": 0.007239548755543572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5717058181762695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06745592504739761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05807477980852127,
      "backward_entropy": 0.0072406429265226635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.834074974060059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06748367100954056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05800215154886246,
      "backward_entropy": 0.0072401368192264014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2752838134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06751252710819244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05792523920536041,
      "backward_entropy": 0.007240980331386838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.978215217590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0675407350063324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0578506737947464,
      "backward_entropy": 0.00724096702677863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.660416603088379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06756918877363205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057775065302848816,
      "backward_entropy": 0.007241399160453251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.31795883178711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06759859621524811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057695914059877396,
      "backward_entropy": 0.007241626935345786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.832785129547119,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06762956082820892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057611286640167236,
      "backward_entropy": 0.0072404321815286365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.476587295532227,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06766047328710556,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.057526685297489166,
      "backward_entropy": 0.09901377132960729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.091830253601074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06769197434186935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05744031071662903,
      "backward_entropy": 0.007237890469176429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.34006404876709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06772469729185104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057349931448698044,
      "backward_entropy": 0.0072328996445451465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27333927154541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0677579864859581,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057257212698459625,
      "backward_entropy": 0.007230458515030997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.571535110473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06779174506664276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057162486016750336,
      "backward_entropy": 0.007229711328233991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2704782485961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06782504171133041,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057069700211286545,
      "backward_entropy": 0.006547119468450546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.852528095245361,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06785641610622406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056984204798936844,
      "backward_entropy": 0.007224699748413903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.613435745239258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06788691878318787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.056901656091213226,
      "backward_entropy": 0.006489841533558709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.777350425720215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0679188147187233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05681405961513519,
      "backward_entropy": 0.0072224922478199005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1676783561706543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06794977188110352,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05672961473464966,
      "backward_entropy": 0.00643743308527129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.703381538391113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0679791122674942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056651052087545395,
      "backward_entropy": 0.007224066981247493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1197431087493896,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06800781935453415,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.056574419140815735,
      "backward_entropy": 0.09901077406747001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720274925231934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06803517788648605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056502461433410645,
      "backward_entropy": 0.0072332146976675305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5446771383285522,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0680634081363678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056427426636219025,
      "backward_entropy": 0.007237605218376432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.576848983764648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06808968633413315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05635901540517807,
      "backward_entropy": 0.007245295281921115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.073136329650879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06811545789241791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05629265308380127,
      "backward_entropy": 0.007251365908554622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.01114559173584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0681428611278534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0562206506729126,
      "backward_entropy": 0.007254371153456824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.936286926269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06817163527011871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056144386529922485,
      "backward_entropy": 0.007252985345465797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.337711334228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06820183992385864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05606275796890259,
      "backward_entropy": 0.0072522083563464025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787858009338379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06823407858610153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05597366765141487,
      "backward_entropy": 0.007252940109797886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.16427230834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06826740503311157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05588052421808243,
      "backward_entropy": 0.00725507949079786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.764669895172119,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0683021992444992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05578279867768288,
      "backward_entropy": 0.007253611726420266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.280898094177246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06833618134260178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055688515305519104,
      "backward_entropy": 0.00724918395280838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01875726878643036,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06836901605129242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05559791624546051,
      "backward_entropy": 0.007248621966157641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.003656387329102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06839864701032639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05551871657371521,
      "backward_entropy": 0.007250762411526271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.563161849975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0684289038181305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05543697252869606,
      "backward_entropy": 0.007254770291703088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.636772155761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0684589147567749,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05535614490509033,
      "backward_entropy": 0.007258444492306028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.917476654052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06849083304405212,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055268291383981705,
      "backward_entropy": 0.0072630659810134345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11646842956543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06852499395608902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055172815918922424,
      "backward_entropy": 0.00726506273661341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.362878799438477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06855975091457367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055075667798519135,
      "backward_entropy": 0.007264077663421631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.957770347595215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06859376281499863,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05498126894235611,
      "backward_entropy": 0.007263014359133584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.566872596740723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06862838566303253,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05488491803407669,
      "backward_entropy": 0.005915130887712751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6118812561035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06866294890642166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05478890985250473,
      "backward_entropy": 0.007257709545748574,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.561523726433515,
    "avg_log_Z": -0.0671196374297142,
    "success_rate": 1.0,
    "avg_reward": 78.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.1,
      "2": 0.86
    },
    "avg_forward_entropy": 0.05896939255297184,
    "avg_backward_entropy": 0.010829404768134869,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}