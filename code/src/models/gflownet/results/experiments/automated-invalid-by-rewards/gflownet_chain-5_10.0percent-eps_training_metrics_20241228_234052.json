{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13859649896621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13860530853271485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 246.75149536132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261760473251343,
      "backward_entropy": 0.13852622509002685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 247.12477111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00010000001202570274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826341152191162,
      "backward_entropy": 0.13860870599746705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 247.074951171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0001999783271458,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18265028794606528,
      "backward_entropy": 0.13860708475112915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 264.0220642089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0002999501011800021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266604344050089,
      "backward_entropy": 0.13861455917358398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.4104461669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004002195200882852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826814611752828,
      "backward_entropy": 0.13861706256866455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.7890167236328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004990024608559906,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18269634246826172,
      "backward_entropy": 0.13861870765686035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.74581909179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005967948236502707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18271074692408243,
      "backward_entropy": 0.13862098455429078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 247.6715545654297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006939330487512052,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827247142791748,
      "backward_entropy": 0.13862366676330568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 246.780029296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007918381597846746,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827383836110433,
      "backward_entropy": 0.13862547874450684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 247.9927215576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008904006681405008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275203307469687,
      "backward_entropy": 0.1386249542236328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.3941955566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009893415262922645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827651858329773,
      "backward_entropy": 0.13857641220092773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.107177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010892754653468728,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827783783276876,
      "backward_entropy": 0.13857953548431395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.90370178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011881300015375018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279115358988443,
      "backward_entropy": 0.1386273145675659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 263.4976501464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012859874404966831,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828034520149231,
      "backward_entropy": 0.1386293888092041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 246.90158081054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013849869137629867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281553188959757,
      "backward_entropy": 0.13858671188354493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.97256469726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001484340988099575,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18282729387283325,
      "backward_entropy": 0.13862936496734618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.4689483642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015819581458345056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18283859888712564,
      "backward_entropy": 0.13859000205993652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.7971954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016789142973721027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18284958600997925,
      "backward_entropy": 0.13862873315811158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.8123474121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017759575275704265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286025524139404,
      "backward_entropy": 0.13862881660461426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.80734252929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018744143890216947,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828707456588745,
      "backward_entropy": 0.1386285901069641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.65304565429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001971255987882614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18288073937098184,
      "backward_entropy": 0.13859305381774903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.7237548828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002068191533908248,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289039532343546,
      "backward_entropy": 0.13859319686889648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.6585235595703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021637144964188337,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828995943069458,
      "backward_entropy": 0.13862826824188232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 294.3222351074219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0022603371180593967,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290859460830688,
      "backward_entropy": 0.13862825632095338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 328.9566955566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0023598861880600452,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18291769425074259,
      "backward_entropy": 0.1386283040046692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 246.33506774902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002462726319208741,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292677402496338,
      "backward_entropy": 0.1385917067527771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 278.0447998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025653718039393425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293535709381104,
      "backward_entropy": 0.13862817287445067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 278.8173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026693118270486593,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18294376134872437,
      "backward_entropy": 0.1386286735534668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.9210662841797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027742504607886076,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18295162916183472,
      "backward_entropy": 0.13862881660461426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.19952392578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002877314342185855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829588015874227,
      "backward_entropy": 0.13862730264663697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 311.6259460449219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0029808313120156527,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18296565612157187,
      "backward_entropy": 0.13862907886505127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.27096557617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0030866158194839954,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18297235171000162,
      "backward_entropy": 0.13862917423248292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.8580627441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0031911011319607496,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18297863006591797,
      "backward_entropy": 0.1386292815208435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.51478576660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0032956753857433796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298441171646118,
      "backward_entropy": 0.13862550258636475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.6377868652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003398156026378274,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298961718877158,
      "backward_entropy": 0.13862940073013305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.31114196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003501623636111617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299442529678345,
      "backward_entropy": 0.13862416744232178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.3809509277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036038311664015055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299885590871176,
      "backward_entropy": 0.13857824802398683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.8517303466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003706562565639615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300306797027588,
      "backward_entropy": 0.13857686519622803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 295.8601989746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003808998968452215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830068826675415,
      "backward_entropy": 0.1386216998100281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.1746826171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003913125488907099,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301033973693848,
      "backward_entropy": 0.1386207938194275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.93649291992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004014191217720509,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301308155059814,
      "backward_entropy": 0.1386293053627014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.093994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004113632254302502,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.183015247186025,
      "backward_entropy": 0.13857173919677734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.12571716308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004213913809508085,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830171545346578,
      "backward_entropy": 0.13862919807434082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 294.71185302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004313347395509481,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301868438720703,
      "backward_entropy": 0.13856924772262574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.8496856689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004415004979819059,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301993608474731,
      "backward_entropy": 0.13856813907623292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.38539123535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00451550493016839,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302067120869955,
      "backward_entropy": 0.13862903118133546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.4787139892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004615039564669132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302100896835327,
      "backward_entropy": 0.13856595754623413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.9914093017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004712933208793402,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302090962727866,
      "backward_entropy": 0.13862892389297485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.5171813964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004808485507965088,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302035331726074,
      "backward_entropy": 0.13856372833251954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.46945190429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004905237350612879,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301941951115927,
      "backward_entropy": 0.13862885236740113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.0094299316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004998847842216492,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301800886789957,
      "backward_entropy": 0.13856157064437866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.00709533691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005094835069030523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301637967427573,
      "backward_entropy": 0.13860852718353273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.05255126953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0051897610537707806,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301449219385782,
      "backward_entropy": 0.13862879276275636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.1535186767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005286175757646561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301236629486084,
      "backward_entropy": 0.13860619068145752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.92762756347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00538222212344408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830098032951355,
      "backward_entropy": 0.138604998588562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 292.700439453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005478739272803068,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300684293111166,
      "backward_entropy": 0.1385570526123047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.9913330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005578191485255957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300354480743408,
      "backward_entropy": 0.13860279321670532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.52574157714844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005676924251019955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299980958302817,
      "backward_entropy": 0.13862893581390381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.2755126953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0057750847190618515,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829956571261088,
      "backward_entropy": 0.13862898349761962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.01454162597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005874439142644405,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299112717310587,
      "backward_entropy": 0.1386290192604065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.75302124023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005972268059849739,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298633893330893,
      "backward_entropy": 0.1386290431022644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.931884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006070489529520273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298123280207315,
      "backward_entropy": 0.13859618902206422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.6561584472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006170358043164015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829754908879598,
      "backward_entropy": 0.1385946035385132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.1859588623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006270971614867449,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296917279561362,
      "backward_entropy": 0.13855044841766356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.3117980957031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0063707889057695866,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829624573389689,
      "backward_entropy": 0.13862912654876708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.4227294921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0064721317030489445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829550862312317,
      "backward_entropy": 0.1385890483856201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.4517059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006574943661689758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294715881347656,
      "backward_entropy": 0.13858698606491088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.3168029785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006675672717392445,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293869495391846,
      "backward_entropy": 0.13862913846969604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.3875427246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006777032278478146,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829295555750529,
      "backward_entropy": 0.13862912654876708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.69583129882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006879981141537428,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291995922724405,
      "backward_entropy": 0.1385425806045532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.7501678466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0069801113568246365,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290996551513672,
      "backward_entropy": 0.13854076862335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.4613037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00708006089553237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289929628372192,
      "backward_entropy": 0.1385388493537903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.61697387695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007180050481110811,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182888130346934,
      "backward_entropy": 0.13853683471679687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.64016723632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007279873359948397,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828762690226237,
      "backward_entropy": 0.1385667324066162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.32875061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00737796351313591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286393086115518,
      "backward_entropy": 0.13856279850006104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.03807067871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0074753426015377045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285101652145386,
      "backward_entropy": 0.13852987289428711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.61073303222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007569528184831142,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828377644220988,
      "backward_entropy": 0.1385270833969116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.54832458496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007663358934223652,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18282389640808105,
      "backward_entropy": 0.13862864971160888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 291.78045654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00775687862187624,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828093727429708,
      "backward_entropy": 0.13852115869522094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.65411376953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007853674702346325,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279409408569336,
      "backward_entropy": 0.13862841129302977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.45358276367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007951696403324604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277812004089355,
      "backward_entropy": 0.13851563930511473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.9508819580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008050058968365192,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827616294225057,
      "backward_entropy": 0.13862826824188232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.6213073730469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008147051557898521,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274478117624918,
      "backward_entropy": 0.1386281967163086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.93212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008245392702519894,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18272729714711508,
      "backward_entropy": 0.13851709365844728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.8766326904297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00834136176854372,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18270943562189737,
      "backward_entropy": 0.13862807750701905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.7164001464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00843699462711811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18269099791844687,
      "backward_entropy": 0.13850610256195067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.84249877929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008534683845937252,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18267152706782022,
      "backward_entropy": 0.13849833011627197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.7698974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008632619865238667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18265132109324136,
      "backward_entropy": 0.13849539756774903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.85726928710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00873077753931284,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18263045946756998,
      "backward_entropy": 0.13862791061401367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8623504638672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008826355449855328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18260916074117026,
      "backward_entropy": 0.13862781524658202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.90667724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008920783177018166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18258744478225708,
      "backward_entropy": 0.13848519325256348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.8125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009017490781843662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256469567616782,
      "backward_entropy": 0.1384652853012085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.2694091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009113714098930359,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254135052363077,
      "backward_entropy": 0.13847784996032714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.86854553222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009211334399878979,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825171709060669,
      "backward_entropy": 0.13847416639328003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 290.8284606933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00930851697921753,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249249458312988,
      "backward_entropy": 0.138627290725708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.73391723632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009408565238118172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18246658643086752,
      "backward_entropy": 0.1384324312210083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.42837524414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009504124522209167,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18244057893753052,
      "backward_entropy": 0.13862712383270265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0200958251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009598156437277794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18241381645202637,
      "backward_entropy": 0.1384575843811035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 290.0660400390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0096886046230793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18238713343938193,
      "backward_entropy": 0.13840150833129883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.0441131591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009782761335372925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235903978347778,
      "backward_entropy": 0.1383909225463867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.65716552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009876914322376251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233021100362143,
      "backward_entropy": 0.13838040828704834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.07980346679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009973466396331787,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18230005105336508,
      "backward_entropy": 0.13862625360488892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.3847198486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010068750008940697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18226927518844604,
      "backward_entropy": 0.1383589506149292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.3334503173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010160835459828377,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18223756551742554,
      "backward_entropy": 0.13862591981887817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.6892852783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010252419859170914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18220533927281699,
      "backward_entropy": 0.1384220838546753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.79861450195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01034472044557333,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18217158317565918,
      "backward_entropy": 0.13841624259948732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.33470153808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01043621264398098,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821370323499044,
      "backward_entropy": 0.13841012716293336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.2444305419922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010525873862206936,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18210172653198242,
      "backward_entropy": 0.13862459659576415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.60972595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010615896433591843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18206536769866943,
      "backward_entropy": 0.13827359676361084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.1513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01070372574031353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18202877044677734,
      "backward_entropy": 0.13838958740234375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.43618774414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010789284482598305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18199169635772705,
      "backward_entropy": 0.13823896646499634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.1953887939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010874772444367409,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195376793543497,
      "backward_entropy": 0.1383739233016968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.96533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010959227569401264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1819155216217041,
      "backward_entropy": 0.13820122480392455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.1770782470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011041773483157158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18187673886617026,
      "backward_entropy": 0.13818044662475587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.79318237304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011125415563583374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18183664480845133,
      "backward_entropy": 0.13834829330444337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.2193145751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011208086274564266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18179567654927573,
      "backward_entropy": 0.13833918571472167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.43043518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01129201427102089,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1817535161972046,
      "backward_entropy": 0.13833050727844237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3778839111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011372089385986328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817113161087036,
      "backward_entropy": 0.13861846923828125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.32080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011448698118329048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18166905641555786,
      "backward_entropy": 0.13806287050247193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.47071838378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011525320820510387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1816259225209554,
      "backward_entropy": 0.1380352258682251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.9381561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011598589830100536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18158272902170816,
      "backward_entropy": 0.13800394535064697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.71434020996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011669796891510487,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18153921763102213,
      "backward_entropy": 0.13796956539154054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.72142028808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011741292662918568,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18149451414744058,
      "backward_entropy": 0.13825855255126954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.7906951904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011810285039246082,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1814497709274292,
      "backward_entropy": 0.1378961682319641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 287.51092529296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011881855316460133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18140316009521484,
      "backward_entropy": 0.13785912990570068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.8346405029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01195963378995657,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813536286354065,
      "backward_entropy": 0.13821765184402465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.65762329101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012036986649036407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18130185206731161,
      "backward_entropy": 0.13820573091506957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.4925994873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012115221470594406,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.181248406569163,
      "backward_entropy": 0.13860669136047363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.6051788330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012193243019282818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18119351069132486,
      "backward_entropy": 0.13818219900131226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.662353515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012270845472812653,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18113712469736734,
      "backward_entropy": 0.13860563039779664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3815155029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012347212061285973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18107972542444864,
      "backward_entropy": 0.13815584182739257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.05491638183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012422315776348114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18102125326792398,
      "backward_entropy": 0.13814098834991456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.44273376464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012498835101723671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18096119165420532,
      "backward_entropy": 0.13812699317932128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.7628173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012574255466461182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1809000571568807,
      "backward_entropy": 0.13752470016479493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.7154083251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012648616917431355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808378299077352,
      "backward_entropy": 0.13809573650360107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.00003051757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012722441926598549,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18077480792999268,
      "backward_entropy": 0.13807915449142455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.32583618164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01279466412961483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18071132898330688,
      "backward_entropy": 0.13806145191192626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.68418884277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012865371070802212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1806472341219584,
      "backward_entropy": 0.13804249763488768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.898681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012935052625834942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18058276176452637,
      "backward_entropy": 0.13727773427963258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.74696350097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013009818270802498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18051505088806152,
      "backward_entropy": 0.1380079984664917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.27804565429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013085020706057549,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.180445929368337,
      "backward_entropy": 0.1379931688308716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.96255493164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013162780553102493,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18037460247675577,
      "backward_entropy": 0.13798050880432128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.42724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013242681510746479,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18030095100402832,
      "backward_entropy": 0.13710694313049315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.78858947753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013324188999831676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1802248160044352,
      "backward_entropy": 0.13795785903930663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.7213134765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013405394740402699,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18014742930730185,
      "backward_entropy": 0.1385966420173645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.71701049804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013485290110111237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18006926774978638,
      "backward_entropy": 0.13793152570724487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.47471618652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013566902838647366,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17998860279719034,
      "backward_entropy": 0.13859673738479614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 285.4866638183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013649269938468933,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17990614970525107,
      "backward_entropy": 0.13859689235687256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.2134246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013736936263740063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.179819126923879,
      "backward_entropy": 0.13682832717895507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.4874725341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013825759291648865,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17973009745279947,
      "backward_entropy": 0.13859865665435792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.3008270263672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013915542513132095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17963898181915283,
      "backward_entropy": 0.13859946727752687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.25035095214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01400720700621605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17954530318578085,
      "backward_entropy": 0.13668880462646485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 267.26129150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014099540188908577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17944963773091635,
      "backward_entropy": 0.13664114475250244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.58114624023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014195415191352367,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17935029665629068,
      "backward_entropy": 0.13860249519348145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.90220642089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01428938191384077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1792502204577128,
      "backward_entropy": 0.1365440845489502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 266.8132629394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014379709959030151,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.179150660832723,
      "backward_entropy": 0.13648303747177123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.48289489746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014473799616098404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17904714743296304,
      "backward_entropy": 0.1377699851989746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.21299743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014566324651241302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17894295851389566,
      "backward_entropy": 0.13636322021484376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.5386505126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01465768925845623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17883817354838052,
      "backward_entropy": 0.1377282738685608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.3523406982422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014745677821338177,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17873384555180868,
      "backward_entropy": 0.1385999798774719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.4393310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014836686663329601,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17862568298975626,
      "backward_entropy": 0.13615671396255494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.3285369873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014927169308066368,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17851569255193075,
      "backward_entropy": 0.13859717845916747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.5829315185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015015584416687489,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17840564250946045,
      "backward_entropy": 0.13762449026107787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.69117736816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015103667974472046,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.178293506304423,
      "backward_entropy": 0.13859241008758544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2110595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015191621147096157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1781794230143229,
      "backward_entropy": 0.1358185052871704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.10862731933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015276717953383923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17806597550710043,
      "backward_entropy": 0.13571997880935668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.17567443847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015361282043159008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1779512564341227,
      "backward_entropy": 0.135619592666626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.65101623535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015446338802576065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17783451080322266,
      "backward_entropy": 0.13745005130767823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.3142852783203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015530713833868504,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17771639426549277,
      "backward_entropy": 0.13857362270355225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.27554321289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015615533106029034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17759605248769125,
      "backward_entropy": 0.13530753850936889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.7815399169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015699952840805054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17747672398885092,
      "backward_entropy": 0.13520150184631347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.29724884033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01578410156071186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17735747496287027,
      "backward_entropy": 0.13509759902954102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.34624481201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015862565487623215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17724118630091348,
      "backward_entropy": 0.13497960567474365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.45852661132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015935063362121582,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17712871233622232,
      "backward_entropy": 0.13720064163208007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.52566528320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016008522361516953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17701403299967447,
      "backward_entropy": 0.1347226619720459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.4251708984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016081364825367928,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17689776420593262,
      "backward_entropy": 0.13853641748428344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 231.78456115722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016153663396835327,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17677980661392212,
      "backward_entropy": 0.13444558382034302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.35832977294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01622982881963253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17665676275889078,
      "backward_entropy": 0.13699941635131835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.96580505371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016302036121487617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1765353480974833,
      "backward_entropy": 0.13694581985473633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.76805114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016369493678212166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17641623814900717,
      "backward_entropy": 0.1368856191635132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.56939697265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016436805948615074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17629496256510416,
      "backward_entropy": 0.13383309841156005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.23171997070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016500374302268028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17617626984914145,
      "backward_entropy": 0.13365821838378905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.17213439941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016565298661589622,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17605402072270712,
      "backward_entropy": 0.13669202327728272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.5364227294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016629863530397415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17593093713124594,
      "backward_entropy": 0.13662619590759278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.9366455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016697047278285027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17580360174179077,
      "backward_entropy": 0.13656471967697142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.63525390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016767919063568115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17567149798075357,
      "backward_entropy": 0.13651140928268432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.28219604492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01683768816292286,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1755390167236328,
      "backward_entropy": 0.1384449005126953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.68386840820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01690630242228508,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1754058599472046,
      "backward_entropy": 0.13639504909515382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.9476318359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016975238919258118,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1752710739771525,
      "backward_entropy": 0.13843191862106324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.52645874023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017044389620423317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1751344601313273,
      "backward_entropy": 0.1362788200378418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.84007263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017111793160438538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1749985615412394,
      "backward_entropy": 0.13213014602661133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.7702407836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017179330810904503,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17486035823822021,
      "backward_entropy": 0.13615965843200684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.6183624267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01724245585501194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17472449938456217,
      "backward_entropy": 0.13174829483032227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.94224548339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017306162044405937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17458597819010416,
      "backward_entropy": 0.131538724899292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.5298309326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017369292676448822,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1744460662206014,
      "backward_entropy": 0.1383810043334961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.26551818847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017435992136597633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1742997169494629,
      "backward_entropy": 0.13110957145690919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.5261688232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017502175644040108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17415277163187662,
      "backward_entropy": 0.13089182376861572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.96131896972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017567817121744156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17400503158569336,
      "backward_entropy": 0.13572777509689332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.91304779052734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01763332448899746,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17385679483413696,
      "backward_entropy": 0.1383424162864685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.55369567871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017696216702461243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1737102468808492,
      "backward_entropy": 0.13023537397384644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.24374389648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017756585031747818,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17356487115224203,
      "backward_entropy": 0.12999749183654785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.5088348388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017818238586187363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1734166940053304,
      "backward_entropy": 0.1297659158706665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.4947509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01787872239947319,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1732683777809143,
      "backward_entropy": 0.13533241748809816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.3158721923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017937902361154556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17311946551005045,
      "backward_entropy": 0.1292708396911621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.08113861083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017996177077293396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1729701360066732,
      "backward_entropy": 0.12900803089141846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.4765167236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018048888072371483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17282583316167197,
      "backward_entropy": 0.13504652976989745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.90159606933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018106738105416298,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1726734439531962,
      "backward_entropy": 0.1284485101699829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.05291748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018164625391364098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17251892884572348,
      "backward_entropy": 0.1281638264656067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.68014526367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01821947656571865,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17236689726511636,
      "backward_entropy": 0.13820103406906128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.5635223388672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01827937550842762,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17220693826675415,
      "backward_entropy": 0.13818845748901368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.7854766845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018340613692998886,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17204401890436807,
      "backward_entropy": 0.1345543622970581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.86624145507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01840592548251152,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17187345027923584,
      "backward_entropy": 0.134468412399292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.27223205566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018469693139195442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17170341809590658,
      "backward_entropy": 0.13437455892562866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.69921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018535394221544266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1715292533238729,
      "backward_entropy": 0.13428261280059814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.73419189453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018601972609758377,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1713529626528422,
      "backward_entropy": 0.1341940402984619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.88619995117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018663626164197922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1711821953455607,
      "backward_entropy": 0.13813474178314208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.42388916015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018727200105786324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17100648085276285,
      "backward_entropy": 0.12565480470657348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.16517639160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01879834569990635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.170819362004598,
      "backward_entropy": 0.13391475677490233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.76353454589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01886642724275589,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17063538233439127,
      "backward_entropy": 0.1338255763053894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.16502380371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018937870860099792,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1704441706339518,
      "backward_entropy": 0.13373823165893556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.54499816894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019013864919543266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17024526993433634,
      "backward_entropy": 0.13366363048553467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.0218048095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019085178151726723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17005203167597452,
      "backward_entropy": 0.12435575723648071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.65357971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019154570996761322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16986048221588135,
      "backward_entropy": 0.1240734577178955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.18041229248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019220834597945213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16967161496480307,
      "backward_entropy": 0.13337405920028686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.67678833007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019284630194306374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1694855491320292,
      "backward_entropy": 0.12344491481781006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.04592895507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01935182884335518,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16929360230763754,
      "backward_entropy": 0.13315718173980712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.45054626464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01941956952214241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1690990924835205,
      "backward_entropy": 0.13305337429046632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.1939239501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019489113241434097,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1689006487528483,
      "backward_entropy": 0.13295187950134277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.46371459960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019557923078536987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1687017281850179,
      "backward_entropy": 0.12224807739257812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.86190032958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019628360867500305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16849891344706217,
      "backward_entropy": 0.1219406008720398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.9286651611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019695861265063286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16829905907313028,
      "backward_entropy": 0.1326163649559021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.1383819580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01976187713444233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16810001929601034,
      "backward_entropy": 0.13249123096466064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.16220092773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01982673443853855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16790207227071127,
      "backward_entropy": 0.12094159126281738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.08063507080078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019891194999217987,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1677023967107137,
      "backward_entropy": 0.13801822662353516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.94387817382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019953424111008644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16750534375508627,
      "backward_entropy": 0.12020833492279052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.97323608398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020019063726067543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16730105876922607,
      "backward_entropy": 0.11984919309616089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.60739135742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020083526149392128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1670978864034017,
      "backward_entropy": 0.11948347091674805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.23251342773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02014791965484619,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16689340273539224,
      "backward_entropy": 0.11911004781723022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.75079345703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020213499665260315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16668597857157388,
      "backward_entropy": 0.13152236938476564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.92282104492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02027551457285881,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16648328304290771,
      "backward_entropy": 0.13136653900146483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.36256408691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02033897116780281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16627715031305948,
      "backward_entropy": 0.11796064376831054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.9327392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020401760935783386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16607220967610678,
      "backward_entropy": 0.13106446266174315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.44554138183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020465850830078125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16586440801620483,
      "backward_entropy": 0.11720364093780518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.21968841552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020532099530100822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16565153996149698,
      "backward_entropy": 0.11683244705200195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.8133087158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020594745874404907,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16544365882873535,
      "backward_entropy": 0.13060388565063477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.85659790039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02065889909863472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16523252924283346,
      "backward_entropy": 0.11601728200912476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.8674545288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02072613127529621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16501360138257345,
      "backward_entropy": 0.11561919450759887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.6365509033203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02079085074365139,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16479810078938803,
      "backward_entropy": 0.13782107830047607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.20314025878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020856808871030807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16457969943682352,
      "backward_entropy": 0.12995502948760987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.41883850097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020926835015416145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.164352019627889,
      "backward_entropy": 0.12980411052703858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.98405456542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02099667116999626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16412494579950967,
      "backward_entropy": 0.11399972438812256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.63526916503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021062158048152924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16390308737754822,
      "backward_entropy": 0.12947007417678832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.20004272460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02112891525030136,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1636787454287211,
      "backward_entropy": 0.13775835037231446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.7511444091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021200835704803467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16344338655471802,
      "backward_entropy": 0.11269257068634034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.32376098632812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02127072960138321,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16321023305257162,
      "backward_entropy": 0.13773822784423828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.44017028808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02134113200008869,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16297494371732077,
      "backward_entropy": 0.1287924289703369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.06303405761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021411914378404617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16273751854896545,
      "backward_entropy": 0.11134604215621949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.03294372558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021481139585375786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16250298420588175,
      "backward_entropy": 0.11087946891784668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.0450668334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02155555784702301,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1622584064801534,
      "backward_entropy": 0.11045660972595214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.2786865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021625470370054245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16202103098233542,
      "backward_entropy": 0.12808423042297362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.24305725097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021694840863347054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178381443023682,
      "backward_entropy": 0.10949908494949341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.40790557861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02176588401198387,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.161542276541392,
      "backward_entropy": 0.12770003080368042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.5553970336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02183394879102707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1613056759039561,
      "backward_entropy": 0.1274928331375122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.72088623046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021899251267313957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1610726316769918,
      "backward_entropy": 0.1079641580581665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.67494201660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021963084116578102,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1608408292134603,
      "backward_entropy": 0.13757387399673462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.204345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022024760022759438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16061274210611978,
      "backward_entropy": 0.10680515766143799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.41239929199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022087853401899338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16038119792938232,
      "backward_entropy": 0.12655164003372193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.62159729003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022147780284285545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16015567382176718,
      "backward_entropy": 0.10561192035675049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.40419006347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022207224741578102,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15993101398150125,
      "backward_entropy": 0.12602322101593016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.7930450439453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022267336025834084,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15970484415690103,
      "backward_entropy": 0.13739897012710572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.8925552368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02233031578361988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1594728430112203,
      "backward_entropy": 0.1255039930343628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.7039031982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022390171885490417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15924682219823202,
      "backward_entropy": 0.10323286056518555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.15773010253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022454185411334038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15901297330856323,
      "backward_entropy": 0.10267643928527832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.32049560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022520696744322777,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15877453486124674,
      "backward_entropy": 0.12473602294921875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.03112030029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022583508864045143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15854322910308838,
      "backward_entropy": 0.10155333280563354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.7776641845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022645441815257072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15831318497657776,
      "backward_entropy": 0.10095340013504028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.49041748046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022710030898451805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15807769695917764,
      "backward_entropy": 0.12393525838851929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2716064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022774675861001015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15784158309300741,
      "backward_entropy": 0.09978212118148803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.60166931152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02284071408212185,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15760316451390585,
      "backward_entropy": 0.12341172695159912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.10337829589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0229055043309927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15736663341522217,
      "backward_entropy": 0.12313776016235352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.23719787597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022970596328377724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15713017185529074,
      "backward_entropy": 0.0980251669883728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.84275817871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023035570979118347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15689278642336527,
      "backward_entropy": 0.12257905006408691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.48976135253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023097464814782143,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1566625734170278,
      "backward_entropy": 0.12227652072906495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.08058166503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02315635047852993,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15643823146820068,
      "backward_entropy": 0.12195273637771606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.18458557128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0232162456959486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15621290604273477,
      "backward_entropy": 0.09549282789230347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.3926010131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023276664316654205,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15598615010579428,
      "backward_entropy": 0.1213235855102539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.5386505126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023333454504609108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1557681163152059,
      "backward_entropy": 0.0941888451576233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.7362060546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023391179740428925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1555460790793101,
      "backward_entropy": 0.12065765857696534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.0430908203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023448653519153595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15532243251800537,
      "backward_entropy": 0.0928657054901123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.37956237792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023502178490161896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15510455767313638,
      "backward_entropy": 0.09214476346969605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.46002960205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023555893450975418,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1548855702082316,
      "backward_entropy": 0.1195894718170166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.62666702270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023610025644302368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15466631452242532,
      "backward_entropy": 0.0907190203666687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.43618774414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023659922182559967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15445675452550253,
      "backward_entropy": 0.11884304285049438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.16802978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023714037612080574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15423900882403055,
      "backward_entropy": 0.11848818063735962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.24185943603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02376943826675415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15401819348335266,
      "backward_entropy": 0.08864861726760864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.12586212158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02382497489452362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15379707018534342,
      "backward_entropy": 0.08796682357788085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.48711395263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023878414183855057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.153580904006958,
      "backward_entropy": 0.08727371692657471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.7887420654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02393140085041523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1533676485220591,
      "backward_entropy": 0.08660306930541992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.33131408691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023986944928765297,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15314855178197226,
      "backward_entropy": 0.08594400882720947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.6414031982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02404487505555153,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15292458732922873,
      "backward_entropy": 0.08530193567276001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.66265106201172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024105112999677658,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15269684791564941,
      "backward_entropy": 0.1362830638885498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.00575256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02416365034878254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15247181057929993,
      "backward_entropy": 0.08403730392456055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.17144775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024227827787399292,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15223683913548788,
      "backward_entropy": 0.11530433893203736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.27200317382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02429119311273098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15200375517209372,
      "backward_entropy": 0.08284156322479248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.95835876464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024354945868253708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15176993608474731,
      "backward_entropy": 0.08222087621688842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.7184600830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024415791034698486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1515431503454844,
      "backward_entropy": 0.11428091526031495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.38587188720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02447766624391079,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15131606658299765,
      "backward_entropy": 0.0809406042098999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.91929626464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02453571744263172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15109793345133463,
      "backward_entropy": 0.08028446435928345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.69850158691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024593690410256386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15088041623433432,
      "backward_entropy": 0.07962325811386109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.4524688720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024653974920511246,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15065927306811014,
      "backward_entropy": 0.13609092235565184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.60444641113281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024716345593333244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15043506026268005,
      "backward_entropy": 0.07837268114089965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.2285614013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024775782600045204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15021667877833048,
      "backward_entropy": 0.07771188616752625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.17294311523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024836156517267227,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14999703566233316,
      "backward_entropy": 0.11169841289520263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.2752456665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02489767037332058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14977723360061646,
      "backward_entropy": 0.11133553981781005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.5027084350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02495860494673252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14955843488375345,
      "backward_entropy": 0.07577489614486695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.2373046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025016935542225838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14934566617012024,
      "backward_entropy": 0.13595795631408691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.79576873779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025075241923332214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14913439750671387,
      "backward_entropy": 0.0743989884853363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.7835464477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025132490321993828,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1489259898662567,
      "backward_entropy": 0.10971438884735107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.4236831665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025186477228999138,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14872522155443826,
      "backward_entropy": 0.10926575660705566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.29092025756836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025239858776330948,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1485272248586019,
      "backward_entropy": 0.13578493595123292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.67105102539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02528897300362587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14833746353785196,
      "backward_entropy": 0.07153159379959106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.36646270751953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025342537090182304,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14814029137293497,
      "backward_entropy": 0.1356644630432129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.33464813232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02539648860692978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14794254302978516,
      "backward_entropy": 0.10740346908569336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.38753509521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025448555126786232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14774900674819946,
      "backward_entropy": 0.0693728506565094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.67346954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025501392781734467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14755537112553915,
      "backward_entropy": 0.06865822672843933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.25250244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02555367723107338,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14736366271972656,
      "backward_entropy": 0.06793293952941895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.4620246887207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02560342662036419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14717909693717957,
      "backward_entropy": 0.06720966100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.72068786621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025649702176451683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14700310428937277,
      "backward_entropy": 0.10496193170547485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.09226989746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025698373094201088,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1468227207660675,
      "backward_entropy": 0.13527870178222656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.24115753173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025746898725628853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14664287368456522,
      "backward_entropy": 0.06499886512756348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.44088745117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02579517476260662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14646359284718832,
      "backward_entropy": 0.10339996814727784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.89412689208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025846946984529495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1462784210840861,
      "backward_entropy": 0.06355265378952027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.90131378173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025896115228533745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14609983563423157,
      "backward_entropy": 0.06282602548599243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.19497680664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025947725400328636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14591903487841287,
      "backward_entropy": 0.06214818954467773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.58850860595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02600371651351452,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14573202530543009,
      "backward_entropy": 0.10146158933639526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.65399932861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026059048250317574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1455475091934204,
      "backward_entropy": 0.10101120471954346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.7889404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02611467055976391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.145362655321757,
      "backward_entropy": 0.06024590730667114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.66294860839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026174113154411316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1451720396677653,
      "backward_entropy": 0.05962971448898315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.63333129882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02623271383345127,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14498559633890787,
      "backward_entropy": 0.09966816902160644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.32789611816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026288187131285667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14480684200922647,
      "backward_entropy": 0.09919496774673461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.241607666015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026346415281295776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14462425311406454,
      "backward_entropy": 0.05778008699417114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.24662399291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026400256901979446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14445058504740396,
      "backward_entropy": 0.09825924634933472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.87789154052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02645009756088257,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14428462584813437,
      "backward_entropy": 0.05643616914749146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.55880737304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026502665132284164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14411747455596924,
      "backward_entropy": 0.055811595916748044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.10704040527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02656080201268196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14394344886144003,
      "backward_entropy": 0.05525748729705811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.59964752197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026617059484124184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14377417167027792,
      "backward_entropy": 0.05468024611473084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.86537170410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026672644540667534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14360694090525308,
      "backward_entropy": 0.05408765077590942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.9020004272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026729999110102654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14343814055124918,
      "backward_entropy": 0.053514957427978516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.1580581665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026786716654896736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1432721217473348,
      "backward_entropy": 0.09499276876449585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.66471099853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026843104511499405,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14310959974924722,
      "backward_entropy": 0.09454120397567749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.14381408691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026896368712186813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.142951766649882,
      "backward_entropy": 0.05178492069244385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.06813049316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026949496939778328,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.142796258131663,
      "backward_entropy": 0.05119363665580749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.40030670166016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026999972760677338,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14264538884162903,
      "backward_entropy": 0.1346881866455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.95899963378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027048302814364433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1424998641014099,
      "backward_entropy": 0.04994234144687652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.83154296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027099281549453735,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14235190550486246,
      "backward_entropy": 0.09199213981628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.45361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02715260349214077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14220192035039267,
      "backward_entropy": 0.04877430200576782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.03575897216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027208101004362106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14205034573872885,
      "backward_entropy": 0.048223716020584104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.4637451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02726326882839203,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1419005493323008,
      "backward_entropy": 0.047673916816711424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.9783172607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02732066810131073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1417505145072937,
      "backward_entropy": 0.09012187123298646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.710140228271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027385471388697624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14159125089645386,
      "backward_entropy": 0.046723169088363645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.18463134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02744426764547825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1414418121178945,
      "backward_entropy": 0.08933216333389282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.0267448425293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027503563091158867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14129332701365152,
      "backward_entropy": 0.08889588117599487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.82490539550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027558768168091774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14115277926127115,
      "backward_entropy": 0.045174640417098996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.56310272216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027613680809736252,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14101394017537436,
      "backward_entropy": 0.08793990015983581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.03807067871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02766946516931057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1408749222755432,
      "backward_entropy": 0.04412155151367188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.06367492675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027727268636226654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1407349705696106,
      "backward_entropy": 0.04362185299396515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.90999984741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02778461202979088,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1405978004137675,
      "backward_entropy": 0.08658349514007568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.28367614746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02783833257853985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14046900471051535,
      "backward_entropy": 0.04261876940727234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.8028793334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027895329520106316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14033534129460654,
      "backward_entropy": 0.08566792011260986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.39168548583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027951784431934357,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1402033567428589,
      "backward_entropy": 0.041652601957321164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.25807189941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028006840497255325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14007513721783957,
      "backward_entropy": 0.084747052192688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.96900177001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028061626479029655,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13994792103767395,
      "backward_entropy": 0.08426225781440735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.36360931396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028118710964918137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13982051610946655,
      "backward_entropy": 0.08379955291748047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.693603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028174085542559624,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13969520727793375,
      "backward_entropy": 0.08331170082092285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.17000579833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028234954923391342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1395646333694458,
      "backward_entropy": 0.08288284540176391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.85078430175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0282951220870018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1394367218017578,
      "backward_entropy": 0.0824430227279663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.70708465576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028354717418551445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13931125402450562,
      "backward_entropy": 0.038358211517333984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.39654541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028413763269782066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1391881505648295,
      "backward_entropy": 0.08153865337371827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.25237274169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02847004123032093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13906984527905783,
      "backward_entropy": 0.037443962693214414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.10865783691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028526127338409424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.138953427473704,
      "backward_entropy": 0.08056578040122986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.30084991455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028582008555531502,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13883868853251138,
      "backward_entropy": 0.0800743579864502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.86302185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028636649250984192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1387267311414083,
      "backward_entropy": 0.03605546653270721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.68341064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028688933700323105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1386178731918335,
      "backward_entropy": 0.03557729125022888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.54791259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028740497305989265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.138512392838796,
      "backward_entropy": 0.03511104583740234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.433956146240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028797032311558723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13840311765670776,
      "backward_entropy": 0.03469468951225281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.18746185302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0288502536714077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13830082615216574,
      "backward_entropy": 0.07758722305297852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.8582534790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028902659192681313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13820147514343262,
      "backward_entropy": 0.03385595083236694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.27300262451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02895442582666874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13810507456461588,
      "backward_entropy": 0.033445891737937924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.07962799072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029006581753492355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1380089521408081,
      "backward_entropy": 0.07610023021697998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.37043762207031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029060382395982742,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1379129191239675,
      "backward_entropy": 0.03265740275382996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.08433532714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02911340445280075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13781962792078653,
      "backward_entropy": 0.075160151720047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.691184997558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02917022444307804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1377235253651937,
      "backward_entropy": 0.03192925751209259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.74445343017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029223676770925522,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1376326084136963,
      "backward_entropy": 0.13457956314086914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.73114013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02927398681640625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13754566510518393,
      "backward_entropy": 0.031175833940505982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.1153793334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02932140603661537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13746166229248047,
      "backward_entropy": 0.03076712489128113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.64372253417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029373114928603172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13737380504608154,
      "backward_entropy": 0.03039126992225647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.44894409179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02942880615592003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1372844179471334,
      "backward_entropy": 0.030049890279769897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.14332580566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02949032001197338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13719030221303305,
      "backward_entropy": 0.07196812629699707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.84880065917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029551340267062187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13709739844004312,
      "backward_entropy": 0.07159155607223511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.53770446777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029611963778734207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.137006143728892,
      "backward_entropy": 0.029144930839538574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.64534378051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02967558242380619,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1369128624598185,
      "backward_entropy": 0.07084940075874328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.12076568603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029735129326581955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13682415088017783,
      "backward_entropy": 0.02853676676750183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.987545013427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02979552373290062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1367353399594625,
      "backward_entropy": 0.028223967552185057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.919105529785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02985348366200924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13665086030960083,
      "backward_entropy": 0.06961373090744019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.03278350830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029909193515777588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1365697185198466,
      "backward_entropy": 0.027576917409896852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.02660369873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029967373237013817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13648748397827148,
      "backward_entropy": 0.027267250418663024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.97148513793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030026618391275406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1364051898320516,
      "backward_entropy": 0.02696477472782135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.89268493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03008120320737362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1363277236620585,
      "backward_entropy": 0.026636409759521484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.89765930175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03013603202998638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13624995946884155,
      "backward_entropy": 0.02630729377269745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.07065200805664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03019346110522747,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361709932486216,
      "backward_entropy": 0.06702483892440796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.74338722229004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030248641967773438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13609411319096884,
      "backward_entropy": 0.06658082604408264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.72901916503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030298590660095215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602310419082642,
      "backward_entropy": 0.025335651636123658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.26459503173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030349500477313995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13595362504323324,
      "backward_entropy": 0.06561614871025086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.64029312133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0304022915661335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588268558184305,
      "backward_entropy": 0.06515994071960449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.233097076416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030452389270067215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135815699895223,
      "backward_entropy": 0.06468503475189209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.42826843261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030501054599881172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13574979702631632,
      "backward_entropy": 0.02405879497528076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.86857223510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030551964417099953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356834669907888,
      "backward_entropy": 0.023756548762321472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.8614273071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03060142882168293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13561866680781046,
      "backward_entropy": 0.06328277587890625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.14859390258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030655328184366226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355533798535665,
      "backward_entropy": 0.023175033926963805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.76638412475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030706359073519707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13548892736434937,
      "backward_entropy": 0.022885623574256896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.14798355102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03075502999126911,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1354276736577352,
      "backward_entropy": 0.022596675157546996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.19430923461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03080260381102562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13536773125330606,
      "backward_entropy": 0.06152979731559753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.06254959106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030847033485770226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353116830190023,
      "backward_entropy": 0.061049389839172366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.37245178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030888676643371582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13525905211766562,
      "backward_entropy": 0.021709713339805602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.45999908447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030932173132896423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1352049708366394,
      "backward_entropy": 0.06008015871047974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.43212127685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030978478491306305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13514925042788187,
      "backward_entropy": 0.02115282267332077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.9384536743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031028496101498604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1350919802983602,
      "backward_entropy": 0.020908558368682863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.2317123413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03108074702322483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13503390550613403,
      "backward_entropy": 0.05889638662338257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.7652816772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031132837757468224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13497676452000937,
      "backward_entropy": 0.02045937776565552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.17362976074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031187960878014565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13491769631703696,
      "backward_entropy": 0.02024846524000168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.82396697998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031244860962033272,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13485892613728842,
      "backward_entropy": 0.020054122805595397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.89757537841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031302232295274734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1348004142443339,
      "backward_entropy": 0.019864079356193543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.996612548828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031362127512693405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13473995526631674,
      "backward_entropy": 0.019679880142211913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.02569580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03141671046614647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13468432426452637,
      "backward_entropy": 0.01947527676820755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.9891357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0314687080681324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1346312165260315,
      "backward_entropy": 0.056615525484085084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.816061973571777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03151940926909447,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13457898298899332,
      "backward_entropy": 0.05624144077301026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.69706153869629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031564611941576004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13453098138173422,
      "backward_entropy": 0.01881040185689926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.16320037841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03160602226853371,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13448586066563925,
      "backward_entropy": 0.01856853663921356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.88834381103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03165280073881149,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13443789879480997,
      "backward_entropy": 0.055031108856201175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.57315826416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03170441463589668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13438784082730612,
      "backward_entropy": 0.01816077083349228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.6444091796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03176040202379227,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1343354880809784,
      "backward_entropy": 0.13501291275024413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.38236999511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031818050891160965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13428147633870444,
      "backward_entropy": 0.05414628982543945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.5943832397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03187720105051994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13422646125157675,
      "backward_entropy": 0.017660781741142273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.76507568359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031939998269081116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1341706116994222,
      "backward_entropy": 0.05366201400756836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.02800750732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032003872096538544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1341149608294169,
      "backward_entropy": 0.017378784716129303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.852294921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032066553831100464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13406081994374594,
      "backward_entropy": 0.017241112887859344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.38321685791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03212812542915344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13400848706563315,
      "backward_entropy": 0.01709972620010376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.30591583251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03218970447778702,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1339541474978129,
      "backward_entropy": 0.016948440670967103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.58491897583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03225356340408325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13389946023623148,
      "backward_entropy": 0.05251948237419128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.80659866333008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03231518343091011,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13384738564491272,
      "backward_entropy": 0.05226491093635559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.329750061035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032373759895563126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1337986389795939,
      "backward_entropy": 0.05199729204177857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.631595611572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032430533319711685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1337502400080363,
      "backward_entropy": 0.016344156861305238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.93155670166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032486818730831146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13370224833488464,
      "backward_entropy": 0.01618206351995468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.308719635009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03254372999072075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1336534023284912,
      "backward_entropy": 0.016020867228507995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.25191497802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03259805589914322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13360613584518433,
      "backward_entropy": 0.015855842828750612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.20494079589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03265545144677162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13355916738510132,
      "backward_entropy": 0.01570475548505783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.03492736816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032713454216718674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13351275523503622,
      "backward_entropy": 0.05028433799743652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.6648178100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03277193382382393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13346529006958008,
      "backward_entropy": 0.015415306389331817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.78849792480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032831039279699326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1334193249543508,
      "backward_entropy": 0.015282022953033447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.47905731201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03289169445633888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13337325056393942,
      "backward_entropy": 0.049532949924468994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.12006950378418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03294947370886803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13332964976628622,
      "backward_entropy": 0.015027561783790588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.28197479248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03300359100103378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13328859210014343,
      "backward_entropy": 0.01489076167345047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.062705993652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033060744404792786,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13324515024820963,
      "backward_entropy": 0.04876812100410462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.097450256347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03311542794108391,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13320394357045492,
      "backward_entropy": 0.04850797057151794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.0391845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03316893056035042,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1331640879313151,
      "backward_entropy": 0.04824402928352356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.4435577392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033222466707229614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13312549392382303,
      "backward_entropy": 0.014370939135551453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.62213134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03328341618180275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1330836017926534,
      "backward_entropy": 0.014267359673976899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.40188980102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033342573791742325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1330427328745524,
      "backward_entropy": 0.0475473016500473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.310455322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03339802101254463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1330040693283081,
      "backward_entropy": 0.04729863405227661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.22098159790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03345116600394249,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.132966677347819,
      "backward_entropy": 0.013920752704143525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.84333038330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03350119665265083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1329313119252523,
      "backward_entropy": 0.013792440295219421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.93406295776367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03355269879102707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1328961948553721,
      "backward_entropy": 0.04648835659027099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.060302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03360234200954437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13286244869232178,
      "backward_entropy": 0.04621663391590118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.98377227783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03364819660782814,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13283058007558188,
      "backward_entropy": 0.04592638611793518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.921709060668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03369801864027977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1327958106994629,
      "backward_entropy": 0.04566513299942017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.46462631225586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03374408558011055,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13276368379592896,
      "backward_entropy": 0.13624712228775024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.332496643066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03378889337182045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1327322522799174,
      "backward_entropy": 0.045104536414146426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.01056671142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033832620829343796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13270241022109985,
      "backward_entropy": 0.04482454061508179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.50138092041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03387638181447983,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.132672647635142,
      "backward_entropy": 0.012825721502304077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.75833511352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03392544016242027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13264061013857523,
      "backward_entropy": 0.04432504177093506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.94660186767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033973973244428635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1326072613398234,
      "backward_entropy": 0.044100618362426756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.37541198730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03402416408061981,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13257241249084473,
      "backward_entropy": 0.012525498867034912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.9458999633789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03407692164182663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13253607352574667,
      "backward_entropy": 0.04370198845863342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.05311584472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034135181456804276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13249812523523966,
      "backward_entropy": 0.04354336857795715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.395118713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03419725224375725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13245745499928793,
      "backward_entropy": 0.01229325234889984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.25389862060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03425655514001846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13241881132125854,
      "backward_entropy": 0.012222678959369659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.62727737426758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0343133918941021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13238224387168884,
      "backward_entropy": 0.012148735672235489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.36341857910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03436901792883873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13234573602676392,
      "backward_entropy": 0.042908710241317746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.01177978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03442567586898804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1323100725809733,
      "backward_entropy": 0.012000002712011338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.13375473022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03448529168963432,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13227238257726034,
      "backward_entropy": 0.011933521926403045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.98324966430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03454345464706421,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13223589460055032,
      "backward_entropy": 0.042437827587127684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.82632064819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034600287675857544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1321995755036672,
      "backward_entropy": 0.011795156449079514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.95909881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03465282544493675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13216559092203775,
      "backward_entropy": 0.01171828955411911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.23613739013672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03470567613840103,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.132132887840271,
      "backward_entropy": 0.13676137924194337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.35160064697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03475674241781235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1321016550064087,
      "backward_entropy": 0.011571630090475082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.64955139160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03481133654713631,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13206847508748373,
      "backward_entropy": 0.1368154764175415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.87107467651367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034867048263549805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1320342222849528,
      "backward_entropy": 0.011442525684833527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.75529098510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03492069989442825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13200136025746664,
      "backward_entropy": 0.011377653479576111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.38555908203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03497248888015747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13196919361750284,
      "backward_entropy": 0.011311013996601105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.81196212768555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03502053767442703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1319388449192047,
      "backward_entropy": 0.04092984199523926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.76875305175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035070404410362244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13190826773643494,
      "backward_entropy": 0.04076795279979706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.29069519042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03512392193078995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13187466065088907,
      "backward_entropy": 0.011115052551031113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.155197143554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03517560660839081,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13184193770090738,
      "backward_entropy": 0.011053112894296646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.05693817138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03522462770342827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13181078433990479,
      "backward_entropy": 0.010988145321607589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.017126083374023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03527228161692619,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13177997867266336,
      "backward_entropy": 0.040161889791488645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.77492141723633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03531668335199356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13175185521443686,
      "backward_entropy": 0.010853724926710129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.55824661254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03536121919751167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13172378142674765,
      "backward_entropy": 0.03981896340847015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.39850616455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035406894981861115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13169475396474203,
      "backward_entropy": 0.039655801653862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.089149475097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03545361012220383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13166499137878418,
      "backward_entropy": 0.03949991464614868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.409358978271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035502295941114426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13163395722707114,
      "backward_entropy": 0.03935944139957428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.2940788269043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03554969280958176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13160312175750732,
      "backward_entropy": 0.010540201514959335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.635297775268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03559594973921776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13157341877619425,
      "backward_entropy": 0.010481688380241393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.59463119506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03563913702964783,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13154568274815878,
      "backward_entropy": 0.03891668021678925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.7101936340332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03568363934755325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13151698311169943,
      "backward_entropy": 0.010362550616264343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.880680084228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0357283279299736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1314879059791565,
      "backward_entropy": 0.03862711191177368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.098684310913086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035772163420915604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13145957390467325,
      "backward_entropy": 0.010251782089471816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.33000564575195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03581422567367554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13143259286880493,
      "backward_entropy": 0.038337346911430356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.951801300048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035856734961271286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13140563170115152,
      "backward_entropy": 0.03819761872291565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.90323638916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03589760512113571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1313790480295817,
      "backward_entropy": 0.010090411454439164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.11943817138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035942092537879944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1313503384590149,
      "backward_entropy": 0.010043458640575409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.824989318847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03598882257938385,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13131999969482422,
      "backward_entropy": 0.13721508979797364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.79853057861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03603554517030716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13128920396169028,
      "backward_entropy": 0.009957585483789444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.04070281982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036086305975914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13125556707382202,
      "backward_entropy": 0.03762176036834717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.863346099853516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03613969311118126,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13122135400772095,
      "backward_entropy": 0.1372917413711548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.120304107666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036193426698446274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13118715087572733,
      "backward_entropy": 0.009858554601669312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.31192016601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036248479038476944,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13115179538726807,
      "backward_entropy": 0.03738760352134705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.303855895996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03630571439862251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13111541668574014,
      "backward_entropy": 0.009806559979915619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.45615768432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0363629050552845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1310787002245585,
      "backward_entropy": 0.009782452881336213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.60523223876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03642105311155319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13104130824406943,
      "backward_entropy": 0.00975942388176918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.72626876831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036478061228990555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13100457191467285,
      "backward_entropy": 0.009735384583473205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.037479400634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03653503581881523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13096842169761658,
      "backward_entropy": 0.009712260961532593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.5672607421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036589980125427246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13093348344167074,
      "backward_entropy": 0.009687179327011108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.414348602294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03664609417319298,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1308977206548055,
      "backward_entropy": 0.036929449439048766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.51128578186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03669826313853264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13086428244908652,
      "backward_entropy": 0.009635959565639497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.555721282958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03674788773059845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1308319866657257,
      "backward_entropy": 0.036765220761299136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.65018081665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03679622337222099,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1308000385761261,
      "backward_entropy": 0.009572641551494598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.482601165771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036845386028289795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1307672361532847,
      "backward_entropy": 0.036589807271957396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.31494140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03689529746770859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.130733589331309,
      "backward_entropy": 0.009510824829339981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.14155197143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03694586828351021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13069977362950644,
      "backward_entropy": 0.009482336044311524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.9235610961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03699703887104988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13066531221071878,
      "backward_entropy": 0.03634721338748932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.947249412536621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037052690982818604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13062888383865356,
      "backward_entropy": 0.03628372848033905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.603092193603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03710447624325752,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13059418400128683,
      "backward_entropy": 0.03621024787425995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.42752456665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037156738340854645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13055896759033203,
      "backward_entropy": 0.009383583068847656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.507787704467773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037209413945674896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1305235226949056,
      "backward_entropy": 0.009359999001026154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.072635650634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037260502576828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13048887252807617,
      "backward_entropy": 0.009335263073444367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.897491455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03731213137507439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13045364618301392,
      "backward_entropy": 0.03592544198036194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.50220489501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03736424446105957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13041790326436362,
      "backward_entropy": 0.009288877248764038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.530318260192871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03741776943206787,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1303807497024536,
      "backward_entropy": 0.03579604625701904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.921171188354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037467654794454575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1303461194038391,
      "backward_entropy": 0.009243348240852356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.50492477416992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03751622512936592,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1303123732407888,
      "backward_entropy": 0.009218497574329377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.367855072021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03756460174918175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13027828931808472,
      "backward_entropy": 0.009193680435419082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.15373992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03761279955506325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13024426500002542,
      "backward_entropy": 0.03550372719764709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.4769344329834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03766376152634621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13020757834116617,
      "backward_entropy": 0.009147146344184875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.11197280883789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03771327808499336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13017270962397257,
      "backward_entropy": 0.009124533832073211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.464073181152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03776444494724274,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13013686736424765,
      "backward_entropy": 0.035297286510467527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.16653060913086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0378180555999279,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13009877999623617,
      "backward_entropy": 0.03523463010787964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.48129653930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03787195309996605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13005956013997397,
      "backward_entropy": 0.03517591655254364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.1908950805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03792704641819,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1300192872683207,
      "backward_entropy": 0.009049209207296372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.739458084106445,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037985119968652725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1299768090248108,
      "backward_entropy": 0.13803012371063234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.00954818725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03804107382893562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1299355427424113,
      "backward_entropy": 0.03501361906528473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.85615921020508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038096096366643906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1298942764600118,
      "backward_entropy": 0.009001146256923675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.0312557220459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03815025836229324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12985319892565408,
      "backward_entropy": 0.008984045684337616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.865821838378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03820168972015381,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12981478373209634,
      "backward_entropy": 0.034843331575393675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.851337432861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038253553211688995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12977641820907593,
      "backward_entropy": 0.034784096479415896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.267086029052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038302935659885406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12973934412002563,
      "backward_entropy": 0.008929899334907532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.90489387512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03835200518369675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12970236937204996,
      "backward_entropy": 0.034655523300170896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.405021667480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0383998267352581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12966614961624146,
      "backward_entropy": 0.00889194682240486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.02782440185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038444604724645615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12963241338729858,
      "backward_entropy": 0.008871246129274368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.727073669433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03849049285054207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12959730625152588,
      "backward_entropy": 0.008851901441812516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.71111297607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03853641450405121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1295618216196696,
      "backward_entropy": 0.008832971006631852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.551082611083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03858331963419914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1295253038406372,
      "backward_entropy": 0.008815179765224456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.38735580444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03863108903169632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1294878919919332,
      "backward_entropy": 0.008798020333051682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.286319732666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03867962211370468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12944987416267395,
      "backward_entropy": 0.008781180530786515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.036251068115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038730744272470474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12940953175226846,
      "backward_entropy": 0.03413917422294617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.98779821395874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03878135606646538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1293689509232839,
      "backward_entropy": 0.03408013880252838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.857961654663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038827717304229736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12933199604352316,
      "backward_entropy": 0.008733299374580384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.858004570007324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03887215256690979,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12929685910542807,
      "backward_entropy": 0.03394869565963745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.710466384887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03891390189528465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12926408648490906,
      "backward_entropy": 0.033879607915878296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.39120864868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03895415738224983,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1292329728603363,
      "backward_entropy": 0.008678227663040161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.416688919067383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038994960486888885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1292017102241516,
      "backward_entropy": 0.03373695611953735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.97422409057617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03903534635901451,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12916998068491617,
      "backward_entropy": 0.008642486482858657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.83035659790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03907729685306549,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1291357676188151,
      "backward_entropy": 0.008627232909202576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.236820220947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0391206257045269,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12909972667694092,
      "backward_entropy": 0.00861339047551155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.77049255371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03916706517338753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12906036774317423,
      "backward_entropy": 0.008601851761341095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.458788871765137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03921343386173248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12902098894119263,
      "backward_entropy": 0.00859033763408661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.20782470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039256948977708817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12898423274358115,
      "backward_entropy": 0.008578083664178848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.04929733276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03930163010954857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12894616524378458,
      "backward_entropy": 0.00856662392616272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.53910446166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039347391575574875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1289065678914388,
      "backward_entropy": 0.00855640321969986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.487455368041992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03939502686262131,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1288649042447408,
      "backward_entropy": 0.03326862752437591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.78408432006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0394415445625782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12882423400878906,
      "backward_entropy": 0.008538047224283219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.540428161621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039486151188611984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1287850042184194,
      "backward_entropy": 0.008528869599103928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.781436920166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03953367471694946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12874255577723184,
      "backward_entropy": 0.008521462976932525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.032007217407227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039582882076501846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12869810064633688,
      "backward_entropy": 0.00851501226425171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.46370506286621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03962891548871994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12865694363911948,
      "backward_entropy": 0.008507024496793747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.754600524902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03967300429940224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12861794233322144,
      "backward_entropy": 0.033024963736534116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.599369049072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039718203246593475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12857725222905478,
      "backward_entropy": 0.008489512652158738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.821266174316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03976435959339142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12853528062502542,
      "backward_entropy": 0.00848185494542122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.907468795776367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03980763629078865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12849650780359903,
      "backward_entropy": 0.008472795784473418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.195430755615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039851125329732895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12845714886983237,
      "backward_entropy": 0.008463963121175765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.337162971496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03989850729703903,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12841316064198813,
      "backward_entropy": 0.0328086256980896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.91398811340332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039941977709531784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12837348381678262,
      "backward_entropy": 0.008448633551597595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.839948654174805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03998377174139023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12833545605341592,
      "backward_entropy": 0.008439578860998154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.513761520385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04002406448125839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1282988985379537,
      "backward_entropy": 0.00843031331896782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.4708890914917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04006211459636688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1282647649447123,
      "backward_entropy": 0.008421139419078827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.056241989135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04009811952710152,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1282328963279724,
      "backward_entropy": 0.00841161385178566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.383095741271973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040135059505701065,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12819947799046835,
      "backward_entropy": 0.008403167873620988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.677982330322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0401700921356678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12816784779230753,
      "backward_entropy": 0.00839485451579094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.74007797241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0402052216231823,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1281360387802124,
      "backward_entropy": 0.008387087285518647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.38426399230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04024137556552887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12810254096984863,
      "backward_entropy": 0.008380603790283204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.424814224243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04027659818530083,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12806998689969382,
      "backward_entropy": 0.0323344737291336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.50955581665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04031192511320114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12803693612416586,
      "backward_entropy": 0.032293713092803954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.68482208251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04034915566444397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12800131241480509,
      "backward_entropy": 0.03225595951080322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.259422302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040392663329839706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12795782089233398,
      "backward_entropy": 0.008361586928367614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.046127319335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040438178926706314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12791135907173157,
      "backward_entropy": 0.0322037935256958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.959901809692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040482744574546814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1278657615184784,
      "backward_entropy": 0.00835985317826271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.925614356994629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04052550718188286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.127822478612264,
      "backward_entropy": 0.032150769233703615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.680097579956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04056575521826744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12778224547704062,
      "backward_entropy": 0.008355285972356796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.471397399902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04060649499297142,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1277408997217814,
      "backward_entropy": 0.03208991885185242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.781170845031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040648575872182846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1276974081993103,
      "backward_entropy": 0.032063379883766174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.59639549255371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040688201785087585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1276569366455078,
      "backward_entropy": 0.008350106328725815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.88896560668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04072653874754906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12761789560317993,
      "backward_entropy": 0.008347830921411514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.273714065551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040767326951026917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12757531801859537,
      "backward_entropy": 0.008346304297447205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.385717391967773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04080759361386299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12753325700759888,
      "backward_entropy": 0.008344433456659316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.316404342651367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04084650054574013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12749265631039938,
      "backward_entropy": 0.03191160559654236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.742477416992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04088418930768967,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1274533967177073,
      "backward_entropy": 0.008340327441692353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.63150978088379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0409226156771183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12741263707478842,
      "backward_entropy": 0.008339467644691467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.920108795166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04096165671944618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12737067540486655,
      "backward_entropy": 0.008338813483715058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.716032028198242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0410030297935009,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12732526659965515,
      "backward_entropy": 0.031779274344444275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.967580795288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04104384779930115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1272804538408915,
      "backward_entropy": 0.008339094370603562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.16046142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04108325019478798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12723716100056967,
      "backward_entropy": 0.008339354395866394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.64725875854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041123103350400925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12719311316808066,
      "backward_entropy": 0.008338727056980133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.337297439575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04116429388523102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12714680035909018,
      "backward_entropy": 0.00833686739206314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.91580581665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041204895824193954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12710118293762207,
      "backward_entropy": 0.008335090428590774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.20505905151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04124763235449791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.127052108446757,
      "backward_entropy": 0.031571227312088015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.528350830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04129141941666603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12700113654136658,
      "backward_entropy": 0.008333266526460648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.938018798828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041333504021167755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12695215145746866,
      "backward_entropy": 0.008333290368318558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.380685806274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041374895721673965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12690393129984537,
      "backward_entropy": 0.031473520398139956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.181081771850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041414812207221985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1268573304017385,
      "backward_entropy": 0.03144181966781616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.828542709350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04145510867238045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12680999437967935,
      "backward_entropy": 0.008333489298820496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.562572479248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04149314761161804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12676562865575156,
      "backward_entropy": 0.03137481510639191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.203765869140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04153084009885788,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12672168016433716,
      "backward_entropy": 0.008333003520965577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.72139549255371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04156999662518501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12667524814605713,
      "backward_entropy": 0.008332014083862305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.243751525878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04160960018634796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1266278624534607,
      "backward_entropy": 0.00833105742931366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.06790542602539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04165131226181984,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.126577099164327,
      "backward_entropy": 0.1384551167488098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.88684844970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04169497266411781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12652293841044107,
      "backward_entropy": 0.008328556269407272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.70089340209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04174037650227547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1264654298623403,
      "backward_entropy": 0.008328214287757874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.291213989257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041787292808294296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12640565633773804,
      "backward_entropy": 0.008327412605285644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.37828254699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04183473065495491,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12634454170862833,
      "backward_entropy": 0.008326956629753112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.484216690063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041879210621118546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1262874205907186,
      "backward_entropy": 0.008327525854110718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.680377960205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041921913623809814,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12623242537180582,
      "backward_entropy": 0.03100089430809021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.20569610595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041964657604694366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12617701292037964,
      "backward_entropy": 0.008331401646137238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.331785202026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042012643069028854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12611267964045206,
      "backward_entropy": 0.00833418220281601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.48982620239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0420592799782753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12605013449986777,
      "backward_entropy": 0.008336848765611648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.128345489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04210894554853439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12598235408465067,
      "backward_entropy": 0.03088313341140747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.97444152832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042157966643571854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1259150505065918,
      "backward_entropy": 0.00834118202328682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.76962661743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04220810905098915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12584526340166727,
      "backward_entropy": 0.00834423154592514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.619991302490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04225922375917435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12577329079310098,
      "backward_entropy": 0.03079923093318939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.54006576538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0423104502260685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12570015589396158,
      "backward_entropy": 0.030779603123664855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.01915740966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04236077889800072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.125628133614858,
      "backward_entropy": 0.008356936275959015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.394662857055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0424128882586956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12555245558420816,
      "backward_entropy": 0.030733752250671386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.092424392700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04246314987540245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12547953923543295,
      "backward_entropy": 0.008365320414304734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.737714767456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04251261055469513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.125407874584198,
      "backward_entropy": 0.00836864709854126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.320167541503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04256211966276169,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1253359615802765,
      "backward_entropy": 0.030648979544639587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.195021629333496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04261253774166107,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12526211142539978,
      "backward_entropy": 0.030613863468170167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.61654281616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04266048222780228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12519209583600363,
      "backward_entropy": 0.030581140518188478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.023198127746582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042710307985544205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1251179575920105,
      "backward_entropy": 0.00837339535355568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.584383010864258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042757708579301834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1250475843747457,
      "backward_entropy": 0.03051516115665436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.630093097686768,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04280373454093933,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12497933705647786,
      "backward_entropy": 0.138519024848938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.194825172424316,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042845938354730606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12491826216379802,
      "backward_entropy": 0.008378738164901733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.286436080932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042885586619377136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12486126025517781,
      "backward_entropy": 0.008379743248224259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.37611389160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04292456805706024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12480516235033672,
      "backward_entropy": 0.00838022232055664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.618070602416992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04296628013253212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1247432033220927,
      "backward_entropy": 0.008380864560604096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.00076675415039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043007928878068924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1246808369954427,
      "backward_entropy": 0.030295801162719727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.430726051330566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04304865002632141,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12461959322293599,
      "backward_entropy": 0.008379614353179932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.709402084350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04308773949742317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12456158796946208,
      "backward_entropy": 0.03020486533641815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.290562629699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043127842247486115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12450165549914043,
      "backward_entropy": 0.008376971632242203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.820914268493652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04316636919975281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12444390853246053,
      "backward_entropy": 0.008375570178031921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.539714813232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043202612549066544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12439073125521342,
      "backward_entropy": 0.008372928202152252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.53631019592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04323847219347954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12433777252833049,
      "backward_entropy": 0.030009430646896363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.70271873474121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04327641800045967,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12428027391433716,
      "backward_entropy": 0.00836668610572815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.272890090942383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0433146134018898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12422176202138265,
      "backward_entropy": 0.00836310237646103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.475549697875977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04335225000977516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12416376670201619,
      "backward_entropy": 0.008360209316015244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.633708953857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043390218168497086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12410445014635722,
      "backward_entropy": 0.029797202348709105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.251569747924805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043429285287857056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12404195467631023,
      "backward_entropy": 0.008357996493577958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.13398551940918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0434684194624424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12397925059000652,
      "backward_entropy": 0.02970074415206909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.21824073791504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0435076542198658,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12391600012779236,
      "backward_entropy": 0.008354328572750092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.365619659423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04354779049754143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1238502065340678,
      "backward_entropy": 0.1385184645652771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.94209861755371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04358556121587753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12378887335459392,
      "backward_entropy": 0.008352375030517578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.670902252197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04362434521317482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12372493743896484,
      "backward_entropy": 0.008351805061101914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231751441955566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04366328567266464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12365998824437459,
      "backward_entropy": 0.029456785321235655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.361370086669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043699897825717926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12360000610351562,
      "backward_entropy": 0.008351988345384597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.274824142456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0437360443174839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12354043126106262,
      "backward_entropy": 0.008352144062519074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.323455810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04377179592847824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12348127365112305,
      "backward_entropy": 0.008353615552186966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.168426513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043809592723846436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1234167218208313,
      "backward_entropy": 0.029280579090118407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.0064697265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04384918883442879,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12334736188252766,
      "backward_entropy": 0.13851985931396485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.915141105651855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04388883709907532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12327724695205688,
      "backward_entropy": 0.008364009857177734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.918501853942871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04392770305275917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12320834398269653,
      "backward_entropy": 0.02917760908603668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.739896774291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04396427422761917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12314448753992717,
      "backward_entropy": 0.008373419940471648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.652475357055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0440002903342247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12308166424433391,
      "backward_entropy": 0.029107487201690672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.458480834960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044035885483026505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1230191985766093,
      "backward_entropy": 0.00838097557425499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.35112953186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04407185688614845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12295518318812053,
      "backward_entropy": 0.008385159075260162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.39873218536377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04410821199417114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12288970748583476,
      "backward_entropy": 0.02900831401348114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.31291675567627,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04414409026503563,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12282472848892212,
      "backward_entropy": 0.13852773904800414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.232468605041504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044179584830999374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12275983889897664,
      "backward_entropy": 0.00840458869934082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.578355312347412,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0442146435379982,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12269566456476848,
      "backward_entropy": 0.008411663770675658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.072680473327637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044247858226299286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12263528505961101,
      "backward_entropy": 0.008420891314744949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.99377727508545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044280849397182465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12257516384124756,
      "backward_entropy": 0.008429330587387086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.91932487487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04431368410587311,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12251478433609009,
      "backward_entropy": 0.008438176661729812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.54960060119629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04434630274772644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12245468298594157,
      "backward_entropy": 0.028852930665016173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.451679229736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04437950626015663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12239265441894531,
      "backward_entropy": 0.028828537464141844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.023212432861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0444132462143898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12232877810796101,
      "backward_entropy": 0.008458730578422547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.252641677856445,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04444815590977669,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12226162354151408,
      "backward_entropy": 0.1385400652885437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.026180267333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04448334872722626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12219373385111491,
      "backward_entropy": 0.008464650809764862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.223227024078369,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04452115669846535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12211830417315166,
      "backward_entropy": 0.008466504514217377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.76508903503418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044556695967912674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1220485270023346,
      "backward_entropy": 0.028656047582626343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1437296867370605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04459094628691673,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1219817300637563,
      "backward_entropy": 0.028615662455558778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.457244873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04462320730090141,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12192048629124959,
      "backward_entropy": 0.00846833512187004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.62326431274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0446598157286644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12184691429138184,
      "backward_entropy": 0.00846717283129692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.018972396850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04469668120145798,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1217714250087738,
      "backward_entropy": 0.02848609387874603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.453564643859863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04473287984728813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12169737617174785,
      "backward_entropy": 0.028449350595474245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.476245164871216,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04476773738861084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12162646651268005,
      "backward_entropy": 0.0284135103225708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.777502059936523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0447997972369194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12156331539154053,
      "backward_entropy": 0.008475305885076523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4351532459259033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04483164846897125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12150029341379802,
      "backward_entropy": 0.0084763303399086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.03818702697754,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04486110433936119,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12144358952840169,
      "backward_entropy": 0.13854033946990968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.338069915771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0448913648724556,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12138401468594869,
      "backward_entropy": 0.02825857698917389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.118408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044923052191734314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12132000923156738,
      "backward_entropy": 0.008482906967401505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.417462348937988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044953860342502594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12125792105992635,
      "backward_entropy": 0.008486033231019974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.343732833862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044984541833400726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12119585275650024,
      "backward_entropy": 0.008488675206899643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.580690383911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04501732066273689,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12112730741500854,
      "backward_entropy": 0.028108739852905275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.188966751098633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04505055770277977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12105658650398254,
      "backward_entropy": 0.008492478728294372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.114029884338379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045083481818437576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12098652124404907,
      "backward_entropy": 0.008496104925870895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.551645278930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045116063207387924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12091686328252156,
      "backward_entropy": 0.008499439060688018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.723297119140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04514973983168602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12084369858105977,
      "backward_entropy": 0.008500709384679794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.751235961914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045182257890701294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12077354391415913,
      "backward_entropy": 0.008502145111560822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.191621780395508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04521740600466728,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12069509426752727,
      "backward_entropy": 0.027885138988494873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.366564750671387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04525353014469147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12061238288879395,
      "backward_entropy": 0.02785141170024872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.261058807373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04528750851750374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12053592999776204,
      "backward_entropy": 0.027819213271141053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.824417114257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045323967933654785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12045119206110637,
      "backward_entropy": 0.008513272553682328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.12957763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045361150056123734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12036363283793132,
      "backward_entropy": 0.008517184108495713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.575990676879883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04539532959461212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1202852229277293,
      "backward_entropy": 0.008521024882793427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.527956008911133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04543047025799751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12020301818847656,
      "backward_entropy": 0.008525622636079788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.329833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045467182993888855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12011521061261494,
      "backward_entropy": 0.008531078696250916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.047545909881592,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04550452530384064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12002497911453247,
      "backward_entropy": 0.008535689115524292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.050835609436035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04553883895277977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11994420488675435,
      "backward_entropy": 0.00854010060429573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.9854097366333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04557182639837265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11986740430196126,
      "backward_entropy": 0.027573758363723756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.884712219238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045604344457387924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11979183554649353,
      "backward_entropy": 0.008545927703380585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.925421237945557,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04563711956143379,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11971513430277507,
      "backward_entropy": 0.02749480903148651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.824511528015137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045668039470911026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11964398622512817,
      "backward_entropy": 0.027455636858940126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.613167762756348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04569804668426514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1195753812789917,
      "backward_entropy": 0.008552248775959014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.62428092956543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04572859779000282,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11950439214706421,
      "backward_entropy": 0.008555888384580611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.668807983398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04575890675187111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1194336215655009,
      "backward_entropy": 0.008559422194957733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.222623825073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04578833281993866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11936530470848083,
      "backward_entropy": 0.008563932776451112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.567659378051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04581901431083679,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11929229895273845,
      "backward_entropy": 0.008567625284194946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.348950386047363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04584870487451553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11922228336334229,
      "backward_entropy": 0.008570781350135804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.095988273620605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04587821662425995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1191524863243103,
      "backward_entropy": 0.008573692291975021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.412894248962402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04590829089283943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11908002694447835,
      "backward_entropy": 0.00857713595032692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.925115585327148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04593746364116669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11901030937830608,
      "backward_entropy": 0.02715173065662384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.074963569641113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045967258512973785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1189375917116801,
      "backward_entropy": 0.008586165308952332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.007506370544434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04599691554903984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11886455615361531,
      "backward_entropy": 0.008593061566352844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.672791481018066,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04602644219994545,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11879114309946696,
      "backward_entropy": 0.13855068683624266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.305967330932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046056512743234634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11871509750684102,
      "backward_entropy": 0.00860990434885025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.804777145385742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04608764499425888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11863515774408977,
      "backward_entropy": 0.027031701803207398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.377071380615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046118397265672684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11855638027191162,
      "backward_entropy": 0.008621291816234588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.669140815734863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0461474172770977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11848356326421101,
      "backward_entropy": 0.008625905215740203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.605259895324707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0461762510240078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11841120322545369,
      "backward_entropy": 0.008629893511533737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.801397323608398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04620487242937088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11833945910135905,
      "backward_entropy": 0.008632240444421768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.246716022491455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046234630048274994,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11826302607854207,
      "backward_entropy": 0.026858499646186827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.00083065032959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046262696385383606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11819314956665039,
      "backward_entropy": 0.008630746603012085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.919227600097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04629140719771385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1181205411752065,
      "backward_entropy": 0.0267697274684906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.401376724243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04632068797945976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11804437637329102,
      "backward_entropy": 0.008634109795093537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.207197189331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046351127326488495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11796307563781738,
      "backward_entropy": 0.008637458086013794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.610030174255371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04638117924332619,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11788293719291687,
      "backward_entropy": 0.026661604642868042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.583365440368652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04641018435359001,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11780683199564616,
      "backward_entropy": 0.008640997856855393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.503374099731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046439699828624725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11772771676381429,
      "backward_entropy": 0.008643991500139236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.459720134735107,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04646958410739899,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11764683326085408,
      "backward_entropy": 0.008646391332149506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.946303844451904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04649844393134117,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11756972471872966,
      "backward_entropy": 0.008648183941841126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.813370704650879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046525739133358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11749843756357829,
      "backward_entropy": 0.008650211244821548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.91322135925293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04655291885137558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11742742856343587,
      "backward_entropy": 0.00865137279033661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.26617956161499,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046583399176597595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11734222372372945,
      "backward_entropy": 0.008653932809829712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.016809463500977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04661282151937485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11726086338361104,
      "backward_entropy": 0.00865696370601654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.55231761932373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046642571687698364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11717770497004192,
      "backward_entropy": 0.008659341931343078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.850714683532715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04667191579937935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1170961062113444,
      "backward_entropy": 0.00866035521030426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.771858215332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04670159891247749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11701265970865886,
      "backward_entropy": 0.008661701530218124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.015731811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04673147201538086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11692814032236735,
      "backward_entropy": 0.008660614490509033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.336949586868286,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04676230624318123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11683906118075053,
      "backward_entropy": 0.008661100268363952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.221466064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04679066315293312,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11676036318143208,
      "backward_entropy": 0.026106053590774538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.443280220031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04681871458888054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11668280760447185,
      "backward_entropy": 0.026060622930526734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.092264175415039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04684712737798691,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1166033148765564,
      "backward_entropy": 0.026011893153190614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.284774780273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04687530919909477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1165239413579305,
      "backward_entropy": 0.008658995479345321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.966901779174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04690384492278099,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11644283930460612,
      "backward_entropy": 0.025920644402503967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.566498756408691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046932101249694824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1163622538248698,
      "backward_entropy": 0.008658427000045776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.65768051147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04696204513311386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11627364158630371,
      "backward_entropy": 0.008659945428371429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.584359169006348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04699406027793884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1161756416161855,
      "backward_entropy": 0.008660625666379929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.863789558410645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0470246896147728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11608364184697469,
      "backward_entropy": 0.00865928828716278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.938490867614746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04705560952425003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11598879098892212,
      "backward_entropy": 0.02571456730365753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.293890476226807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047087229788303375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11589024464289348,
      "backward_entropy": 0.008668270707130433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.738349914550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047116901725530624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11580024162928264,
      "backward_entropy": 0.00867188572883606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1262900829315186,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047147348523139954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11570624510447185,
      "backward_entropy": 0.00867488756775856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.45698070526123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04717531427741051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11562349398930867,
      "backward_entropy": 0.025568920373916625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.167214870452881,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04720365256071091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11553853750228882,
      "backward_entropy": 0.008681006729602814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.200007915496826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04723035544157028,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11546067396799724,
      "backward_entropy": 0.025497108697891235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.234550476074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04725607857108116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11538766821225484,
      "backward_entropy": 0.00868368223309517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.050534963607788,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047282442450523376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11531056960423787,
      "backward_entropy": 0.025412237644195555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.070394039154053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047306790947914124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11524232228597005,
      "backward_entropy": 0.008691148459911346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.026919841766357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04733051732182503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1151766578356425,
      "backward_entropy": 0.008694764226675034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.985335350036621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047353118658065796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11511592070261638,
      "backward_entropy": 0.008699624240398407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.975358486175537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04737589508295059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11505380272865295,
      "backward_entropy": 0.008704277127981186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8875041007995605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04739770293235779,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11499543984731038,
      "backward_entropy": 0.008711960911750794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841691017150879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047419801354408264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11493517955144246,
      "backward_entropy": 0.008720427006483077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.967538833618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047442104667425156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11487348874409993,
      "backward_entropy": 0.00872822180390358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.681571006774902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04746268689632416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11482034126917522,
      "backward_entropy": 0.008733539283275605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.700565814971924,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04748421534895897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11476232608159383,
      "backward_entropy": 0.008738300949335098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.470505714416504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04750606045126915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11470210552215576,
      "backward_entropy": 0.008744794875383377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.711634159088135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04752940312027931,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11463358004887898,
      "backward_entropy": 0.00875287726521492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7875115871429443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04755215346813202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11456801493962605,
      "backward_entropy": 0.008759309351444245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.639525413513184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047573864459991455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11450691024462382,
      "backward_entropy": 0.025008910894393922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.047903060913086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04759515821933746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11444775263468425,
      "backward_entropy": 0.02497921884059906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.111113548278809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04761851578950882,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11437785625457764,
      "backward_entropy": 0.008780094981193542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.201275825500488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04764315113425255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11430088678995769,
      "backward_entropy": 0.008787390589714051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6700918674468994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0476682186126709,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11422179142634074,
      "backward_entropy": 0.008792217820882797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.449399471282959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04769183322787285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11415022611618042,
      "backward_entropy": 0.00879361629486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.211057186126709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04771486297249794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11408120393753052,
      "backward_entropy": 0.008795861899852753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5861828327178955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04773792624473572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11401166518529256,
      "backward_entropy": 0.008798053860664368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.566376209259033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04775998368859291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1139459212621053,
      "backward_entropy": 0.008804792165756225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5441765785217285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04778103902935982,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11388528347015381,
      "backward_entropy": 0.008812836557626724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0306077003479,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0478011891245842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11382833123207092,
      "backward_entropy": 0.008821921050548553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72446060180664,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04782158508896828,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11377020676930745,
      "backward_entropy": 0.13855037689208985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2101335525512695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04784289002418518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11370664834976196,
      "backward_entropy": 0.00883602723479271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.32927131652832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047863803803920746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11364478866259257,
      "backward_entropy": 0.008843413740396499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.852552890777588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04788623005151749,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11357372999191284,
      "backward_entropy": 0.024586111307144165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.503524780273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04790864884853363,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11350299914677937,
      "backward_entropy": 0.13855357170104982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.755917072296143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04793157801032066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1134299635887146,
      "backward_entropy": 0.008865173906087875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3643603324890137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04795448109507561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11335666974385579,
      "backward_entropy": 0.008868134021759034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.002075672149658,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04797621816396713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11328926682472229,
      "backward_entropy": 0.008871175348758698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.619988918304443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04799746721982956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11322442690531413,
      "backward_entropy": 0.008873938024044037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.933405876159668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048018794506788254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11315923929214478,
      "backward_entropy": 0.008874820917844773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2761595249176025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048039715737104416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11309533317883809,
      "backward_entropy": 0.024332267045974732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.953102111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04805963113903999,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1130369504292806,
      "backward_entropy": 0.008878786861896516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.832662105560303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048082105815410614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11296372612317403,
      "backward_entropy": 0.008879469335079193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6173202991485596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048104096204042435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11289240916570027,
      "backward_entropy": 0.024220754206180573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.355124473571777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04812436178326607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11283077796300252,
      "backward_entropy": 0.024183514714241027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5934677124023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04814479500055313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11276823282241821,
      "backward_entropy": 0.008885225653648377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1475558280944824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048163726925849915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.112713356812795,
      "backward_entropy": 0.008886418491601943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.234307765960693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04818183556199074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1126631498336792,
      "backward_entropy": 0.024063968658447267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.282511711120605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04820035770535469,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11261037985483806,
      "backward_entropy": 0.024025186896324158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.154850482940674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048220399767160416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11254828174908955,
      "backward_entropy": 0.02398962527513504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.637638568878174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04824065417051315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11248446504275005,
      "backward_entropy": 0.008895763009786607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.60151481628418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0482616201043129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11241661508878072,
      "backward_entropy": 0.00889851599931717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.522420406341553,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04828452691435814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11233643690745036,
      "backward_entropy": 0.0089063860476017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95622730255127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048307958990335464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11225275198618571,
      "backward_entropy": 0.008915850520133972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.449799537658691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04833230376243591,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11216375231742859,
      "backward_entropy": 0.023848190903663635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.880372524261475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04835587367415428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1120786468187968,
      "backward_entropy": 0.008932072669267654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.744091987609863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048379261046648026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1119941274325053,
      "backward_entropy": 0.02379991263151169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.911999225616455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048403456807136536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11190557479858398,
      "backward_entropy": 0.008944140374660492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.308289527893066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0484260730445385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11182719469070435,
      "backward_entropy": 0.02371784746646881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.27593469619751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04844806715846062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11175179481506348,
      "backward_entropy": 0.008941087871789932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.062126159667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04846947267651558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11167913675308228,
      "backward_entropy": 0.008941314369440078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.610178470611572,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04849133640527725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11160409450531006,
      "backward_entropy": 0.1385445475578308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.175904273986816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04851307347416878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11152944962183635,
      "backward_entropy": 0.00893704891204834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.520205497741699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04853428527712822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.111456960439682,
      "backward_entropy": 0.008936816453933715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.47601842880249,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04855551943182945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11138416330019633,
      "backward_entropy": 0.008938226848840714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3742412328720093,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04857682064175606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1113102634747823,
      "backward_entropy": 0.008942458778619766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.396575927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04859652742743492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11124507586161296,
      "backward_entropy": 0.008947621285915374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.360140800476074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04861639067530632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1111783782641093,
      "backward_entropy": 0.00895354300737381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.669562578201294,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048636313527822495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11111132303873698,
      "backward_entropy": 0.008957818895578385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.594306468963623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04865529388189316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11104954282442729,
      "backward_entropy": 0.008962708711624145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9326493740081787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0486750490963459,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11098223924636841,
      "backward_entropy": 0.02326764613389969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.801536560058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04869450628757477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11091544230779012,
      "backward_entropy": 0.008980357646942138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.166153907775879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0487150214612484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11084296305974324,
      "backward_entropy": 0.008986765146255493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.84897780418396,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048735521733760834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11077024539311726,
      "backward_entropy": 0.008992036432027816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.352050304412842,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04875551164150238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11070030927658081,
      "backward_entropy": 0.008997441828250885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.787041187286377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048776086419820786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11062634984652202,
      "backward_entropy": 0.009003124386072158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2669976949691772,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04879620671272278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11055421829223633,
      "backward_entropy": 0.023105794191360475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.210880756378174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04881482198834419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11049129565556844,
      "backward_entropy": 0.00901932716369629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1635613441467285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04883408173918724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11042426029841106,
      "backward_entropy": 0.009025994688272476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6765363216400146,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04885393753647804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11035310228665669,
      "backward_entropy": 0.009031958132982253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.651632308959961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04887333884835243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11028440793355306,
      "backward_entropy": 0.00903840884566307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.022003650665283,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04889225214719772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1102184255917867,
      "backward_entropy": 0.009043049812316895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.97727108001709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048911821097135544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11014804244041443,
      "backward_entropy": 0.009048454463481903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9253010749816895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048931922763586044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11007399360338847,
      "backward_entropy": 0.009053096920251847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.710333347320557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04895259067416191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10999545454978943,
      "backward_entropy": 0.009060033410787583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.508070707321167,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048973117023706436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10991821686426799,
      "backward_entropy": 0.009064699709415435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.937302112579346,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04899304360151291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10984444618225098,
      "backward_entropy": 0.009068461507558823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5869317054748535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04901392012834549,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10976420839627583,
      "backward_entropy": 0.00907130166888237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8181891441345215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04903478920459747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10968286792437236,
      "backward_entropy": 0.00907771959900856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.633094787597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0490565188229084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10959540804227193,
      "backward_entropy": 0.009083747863769531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.475414752960205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049078550189733505,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10950579245885213,
      "backward_entropy": 0.022697466611862182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5299763679504395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04910020902752876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1094189981619517,
      "backward_entropy": 0.022663319110870363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.206279993057251,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04912218078970909,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10932926336924235,
      "backward_entropy": 0.009098316729068755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.440510272979736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049142882227897644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10924776395161946,
      "backward_entropy": 0.022600702941417694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1665232181549072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04916374757885933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10916622479756673,
      "backward_entropy": 0.009100770950317383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.278775691986084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049183472990989685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10909169912338257,
      "backward_entropy": 0.02251404821872711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.24008321762085,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049203045666217804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10901854435602824,
      "backward_entropy": 0.00909719169139862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.290585041046143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04922252148389816,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10894572734832764,
      "backward_entropy": 0.022419068217277526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.19891357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049242954701185226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10886549949645996,
      "backward_entropy": 0.022376038134098053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.125685214996338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049263741821050644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10878247022628784,
      "backward_entropy": 0.009093347936868668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0539183616638184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928434640169144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10870015621185303,
      "backward_entropy": 0.009094820916652679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02198071964085102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049303848296403885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10862459739049275,
      "backward_entropy": 0.009097592532634735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.01940393447876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04932137206196785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10856254895528157,
      "backward_entropy": 0.009100484102964402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0071980953216553,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049339041113853455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10849865277608235,
      "backward_entropy": 0.00910487100481987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9733824729919434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935581237077713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10844118396441142,
      "backward_entropy": 0.009107789397239685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.973889708518982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04937230795621872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10838504632314046,
      "backward_entropy": 0.009111739695072174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.96164071559906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0493880920112133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10833340883255005,
      "backward_entropy": 0.022098594903945924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.795726299285889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04940318316221237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10828662912050883,
      "backward_entropy": 0.022066573798656463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.930190086364746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049419600516557693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10822956760724385,
      "backward_entropy": 0.009128437936306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9161252975463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0494353286921978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10817654927571614,
      "backward_entropy": 0.009137006103992462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9067968130111694,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04945043474435806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10812740524609883,
      "backward_entropy": 0.009146962314844131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020159099251031876,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0494648739695549,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10808318853378296,
      "backward_entropy": 0.02197239696979523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596473217010498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04947785660624504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10804891586303711,
      "backward_entropy": 0.009162976592779159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7911174297332764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049492329359054565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10800343751907349,
      "backward_entropy": 0.009172942489385605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9382514357566833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049506690353155136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10795845588048299,
      "backward_entropy": 0.009181974083185196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.756474256515503,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04952001944184303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10792091488838196,
      "backward_entropy": 0.009189862757921219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8309439420700073,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049533288925886154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10788397987683614,
      "backward_entropy": 0.009195244312286377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.817435383796692,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04954610392451286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10784998536109924,
      "backward_entropy": 0.009200471639633178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7051234245300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04955855756998062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10781797766685486,
      "backward_entropy": 0.009207119047641755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.68440842628479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04957102984189987,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10778584082921346,
      "backward_entropy": 0.021763518452644348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7840756177902222,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049583613872528076,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10775241255760193,
      "backward_entropy": 0.13854432106018066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5309109687805176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049595851451158524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10772091150283813,
      "backward_entropy": 0.02170958071947098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.383293628692627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049608632922172546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10768500963846843,
      "backward_entropy": 0.00923115313053131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8901664018630981,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049622293561697006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10764298836390178,
      "backward_entropy": 0.009235653281211852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.603975296020508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04963488504290581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10760945081710815,
      "backward_entropy": 0.009236001968383789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.729503870010376,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049647461622953415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10757601261138916,
      "backward_entropy": 0.009234193712472916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.569032907485962,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04965963587164879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10754500826199849,
      "backward_entropy": 0.009233088791370391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.400559186935425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04967188462615013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10751320918401082,
      "backward_entropy": 0.009232577681541444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.216601848602295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0496845617890358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10747891664505005,
      "backward_entropy": 0.009229956567287445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.184086322784424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049698080867528915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10743830601374309,
      "backward_entropy": 0.009225820004940034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.670968770980835,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04971242696046829,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10739122827847798,
      "backward_entropy": 0.009222740679979325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8427035212516785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497262179851532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10734756787618001,
      "backward_entropy": 0.009221439808607101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.464174509048462,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04973893612623215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10731224219004314,
      "backward_entropy": 0.021268990635871888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.445042371749878,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04975166544318199,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10727648933728536,
      "backward_entropy": 0.009214494377374649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.23460054397583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497644767165184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10723922650019328,
      "backward_entropy": 0.009215103089809417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.009954452514648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04977773502469063,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10719814896583557,
      "backward_entropy": 0.02115216851234436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4000754356384277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497918426990509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10715027650197347,
      "backward_entropy": 0.009220791608095169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.737161159515381,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04980567842721939,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10710493723551433,
      "backward_entropy": 0.13852393627166748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9196057319641113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04982071742415428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10705022017161052,
      "backward_entropy": 0.009221070259809495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1175835132598877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04983636364340782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10699076453844707,
      "backward_entropy": 0.009222251176834107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.085047960281372,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04985196888446808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10693265000979106,
      "backward_entropy": 0.009218636155128478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8190152645111084,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049867719411849976,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10687300562858582,
      "backward_entropy": 0.13851888179779054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5232889652252197,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988401383161545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10680840412775676,
      "backward_entropy": 0.009216973930597306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.25896954536438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049899544566869736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1067491074403127,
      "backward_entropy": 0.009219181537628175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.977409839630127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049914754927158356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10669191678365071,
      "backward_entropy": 0.00922100692987442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.15635347366333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04993019998073578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10663179556528728,
      "backward_entropy": 0.020792739093303682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4688196182250977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994705691933632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10656068722407024,
      "backward_entropy": 0.009234300255775452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016238974407315254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049963150173425674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10649404923121135,
      "backward_entropy": 0.009245703369379044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.732212245464325,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04997764155268669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10643944144248962,
      "backward_entropy": 0.00925772488117218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8526883125305176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049991074949502945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10639293988545735,
      "backward_entropy": 0.0092691108584404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8372881412506104,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050004877150058746,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10634291172027588,
      "backward_entropy": 0.13852490186691285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.511265993118286,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500187985599041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10629268487294515,
      "backward_entropy": 0.009291408956050873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.791348695755005,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050033293664455414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10623808701833089,
      "backward_entropy": 0.009297603368759155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.389825463294983,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050047826021909714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10618398586908977,
      "backward_entropy": 0.009299424290657044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.058415412902832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050061702728271484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10613438487052917,
      "backward_entropy": 0.009301818907260895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.721456289291382,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050075430423021317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1060851017634074,
      "backward_entropy": 0.009306137263774873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3561850786209106,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05008930340409279,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10603501399358113,
      "backward_entropy": 0.009308038651943207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.000895977020264,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05010257661342621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1059892972310384,
      "backward_entropy": 0.00931071862578392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9954200983047485,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05011702701449394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1059332291285197,
      "backward_entropy": 0.020491001009941102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.323412537574768,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050131142139434814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10587986310323079,
      "backward_entropy": 0.00932224839925766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.95947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05014460161328316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10583146413167317,
      "backward_entropy": 0.0093263179063797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2304797172546387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05015790835022926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10578378041585286,
      "backward_entropy": 0.009331314265727997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8398520946502686,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05017182603478432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10573101043701172,
      "backward_entropy": 0.02037946730852127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9088630676269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05018669739365578,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10567042231559753,
      "backward_entropy": 0.009340490400791168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8917551040649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050201281905174255,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10561152299245198,
      "backward_entropy": 0.020328617095947264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.256056547164917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05021560564637184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10555407404899597,
      "backward_entropy": 0.009354230761528016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0910983085632324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050229255110025406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10550155242284139,
      "backward_entropy": 0.009361561387777328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8419221639633179,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05024344474077225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10544442137082417,
      "backward_entropy": 0.009367845952510834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8242683410644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05025741830468178,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10538862148920695,
      "backward_entropy": 0.020241962373256685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2124103307724,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05027123540639877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10533305009206136,
      "backward_entropy": 0.009387905150651932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3890843391418457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050284434109926224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1052816907564799,
      "backward_entropy": 0.009399230033159256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.370386838912964,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050297871232032776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1052278180917104,
      "backward_entropy": 0.009411577880382539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7675567865371704,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05031147226691246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10517261425654094,
      "backward_entropy": 0.009423135966062545,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.1132240203768013,
    "avg_log_Z": -0.04958682022988796,
    "success_rate": 1.0,
    "avg_reward": 71.2,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.19,
      "2": 0.77
    },
    "avg_forward_entropy": 0.10775779604911805,
    "avg_backward_entropy": 0.01674582850188017,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}