{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1385420560836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1385420560836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1385420560836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1385420560836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1385420560836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1384933114051819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1385420560836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.1385420560836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.69386291503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13847408294677735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.65982055664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830000082651774,
      "backward_entropy": 0.13847711086273193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.98411560058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00019999986398033798,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299372990926108,
      "backward_entropy": 0.13850587606430054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.59219360351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00030027731554582715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18298731247584024,
      "backward_entropy": 0.13855044841766356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.2062530517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004002485075034201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829808553059896,
      "backward_entropy": 0.13848607540130614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.1759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004991135792806745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297427892684937,
      "backward_entropy": 0.1384887933731079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.93394470214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005972957005724311,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296786149342856,
      "backward_entropy": 0.13855767250061035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.34048461914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006940219318494201,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296154340108237,
      "backward_entropy": 0.13855979442596436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.86508178710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000789604673627764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18295510609944662,
      "backward_entropy": 0.1385617733001709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.85630798339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008862799149937928,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18294850985209146,
      "backward_entropy": 0.13856372833251954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.4926300048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000981986289843917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294175465901694,
      "backward_entropy": 0.13849973678588867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.0371856689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001075548818334937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293495972951254,
      "backward_entropy": 0.1385013461112976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.91525268554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011674955021589994,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829280455907186,
      "backward_entropy": 0.1385553002357483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.09292602539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012596247252076864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829209327697754,
      "backward_entropy": 0.13857026100158693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.44781494140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013486898969858885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291385968526205,
      "backward_entropy": 0.1385715126991272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.70518493652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014337465399876237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290676673253378,
      "backward_entropy": 0.1385725498199463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.24844360351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015199010958895087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289945522944132,
      "backward_entropy": 0.1385735511779785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.14859771728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016071361023932695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289186557133993,
      "backward_entropy": 0.13850855827331543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.31170654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016923710936680436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828841765721639,
      "backward_entropy": 0.13857543468475342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.0380096435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001777276978828013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287632862726846,
      "backward_entropy": 0.13857628107070924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2854766845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018633239669725299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828682820002238,
      "backward_entropy": 0.13851065635681153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.6922149658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019508467521518469,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285995721817017,
      "backward_entropy": 0.1385779023170471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0618133544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0020395538304001093,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285133441289267,
      "backward_entropy": 0.13857868909835816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.54901885986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002128214342519641,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828425129254659,
      "backward_entropy": 0.13857944011688234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.7119369506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022114012390375137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18283379077911377,
      "backward_entropy": 0.13851300477981568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.55567932128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022935897577553988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18282492955525717,
      "backward_entropy": 0.1385132074356079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.5359878540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0023746320512145758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182815949122111,
      "backward_entropy": 0.13858065605163575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.38258361816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0024546831846237183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828068494796753,
      "backward_entropy": 0.13858085870742798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.2469024658203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0025357678532600403,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827975114186605,
      "backward_entropy": 0.13859708309173585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.90628051757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002620506100356579,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827877958615621,
      "backward_entropy": 0.13859875202178956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.8705825805664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0027058799751102924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277798096338907,
      "backward_entropy": 0.13858139514923096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.2942352294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0027884396258741617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276852369308472,
      "backward_entropy": 0.13858137130737305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.13188934326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002871810458600521,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275882800420126,
      "backward_entropy": 0.13851213455200195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.5355987548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002952112816274166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274923165639242,
      "backward_entropy": 0.13858104944229127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.36192321777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003035216825082898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827392578125,
      "backward_entropy": 0.1385808229446411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.07139587402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0031224500853568316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827288269996643,
      "backward_entropy": 0.13851059675216676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.63201904296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032097254879772663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18271827697753906,
      "backward_entropy": 0.138580584526062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.32132720947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003293682122603059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827077865600586,
      "backward_entropy": 0.13850934505462648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.43867492675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0033764236140996218,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18269725640614828,
      "backward_entropy": 0.13857991695404054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1211395263672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034584070090204477,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18268656730651855,
      "backward_entropy": 0.13860948085784913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.3614501953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035414209123700857,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826756795247396,
      "backward_entropy": 0.13861008882522582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6455841064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0036282045766711235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266441424687704,
      "backward_entropy": 0.13850482702255248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.36027526855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003715639002621174,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826529105504354,
      "backward_entropy": 0.13850364685058594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.51139831542969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038018471095710993,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826413075129191,
      "backward_entropy": 0.13861184120178222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.18412017822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00388486054725945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826297640800476,
      "backward_entropy": 0.13850064277648927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.3994903564453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003966827876865864,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261818091074625,
      "backward_entropy": 0.13861265182495117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.38399505615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004050836898386478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18260614077250162,
      "backward_entropy": 0.13857479095458985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.80874633789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0041274274699389935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825944979985555,
      "backward_entropy": 0.1385737180709839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.99434661865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004205453209578991,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18258269627888998,
      "backward_entropy": 0.13849251270294188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.4090576171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004281285218894482,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257083495457968,
      "backward_entropy": 0.13861346244812012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.57926940917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004354982636868954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18255901336669922,
      "backward_entropy": 0.13856993913650512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.8606719970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004424420651048422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254737059275308,
      "backward_entropy": 0.13856832981109618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.16788482666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004496530629694462,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18253540992736816,
      "backward_entropy": 0.1385667324066162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.1730041503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004569195676594973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18252317110697427,
      "backward_entropy": 0.13847684860229492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.22640991210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004656275734305382,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250970045725504,
      "backward_entropy": 0.13861339092254638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.10716247558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004743725061416626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249595165252686,
      "backward_entropy": 0.1384710431098938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3167266845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004829923156648874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18248200416564941,
      "backward_entropy": 0.13856108188629152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.56224060058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004916932433843613,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18246773878733316,
      "backward_entropy": 0.13861367702484131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.8768768310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0050000702030956745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18245363235473633,
      "backward_entropy": 0.1385580539703369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.86204528808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005087307654321194,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18243900934855142,
      "backward_entropy": 0.13861370086669922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.08262634277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005181614775210619,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242353200912476,
      "backward_entropy": 0.13861384391784667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.41262817382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005275501869618893,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240787585576376,
      "backward_entropy": 0.1384517788887024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.753662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005371142644435167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239176273345947,
      "backward_entropy": 0.138551664352417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.93106842041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00547274062409997,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823748747507731,
      "backward_entropy": 0.1385501503944397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.55548858642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0055715162307024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823579470316569,
      "backward_entropy": 0.13854848146438598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.609619140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005662386305630207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823414365450541,
      "backward_entropy": 0.13843884468078613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.92916870117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005750885233283043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18232510487238565,
      "backward_entropy": 0.13843469619750975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.13500213623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005839528050273657,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18230926990509033,
      "backward_entropy": 0.13854167461395264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.37364196777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00592620437964797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182293434937795,
      "backward_entropy": 0.13853902816772462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1920623779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006014672107994556,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182277242342631,
      "backward_entropy": 0.13861407041549684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.63935089111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006105510052293539,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182260533173879,
      "backward_entropy": 0.13853355646133422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.8939437866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006194328423589468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18224382400512695,
      "backward_entropy": 0.13841066360473633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.92276000976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006282000336796045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822268764177958,
      "backward_entropy": 0.13840537071228026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.6534423828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0063702878542244434,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18220961093902588,
      "backward_entropy": 0.13861334323883057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.6710968017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006461185868829489,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18219178915023804,
      "backward_entropy": 0.1385211706161499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.91771697998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006555919069796801,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18217319250106812,
      "backward_entropy": 0.1385181427001953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.25372314453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006646385416388512,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18215479453404745,
      "backward_entropy": 0.13861290216445923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.345947265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006737011019140482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821360985438029,
      "backward_entropy": 0.13851113319396974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.37559509277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006825314834713936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821174422899882,
      "backward_entropy": 0.1385071873664856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.00776672363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006915952078998089,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820982297261556,
      "backward_entropy": 0.13850326538085939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.0836181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007004774175584316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18207897742589316,
      "backward_entropy": 0.138499116897583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.26364135742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007099401205778122,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820587714513143,
      "backward_entropy": 0.1384951114654541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.20703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00719407107681036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1820382078488668,
      "backward_entropy": 0.1383455514907837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.21083068847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007284289225935936,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18201792240142822,
      "backward_entropy": 0.13861072063446045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.35731506347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007375035434961319,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18199723958969116,
      "backward_entropy": 0.13848164081573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.90792846679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007469729986041784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18197578191757202,
      "backward_entropy": 0.13832355737686158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.08854293823242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0075695449486374855,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195341030756632,
      "backward_entropy": 0.13847272396087645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.37833404541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007659066002815962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18193191289901733,
      "backward_entropy": 0.13830881118774413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.35198974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007745286915451288,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18191049496332803,
      "backward_entropy": 0.13830041885375977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.34324645996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00782680045813322,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181889275709788,
      "backward_entropy": 0.13845547437667846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.3170166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007909231819212437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18186771869659424,
      "backward_entropy": 0.1384488344192505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.02776336669922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00799081102013588,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818459431330363,
      "backward_entropy": 0.13860669136047363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.99445343017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008063788525760174,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18182496229807535,
      "backward_entropy": 0.13843379020690919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.84947204589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008136194199323654,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18180386225382486,
      "backward_entropy": 0.1384252905845642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.4923553466797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008204171434044838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817831794420878,
      "backward_entropy": 0.13860297203063965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.63404083251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008275242522358894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18176168203353882,
      "backward_entropy": 0.13840668201446532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.05794525146484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008346503600478172,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817399263381958,
      "backward_entropy": 0.13860025405883789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.51637268066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00841599702835083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.181718111038208,
      "backward_entropy": 0.13818826675415039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.30835723876953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008492198772728443,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18169504404067993,
      "backward_entropy": 0.13859741687774657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.88243103027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008565608412027359,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18167213598887125,
      "backward_entropy": 0.13859589099884034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.02931213378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00864514708518982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181648055712382,
      "backward_entropy": 0.13835616111755372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.476806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008727646432816982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816233197848002,
      "backward_entropy": 0.1383459210395813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.882080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008810426108539104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18159802754720053,
      "backward_entropy": 0.138335657119751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.0457763671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008893297053873539,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18157229820887247,
      "backward_entropy": 0.13832526206970214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.24119567871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008973626419901848,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18154658873875937,
      "backward_entropy": 0.13859007358551026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.33154296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009061165153980255,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18151948849360147,
      "backward_entropy": 0.1385892391204834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9771728515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00915017630904913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18149169286092123,
      "backward_entropy": 0.13805599212646485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.55307006835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009241507388651371,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18146326144536337,
      "backward_entropy": 0.1385878801345825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.30591583251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009338609874248505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18143357833226523,
      "backward_entropy": 0.1380284070968628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.27787017822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009433274157345295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18140393495559692,
      "backward_entropy": 0.1380135416984558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.75978088378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009525753557682037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813742717107137,
      "backward_entropy": 0.13799731731414794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.31065368652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00961816031485796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18134419123331705,
      "backward_entropy": 0.13798012733459472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.4829864501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009714318439364433,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18131303787231445,
      "backward_entropy": 0.13821189403533934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.6631088256836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009816009551286697,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1812804937362671,
      "backward_entropy": 0.13858366012573242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.40309143066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009912872686982155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812483270963033,
      "backward_entropy": 0.13818254470825195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.74995422363281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010011662729084492,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18121532599131265,
      "backward_entropy": 0.13858203887939452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.2127685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010106263682246208,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1811826229095459,
      "backward_entropy": 0.13815032243728637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.15383911132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010199006646871567,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18114984035491943,
      "backward_entropy": 0.13787167072296141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.78903198242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010293803177773952,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1811162233352661,
      "backward_entropy": 0.13811440467834474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.22122192382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010394446551799774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18108107646306357,
      "backward_entropy": 0.13783258199691772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.55638122558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010501896031200886,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18104414145151773,
      "backward_entropy": 0.1385775089263916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.30913543701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010613330639898777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18100599447886148,
      "backward_entropy": 0.1377991795539856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.09678649902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010718547739088535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18096856276194254,
      "backward_entropy": 0.13777945041656495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.35929107666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010824677534401417,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1809304157892863,
      "backward_entropy": 0.13802783489227294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.09999084472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010923369787633419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1808932622273763,
      "backward_entropy": 0.13773672580718993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.92916107177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011020027101039886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18085592985153198,
      "backward_entropy": 0.1377130389213562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.85655212402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011114518158137798,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18081853787104288,
      "backward_entropy": 0.13796091079711914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.40257263183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011202890425920486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18078192075093588,
      "backward_entropy": 0.13793516159057617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.8498992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011285925284028053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18074591954549155,
      "backward_entropy": 0.13790738582611084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.0860595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01137025561183691,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1807082692782084,
      "backward_entropy": 0.1378791093826294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.37783813476562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011451063677668571,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18066994349161783,
      "backward_entropy": 0.13856213092803954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.73755645751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011538405902683735,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18062804142634073,
      "backward_entropy": 0.1375357389450073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.27404022216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011624549515545368,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18058518568674722,
      "backward_entropy": 0.13855698108673095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.09598541259766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011707708239555359,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18054187297821045,
      "backward_entropy": 0.13855397701263428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.88771057128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01178993470966816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1804978052775065,
      "backward_entropy": 0.13743138313293457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.34049224853516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011877109296619892,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18045157194137573,
      "backward_entropy": 0.138547945022583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.74794006347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011958161368966103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804060935974121,
      "backward_entropy": 0.13765209913253784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.46800231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012048187665641308,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18035751581192017,
      "backward_entropy": 0.137318754196167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.5599136352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012140798382461071,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18030711015065512,
      "backward_entropy": 0.13758187294006347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.02053833007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012225319631397724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18025722106297812,
      "backward_entropy": 0.1372420072555542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.67198181152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012316284701228142,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1802046298980713,
      "backward_entropy": 0.13750340938568115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.3505630493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012413437478244305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18014933665593466,
      "backward_entropy": 0.13716999292373658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.0220489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01250835508108139,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18009366591771445,
      "backward_entropy": 0.13742653131484986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.40544891357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012606917880475521,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18003598848978677,
      "backward_entropy": 0.13738698959350587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.358642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012703443877398968,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799779733022054,
      "backward_entropy": 0.1373455286026001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.25218200683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012806271202862263,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17991739511489868,
      "backward_entropy": 0.13852293491363527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.69849395751953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012908607721328735,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17985618114471436,
      "backward_entropy": 0.13852131366729736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.92660522460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013008328154683113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1797947883605957,
      "backward_entropy": 0.13721933364868164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.82869720458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013112555257976055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1797312100728353,
      "backward_entropy": 0.13717591762542725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.53013610839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01321227103471756,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1796680490175883,
      "backward_entropy": 0.13712940216064454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.99034118652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013312773779034615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17960357666015625,
      "backward_entropy": 0.13681601285934447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.70441436767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013411819003522396,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17953856786092123,
      "backward_entropy": 0.13703181743621826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.92518615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0135068753734231,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17947413523991904,
      "backward_entropy": 0.1369790554046631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.40626525878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013603385537862778,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17940851052602133,
      "backward_entropy": 0.13850533962249756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.95057678222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013700226321816444,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17934183279673258,
      "backward_entropy": 0.13850202560424804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.46255493164062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013798670843243599,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17927364508310953,
      "backward_entropy": 0.13849873542785646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.2685089111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013898716308176517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1792039473851522,
      "backward_entropy": 0.1365089535713196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.58384704589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014000972732901573,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17913246154785156,
      "backward_entropy": 0.13849277496337892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.53890228271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014098032377660275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17906179030736288,
      "backward_entropy": 0.1366339683532715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.6427001953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014190414920449257,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17899207274119058,
      "backward_entropy": 0.13848409652709961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.71205139160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014284868724644184,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17892038822174072,
      "backward_entropy": 0.13847968578338624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.78854370117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014384893700480461,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17884546518325806,
      "backward_entropy": 0.13641705513000488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.35454559326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014487938955426216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17876861492792764,
      "backward_entropy": 0.13613538742065429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.23666381835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014585698023438454,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17869271834691366,
      "backward_entropy": 0.13846932649612426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.2762908935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014684591442346573,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17861531178156534,
      "backward_entropy": 0.1361844778060913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.27989196777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014785951934754848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17853577931722006,
      "backward_entropy": 0.1361026406288147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6428680419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014886078424751759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1784555713335673,
      "backward_entropy": 0.13583090305328369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.8343734741211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014984927140176296,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17837470769882202,
      "backward_entropy": 0.13845266103744508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.09207153320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015079439617693424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17829455931981406,
      "backward_entropy": 0.13583002090454102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.251220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015173432417213917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1782134771347046,
      "backward_entropy": 0.1355579137802124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.1099624633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015268792398273945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17813060681025186,
      "backward_entropy": 0.13545937538146974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015359996818006039,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17804845174153647,
      "backward_entropy": 0.13551764488220214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.30909729003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015448818914592266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17796609799067178,
      "backward_entropy": 0.13524714708328248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.60772705078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015547620132565498,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1778783599535624,
      "backward_entropy": 0.13841497898101807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.8948974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015639660879969597,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17779233058293661,
      "backward_entropy": 0.13501737117767335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.00609588623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01573324389755726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17770421504974365,
      "backward_entropy": 0.1350654125213623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.53184509277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01582319289445877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17761667569478354,
      "backward_entropy": 0.13494254350662233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.3397216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015910055488348007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17752963304519653,
      "backward_entropy": 0.13481385707855226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.66014099121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016004711389541626,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17743778228759766,
      "backward_entropy": 0.13468903303146362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.94631958007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016104688867926598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17734209696451822,
      "backward_entropy": 0.13436367511749267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.7496795654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01620371825993061,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1772456169128418,
      "backward_entropy": 0.13444050550460815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.68070983886719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016305657103657722,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1771464745203654,
      "backward_entropy": 0.13835649490356444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.4963150024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016403116285800934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1770482063293457,
      "backward_entropy": 0.1341794967651367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.73612213134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016498921439051628,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17694973945617676,
      "backward_entropy": 0.1340397596359253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.07232666015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01658690720796585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17685421307881674,
      "backward_entropy": 0.13362908363342285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.57059478759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01666921377182007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17676037549972534,
      "backward_entropy": 0.1337272047996521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.03305053710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016750898212194443,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17666560411453247,
      "backward_entropy": 0.13830766677856446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.74168395996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01683371514081955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17656888564427695,
      "backward_entropy": 0.13307267427444458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.32862854003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016921378672122955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1764682133992513,
      "backward_entropy": 0.13828476667404174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.31562042236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017015310004353523,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17636283238728842,
      "backward_entropy": 0.13306448459625245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.23629760742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017101265490055084,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17626150449117026,
      "backward_entropy": 0.1382650375366211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.7377471923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017189566045999527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17615830898284912,
      "backward_entropy": 0.1322898268699646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.9901123046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01728014275431633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1760522723197937,
      "backward_entropy": 0.132080340385437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.70762634277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017373446375131607,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17594337463378906,
      "backward_entropy": 0.13823442459106444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.20568084716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017464328557252884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17583425839742026,
      "backward_entropy": 0.13215349912643432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.86394500732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017545996233820915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17572949330012003,
      "backward_entropy": 0.131947922706604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.63290405273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017620552331209183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1756277879079183,
      "backward_entropy": 0.1317274808883667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.55213928222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017697693780064583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17552347977956137,
      "backward_entropy": 0.13150739669799805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.9287109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017770640552043915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1754205028216044,
      "backward_entropy": 0.13815507888793946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.6846923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01784154400229454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17531736691792807,
      "backward_entropy": 0.1303795576095581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.21327209472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017920421436429024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17520789305369058,
      "backward_entropy": 0.13011206388473512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.14286041259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017996493726968765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17509796222050986,
      "backward_entropy": 0.1305633544921875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8638458251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018071938306093216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1749859849611918,
      "backward_entropy": 0.1295391321182251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.63984680175781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01815021224319935,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17486993471781412,
      "backward_entropy": 0.13805673122406006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.0415496826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018222123384475708,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17475664615631104,
      "backward_entropy": 0.12979342937469482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.42633056640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0182979516685009,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17463854948679605,
      "backward_entropy": 0.12952448129653932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.93934631347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0183733981102705,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17451727390289307,
      "backward_entropy": 0.13798792362213136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.24574279785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018448691815137863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17439391215642294,
      "backward_entropy": 0.12795166969299315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.24832153320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018531419336795807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1742633581161499,
      "backward_entropy": 0.1286737561225891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.9315948486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01861714944243431,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17412875096003214,
      "backward_entropy": 0.12730787992477416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.53968811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018706094473600388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1739903688430786,
      "backward_entropy": 0.12811856269836425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.88258361816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01879451796412468,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17385021845499674,
      "backward_entropy": 0.12783340215682984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.3254852294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01887809857726097,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17371239264806113,
      "backward_entropy": 0.12753419876098632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.53147888183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01896260678768158,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17357214291890463,
      "backward_entropy": 0.12723236083984374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.2280731201172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019046450033783913,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17343086004257202,
      "backward_entropy": 0.1378403663635254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.96998596191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01914244145154953,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17327890793482462,
      "backward_entropy": 0.1266378402709961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.58132934570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019242016598582268,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17312212785085043,
      "backward_entropy": 0.1263521432876587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019343174993991852,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1729622483253479,
      "backward_entropy": 0.12606556415557862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.7113800048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019442131742835045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17280258735020956,
      "backward_entropy": 0.124314284324646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.8334503173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019541285932064056,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17264111836751303,
      "backward_entropy": 0.13778605461120605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.5067138671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019642246887087822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17247645060221353,
      "backward_entropy": 0.12366549968719483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.1939697265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01974448561668396,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17230925957361856,
      "backward_entropy": 0.13776650428771972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.26954650878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019849641248583794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1721381942431132,
      "backward_entropy": 0.12301490306854249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.59752655029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019957730546593666,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1719630559285482,
      "backward_entropy": 0.1226954460144043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.69834899902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0200592502951622,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17179210980733237,
      "backward_entropy": 0.12397143840789795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.37521362304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020154325291514397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.171625554561615,
      "backward_entropy": 0.12363588809967041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.72315216064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020258912816643715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17144906520843506,
      "backward_entropy": 0.12165632247924804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.23681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02035929635167122,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1712748408317566,
      "backward_entropy": 0.12130796909332275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.5820770263672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02045300044119358,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17110558350880942,
      "backward_entropy": 0.13769330978393554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.6082305908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020549453794956207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17093165715535483,
      "backward_entropy": 0.12229506969451905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.11212921142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02064795233309269,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1707538366317749,
      "backward_entropy": 0.12194441556930542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.51852416992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020738650113344193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17058237393697104,
      "backward_entropy": 0.12156869173049926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.65465545654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020831486210227013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1704071561495463,
      "backward_entropy": 0.12119396924972534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.7597427368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02091974765062332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17023460070292154,
      "backward_entropy": 0.118858802318573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.42472839355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021007321774959564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17006095250447592,
      "backward_entropy": 0.12039625644683838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.88743591308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0210939422249794,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16988650957743326,
      "backward_entropy": 0.13754897117614745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.18865966796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021185286343097687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16970527172088623,
      "backward_entropy": 0.11958177089691162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.34584045410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02127365581691265,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16952417294184366,
      "backward_entropy": 0.13750238418579103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.06436157226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02136300317943096,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16934003432591757,
      "backward_entropy": 0.1187356948852539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.57867431640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02146012894809246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16914616028467813,
      "backward_entropy": 0.11605827808380127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.88510131835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021549144759774208,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16895918051401773,
      "backward_entropy": 0.13743290901184083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.61421966552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021643638610839844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16876510779062906,
      "backward_entropy": 0.1150855541229248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.3430938720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021732330322265625,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16857564449310303,
      "backward_entropy": 0.1373835802078247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.79823303222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021820764988660812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1683839956919352,
      "backward_entropy": 0.11656063795089722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.5792694091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02190384455025196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16819663842519125,
      "backward_entropy": 0.11608004570007324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.13319396972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021987957879900932,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16800624132156372,
      "backward_entropy": 0.13727501630783082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.3455810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02207675576210022,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16780885060628256,
      "backward_entropy": 0.11511694192886353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.19837951660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022168489173054695,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16760671138763428,
      "backward_entropy": 0.13721102476119995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.80655670166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022262858226895332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16740018129348755,
      "backward_entropy": 0.11417689323425292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.68231964111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022349495440721512,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1672010620435079,
      "backward_entropy": 0.11367406845092773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.95083618164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0224353838711977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16700132687886557,
      "backward_entropy": 0.11316306591033935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.78396606445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0225259680300951,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1667946974436442,
      "backward_entropy": 0.11266254186630249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.57806396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022620752453804016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16658138235410055,
      "backward_entropy": 0.10900158882141113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.83306121826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02271432988345623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16636850436528525,
      "backward_entropy": 0.11167778968811035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.67861938476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02280416153371334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16615857680638632,
      "backward_entropy": 0.10784354209899902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.19041442871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022900033742189407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1659397085507711,
      "backward_entropy": 0.11066281795501709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.69447326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02299899235367775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.165716419617335,
      "backward_entropy": 0.10672633647918701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.1634979248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023106545209884644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16548186540603638,
      "backward_entropy": 0.10620951652526855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.90626525878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023219548165798187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16523921489715576,
      "backward_entropy": 0.10928151607513428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.4398193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023328473791480064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1649999221165975,
      "backward_entropy": 0.10513447523117066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.4731903076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023435330018401146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16476133465766907,
      "backward_entropy": 0.10830358266830445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.89065551757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02354307845234871,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1645206113656362,
      "backward_entropy": 0.10395568609237671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.8553009033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02365638129413128,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16427167256673178,
      "backward_entropy": 0.10732003450393676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6179656982422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023769060149788857,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1640218993028005,
      "backward_entropy": 0.1368474006652832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.58711242675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02388167753815651,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16377105315526327,
      "backward_entropy": 0.1021793007850647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.203857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023990953341126442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1635239322980245,
      "backward_entropy": 0.10156466960906982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.83918762207031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024095483124256134,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16328205664952597,
      "backward_entropy": 0.1052498459815979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.5497589111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02419908158481121,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16303987304369608,
      "backward_entropy": 0.13676252365112304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.35739135742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024303246289491653,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1627954641977946,
      "backward_entropy": 0.13673546314239501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.64404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024407923221588135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16254907846450806,
      "backward_entropy": 0.09896373152732849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.48423767089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02451200783252716,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16230279207229614,
      "backward_entropy": 0.1029936671257019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.55665588378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02461506985127926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.162056694428126,
      "backward_entropy": 0.10240732431411743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.7934341430664,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024721136316657066,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1618058184782664,
      "backward_entropy": 0.13662221431732177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.90187072753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024820752441883087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16156399250030518,
      "backward_entropy": 0.09625981450080871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.946533203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024925578385591507,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16131316622098288,
      "backward_entropy": 0.10063849687576294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.6005859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025025686249136925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16106860836346945,
      "backward_entropy": 0.09489469528198242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.79489135742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02512570656836033,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16082350413004556,
      "backward_entropy": 0.0994107484817505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.50133514404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025227200239896774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16057546933492026,
      "backward_entropy": 0.098801589012146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.04551696777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025323107838630676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160335103670756,
      "backward_entropy": 0.09816707372665405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.24107360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025412408635020256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16010427474975586,
      "backward_entropy": 0.09208188056945801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.45368194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02550651505589485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15986623366673788,
      "backward_entropy": 0.09139129519462585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.92481994628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02559565007686615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15963498751322427,
      "backward_entropy": 0.09067733883857727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.14672088623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025683989748358727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1594040592511495,
      "backward_entropy": 0.08995829820632935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.22076416015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02576972357928753,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15917615095774332,
      "backward_entropy": 0.09487369060516357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.59060668945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025851938873529434,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1589518884817759,
      "backward_entropy": 0.13612098693847657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.3505401611328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025937402620911598,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15872211257616678,
      "backward_entropy": 0.1360640048980713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.01115417480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026027988642454147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15848490595817566,
      "backward_entropy": 0.08692142963409424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.0496826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026113897562026978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1582545042037964,
      "backward_entropy": 0.09211033582687378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.70713806152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026211675256490707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15800681710243225,
      "backward_entropy": 0.08546571731567383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.98028564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026313256472349167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15775421261787415,
      "backward_entropy": 0.0908849835395813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.972896575927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02641374245285988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1575020949045817,
      "backward_entropy": 0.09026477336883545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.10887145996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026506707072257996,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15726170937220255,
      "backward_entropy": 0.13584980964660645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.9967803955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02660548873245716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15701294938723245,
      "backward_entropy": 0.0826614499092102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.22166442871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026707325130701065,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15675954023996988,
      "backward_entropy": 0.08195658326148987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.17652893066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02681121602654457,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1565041939417521,
      "backward_entropy": 0.0812837839126587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.3708038330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026914797723293304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15625024835268655,
      "backward_entropy": 0.08061554431915283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.58769989013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027022898197174072,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15598946809768677,
      "backward_entropy": 0.08654717206954957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.51698303222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027126245200634003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15573620796203613,
      "backward_entropy": 0.08593277931213379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.57894897460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027230851352214813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1554815967877706,
      "backward_entropy": 0.08532411456108094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.0968475341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027336429804563522,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15522624055544534,
      "backward_entropy": 0.07793549299240113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.12948608398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027445003390312195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1549669106801351,
      "backward_entropy": 0.08413535356521606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.4452896118164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02755609154701233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15470488866170248,
      "backward_entropy": 0.08356554508209228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.3851318359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027666324749588966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15444548924763998,
      "backward_entropy": 0.07604480981826782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.18614959716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027773164212703705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1541918714841207,
      "backward_entropy": 0.08239023685455323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.86931610107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027876965701580048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15394332011540732,
      "backward_entropy": 0.07468459010124207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.03096771240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02797870710492134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15369874238967896,
      "backward_entropy": 0.07398532629013062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.68821716308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028076447546482086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15346078077952066,
      "backward_entropy": 0.07325990796089173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.01387786865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02817591466009617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15322083234786987,
      "backward_entropy": 0.07979211807250977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.10997772216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028275294229388237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15298149983088175,
      "backward_entropy": 0.07914000749588013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.18890380859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028373122215270996,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15274547537167868,
      "backward_entropy": 0.07848657369613647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.47630310058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028469407930970192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15251260002454123,
      "backward_entropy": 0.07039036750793456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.8644027709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028567776083946228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15227734049161276,
      "backward_entropy": 0.07718455791473389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.156848907470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02866392210125923,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15204606453577676,
      "backward_entropy": 0.0765199065208435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.63691711425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02874828688800335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1518349051475525,
      "backward_entropy": 0.07580225467681885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.92044830322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02883053570985794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15162664651870728,
      "backward_entropy": 0.06739033460617065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.28998565673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02890939638018608,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1514241099357605,
      "backward_entropy": 0.06659560799598693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.3862762451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028984900563955307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15122767289479574,
      "backward_entropy": 0.07359390258789063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.739990234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02906636707484722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15102237462997437,
      "backward_entropy": 0.06501360535621643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.41962814331055,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02914443612098694,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15082329511642456,
      "backward_entropy": 0.13507018089294434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.09754180908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029216602444648743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15063510338465372,
      "backward_entropy": 0.0714221477508545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.153934478759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029290195554494858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15044552087783813,
      "backward_entropy": 0.07069584727287292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.768943786621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029360245913267136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15026291211446127,
      "backward_entropy": 0.06996597051620483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.93013763427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029426636174321175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15008682012557983,
      "backward_entropy": 0.06112549304962158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.54488372802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029493123292922974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14991106589635214,
      "backward_entropy": 0.060350829362869264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.61969757080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029563384130597115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14973036448160806,
      "backward_entropy": 0.05960471630096435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.7141571044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02963341400027275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14955063660939535,
      "backward_entropy": 0.058861613273620605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.51464080810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029708227142691612,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.149364044268926,
      "backward_entropy": 0.058142060041427614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.86082458496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02978324145078659,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14917753140131632,
      "backward_entropy": 0.05739986300468445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.144161224365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029858794063329697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14899112780888876,
      "backward_entropy": 0.05665209293365479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.24757385253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02993019111454487,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1488128900527954,
      "backward_entropy": 0.05589423179626465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.18216705322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03000105544924736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1486363708972931,
      "backward_entropy": 0.06360371112823486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.61858367919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030073784291744232,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1484585404396057,
      "backward_entropy": 0.0629292905330658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.30461883544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030149374157190323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1482775111993154,
      "backward_entropy": 0.05370454788208008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.26405334472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030224425718188286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1480987767378489,
      "backward_entropy": 0.05300554633140564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.66320037841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030304428189992905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14791468779246011,
      "backward_entropy": 0.052349400520324704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.66368103027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030388403683900833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14772597948710123,
      "backward_entropy": 0.05171361565589905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.25711822509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030472707003355026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1475386619567871,
      "backward_entropy": 0.05108494758605957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.22818756103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03055748902261257,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14735257625579834,
      "backward_entropy": 0.0593532919883728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.6593017578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030641088262200356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14717073241869608,
      "backward_entropy": 0.04985645711421967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.8431396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030725441873073578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14698932568232217,
      "backward_entropy": 0.058262956142425534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.74638366699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03081163391470909,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14680627981821695,
      "backward_entropy": 0.04868350028991699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.43132781982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030895093455910683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14662966132164001,
      "backward_entropy": 0.057219356298446655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.9297866821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030978254973888397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14645430445671082,
      "backward_entropy": 0.056676816940307614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.24560546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031060025095939636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14628247419993082,
      "backward_entropy": 0.046901842951774596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.14221954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03114236146211624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14611119031906128,
      "backward_entropy": 0.046300143003463745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.63765716552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031227324157953262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1459382176399231,
      "backward_entropy": 0.045731177926063536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.62821197509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03131143003702164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14576852321624756,
      "backward_entropy": 0.05455489158630371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.05866241455078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03139592707157135,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14559988180796304,
      "backward_entropy": 0.13392446041107178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.24842071533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03147771209478378,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1454369525114695,
      "backward_entropy": 0.05354433059692383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.2004623413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031562257558107376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1452722946802775,
      "backward_entropy": 0.04353680014610291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.15081024169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031649135053157806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14510637521743774,
      "backward_entropy": 0.043020063638687135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.26280212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03173588588833809,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1449418862660726,
      "backward_entropy": 0.04249264001846313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.3545379638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03181995078921318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1447835365931193,
      "backward_entropy": 0.04196887016296387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.38886260986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03191366791725159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14461491505304971,
      "backward_entropy": 0.04151688814163208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.70280456542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032005637884140015,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.144450843334198,
      "backward_entropy": 0.05084941983222961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.79180145263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03209557756781578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14429121216138205,
      "backward_entropy": 0.050435662269592285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.5174331665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032187364995479584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14413156112035116,
      "backward_entropy": 0.04014905691146851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.95258331298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03227892890572548,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14397400617599487,
      "backward_entropy": 0.03968640863895416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.84699249267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032371580600738525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14381646116574606,
      "backward_entropy": 0.03921258151531219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.49031829833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03245947137475014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14366730054219565,
      "backward_entropy": 0.048766922950744626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.14515686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032546959817409515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1435196797053019,
      "backward_entropy": 0.03824875056743622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.29236602783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03263154253363609,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1433775027592977,
      "backward_entropy": 0.047881653904914855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.48750305175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0327095203101635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14324477314949036,
      "backward_entropy": 0.047401908040046695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.97099304199219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03278956562280655,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1431116759777069,
      "backward_entropy": 0.1340649366378784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.83685302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03286721557378769,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1429828405380249,
      "backward_entropy": 0.036248034238815306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.382301330566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03294796869158745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14285178979237875,
      "backward_entropy": 0.03577516973018646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.69216918945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033024862408638,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14272738496462503,
      "backward_entropy": 0.04565524160861969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.4072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03310965374112129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.142595112323761,
      "backward_entropy": 0.034848958253860474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.7209701538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033193256705999374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14246615767478943,
      "backward_entropy": 0.04486527442932129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.75616455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033278003334999084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14233694473902384,
      "backward_entropy": 0.044487285614013675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.70564270019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03336191549897194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14221098025639853,
      "backward_entropy": 0.033543547987937926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.80638122558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03344336524605751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14208958546320596,
      "backward_entropy": 0.033107641339302066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.71099853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033522311598062515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14197246233622232,
      "backward_entropy": 0.043318641185760495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.81285858154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03360467031598091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14185320337613425,
      "backward_entropy": 0.03224411606788635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.84967803955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033688243478536606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14173442125320435,
      "backward_entropy": 0.03183945417404175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.26738739013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03377262130379677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.141616423924764,
      "backward_entropy": 0.04223387241363526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.5478401184082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03385819494724274,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1414988934993744,
      "backward_entropy": 0.04189753532409668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.77337646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03393750265240669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14138986666997275,
      "backward_entropy": 0.041530287265777587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.57173156738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03401339054107666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14128617445627847,
      "backward_entropy": 0.041159385442733766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.8309440612793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03409405052661896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14117844899495444,
      "backward_entropy": 0.04080711007118225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.2287368774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034172117710113525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14107642571131387,
      "backward_entropy": 0.04047861993312836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.36703109741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034248389303684235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14097722371419272,
      "backward_entropy": 0.04014683067798615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.18122100830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03432149812579155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1408827304840088,
      "backward_entropy": 0.03980744481086731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.21590423583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03439663350582123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14078720410664877,
      "backward_entropy": 0.028301477432250977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.67176818847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034472208470106125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14069247245788574,
      "backward_entropy": 0.039154306054115295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.85418701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03454975038766861,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14059742291768393,
      "backward_entropy": 0.027579870820045472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.04642486572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03462410718202591,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14050705234209696,
      "backward_entropy": 0.03852405846118927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.400482177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03470185026526451,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14041486382484436,
      "backward_entropy": 0.02685617804527283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.00456237792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03477673605084419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1403266191482544,
      "backward_entropy": 0.026505747437477113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.87391662597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03485586494207382,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14023557305335999,
      "backward_entropy": 0.037640580534935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.0932388305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03494471684098244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14013728499412537,
      "backward_entropy": 0.037413308024406434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.72880554199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03503774106502533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1400370200475057,
      "backward_entropy": 0.025636449456214905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.28265380859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035132426768541336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13993698358535767,
      "backward_entropy": 0.03700380027294159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.06576156616211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03522888943552971,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1398371458053589,
      "backward_entropy": 0.13439300060272216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.457725524902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03532158583402634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1397432486216227,
      "backward_entropy": 0.024869483709335328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.53351593017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03541003540158272,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13965487480163574,
      "backward_entropy": 0.02462553232908249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.64766311645508,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.035498835146427155,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13956725597381592,
      "backward_entropy": 0.1345531940460205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.13225173950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03558505326509476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1394835114479065,
      "backward_entropy": 0.024107319116592408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.92313003540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0356656014919281,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13940622409184775,
      "backward_entropy": 0.03580238223075867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.6860237121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03574514389038086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13933121164639792,
      "backward_entropy": 0.03558610081672668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.0458984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03582015633583069,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13926140467325845,
      "backward_entropy": 0.03536306023597717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.10219955444336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035895854234695435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13919188578923544,
      "backward_entropy": 0.035146912932395934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.37622833251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03596995025873184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13912445306777954,
      "backward_entropy": 0.03491463661193848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.44196319580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03604194521903992,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13906011978785196,
      "backward_entropy": 0.13468809127807618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.924367904663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03611857444047928,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13899322350819907,
      "backward_entropy": 0.022229103744029997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.4764633178711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03618995472788811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1389323870340983,
      "backward_entropy": 0.021993620693683623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.07469177246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0362619124352932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13887114326159158,
      "backward_entropy": 0.02175108641386032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.71253204345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03633798658847809,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13880773385365805,
      "backward_entropy": 0.03394441604614258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.03577423095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036418039351701736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1387425661087036,
      "backward_entropy": 0.03378242254257202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.56690216064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036493271589279175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13868212699890137,
      "backward_entropy": 0.03359970450401306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.58023834228516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03656916692852974,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13862208525339761,
      "backward_entropy": 0.13484656810760498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.3498077392578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03664525970816612,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1385626494884491,
      "backward_entropy": 0.1348626971244812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.07930755615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036731280386447906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1384967863559723,
      "backward_entropy": 0.020379871129989624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.41934967041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03681676462292671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1384328007698059,
      "backward_entropy": 0.032881876826286315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.804447174072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03690502792596817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13836834828058878,
      "backward_entropy": 0.032721790671348575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.32199096679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03699022904038429,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1383074422677358,
      "backward_entropy": 0.01975429356098175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.508201599121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03707541152834892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13824785749117532,
      "backward_entropy": 0.03244867920875549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.7740364074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03715882450342178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1381907065709432,
      "backward_entropy": 0.019373968243598938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.80412292480469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03723805770277977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1381377081076304,
      "backward_entropy": 0.032189908623695376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.49448013305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03732234239578247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13808236519495645,
      "backward_entropy": 0.01901380717754364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.78186798095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03740321472287178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13803021113077799,
      "backward_entropy": 0.01882766783237457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.54813766479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037483058869838715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1379798154036204,
      "backward_entropy": 0.03182272315025329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.17901611328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03755872696638107,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13793309529622397,
      "backward_entropy": 0.0316985547542572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.77613067626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037638358771800995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1378844678401947,
      "backward_entropy": 0.03158507943153381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.72441482543945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03771885856986046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13783649603525797,
      "backward_entropy": 0.031488290429115294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.899986267089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037796784192323685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1377910574277242,
      "backward_entropy": 0.017972694337368013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.47993469238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037874411791563034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1377468208471934,
      "backward_entropy": 0.017825740575790405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.12095642089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03795523941516876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13770179947217306,
      "backward_entropy": 0.03127086758613586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.72275924682617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03803670406341553,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13765730460484824,
      "backward_entropy": 0.031232672929763793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.120304107666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038116756826639175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13761423031489053,
      "backward_entropy": 0.017459975183010103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.01551818847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038194313645362854,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13757344086964926,
      "backward_entropy": 0.031125256419181825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.92146301269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03827406466007233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13753200570742288,
      "backward_entropy": 0.031068849563598632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.38590240478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038361962884664536,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13748690485954285,
      "backward_entropy": 0.031025195121765138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.003381729125977,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038449279963970184,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13744292656580606,
      "backward_entropy": 0.13578684329986573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.06806945800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03853081166744232,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13740322987238565,
      "backward_entropy": 0.03092239797115326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.60503387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03861436992883682,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13736330469449362,
      "backward_entropy": 0.03088153004646301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.81904602050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038705501705408096,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13732001185417175,
      "backward_entropy": 0.030847850441932678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.5774917602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03880089893937111,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13727566599845886,
      "backward_entropy": 0.030829960107803346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.98386764526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03889807313680649,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13723132014274597,
      "backward_entropy": 0.03080678582191467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.98968505859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03899093344807625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13719009359677634,
      "backward_entropy": 0.030773115158081055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.65435028076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.039089132100343704,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13714722792307535,
      "backward_entropy": 0.13617905378341674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.23653411865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03919056057929993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13710394501686096,
      "backward_entropy": 0.01611432433128357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.40313720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039291080087423325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13706205288569132,
      "backward_entropy": 0.03074210286140442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.107177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03938693925738335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1370233198006948,
      "backward_entropy": 0.015947869420051573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.05503463745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039480287581682205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13698657353719076,
      "backward_entropy": 0.0158573642373085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.33567810058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039569929242134094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13695230086644491,
      "backward_entropy": 0.030710273981094362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7180950045585632,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03966101258993149,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13691814740498862,
      "backward_entropy": 0.0156815841794014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.33526611328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039742082357406616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13688929875691733,
      "backward_entropy": 0.03068203330039978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.8764419555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03982319310307503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13686070839564005,
      "backward_entropy": 0.015471626818180085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.1721305847168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039905890822410583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13683189948399863,
      "backward_entropy": 0.015360628068447114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.31886672973633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03998727351427078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13680424292882284,
      "backward_entropy": 0.015248189866542815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.72087860107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04006604105234146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13677825530370077,
      "backward_entropy": 0.03049865663051605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.40187454223633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040148746222257614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13675124446551004,
      "backward_entropy": 0.03046584129333496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.22148895263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040227390825748444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1367264191309611,
      "backward_entropy": 0.014932303130626679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.35556411743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04030633345246315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1367018222808838,
      "backward_entropy": 0.014824266731739043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.85609436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04038102179765701,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13667946060498556,
      "backward_entropy": 0.030326902866363525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.979385375976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040459711104631424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1366559068361918,
      "backward_entropy": 0.014592050015926361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.91657829284668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04053499177098274,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13663427035013834,
      "backward_entropy": 0.030227518081665038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.830699920654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04060709848999977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13661436239878336,
      "backward_entropy": 0.014386270940303803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.62900924682617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04067635163664818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13659598429997763,
      "backward_entropy": 0.030167651176452637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.9322509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040745899081230164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13657782475153604,
      "backward_entropy": 0.030147218704223634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.81386184692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040817029774188995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13655938704808554,
      "backward_entropy": 0.014105600118637086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.41010284423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04088936001062393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13654088973999023,
      "backward_entropy": 0.01400982290506363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.372528076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040965382009744644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13652112086613974,
      "backward_entropy": 0.01390569806098938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.35372543334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04104255512356758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136501411596934,
      "backward_entropy": 0.030009979009628297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.06312942504883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041116178035736084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13648351033528647,
      "backward_entropy": 0.013710367679595947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.11054229736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0411909781396389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13646541039148966,
      "backward_entropy": 0.02993674874305725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.37126922607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04126835614442825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13644683361053467,
      "backward_entropy": 0.029906493425369263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.16365432739258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04135062173008919,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13642694552739462,
      "backward_entropy": 0.02987368404865265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.28458023071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0414302684366703,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13640841841697693,
      "backward_entropy": 0.013340303301811218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.80503273010254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0415106937289238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13639003038406372,
      "backward_entropy": 0.029820901155471802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.13922882080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041587166488170624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13637338081995645,
      "backward_entropy": 0.013169090449810027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.623409271240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041665393859148026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363564133644104,
      "backward_entropy": 0.02975095808506012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.58697509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04174162819981575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13634055852890015,
      "backward_entropy": 0.02971559464931488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.396759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041817162185907364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13632520039876303,
      "backward_entropy": 0.029676553606987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.02733612060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04189087823033333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13631081581115723,
      "backward_entropy": 0.012800754606723785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.95458221435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04197191819548607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13629435499509177,
      "backward_entropy": 0.012725600600242614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.795040130615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042053889483213425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13627811272939047,
      "backward_entropy": 0.029644066095352174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.934932708740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04213648661971092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13626205921173096,
      "backward_entropy": 0.029662582278251647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.881183624267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04221624135971069,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362472673257192,
      "backward_entropy": 0.012538966536521912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.68470001220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042292553931474686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13623380661010742,
      "backward_entropy": 0.02968522608280182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.7147274017334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04236665368080139,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13622117042541504,
      "backward_entropy": 0.029690441489219666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.1840934753418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04243777319788933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13620968659718832,
      "backward_entropy": 0.029701998829841612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.62584114074707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0425087995827198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13619850079218546,
      "backward_entropy": 0.029709070920944214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.65361785888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04257654771208763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361885368824005,
      "backward_entropy": 0.029699334502220155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.78019714355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04264562949538231,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13617817560831705,
      "backward_entropy": 0.029676079750061035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.22151184082031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042719170451164246,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13616685072580972,
      "backward_entropy": 0.02965598404407501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.842674255371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04279788210988045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13615429401397705,
      "backward_entropy": 0.029631689190864563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.48848724365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042874254286289215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13614267110824585,
      "backward_entropy": 0.02960694134235382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.157569885253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04295266047120094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13613074024518332,
      "backward_entropy": 0.011822777986526489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.5367202758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04303004965186119,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361193060874939,
      "backward_entropy": 0.02954484224319458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.29566955566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04311101883649826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1361071765422821,
      "backward_entropy": 0.011667062342166901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.0118408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043195001780986786,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13609455029169717,
      "backward_entropy": 0.029487478733062743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.34349822998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04328177496790886,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13608147700627646,
      "backward_entropy": 0.02945939302444458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.84637451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043369315564632416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360685427983602,
      "backward_entropy": 0.011439216136932374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.13877868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04346051439642906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13605494300524393,
      "backward_entropy": 0.011360470205545425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.91024398803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043553829193115234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13604108492533365,
      "backward_entropy": 0.011286059021949768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.39167022705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04364471137523651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602819045384726,
      "backward_entropy": 0.02930552661418915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.78914260864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04373260959982872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13601634899775186,
      "backward_entropy": 0.011147847026586532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.74552917480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043819963932037354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13600488503774008,
      "backward_entropy": 0.011082546412944793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.8284683227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04390862211585045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13599334160486856,
      "backward_entropy": 0.011024004220962525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.972415924072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04400128126144409,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13598122199376425,
      "backward_entropy": 0.010974181443452835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.79586410522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04409182444214821,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135970006386439,
      "backward_entropy": 0.010926636308431626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.681373596191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04418036341667175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13595956563949585,
      "backward_entropy": 0.02932272255420685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.496543884277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04426842927932739,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13594947258631387,
      "backward_entropy": 0.010832589119672775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.281646728515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04435738921165466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13593940933545431,
      "backward_entropy": 0.010785186290740966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.97721481323242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04444536566734314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13592976331710815,
      "backward_entropy": 0.010729876160621644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.83660125732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04453440010547638,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13592010736465454,
      "backward_entropy": 0.02936483025550842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.183907508850098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0446225181221962,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591080904006958,
      "backward_entropy": 0.02935870587825775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.22329330444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044703129678964615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590349753697714,
      "backward_entropy": 0.01056167334318161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.18730926513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04478568211197853,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589574893315634,
      "backward_entropy": 0.02936221957206726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.41504669189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04486830160021782,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588819901148477,
      "backward_entropy": 0.029374721646308898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.029266357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044948238879442215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135881374279658,
      "backward_entropy": 0.010414982587099076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.30620574951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04502716660499573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587490717569986,
      "backward_entropy": 0.010368763655424117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.3930549621582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04510781913995743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358681619167328,
      "backward_entropy": 0.0103227861225605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.8535270690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045188527554273605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586159547170004,
      "backward_entropy": 0.029436266422271727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.3754997253418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045270420610904694,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135854701201121,
      "backward_entropy": 0.0294331431388855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.60511016845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04535066336393356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13584833343823752,
      "backward_entropy": 0.029418033361434937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.01057052612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045428358018398285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358426014582316,
      "backward_entropy": 0.010106062144041061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.3471794128418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04550541192293167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358371078968048,
      "backward_entropy": 0.029406815767288208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.201351165771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04558006674051285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583221038182577,
      "backward_entropy": 0.029403021931648253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.9311752319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04565298184752464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582775990168253,
      "backward_entropy": 0.009952565282583236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.67037963867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0457291379570961,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358226736386617,
      "backward_entropy": 0.02940206229686737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6333646774292,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04580819234251976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13581726948420206,
      "backward_entropy": 0.02938021719455719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.49920654296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045880962163209915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13581336537996927,
      "backward_entropy": 0.009785417467355728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.54734420776367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04595864936709404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580807050069174,
      "backward_entropy": 0.02936559319496155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.422027587890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04603792726993561,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580251733462015,
      "backward_entropy": 0.029355728626251222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.7503604888916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046114660799503326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13579756021499634,
      "backward_entropy": 0.029345983266830446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.163299560546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046186987310647964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357937455177307,
      "backward_entropy": 0.00958533063530922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.24094009399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046257466077804565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13579034805297852,
      "backward_entropy": 0.029372203350067138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.57486343383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046327732503414154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13578705986340842,
      "backward_entropy": 0.009497596323490143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.943782806396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04639359936118126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13578468561172485,
      "backward_entropy": 0.009452519565820694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.1509017944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0464598648250103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135782261689504,
      "backward_entropy": 0.009411695599555969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.5648078918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0465303398668766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357790231704712,
      "backward_entropy": 0.029435932636260986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.387113571166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046599145978689194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13577616214752197,
      "backward_entropy": 0.00933346301317215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.325279235839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04666515439748764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13577393690745035,
      "backward_entropy": 0.029474204778671263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.21697998046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046730317175388336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13577181100845337,
      "backward_entropy": 0.029507365822792054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.119731903076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046801187098026276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357686718304952,
      "backward_entropy": 0.009228835254907608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.971630096435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046869125217199326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576612869898477,
      "backward_entropy": 0.009197989106178283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.857168197631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046935778111219406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357638438542684,
      "backward_entropy": 0.029623258113861083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.855396270751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04700089991092682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576185703277588,
      "backward_entropy": 0.009132510423660279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.488922119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04706373065710068,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357603371143341,
      "backward_entropy": 0.029682213068008424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.856671333312988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04712683707475662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357587476571401,
      "backward_entropy": 0.009062997251749038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.82796859741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04718664288520813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575786352157593,
      "backward_entropy": 0.02974100410938263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.301315307617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0472499318420887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135756254196167,
      "backward_entropy": 0.029777884483337402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.941707611083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047312602400779724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575484355290732,
      "backward_entropy": 0.02982637584209442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.80266189575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047375909984111786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13575331370035806,
      "backward_entropy": 0.008950661122798919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.05458450317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04743942618370056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575170437494913,
      "backward_entropy": 0.02992214262485504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.84977149963379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047505803406238556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357495387395223,
      "backward_entropy": 0.008893437683582306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.37257766723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04757115617394447,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574757178624472,
      "backward_entropy": 0.030000019073486327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.83580780029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04763685166835785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13574556509653726,
      "backward_entropy": 0.008842970430850982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.240135192871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04770362004637718,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574333985646567,
      "backward_entropy": 0.030078008770942688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.272351264953613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04777295142412186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574055830637613,
      "backward_entropy": 0.030103927850723265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.25822639465332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0478379912674427,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13573861122131348,
      "backward_entropy": 0.008747776597738266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.6379508972168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04790204390883446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13573686281840006,
      "backward_entropy": 0.030154997110366823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.560237884521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047966599464416504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357350548108419,
      "backward_entropy": 0.00869082733988762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.916250228881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048028603196144104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13573368390401205,
      "backward_entropy": 0.008661817014217376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.804758071899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04808984324336052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357324719429016,
      "backward_entropy": 0.00863405242562294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.701282501220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04815025255084038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357313891251882,
      "backward_entropy": 0.030293375253677368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.23382568359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04821038618683815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357304056485494,
      "backward_entropy": 0.030344149470329283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.81665802001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04826880246400833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572974999745688,
      "backward_entropy": 0.03040458858013153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.99149703979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04832804948091507,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572893540064493,
      "backward_entropy": 0.00854683220386505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.54789352416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04838941618800163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572766383488974,
      "backward_entropy": 0.030521076917648316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.908538818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048451367765665054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572630286216736,
      "backward_entropy": 0.03057994544506073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.70589065551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04851606860756874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572436571121216,
      "backward_entropy": 0.030621996521949767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.725147247314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048583295196294785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572190205256143,
      "backward_entropy": 0.008461281657218933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.96261215209961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04864787310361862,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571993509928384,
      "backward_entropy": 0.030684000253677367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.819679260253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048712488263845444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571794827779135,
      "backward_entropy": 0.030710530281066895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.77373504638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04877738654613495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357158621152242,
      "backward_entropy": 0.030744343996047974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.44139289855957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048843517899513245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571351766586304,
      "backward_entropy": 0.030769747495651246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.37112045288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048908211290836334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571141163508096,
      "backward_entropy": 0.00832594707608223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.20132827758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048972971737384796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570924599965414,
      "backward_entropy": 0.03080877959728241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.097503662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04903630167245865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570730884869894,
      "backward_entropy": 0.030817633867263793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.93962478637695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04909716546535492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13570578893025717,
      "backward_entropy": 0.008230935782194138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.79096221923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04915858805179596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570419947306314,
      "backward_entropy": 0.03083501160144806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.36282730102539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04922020435333252,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13570245107014975,
      "backward_entropy": 0.13828465938568116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.49895477294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04928578808903694,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356999079386393,
      "backward_entropy": 0.030832314491271974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.505102157592773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935126379132271,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569738467534384,
      "backward_entropy": 0.008094895631074905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.569833755493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049415472894907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569505016009012,
      "backward_entropy": 0.008061661571264266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.699691772460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04947725683450699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356931726137797,
      "backward_entropy": 0.008030052483081817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.40938949584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049535688012838364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569194078445435,
      "backward_entropy": 0.030846339464187623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.26105499267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049592502415180206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569105664889017,
      "backward_entropy": 0.007978271692991257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.76198196411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04965273290872574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356895168622335,
      "backward_entropy": 0.03091033101081848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.823928833007812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04971694573760033,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13568711280822754,
      "backward_entropy": 0.1383036971092224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.72165870666504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04977993667125702,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568488756815592,
      "backward_entropy": 0.030953556299209595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.46229934692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0498422309756279,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356827716032664,
      "backward_entropy": 0.007887758314609528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.886083602905273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04990756884217262,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356800893942515,
      "backward_entropy": 0.031048646569252013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.9066047668457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04997045546770096,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567785422007242,
      "backward_entropy": 0.031107938289642333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.24281883239746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050033267587423325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13567547996838888,
      "backward_entropy": 0.007843581587076187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.1376838684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05009513348340988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356732745965322,
      "backward_entropy": 0.007828778773546218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.051077842712402,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05016099661588669,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1356702446937561,
      "backward_entropy": 0.13834009170532227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.88913345336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05022290349006653,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356679399808248,
      "backward_entropy": 0.03130597174167633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.764883041381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05028392747044563,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13566577434539795,
      "backward_entropy": 0.031359797716140746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.660810470581055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05034387484192848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566373785336813,
      "backward_entropy": 0.007766386866569519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.913728713989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05040306597948074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566182057062784,
      "backward_entropy": 0.007750901579856873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.1019401550293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05046287178993225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356597145398458,
      "backward_entropy": 0.03151125311851501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.5386848449707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050524305552244186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13565725088119507,
      "backward_entropy": 0.007722973823547363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.47884750366211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05058962106704712,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1356539527575175,
      "backward_entropy": 0.13837170600891113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.56255340576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05065495893359184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13565065463383993,
      "backward_entropy": 0.03166370987892151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.58979034423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05072132870554924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356470783551534,
      "backward_entropy": 0.03171533942222595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.839155197143555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05078984797000885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356430947780609,
      "backward_entropy": 0.03176362514495849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.53707504272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05085710808634758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13563929001490274,
      "backward_entropy": 0.031836530566215514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.580690383911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05092130973935127,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356359918912252,
      "backward_entropy": 0.03189740180969238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.4604434967041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050984349101781845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13563295205434164,
      "backward_entropy": 0.03196570873260498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.47172164916992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05104627460241318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13563010096549988,
      "backward_entropy": 0.007630866765975952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.188343048095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05110969394445419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356269121170044,
      "backward_entropy": 0.007624553889036179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.11418342590332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05117060989141464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13562416036923727,
      "backward_entropy": 0.03218642473220825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.970739364624023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05123176798224449,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356213092803955,
      "backward_entropy": 0.007609798014163971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.831544876098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05129312723875046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13561832904815674,
      "backward_entropy": 0.032330042123794554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.76266860961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05135480687022209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13561527927716574,
      "backward_entropy": 0.007596561312675476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.430728912353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05141539126634598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356123685836792,
      "backward_entropy": 0.007590484619140625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.662166595458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05147740989923477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13560909032821655,
      "backward_entropy": 0.007583923637866974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.423601150512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051536813378334045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13560624917348227,
      "backward_entropy": 0.032615217566490176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.915931701660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05159546434879303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13560354709625244,
      "backward_entropy": 0.0075645364820957186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.185577392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05165550112724304,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13560038805007935,
      "backward_entropy": 0.0327360987663269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.836706161499023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05171426385641098,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13559740781784058,
      "backward_entropy": 0.032775184512138365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.85913848876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05177351459860802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355943183104197,
      "backward_entropy": 0.03282266855239868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.541011810302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05183664336800575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355902155240377,
      "backward_entropy": 0.03287007510662079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.4051513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05189965292811394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13558613260587057,
      "backward_entropy": 0.03291764855384827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.785980224609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051959045231342316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13558282454808554,
      "backward_entropy": 0.007484859973192215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.28486442565918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05202333256602287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13557833433151245,
      "backward_entropy": 0.0330208033323288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.803756713867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0520838126540184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13557466864585876,
      "backward_entropy": 0.033075937628746034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.45429611206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052142102271318436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355714499950409,
      "backward_entropy": 0.0331377774477005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.108235359191895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052204106003046036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13556728760401407,
      "backward_entropy": 0.033189785480499265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.527957916259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05226242169737816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13556390007336935,
      "backward_entropy": 0.007423865050077439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.457443237304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05232105776667595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13556035359700522,
      "backward_entropy": 0.007411526888608933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.940922737121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05237746983766556,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355572541554769,
      "backward_entropy": 0.033346927165985106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.531463623046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052430734038352966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355548103650411,
      "backward_entropy": 0.03339743614196777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.608301162719727,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052485786378383636,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13555183013280234,
      "backward_entropy": 0.13848271369934081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.863622665405273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052540265023708344,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13554892937342325,
      "backward_entropy": 0.03348690867424011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.05953025817871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05259544029831886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13554580012957254,
      "backward_entropy": 0.007341555505990982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.52070999145508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05264866352081299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13554304838180542,
      "backward_entropy": 0.03358481824398041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.901567459106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052706051617860794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355392038822174,
      "backward_entropy": 0.007311787456274033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.321048736572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052761346101760864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13553579648335776,
      "backward_entropy": 0.033668768405914304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.970478057861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052816860377788544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13553214073181152,
      "backward_entropy": 0.0072776123881340025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.0561466217041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287175253033638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13552862405776978,
      "backward_entropy": 0.007261022925376892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.410042762756348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05292697623372078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13552496830622354,
      "backward_entropy": 0.007242438942193985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.098567962646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05297927185893059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13552198807398477,
      "backward_entropy": 0.00722639337182045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.419626235961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05303466320037842,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13551797469456991,
      "backward_entropy": 0.03383838534355164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.535964965820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05308804288506508,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13551447788874307,
      "backward_entropy": 0.03387555778026581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.54999923706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053141999989748,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355107625325521,
      "backward_entropy": 0.03391203582286835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.137468338012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0531989224255085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13550625244776407,
      "backward_entropy": 0.03395606577396393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.108342170715332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05325251817703247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13550249735514322,
      "backward_entropy": 0.033996155858039855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.02721118927002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05330447107553482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13549911975860596,
      "backward_entropy": 0.03404344618320465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.854333877563477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05335477367043495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1354960799217224,
      "backward_entropy": 0.007127150893211365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.823556900024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0534069649875164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13549238443374634,
      "backward_entropy": 0.03412596881389618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.978392124176025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05345873162150383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13548874855041504,
      "backward_entropy": 0.03416827321052551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.415180206298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053506895899772644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13548613588015238,
      "backward_entropy": 0.007090763747692108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.529741287231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05355720967054367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13548282782236734,
      "backward_entropy": 0.007081504166126251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.96638488769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05360718071460724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13547950983047485,
      "backward_entropy": 0.007071793079376221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.32856559753418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05366010591387749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13547526796658835,
      "backward_entropy": 0.007059556990861892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.817733764648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05371237173676491,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13547106583913168,
      "backward_entropy": 0.007046625018119812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.359123229980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05376632511615753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13546627759933472,
      "backward_entropy": 0.007033395022153855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.99496841430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05381856858730316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13546196619669595,
      "backward_entropy": 0.007022672891616821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.628076553344727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05387471243739128,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1354564627011617,
      "backward_entropy": 0.034553584456443784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.426663398742676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05393099784851074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13545082012812296,
      "backward_entropy": 0.006999483704566956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.028059005737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05398412421345711,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13544597228368124,
      "backward_entropy": 0.034643760323524474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.23310661315918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05403885617852211,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13544059793154398,
      "backward_entropy": 0.03469326496124268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.706148147583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05409394949674606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13543505469957987,
      "backward_entropy": 0.03474715948104858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6329779624938965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05415034666657448,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13542898495992026,
      "backward_entropy": 0.006961880624294281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.723031997680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05420255288481712,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13542412718137106,
      "backward_entropy": 0.006955680251121521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.64029598236084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054253194481134415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1354197065035502,
      "backward_entropy": 0.034930503368377684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.103164672851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05430212244391441,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13541565338770548,
      "backward_entropy": 0.0069454297423362735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.40943145751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054352909326553345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13541078567504883,
      "backward_entropy": 0.006938273459672928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.3348445892334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05440852791070938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13540438810984293,
      "backward_entropy": 0.006928105652332306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.768779754638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05446421355009079,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13539783159891763,
      "backward_entropy": 0.03513492345809936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.254910469055176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054518889635801315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13539148370424905,
      "backward_entropy": 0.00690726637840271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.558809280395508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0545714870095253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13538560271263123,
      "backward_entropy": 0.03521849513053894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.104249954223633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054623328149318695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353798508644104,
      "backward_entropy": 0.03525780141353607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.702751159667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05467342957854271,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13537450631459555,
      "backward_entropy": 0.006874863803386688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.965882301330566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05472094193100929,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13536994655927023,
      "backward_entropy": 0.0353475958108902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.74967384338379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05476727336645126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13536572456359863,
      "backward_entropy": 0.006859734654426575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.819693565368652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0548156313598156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13536073764165243,
      "backward_entropy": 0.03545989990234375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.99361801147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05486242473125458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13535606861114502,
      "backward_entropy": 0.03550609052181244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.687341690063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05490898713469505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13535135984420776,
      "backward_entropy": 0.006834405660629273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.818832397460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05495429411530495,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13534696896870932,
      "backward_entropy": 0.13853509426116944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.41425323486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054999638348817825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13534248868624368,
      "backward_entropy": 0.03564687669277191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.634302139282227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05504900589585304,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353364884853363,
      "backward_entropy": 0.035683760046958925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.90544319152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05509798601269722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1353305776913961,
      "backward_entropy": 0.006798061728477478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.33514404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05514949560165405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13532358407974243,
      "backward_entropy": 0.006785630434751511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.490514755249023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05519922077655792,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13531707723935446,
      "backward_entropy": 0.03578808009624481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.23868751525879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05525054782629013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1353099743525187,
      "backward_entropy": 0.006762673705816269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.1389217376709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05530118569731712,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353029410044352,
      "backward_entropy": 0.03585823178291321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.043441772460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05535116419196129,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13529602686564127,
      "backward_entropy": 0.03589637875556946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.993163108825684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055400602519512177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13528921206792197,
      "backward_entropy": 0.0067341640591621395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.81167221069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05544750764966011,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352832317352295,
      "backward_entropy": 0.006728119403123856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.7620210647583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05549520626664162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13527692357699075,
      "backward_entropy": 0.006722736358642578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.401891708374023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05554249882698059,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1352705955505371,
      "backward_entropy": 0.036103397607803345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.11494255065918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05559263378381729,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13526316483815512,
      "backward_entropy": 0.03616002798080444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.046127319335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055646248161792755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13525431354840597,
      "backward_entropy": 0.036211425065994264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.362263679504395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570187047123909,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13524455825487772,
      "backward_entropy": 0.006698630005121231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.447893142700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055756278336048126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13523508111635843,
      "backward_entropy": 0.006691378355026245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.374505996704102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055808454751968384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13522624969482422,
      "backward_entropy": 0.006683334708213806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5480146408081055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055858708918094635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13521800438563028,
      "backward_entropy": 0.006675972044467926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.43363380432129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05590631812810898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13521071275075278,
      "backward_entropy": 0.03644282817840576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.578744888305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05595548078417778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13520267605781555,
      "backward_entropy": 0.03649606704711914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.14505386352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05600491166114807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1351943016052246,
      "backward_entropy": 0.03654090166091919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.676154136657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05605556070804596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13518521189689636,
      "backward_entropy": 0.03657525479793548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.94084644317627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0561053492128849,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1351762811342875,
      "backward_entropy": 0.03660804331302643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.487321853637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0561533086001873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1351678967475891,
      "backward_entropy": 0.03663851320743561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.987279891967773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05620068684220314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13515961170196533,
      "backward_entropy": 0.03666987419128418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.735540390014648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05624854564666748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13515094916025797,
      "backward_entropy": 0.00660933256149292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5763070583343506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056294865906238556,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1351428429285685,
      "backward_entropy": 0.03673776984214783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0803680419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05633781477808952,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13513606786727905,
      "backward_entropy": 0.03678357005119324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.556636810302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056378696113824844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13513011733690897,
      "backward_entropy": 0.03683451414108276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.45589256286621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056420594453811646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13512351115544638,
      "backward_entropy": 0.006581830233335495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.958178997039795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05646340176463127,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13511634866396585,
      "backward_entropy": 0.03691837191581726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.361151695251465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056504108011722565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13510998090108237,
      "backward_entropy": 0.03696119785308838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.442474365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05654377117753029,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13510385155677795,
      "backward_entropy": 0.03699680864810943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.459293365478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056587591767311096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13509579499562582,
      "backward_entropy": 0.006548978388309479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.179190635681152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05663307383656502,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13508681456247965,
      "backward_entropy": 0.006539122015237808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.83843231201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05667721852660179,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1350783407688141,
      "backward_entropy": 0.0065310530364513395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.389228820800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05672203749418259,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1350694199403127,
      "backward_entropy": 0.03713207840919495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.984478950500488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05676647275686264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1350605090459188,
      "backward_entropy": 0.037167906761169434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.219828605651855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056809596717357635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13505208492279053,
      "backward_entropy": 0.03720689713954926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.690799713134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05685245618224144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13504362106323242,
      "backward_entropy": 0.006499695032835007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.56497573852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0568968765437603,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1350341240564982,
      "backward_entropy": 0.0372677743434906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.964788436889648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05694279819726944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13502371311187744,
      "backward_entropy": 0.006477539986371994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.30033302307129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05698823556303978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13501345117886862,
      "backward_entropy": 0.03731271028518677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.599188804626465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057035043835639954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13500231504440308,
      "backward_entropy": 0.0373337984085083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.192464828491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057080406695604324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13499183456103006,
      "backward_entropy": 0.037368834018707275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1692721843719482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05712238699197769,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13498294353485107,
      "backward_entropy": 0.03740957975387573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.54517936706543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05716121196746826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13497544328371683,
      "backward_entropy": 0.03744812607765198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.250771522521973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05720020830631256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1349676251411438,
      "backward_entropy": 0.03749115467071533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.400656700134277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057237569242715836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1349607010682424,
      "backward_entropy": 0.03754875063896179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.250834465026855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057275254279375076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1349535584449768,
      "backward_entropy": 0.006424684077501297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.433170318603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05731218308210373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13494661450386047,
      "backward_entropy": 0.00642257034778595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.223397254943848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05735217407345772,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13493792215983072,
      "backward_entropy": 0.037719365954399106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.102949142456055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0573931448161602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13492858409881592,
      "backward_entropy": 0.03777232468128204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.020705461502075,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05743392929434776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13491912682851157,
      "backward_entropy": 0.006411001086235046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972753524780273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05747167393565178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1349111000696818,
      "backward_entropy": 0.006406357139348983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.884404182434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057508695870637894,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13490339120229086,
      "backward_entropy": 0.006402821838855743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.866521835327148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057545918971300125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13489538431167603,
      "backward_entropy": 0.037978488206863406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.679021835327148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05758243054151535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1348876158396403,
      "backward_entropy": 0.006395401060581207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.846375465393066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05762024223804474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1348791221777598,
      "backward_entropy": 0.0063932381570339205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.604009628295898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05765627697110176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13487140337626138,
      "backward_entropy": 0.0063907958567142485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.413619995117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057692497968673706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13486339648564658,
      "backward_entropy": 0.006386512517929077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.603316307067871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057729728519916534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1348544955253601,
      "backward_entropy": 0.006379124522209167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.395541191101074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05776610225439072,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.134845902522405,
      "backward_entropy": 0.03827954530715942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.80748176574707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05780259892344475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13483699162801108,
      "backward_entropy": 0.006361491233110428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6340131759643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0578419454395771,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1348262627919515,
      "backward_entropy": 0.006349895894527435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598759174346924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057879287749528885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13481645782788595,
      "backward_entropy": 0.03834292590618134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.113005638122559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057914845645427704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13480762640635172,
      "backward_entropy": 0.038362282514572146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.804277420043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05795065686106682,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13479836781819662,
      "backward_entropy": 0.03838324248790741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.236157417297363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05798772722482681,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13478843371073404,
      "backward_entropy": 0.03841267824172974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.904078483581543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05802401900291443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13477879762649536,
      "backward_entropy": 0.006299857795238495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.542245864868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05806039646267891,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13476892312367758,
      "backward_entropy": 0.0384758859872818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.76689624786377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05809784308075905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13475825389226279,
      "backward_entropy": 0.03850581049919129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6861038208007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05813536420464516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13474740584691366,
      "backward_entropy": 0.03853947520256042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.284242630004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05817017704248428,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13473804791768393,
      "backward_entropy": 0.03857654333114624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2893829345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058206234127283096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13472784558931986,
      "backward_entropy": 0.006262108683586121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.975738525390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05824064835906029,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13471853733062744,
      "backward_entropy": 0.038660860061645506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.231201171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05827882140874863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13470659653345743,
      "backward_entropy": 0.0062486760318279265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.185116767883301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058319538831710815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1346928278605143,
      "backward_entropy": 0.038713890314102176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.83832836151123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05835825577378273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1346802810827891,
      "backward_entropy": 0.038750636577606204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.84134864807129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058397576212882996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13466705878575644,
      "backward_entropy": 0.0062243852764368056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.123055458068848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05843929573893547,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13465205828348795,
      "backward_entropy": 0.0388004332780838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.047303199768066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058480508625507355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13463717699050903,
      "backward_entropy": 0.006205834448337555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.484353065490723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0585213229060173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13462238510449728,
      "backward_entropy": 0.006197584792971611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.898261070251465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05856097862124443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1346083084742228,
      "backward_entropy": 0.006191904470324516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.823138236999512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05860041826963425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1345942219098409,
      "backward_entropy": 0.038935303688049316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.184714317321777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05863955616950989,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13458011547724405,
      "backward_entropy": 0.03898071944713592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.923675537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058679282665252686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1345653533935547,
      "backward_entropy": 0.006178930774331093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.599532127380371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058721236884593964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13454881310462952,
      "backward_entropy": 0.006173125654459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.652624130249023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05876260623335838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13453243176142374,
      "backward_entropy": 0.03909718990325928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.444292068481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058805931359529495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13451433181762695,
      "backward_entropy": 0.006159427762031555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.688281059265137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05884857848286629,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13449649016062418,
      "backward_entropy": 0.039156091213226316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9716715812683105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05888877436518669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13448017835617065,
      "backward_entropy": 0.006145958602428436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.819669723510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05892768129706383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1344645619392395,
      "backward_entropy": 0.006139783561229706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14582347869873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05896788462996483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13444764415423074,
      "backward_entropy": 0.03924985527992249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.073420524597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05900765210390091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13443086544672647,
      "backward_entropy": 0.039281314611434935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.506036281585693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05904703959822655,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13441423575083414,
      "backward_entropy": 0.03931804597377777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9312744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059084273874759674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1343989372253418,
      "backward_entropy": 0.006113949418067932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.229682445526123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05912124738097191,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1343835492928823,
      "backward_entropy": 0.039385703206062314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.391281127929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0591556541621685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13437014818191528,
      "backward_entropy": 0.03943280577659607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.556483268737793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059192460030317307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1343544820944468,
      "backward_entropy": 0.03946380913257599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.505997657775879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05922828987240791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13433939218521118,
      "backward_entropy": 0.03950119912624359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.607772827148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05926314741373062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.134324848651886,
      "backward_entropy": 0.006086336076259613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.545720100402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05929797142744064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13431008656819662,
      "backward_entropy": 0.006080728769302368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.481199264526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05933280289173126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1342951456705729,
      "backward_entropy": 0.039612919092178345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.214884281158447,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05936754122376442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13428004582722983,
      "backward_entropy": 0.006070024520158768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012785539962351322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059400517493486404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13426605860392252,
      "backward_entropy": 0.03968039155006409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.159632682800293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0594303235411644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13425459464391074,
      "backward_entropy": 0.0060582801699638365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.194347858428955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059458911418914795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13424398501714072,
      "backward_entropy": 0.03975562453269958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.349026679992676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059487197548151016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13423348466555277,
      "backward_entropy": 0.039792847633361814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.080971717834473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05951846390962601,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13422014315923056,
      "backward_entropy": 0.006041574105620384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.095046997070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05954837426543236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13420788447062174,
      "backward_entropy": 0.039859804511070254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.043349266052246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05957864224910736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13419506947199503,
      "backward_entropy": 0.03989304900169373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986294746398926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05960934981703758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13418179750442505,
      "backward_entropy": 0.039933979511260986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.909565925598145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059640318155288696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13416810830434164,
      "backward_entropy": 0.006020785868167877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876095294952393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05967223271727562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13415315747261047,
      "backward_entropy": 0.040001457929611205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76958179473877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05970437452197075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13413792848587036,
      "backward_entropy": 0.006008823588490486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.757442951202393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059737470000982285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13412171602249146,
      "backward_entropy": 0.006003864854574203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.621612548828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05977050960063934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13410516579945883,
      "backward_entropy": 0.04010525345802307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6386566162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05980432406067848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1340876817703247,
      "backward_entropy": 0.0059912513941526415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.685528755187988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05983799323439598,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13407001892725626,
      "backward_entropy": 0.040157684683799745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.153708457946777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05987067148089409,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13405293226242065,
      "backward_entropy": 0.00597485601902008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.459200859069824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05990565940737724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13403335213661194,
      "backward_entropy": 0.005964675918221474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.396725177764893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0599403977394104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13401378194491068,
      "backward_entropy": 0.04019421339035034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.675985336303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05997486412525177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13399415214856467,
      "backward_entropy": 0.0059445232152938845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.095582008361816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06000768020749092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13397608200709024,
      "backward_entropy": 0.04022519886493683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220037937164307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060041215270757675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1339570681254069,
      "backward_entropy": 0.040245944261550905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.374237537384033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06007463112473488,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1339379052321116,
      "backward_entropy": 0.005921571701765061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.648907661437988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06010717898607254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1339194377263387,
      "backward_entropy": 0.04029539227485657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.285769939422607,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06014110520482063,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13389917214711508,
      "backward_entropy": 0.13857707977294922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4984185695648193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060174036771059036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13387964169184366,
      "backward_entropy": 0.040329208970069884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.124420166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06020530313253403,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13386154174804688,
      "backward_entropy": 0.04034790992736816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.022928237915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06023889407515526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13384079933166504,
      "backward_entropy": 0.00588163249194622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.413015842437744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060274600982666016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13381763299306235,
      "backward_entropy": 0.04038013815879822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.070498466491699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06030845642089844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13379635413487753,
      "backward_entropy": 0.04040567278861999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3542263507843018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060341428965330124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13377588987350464,
      "backward_entropy": 0.04044185876846314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.327035427093506,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06037275120615959,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13375701506932577,
      "backward_entropy": 0.1385766386985779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.237566947937012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060402557253837585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13373951117197672,
      "backward_entropy": 0.04052061438560486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01094756182283163,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060433175414800644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13372071584065756,
      "backward_entropy": 0.005850651860237121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.736349105834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060460884124040604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13370500008265176,
      "backward_entropy": 0.0058469906449317936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.660545349121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06049041077494621,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1336870789527893,
      "backward_entropy": 0.040630298852920535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010709536261856556,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06052152067422867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13366703192392984,
      "backward_entropy": 0.040662699937820436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5960252285003662,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060549672693014145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13365026315053305,
      "backward_entropy": 0.005834218859672546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.157050609588623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06057599186897278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1336356004079183,
      "backward_entropy": 0.04075281023979187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.134439706802368,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0606013722717762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13362191120783487,
      "backward_entropy": 0.005833038687705993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.769099235534668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060625821352005005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1336092253526052,
      "backward_entropy": 0.04087304174900055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.175763130187988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06065155565738678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1335946520169576,
      "backward_entropy": 0.00583254024386406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.600155830383301,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06067778915166855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13357933362325033,
      "backward_entropy": 0.005831800401210785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.567997455596924,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06070363521575928,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13356426358222961,
      "backward_entropy": 0.005829885229468345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.064002990722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060729123651981354,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.133549173672994,
      "backward_entropy": 0.04107301235198975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.998725891113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06075645610690117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13353161017100015,
      "backward_entropy": 0.041107839345932005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.98237681388855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06078391522169113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13351348042488098,
      "backward_entropy": 0.04113113880157471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.912295818328857,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06081019341945648,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13349663217862448,
      "backward_entropy": 0.13858611583709718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.402079105377197,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06083689630031586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13347917795181274,
      "backward_entropy": 0.0058048654347658156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.37090539932251,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06086316332221031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13346203168233237,
      "backward_entropy": 0.005799772590398789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.781944751739502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06088912859559059,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13344517350196838,
      "backward_entropy": 0.041261494159698486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009183715097606182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060915540903806686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13342769940694174,
      "backward_entropy": 0.041305696964263915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.387657165527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06093943491578102,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1334132750829061,
      "backward_entropy": 0.04135342836380005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.88590145111084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06096669286489487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13339433073997498,
      "backward_entropy": 0.041394582390785216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.604313850402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0609961673617363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13337216774622598,
      "backward_entropy": 0.04142328500747681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7835381031036377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06102554872632027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13334977626800537,
      "backward_entropy": 0.005776162445545197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3842227458953857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061053551733493805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13332903385162354,
      "backward_entropy": 0.04147644340991974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.467862606048584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06107955425977707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1333107054233551,
      "backward_entropy": 0.04150830507278443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.134790420532227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06110578402876854,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13329186042149863,
      "backward_entropy": 0.04153455197811127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6957218647003174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06113366782665253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1332703729470571,
      "backward_entropy": 0.04156059324741364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.337918758392334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061160340905189514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13325055440266928,
      "backward_entropy": 0.04159558415412903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.936337471008301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0611872561275959,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1332302689552307,
      "backward_entropy": 0.04163339138031006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.627777099609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06121569871902466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13320761919021606,
      "backward_entropy": 0.041667452454566954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.606712579727173,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06124274432659149,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13318660855293274,
      "backward_entropy": 0.041700500249862674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5862059593200684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061268582940101624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13316703836123148,
      "backward_entropy": 0.005733238160610199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.402020454406738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0612933486700058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13314885894457498,
      "backward_entropy": 0.041778203845024106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3496832847595215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06131912022829056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13312902053197226,
      "backward_entropy": 0.04181596040725708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.781224012374878,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06134571135044098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13310766220092773,
      "backward_entropy": 0.00572115108370781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9977617263793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06137172132730484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13308682044347128,
      "backward_entropy": 0.005715176463127136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010517477989196777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061397891491651535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13306544224421182,
      "backward_entropy": 0.00570889338850975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.373610973358154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06142173707485199,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1330475409825643,
      "backward_entropy": 0.041936805844306944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.094704627990723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061447251588106155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13302693764368692,
      "backward_entropy": 0.005702238529920578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.42206072807312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06147351861000061,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13300479451815286,
      "backward_entropy": 0.13859182596206665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.994747161865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06149856001138687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13298416137695312,
      "backward_entropy": 0.04201936721801758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5684492588043213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06152450665831566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13296198844909668,
      "backward_entropy": 0.04204250276088715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.716036319732666,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06154986843466759,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13294039169947305,
      "backward_entropy": 0.13859143257141113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5096662044525146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06157539039850235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13291836778322855,
      "backward_entropy": 0.04207879304885864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.793198585510254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061600469052791595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.132896622021993,
      "backward_entropy": 0.04210197627544403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3024158477783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06162631884217262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13287344574928284,
      "backward_entropy": 0.005655358731746674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.55780553817749,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06165101006627083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13285197814305624,
      "backward_entropy": 0.005648879706859589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.646714210510254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061675913631916046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1328298052151998,
      "backward_entropy": 0.04216212034225464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3614554405212402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06170162558555603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13280616203943887,
      "backward_entropy": 0.005635548010468483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3326938152313232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06172680854797363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13278313477834067,
      "backward_entropy": 0.005629198998212815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.303668975830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06175154447555542,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13276070356369019,
      "backward_entropy": 0.13859007358551026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.544044017791748,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06177583336830139,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1327387491861979,
      "backward_entropy": 0.13859020471572875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.088275671005249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06180163472890854,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.132714182138443,
      "backward_entropy": 0.04228971004486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0772919654846191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061825692653656006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13269245624542236,
      "backward_entropy": 0.04233050346374512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.130572557449341,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06184803321957588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13267308473587036,
      "backward_entropy": 0.005607961863279343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3300652503967285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061869435012340546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13265504439671835,
      "backward_entropy": 0.04240409135818481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1436140537261963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06189249828457832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.132633904616038,
      "backward_entropy": 0.005598593875765801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.154052257537842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06191528961062431,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13261314233144125,
      "backward_entropy": 0.04246419668197632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0623619556427,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06193841993808746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13259154558181763,
      "backward_entropy": 0.04249863624572754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.046189546585083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06196051463484764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13257145881652832,
      "backward_entropy": 0.00558580681681633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0189491510391235,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06198170781135559,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1325526237487793,
      "backward_entropy": 0.04255889654159546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0171804428100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06200150400400162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13253608345985413,
      "backward_entropy": 0.04259207248687744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.004180669784546,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06202075630426407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13252049684524536,
      "backward_entropy": 0.0055744946002960205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9794440269470215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06203877925872803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13250680764516196,
      "backward_entropy": 0.04267971515655518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9592792987823486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062056951224803925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13249276081720987,
      "backward_entropy": 0.04272439479827881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.894534587860107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062075234949588776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13247828682263693,
      "backward_entropy": 0.04276833832263947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9473062753677368,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06209486350417137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13246132930119833,
      "backward_entropy": 0.005565814673900604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.896695375442505,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06211383640766144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1324453055858612,
      "backward_entropy": 0.04285663366317749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.832322359085083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06213280186057091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13242908318837485,
      "backward_entropy": 0.005561122298240661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.753652095794678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06215234473347664,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13241155942281088,
      "backward_entropy": 0.04293503761291504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8904041051864624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06217304989695549,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13239185015360513,
      "backward_entropy": 0.042970937490463254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.810511350631714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06219300627708435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13237331310908,
      "backward_entropy": 0.04301025271415711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.716360330581665,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062212880700826645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13235443830490112,
      "backward_entropy": 0.005548828840255737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.686079263687134,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062233272939920425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13233468929926553,
      "backward_entropy": 0.04309319257736206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.919002115726471,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06225402280688286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1323139766852061,
      "backward_entropy": 0.04312673211097717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.534051418304443,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062273405492305756,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13229562838872275,
      "backward_entropy": 0.043164172768592836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.599156618118286,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06229385361075401,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1322749654452006,
      "backward_entropy": 0.043195730447769164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.89665287733078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06231469660997391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.132253368695577,
      "backward_entropy": 0.005530750751495362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.192292213439941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062334105372428894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13223427534103394,
      "backward_entropy": 0.043255120515823364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7573010921478271,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062355685979127884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13221067190170288,
      "backward_entropy": 0.043275061249732974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7435661554336548,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06237625703215599,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1321887969970703,
      "backward_entropy": 0.04328787624835968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8676682710647583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062396060675382614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13216819365819296,
      "backward_entropy": 0.0055060476064682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5707740783691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06241457536816597,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13214985529581705,
      "backward_entropy": 0.04333159029483795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.095553874969482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06243305280804634,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13213151693344116,
      "backward_entropy": 0.04335634112358093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3698554039001465,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06245310977101326,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13210970163345337,
      "backward_entropy": 0.1385965585708618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5076544284820557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06247340887784958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13208701213200888,
      "backward_entropy": 0.005478602275252343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.659865140914917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0624934658408165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13206453124682108,
      "backward_entropy": 0.005469702184200287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6454352140426636,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06251279264688492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13204345107078552,
      "backward_entropy": 0.005462227389216423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4454853534698486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06253137439489365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13202364246050516,
      "backward_entropy": 0.005454833805561066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4265482425689697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06254982948303223,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1320037841796875,
      "backward_entropy": 0.04340930879116058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.208477735519409,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06256821751594543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13198391596476236,
      "backward_entropy": 0.005439611524343491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.387143850326538,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0625871866941452,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13196289539337158,
      "backward_entropy": 0.0054338425397872925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5805805921554565,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06260602176189423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1319418748219808,
      "backward_entropy": 0.043463417887687684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.691981315612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06262421607971191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13192210594813028,
      "backward_entropy": 0.0054234031587839125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8769803047180176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06264401227235794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1318987508614858,
      "backward_entropy": 0.005418263748288155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.840067148208618,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0626647099852562,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1318733592828115,
      "backward_entropy": 0.005413411930203438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5258808135986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06268608570098877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13184607028961182,
      "backward_entropy": 0.04355415105819702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7589131593704224,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06270661950111389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13182061910629272,
      "backward_entropy": 0.043581250309944156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2442824840545654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06272581964731216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13179785013198853,
      "backward_entropy": 0.04361827075481415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.704305410385132,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06274484843015671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13177531957626343,
      "backward_entropy": 0.005397112667560577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.204575300216675,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06276475638151169,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13175060351689658,
      "backward_entropy": 0.0053938768804073335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1846275329589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06278438121080399,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13172627488772073,
      "backward_entropy": 0.043723905086517335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.885216474533081,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0628037229180336,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13170223434766135,
      "backward_entropy": 0.1385978102684021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5725226402282715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0628233402967453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13167732954025269,
      "backward_entropy": 0.00538233332335949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4183483123779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06284375488758087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13165034850438437,
      "backward_entropy": 0.005377749726176262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4062719345092773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06286326795816422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1316251258055369,
      "backward_entropy": 0.043834760785102844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6993269324302673,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06288207322359085,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13160155216852823,
      "backward_entropy": 0.13859932422637938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1336445808410645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062899649143219,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1315805415312449,
      "backward_entropy": 0.043911096453666684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.823785305023193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06291864812374115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13155597448349,
      "backward_entropy": 0.043941399455070494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.703808069229126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06294100731611252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13152352968851724,
      "backward_entropy": 0.005358488112688064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3390085697174072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06296338886022568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13149065772692362,
      "backward_entropy": 0.005353847518563271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3063337802886963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06298461556434631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13146018981933594,
      "backward_entropy": 0.005348755791783333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.617011785507202,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0630064383149147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13142818212509155,
      "backward_entropy": 0.044029951095581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6505655646324158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06302818655967712,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13139596581459045,
      "backward_entropy": 0.044050556421279904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.563062906265259,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06304829567670822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13136724630991617,
      "backward_entropy": 0.005332745984196663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.80248761177063,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06306854635477066,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13133804003397623,
      "backward_entropy": 0.13860138654708862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.508958339691162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06308990716934204,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13130592306454977,
      "backward_entropy": 0.044106322526931765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7197718620300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06311121582984924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13127357761065164,
      "backward_entropy": 0.005315156280994415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2290277481079102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06313347071409225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1312385400136312,
      "backward_entropy": 0.04413379430770874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2160958051681519,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06315457820892334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13120620449384054,
      "backward_entropy": 0.04414717257022858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.203346848487854,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06317471712827682,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13117611408233643,
      "backward_entropy": 0.13860141038894652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.968931198120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06319396942853928,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13114803036053976,
      "backward_entropy": 0.0441961795091629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5921401381492615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06321381032466888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1311179200808207,
      "backward_entropy": 0.044218575954437254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4900853633880615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06323229521512985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13109126687049866,
      "backward_entropy": 0.04424825310707092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.603532314300537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06325192749500275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13106139500935873,
      "backward_entropy": 0.005278223007917404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.548933982849121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06327361613512039,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13102606932322183,
      "backward_entropy": 0.04429555833339691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6871050596237183,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06329707056283951,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13098580638567606,
      "backward_entropy": 0.005267292261123657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.220017671585083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06331969052553177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1309474011262258,
      "backward_entropy": 0.04432735443115234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.192229986190796,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06334204971790314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13090930382410684,
      "backward_entropy": 0.044343370199203494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.165557622909546,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06336414068937302,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13087155421574911,
      "backward_entropy": 0.04435687065124512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1386067867279053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06338602304458618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13083407282829285,
      "backward_entropy": 0.005242176726460457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006233402993530035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06340767443180084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13079688946406046,
      "backward_entropy": 0.0052357673645019535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6095893383026123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06342735886573792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13076507051785788,
      "backward_entropy": 0.005231767147779465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.579690456390381,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06344746798276901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13073168198267618,
      "backward_entropy": 0.005227047950029373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0581226348876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06346796452999115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.130696972211202,
      "backward_entropy": 0.04446379244327545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0102590322494507,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06348928064107895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13065963983535767,
      "backward_entropy": 0.005216715484857559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5019406080245972,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06350947916507721,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13062512874603271,
      "backward_entropy": 0.0445102721452713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.46002197265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06352822482585907,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1305945416291555,
      "backward_entropy": 0.044539517164230345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9764220118522644,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06354741007089615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13056246439615884,
      "backward_entropy": 0.005202753469347954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4451545476913452,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0635657086968422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13053260246912637,
      "backward_entropy": 0.04459225833415985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3797566890716553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06358356028795242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1305034557978312,
      "backward_entropy": 0.04461728930473328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9444209337234497,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06360192596912384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13047261039415994,
      "backward_entropy": 0.005188295245170593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8637973070144653,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06361942738294601,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13044416904449463,
      "backward_entropy": 0.0051830530166625975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.843347430229187,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06363705545663834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1304150919119517,
      "backward_entropy": 0.04468649625778198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9141371846199036,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06365475803613663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13038546840349832,
      "backward_entropy": 0.005172807723283768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9046722650527954,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06367164850234985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13035808006922403,
      "backward_entropy": 0.04473319351673126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7862679958343506,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06368781626224518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13033260901769003,
      "backward_entropy": 0.005162936821579933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4460635781288147,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0637042447924614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13030612468719482,
      "backward_entropy": 0.04479014277458191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8777714967727661,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06371960043907166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1302829384803772,
      "backward_entropy": 0.005155926942825318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.734257459640503,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06373437494039536,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1302612324555715,
      "backward_entropy": 0.044865813851356504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8618378639221191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06374949216842651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13023823499679565,
      "backward_entropy": 0.04490373134613037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.277022123336792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06376411765813828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13021673758824667,
      "backward_entropy": 0.005148646235466003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1061899662017822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0637785866856575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13019534945487976,
      "backward_entropy": 0.0449888288974762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6693891286849976,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06379383057355881,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13017145792643228,
      "backward_entropy": 0.005143113061785698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.652419924736023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0638093575835228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1301463544368744,
      "backward_entropy": 0.045065635442733766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2277687788009644,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0638251081109047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13012045621871948,
      "backward_entropy": 0.0451033890247345,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.377940846174024,
    "avg_log_Z": -0.0628809317573905,
    "success_rate": 1.0,
    "avg_reward": 42.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.05,
      "1": 0.54,
      "2": 0.41
    },
    "avg_forward_entropy": 0.1314995715022087,
    "avg_backward_entropy": 0.0327727524600923,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}