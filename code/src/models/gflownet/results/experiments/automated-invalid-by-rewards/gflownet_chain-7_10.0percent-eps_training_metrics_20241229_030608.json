{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09884547335760933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09859347343444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.84547424316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656045496463776,
      "backward_entropy": 0.09871128627232142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.88438415527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656426966190338,
      "backward_entropy": 0.09859926359994071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.30616760253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00019886289373971522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656778633594513,
      "backward_entropy": 0.09885323899132865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.36822509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00029508169973269105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13657061755657196,
      "backward_entropy": 0.09885660239628383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.62887573242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003929978993255645,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657350838184357,
      "backward_entropy": 0.09875275407518659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.76235961914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004921010695397854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13657617568969727,
      "backward_entropy": 0.09862010819571358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.17965698242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005905205616727471,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13657858967781067,
      "backward_entropy": 0.09886724608285087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.70118713378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006901969318278134,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658088445663452,
      "backward_entropy": 0.09878202847072057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.20098876953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000788897683378309,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365828812122345,
      "backward_entropy": 0.09887426240103585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.26519775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008881449466571212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13658471405506134,
      "backward_entropy": 0.09864094427653722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.61077880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000986630329862237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658654689788818,
      "backward_entropy": 0.09888093812125069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.43453979492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010844165226444602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658809661865234,
      "backward_entropy": 0.09888410568237305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.07119750976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011797392508015037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658905029296875,
      "backward_entropy": 0.09888706888471331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.0067138671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012763355625793338,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658994436264038,
      "backward_entropy": 0.09883362906319755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.49359130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013708192855119705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659043610095978,
      "backward_entropy": 0.09889285905020577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.21237182617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014653232647106051,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13659071922302246,
      "backward_entropy": 0.09884847061974662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.94288635253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015596344601362944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659055531024933,
      "backward_entropy": 0.09889824049813407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.40585327148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016554957255721092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659030199050903,
      "backward_entropy": 0.09890090567725045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.49664306640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001751190284267068,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658985495567322,
      "backward_entropy": 0.09886835302625384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.348388671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018464073073118925,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365889012813568,
      "backward_entropy": 0.098874602999006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.17474365234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019376645796000957,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658751547336578,
      "backward_entropy": 0.09888046128409249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.14315795898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0020346546079963446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658630847930908,
      "backward_entropy": 0.09891072341373988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.49490356445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021347671281546354,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365850269794464,
      "backward_entropy": 0.09889266320637294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.5536346435547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00223502772860229,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365830898284912,
      "backward_entropy": 0.09889858109610421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.54058837890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002338774036616087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365811675786972,
      "backward_entropy": 0.09891877004078456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.17735290527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002443396020680666,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365790218114853,
      "backward_entropy": 0.09891034875597272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.06198120117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002552035264670849,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657677173614502,
      "backward_entropy": 0.09891622407095772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.80197143554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026614752132445574,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657402992248535,
      "backward_entropy": 0.09892193760190691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.7234649658203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002770601073279977,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657091557979584,
      "backward_entropy": 0.0989274297441755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.19818115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00288026942871511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656723499298096,
      "backward_entropy": 0.09893267495291573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.737548828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029906814452260733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656330108642578,
      "backward_entropy": 0.09893532310213361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.32359313964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003102522576227784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13655903935432434,
      "backward_entropy": 0.0987403392791748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.83370971679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032156140077859163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13655447959899902,
      "backward_entropy": 0.09874541418892997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.20867919921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0033315327018499374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13654978573322296,
      "backward_entropy": 0.09875060830797468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.36729431152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034459924791008234,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136544868350029,
      "backward_entropy": 0.09895718097686768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.7652587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035601521376520395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13653962314128876,
      "backward_entropy": 0.09894818067550659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.28680419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003673085244372487,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13653425872325897,
      "backward_entropy": 0.09876487936292376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.87606811523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0037858630530536175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13652855157852173,
      "backward_entropy": 0.09876926456178937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.136474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038963211700320244,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13652276992797852,
      "backward_entropy": 0.09897325720105853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.3692169189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0040031005628407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13651667535305023,
      "backward_entropy": 0.0987769535609654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.9016876220703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004106785636395216,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13651043176651,
      "backward_entropy": 0.09897969450269427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.09024047851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00421398039907217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365041881799698,
      "backward_entropy": 0.09895988021578107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.74818420410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004321637563407421,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13649755716323853,
      "backward_entropy": 0.09898553575788226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.5556182861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004431035369634628,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13649077713489532,
      "backward_entropy": 0.09878990479878016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.09249877929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004535186570137739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13648314774036407,
      "backward_entropy": 0.09879265512738909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.62362670898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00464263092726469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364753246307373,
      "backward_entropy": 0.0989659173148019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.37010192871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004751753993332386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13646730780601501,
      "backward_entropy": 0.09879822390420097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.44544982910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004863361362367868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645899295806885,
      "backward_entropy": 0.09880099977765765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.0326690673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004969344008713961,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645072281360626,
      "backward_entropy": 0.09880341802324567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.1201934814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005074472166597843,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13644243776798248,
      "backward_entropy": 0.09900133950369698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.05259704589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0051778401248157024,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13643412292003632,
      "backward_entropy": 0.09900301694869995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.5207061767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005283396691083908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364256590604782,
      "backward_entropy": 0.09897303581237793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.0270538330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005386719945818186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13641682267189026,
      "backward_entropy": 0.09897392988204956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.19161224365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005488437134772539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13640795648097992,
      "backward_entropy": 0.0989747302872794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.42587280273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005585746839642525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363990157842636,
      "backward_entropy": 0.09881401062011719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.79171752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0056817010045051575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13638967275619507,
      "backward_entropy": 0.09897586277553014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.393310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005777896381914616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13637995719909668,
      "backward_entropy": 0.09897633961268834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.45201110839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00587440887466073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136369988322258,
      "backward_entropy": 0.09881684609821864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.62249755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0059709129855036736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635951280593872,
      "backward_entropy": 0.09897709744317192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.90452575683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006069387774914503,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13634903728961945,
      "backward_entropy": 0.09901300498417445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.0034942626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006166477221995592,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13633829355239868,
      "backward_entropy": 0.09881882156644549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.20399475097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00626510102301836,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13632717728614807,
      "backward_entropy": 0.09901435886110578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.06771850585938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006362215615808964,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13631571829319,
      "backward_entropy": 0.09901493787765503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.26626586914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006456674542278051,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13630411028862,
      "backward_entropy": 0.09897809369223458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1278533935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006554372608661652,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13629211485385895,
      "backward_entropy": 0.09881986890520368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.0740203857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00665373494848609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13627976179122925,
      "backward_entropy": 0.09897816181182861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.3267059326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0067514898255467415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13626660406589508,
      "backward_entropy": 0.09881978375571114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.82847595214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006851098965853453,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362532675266266,
      "backward_entropy": 0.09901721136910575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.52655029296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006944692227989435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13623973727226257,
      "backward_entropy": 0.09881886414119176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.49884796142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007039274554699659,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362261325120926,
      "backward_entropy": 0.09881811482565743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.816650390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007129831239581108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13621222972869873,
      "backward_entropy": 0.09881714412144252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.12567138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00722162751480937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13619814813137054,
      "backward_entropy": 0.09881605420793806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.11474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007317493204027414,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13618391752243042,
      "backward_entropy": 0.09901864188058036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.61348724365234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007412307895720005,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13616931438446045,
      "backward_entropy": 0.09901884623936244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.8930358886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007500099949538708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13615477085113525,
      "backward_entropy": 0.09897559029715401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.9337615966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0075971027836203575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13613927364349365,
      "backward_entropy": 0.0989750964300973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.38417053222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007693158928304911,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13612374663352966,
      "backward_entropy": 0.09901937416621617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.83547973632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0077949040569365025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361076533794403,
      "backward_entropy": 0.09880905491965157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.82850646972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007892218418419361,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13609172403812408,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.151611328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007988512516021729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13607577979564667,
      "backward_entropy": 0.09897274630410331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.17312622070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008083796128630638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13605967164039612,
      "backward_entropy": 0.09880452496664864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.121826171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008171717636287212,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13604344427585602,
      "backward_entropy": 0.0990199191229684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.7235870361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008263648487627506,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13602674007415771,
      "backward_entropy": 0.09901997872761317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.37030029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008356420323252678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13601011037826538,
      "backward_entropy": 0.0989694425037929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.03952026367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00844844151288271,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359931081533432,
      "backward_entropy": 0.09902008942195348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.63641357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008535156026482582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13597583770751953,
      "backward_entropy": 0.09879404306411743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.87380981445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008624590933322906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359579861164093,
      "backward_entropy": 0.09896627494267055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.19677734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00872060563415289,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13593944907188416,
      "backward_entropy": 0.09896515096936907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.42523193359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008818372152745724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13592040538787842,
      "backward_entropy": 0.09878695011138916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.14971923828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00892289262264967,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13590040802955627,
      "backward_entropy": 0.09902023417609078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.71575927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009024045430123806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13588017225265503,
      "backward_entropy": 0.09896177904946464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.3769989013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009127635508775711,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13585928082466125,
      "backward_entropy": 0.09896087646484375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.33204650878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00923196505755186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358378380537033,
      "backward_entropy": 0.0989599313054766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.5712127685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009336945600807667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13581582903862,
      "backward_entropy": 0.09877470561436244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.81362915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009443902410566807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13579323887825012,
      "backward_entropy": 0.0989579473223005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.8549346923828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009552783332765102,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1357702612876892,
      "backward_entropy": 0.09902027675083705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.0868682861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009660633280873299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13574713468551636,
      "backward_entropy": 0.0989558185849871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.99363708496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009768983349204063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357237696647644,
      "backward_entropy": 0.0987626314163208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.25128173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009872873313724995,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13569988310337067,
      "backward_entropy": 0.0990201575415475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.53652954101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009972958825528622,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13567569851875305,
      "backward_entropy": 0.09902010645185198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.7711181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010070840828120708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13565081357955933,
      "backward_entropy": 0.09875222614833287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.61326599121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010165944695472717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13562607765197754,
      "backward_entropy": 0.09894888741629464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.0120086669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010253910906612873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13560190796852112,
      "backward_entropy": 0.09894701412745885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.02142333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010341343469917774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13557732105255127,
      "backward_entropy": 0.0989450556891305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.23553466796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010426964610815048,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13555267453193665,
      "backward_entropy": 0.09901959555489677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.68389892578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010512523353099823,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355278193950653,
      "backward_entropy": 0.0990194422858102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.50238037109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010602051392197609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13550186157226562,
      "backward_entropy": 0.09893883977617536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.89727783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010692027397453785,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13547495007514954,
      "backward_entropy": 0.09872150421142578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.30023193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010790100321173668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354471892118454,
      "backward_entropy": 0.09893471002578735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.19915771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01089369785040617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13541845977306366,
      "backward_entropy": 0.0989328111921038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.8466796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010998042300343513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13538925349712372,
      "backward_entropy": 0.0990188377244132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.87596130371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011102852411568165,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13535937666893005,
      "backward_entropy": 0.09901872703007289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.22158813476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011206811293959618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13532911241054535,
      "backward_entropy": 0.09892683369772774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.3390350341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0113096097484231,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13529810309410095,
      "backward_entropy": 0.09869593381881714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.35342407226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011417246423661709,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352660357952118,
      "backward_entropy": 0.09892230374472481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.65618896484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01152040995657444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352335810661316,
      "backward_entropy": 0.0989196811403547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.84136962890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01162705011665821,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1352003663778305,
      "backward_entropy": 0.0990181735583714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.75129699707031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011734033934772015,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.135166734457016,
      "backward_entropy": 0.09901807137898036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.03683471679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011834120377898216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.135133758187294,
      "backward_entropy": 0.09891130243028913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.7603759765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011932088993489742,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13510030508041382,
      "backward_entropy": 0.09901778187070574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.068603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012033993378281593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350657343864441,
      "backward_entropy": 0.0989048821585519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 271.5020751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012132268399000168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13503117859363556,
      "backward_entropy": 0.09890142508915492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.54237365722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012238685972988605,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13499537110328674,
      "backward_entropy": 0.09901739869798933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.63865661621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012348281219601631,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13495901226997375,
      "backward_entropy": 0.09901731354849679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.7581024169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012456262484192848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134922593832016,
      "backward_entropy": 0.0986455764089312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.1903076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012567124329507351,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348855048418045,
      "backward_entropy": 0.09888858454568046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.43482971191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012676309794187546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1348482072353363,
      "backward_entropy": 0.09863626956939697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.6610107421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0127871073782444,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1348106861114502,
      "backward_entropy": 0.09901711770466395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.555908203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012888280674815178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13477309048175812,
      "backward_entropy": 0.09887785570962089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.93853759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012989820912480354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13473433256149292,
      "backward_entropy": 0.09862075533185687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.46380615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013093583285808563,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13469499349594116,
      "backward_entropy": 0.09861530576433454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.97996520996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013194702565670013,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1346551775932312,
      "backward_entropy": 0.09901668344225202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.75172424316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013299200683832169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13461413979530334,
      "backward_entropy": 0.09886103016989571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.97119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01340557262301445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345725804567337,
      "backward_entropy": 0.09859835250037056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.7283172607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013509106822311878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345306932926178,
      "backward_entropy": 0.09859231540134974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.95396423339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013611366972327232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13448801636695862,
      "backward_entropy": 0.09884721892220634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.13912963867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01371325459331274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1344456523656845,
      "backward_entropy": 0.09884242500577654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.5629119873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0138129573315382,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13440315425395966,
      "backward_entropy": 0.0990156786782401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.35989379882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013916170224547386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343592405319214,
      "backward_entropy": 0.0985661234174456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.19635009765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01401724386960268,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13431525230407715,
      "backward_entropy": 0.09901542322976249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.912109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01411911565810442,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13427060842514038,
      "backward_entropy": 0.09901528699057442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.65365600585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014222932048141956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1342247873544693,
      "backward_entropy": 0.09854490416390556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.2586212158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014325610361993313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341783106327057,
      "backward_entropy": 0.09881189891270228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.35504150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01442736480385065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341313123703003,
      "backward_entropy": 0.0988063897405352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.48046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014525532722473145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1340845674276352,
      "backward_entropy": 0.0990147420338222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.75900268554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01462315022945404,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13403703272342682,
      "backward_entropy": 0.09901455470493861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.10093688964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014720180071890354,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13398855924606323,
      "backward_entropy": 0.09901435034615653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.9095916748047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014818334951996803,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1339392215013504,
      "backward_entropy": 0.09901416301727295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.3692626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014921548776328564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13388794660568237,
      "backward_entropy": 0.0987755571092878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 268.8559265136719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015026537701487541,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13383550941944122,
      "backward_entropy": 0.09901399271828788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.60552978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015138727612793446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13378116488456726,
      "backward_entropy": 0.0987637894494193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.10134887695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015253220684826374,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13372576236724854,
      "backward_entropy": 0.09901412895747594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.23977661132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015366516076028347,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1336691677570343,
      "backward_entropy": 0.09846058913639613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.3970489501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015474594198167324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13361254334449768,
      "backward_entropy": 0.09874567815235682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.24916076660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01558621320873499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13355368375778198,
      "backward_entropy": 0.09844519410814558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.83816528320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01569848507642746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13349370658397675,
      "backward_entropy": 0.09873201165880476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.46463012695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015811417251825333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1334327608346939,
      "backward_entropy": 0.09872501237051827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 270.38641357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015927735716104507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13337042927742004,
      "backward_entropy": 0.09871814932141985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.58717346191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016049135476350784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13330528140068054,
      "backward_entropy": 0.09841654981885638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.84759521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016168756410479546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13323970139026642,
      "backward_entropy": 0.09840943132128034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.4324493408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01628556288778782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13317430019378662,
      "backward_entropy": 0.09840161459786552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.30056762695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016401052474975586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13310831785202026,
      "backward_entropy": 0.09839344876153129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.95932006835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016520487144589424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13303998112678528,
      "backward_entropy": 0.09838572570255824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.51617431640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01663864590227604,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13297180831432343,
      "backward_entropy": 0.09901403529303414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.6412811279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01675683818757534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13290300965309143,
      "backward_entropy": 0.09866611446653094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.50495147705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01687842421233654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13283146917819977,
      "backward_entropy": 0.09865848507199969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.31842041015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016992365941405296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13276076316833496,
      "backward_entropy": 0.09835095064980644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.62518310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017105627804994583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13269026577472687,
      "backward_entropy": 0.09834086043494088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.23095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017214840278029442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1326194405555725,
      "backward_entropy": 0.09833010605403356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.08251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017320506274700165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13254837691783905,
      "backward_entropy": 0.0983185853276934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.68634033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01742412894964218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13247615098953247,
      "backward_entropy": 0.09830673251833234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.94796752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0175282284617424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13240407407283783,
      "backward_entropy": 0.09859699862343925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.065185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017637724056839943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13232961297035217,
      "backward_entropy": 0.09858621869768415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.34217834472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017742469906806946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13225588202476501,
      "backward_entropy": 0.09826901980808803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.3184051513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01784864440560341,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13218125700950623,
      "backward_entropy": 0.09901166813714164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.9110107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017954442650079727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13210555911064148,
      "backward_entropy": 0.09855023452213832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.1563262939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018056130036711693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13203105330467224,
      "backward_entropy": 0.09853715556008476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.10772705078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018157904967665672,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13195547461509705,
      "backward_entropy": 0.0990101865359715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.6155548095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01826002635061741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13188078999519348,
      "backward_entropy": 0.0985102653503418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.9839630126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018359826877713203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318066120147705,
      "backward_entropy": 0.09849638598305839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.44891357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01846044696867466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13173194229602814,
      "backward_entropy": 0.09816185065678187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.87112426757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01856536790728569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1316542774438858,
      "backward_entropy": 0.09846958943775722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.66859436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018666153773665428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13157738745212555,
      "backward_entropy": 0.09812861680984497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.96078491210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018764646723866463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13150066137313843,
      "backward_entropy": 0.0984405619757516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.50579833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01886126399040222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13142439723014832,
      "backward_entropy": 0.09842537130628314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.943603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018958477303385735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13134624063968658,
      "backward_entropy": 0.09840968676975795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.50636291503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019057702273130417,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13126595318317413,
      "backward_entropy": 0.09900404725755964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.44418334960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019155843183398247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1311844438314438,
      "backward_entropy": 0.09837749174662999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.39151000976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01925598457455635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1311011165380478,
      "backward_entropy": 0.09836115155901227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.0088653564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01935218833386898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13101789355278015,
      "backward_entropy": 0.0983433553150722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.13860321044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019444944337010384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1309349238872528,
      "backward_entropy": 0.09832433291843959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.63377380371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019533149898052216,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13085263967514038,
      "backward_entropy": 0.09899917670658656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.31109619140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019619882106781006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13076898455619812,
      "backward_entropy": 0.09793058463505336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.32908630371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019709741696715355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1306823492050171,
      "backward_entropy": 0.0982609646660941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.19744873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019799668341875076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13059449195861816,
      "backward_entropy": 0.09788623877934047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.62351989746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019889386370778084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1305048167705536,
      "backward_entropy": 0.09786365713391985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.79098510742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01997631974518299,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13041526079177856,
      "backward_entropy": 0.0978400366646903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.38539123535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020059293136000633,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13032634556293488,
      "backward_entropy": 0.09899067027228219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.5628204345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020143242552876472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1302364617586136,
      "backward_entropy": 0.0981436116354806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.36123657226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02022770792245865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13014471530914307,
      "backward_entropy": 0.09898742607661656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.0895233154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0203088391572237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1300545036792755,
      "backward_entropy": 0.09809185777391706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.76276397705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02039087936282158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12996169924736023,
      "backward_entropy": 0.0977090767451695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.90277099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020467981696128845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12986764311790466,
      "backward_entropy": 0.09803622109549386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 264.0976257324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020547492429614067,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12976917624473572,
      "backward_entropy": 0.09800706590924944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.64320373535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020636269822716713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12966370582580566,
      "backward_entropy": 0.09762213059834071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.37298583984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02072218805551529,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12955763936042786,
      "backward_entropy": 0.09759441443852016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.95858764648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020809950307011604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1294490098953247,
      "backward_entropy": 0.09792484555925642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.17926025390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02089812234044075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12933915853500366,
      "backward_entropy": 0.09789691652570452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.45028686523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020985227078199387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1292288601398468,
      "backward_entropy": 0.09751154695238386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.95465087890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021075570955872536,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1291155368089676,
      "backward_entropy": 0.09897301878247942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.48947143554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02116299793124199,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290021687746048,
      "backward_entropy": 0.09745558670588902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.1492462158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021251946687698364,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12888580560684204,
      "backward_entropy": 0.09897087301526751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.89590454101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021339666098356247,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1287689208984375,
      "backward_entropy": 0.09896972349711827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.0102996826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021419193595647812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1286565363407135,
      "backward_entropy": 0.09736347198486328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.75054931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021500078961253166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12854266166687012,
      "backward_entropy": 0.09732911416462489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.7932891845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02158164605498314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12842576205730438,
      "backward_entropy": 0.09764329876218523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.25489807128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021661099046468735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1283082216978073,
      "backward_entropy": 0.09760546684265137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.77142333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021741483360528946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12818796932697296,
      "backward_entropy": 0.09756687709263392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.26168823242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02182576060295105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12806394696235657,
      "backward_entropy": 0.0975297178540911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.9208221435547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021913347765803337,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12793587148189545,
      "backward_entropy": 0.09895753860473633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.90113830566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022008085623383522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1278015375137329,
      "backward_entropy": 0.09745996338980538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.98355102539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02210632711648941,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12766282260417938,
      "backward_entropy": 0.09710211413247245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.59417724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02220664545893669,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1275218427181244,
      "backward_entropy": 0.09707473005567278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.8707275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022303134202957153,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1273822784423828,
      "backward_entropy": 0.09704399108886719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.25753784179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02240055985748768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1272413730621338,
      "backward_entropy": 0.09732563155038017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.14396667480469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022495798766613007,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12710031867027283,
      "backward_entropy": 0.09697866439819336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.07173156738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022584524005651474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12696143984794617,
      "backward_entropy": 0.09694044930594307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.2188720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022667381912469864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12682455778121948,
      "backward_entropy": 0.09719794137137276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.95050048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02274549938738346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12669116258621216,
      "backward_entropy": 0.09714714118412562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.88455963134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022821752354502678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12655848264694214,
      "backward_entropy": 0.09709286689758301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.5830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022895311936736107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12642914056777954,
      "backward_entropy": 0.09703654050827026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.5936737060547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022970758378505707,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12629765272140503,
      "backward_entropy": 0.09894069603511266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.06948852539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02305327169597149,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12615898251533508,
      "backward_entropy": 0.09692881788526263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.64933013916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023132652044296265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12602292001247406,
      "backward_entropy": 0.09661065680640084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.62266540527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023206068202853203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12589076161384583,
      "backward_entropy": 0.09681561163493566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.75050354003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023282838985323906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575508654117584,
      "backward_entropy": 0.09675834860120501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.9554901123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02335807867348194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12561877071857452,
      "backward_entropy": 0.096449647630964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.68435668945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02343505062162876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12548013031482697,
      "backward_entropy": 0.09639506680624825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.44834899902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02351393736898899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12533943355083466,
      "backward_entropy": 0.09892029421670097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.07489013671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02359428070485592,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1251932978630066,
      "backward_entropy": 0.09891803775514875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.17897033691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023675408214330673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1250421702861786,
      "backward_entropy": 0.09623104333877563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.1092987060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023753024637699127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12489083409309387,
      "backward_entropy": 0.09640611069543022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.3803253173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023837536573410034,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12473088502883911,
      "backward_entropy": 0.09891183887209211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.09835815429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023919671773910522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12457089871168137,
      "backward_entropy": 0.09628738675798688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.24652099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024004120379686356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12440579384565353,
      "backward_entropy": 0.09622687952859062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.33636474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024087753146886826,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1242399662733078,
      "backward_entropy": 0.0989067895071847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.1099853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024172460660338402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12407267093658447,
      "backward_entropy": 0.09590593406132289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.2913360595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024255044758319855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12390609085559845,
      "backward_entropy": 0.09584667001451765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.589599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02433563582599163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12373991310596466,
      "backward_entropy": 0.0959677015032087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.63046264648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02441304922103882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12357547879219055,
      "backward_entropy": 0.09589451551437378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.85293579101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024487249553203583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1234109103679657,
      "backward_entropy": 0.09581593104771205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.16278076171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02456316165626049,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12324276566505432,
      "backward_entropy": 0.09888797146933419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.8714599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02463923953473568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12307299673557281,
      "backward_entropy": 0.09565836191177368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.04595184326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024718305096030235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12289848923683167,
      "backward_entropy": 0.09543487003871373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.6671371459961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024791553616523743,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12272968888282776,
      "backward_entropy": 0.09887674025126866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.2140350341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02486123889684677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12256510555744171,
      "backward_entropy": 0.09540977648326329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.39173126220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024937395006418228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12239163368940353,
      "backward_entropy": 0.09532747949872698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.75453186035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02500784769654274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12222304940223694,
      "backward_entropy": 0.09511356694357735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.24661254882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025076156482100487,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1220548003911972,
      "backward_entropy": 0.09885631288800921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.03594970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02514973282814026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12187983095645905,
      "backward_entropy": 0.09493951286588397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.6611328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025222256779670715,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12170407176017761,
      "backward_entropy": 0.09884670802525111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.71466064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02529514580965042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12152545154094696,
      "backward_entropy": 0.0948648282459804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.15792846679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02536863088607788,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1213451698422432,
      "backward_entropy": 0.09467614548546928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.4950408935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025441262871026993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12116517126560211,
      "backward_entropy": 0.0946706874029977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.8900146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025517551228404045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1209806278347969,
      "backward_entropy": 0.09449449607304164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.2750244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025596950203180313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12079112976789474,
      "backward_entropy": 0.09448526586805071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.5143280029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025675084441900253,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12060322612524033,
      "backward_entropy": 0.09431445598602295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.39588928222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02575165033340454,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12041459232568741,
      "backward_entropy": 0.09881978375571114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.19544982910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02582681179046631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12022579461336136,
      "backward_entropy": 0.09418153762817383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.58338928222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025894612073898315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12004285305738449,
      "backward_entropy": 0.09406093188694545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.16864013671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025964774191379547,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11985485255718231,
      "backward_entropy": 0.09880014828273229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.63864135742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02604128047823906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11965641379356384,
      "backward_entropy": 0.09382457392556327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.06361389160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026118306443095207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1194581538438797,
      "backward_entropy": 0.09369518075670515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.51023864746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026193806901574135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192592978477478,
      "backward_entropy": 0.09358771358217512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.75108337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02627399004995823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11905363202095032,
      "backward_entropy": 0.09347256592341832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.36273956298828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02635267749428749,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11884980648756027,
      "backward_entropy": 0.0987815260887146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.31790161132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026428623124957085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186494529247284,
      "backward_entropy": 0.09322936194283622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.0830535888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026500258594751358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11845222115516663,
      "backward_entropy": 0.09309450217655726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.81514739990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026575447991490364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11824917793273926,
      "backward_entropy": 0.092962418283735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.4749298095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02664799429476261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11804710328578949,
      "backward_entropy": 0.09282248360770089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.95770263671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026725221425294876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783657968044281,
      "backward_entropy": 0.09268452439989362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.6500244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026808174327015877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11761632561683655,
      "backward_entropy": 0.09255197218486241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.85133361816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026893436908721924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11739152669906616,
      "backward_entropy": 0.09241972650800433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.35018920898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02698238380253315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11716197431087494,
      "backward_entropy": 0.09246092183249337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.33692932128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027068713679909706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693485081195831,
      "backward_entropy": 0.09215362582887922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.05885314941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027156919240951538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11670204997062683,
      "backward_entropy": 0.09201254163469587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.9126434326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02724258415400982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11647156625986099,
      "backward_entropy": 0.09186271258762904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.99557495117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027325965464115143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11624274402856827,
      "backward_entropy": 0.09170470918927874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.92922973632812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027411777526140213,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11601004004478455,
      "backward_entropy": 0.0987401008605957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.2138671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02750248834490776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11576969921588898,
      "backward_entropy": 0.09139880963734218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.9019775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027590490877628326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11553215980529785,
      "backward_entropy": 0.09124035494668144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.18304443359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027680277824401855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11529052257537842,
      "backward_entropy": 0.09145774160112653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.02252197265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027770131826400757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11504681408405304,
      "backward_entropy": 0.09132327352251325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.8292694091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027853410691022873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11481407284736633,
      "backward_entropy": 0.09073960781097412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.20652770996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02793603576719761,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1145799309015274,
      "backward_entropy": 0.09101733991077968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.54816436767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028016850352287292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434794217348099,
      "backward_entropy": 0.09036711284092494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.71942138671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028095876798033714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411689221858978,
      "backward_entropy": 0.09017006840024676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.3990020751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028177941218018532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11388187110424042,
      "backward_entropy": 0.08997960601534162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.74111938476562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028259405866265297,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1136450245976448,
      "backward_entropy": 0.09869234902518136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.69281768798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028340497985482216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11340776085853577,
      "backward_entropy": 0.08958005905151367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.53598022460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02841714210808277,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1131773293018341,
      "backward_entropy": 0.0893665041242327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.56983947753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028489453718066216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11295163631439209,
      "backward_entropy": 0.08913847378322057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.48213958740234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028556447476148605,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11273343861103058,
      "backward_entropy": 0.09864749227251325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.4376983642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0286230631172657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11251428723335266,
      "backward_entropy": 0.08864779131753105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.94847106933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028690991923213005,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11229303479194641,
      "backward_entropy": 0.09861564636230469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.8264923095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028758542612195015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11207102239131927,
      "backward_entropy": 0.08815106323787145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.63754272460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028836876153945923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11182935535907745,
      "backward_entropy": 0.08792081901005336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.283447265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02891378290951252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11158934980630875,
      "backward_entropy": 0.08768518481935773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.07212829589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028996625915169716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11134056746959686,
      "backward_entropy": 0.0884030716759818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.08099365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029080599546432495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11109039932489395,
      "backward_entropy": 0.08724021060126168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.8157730102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029163893312215805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11083966493606567,
      "backward_entropy": 0.08700914893831525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.59844207763672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029242387041449547,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11059658229351044,
      "backward_entropy": 0.09856344972337995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.1787567138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029316240921616554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11035788059234619,
      "backward_entropy": 0.08649556125913348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.06063842773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029391838237643242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11011481285095215,
      "backward_entropy": 0.0862264803477696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.74159240722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02946481853723526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10987555980682373,
      "backward_entropy": 0.08716263941356114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.59170532226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029533879831433296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1096414178609848,
      "backward_entropy": 0.08692389726638794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.30636596679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02960231527686119,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10940702259540558,
      "backward_entropy": 0.08536112308502197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.70748138427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029664451256394386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10918277502059937,
      "backward_entropy": 0.08641784531729561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.33610534667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029726512730121613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1089564710855484,
      "backward_entropy": 0.08614922421319145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.40462493896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02978607639670372,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10873644798994064,
      "backward_entropy": 0.08586795840944562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.16351318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029844582080841064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10851743817329407,
      "backward_entropy": 0.08558058738708496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.0306854248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029906604439020157,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1082925945520401,
      "backward_entropy": 0.08530020713806152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.17414855957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029970547184348106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10806535184383392,
      "backward_entropy": 0.08502188750675746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.91019439697266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030032942071557045,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10783892869949341,
      "backward_entropy": 0.09834960528782435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.56600952148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030092762783169746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10761772096157074,
      "backward_entropy": 0.08274048566818237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.09255981445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03015035018324852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10740154981613159,
      "backward_entropy": 0.08239283732005528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.77960968017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030208850279450417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10718461871147156,
      "backward_entropy": 0.08382390226636614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.2153778076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030266303569078445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10696674883365631,
      "backward_entropy": 0.08169123956135341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.25984191894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030325734987854958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10674259066581726,
      "backward_entropy": 0.08133455685206822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.58154296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03038412146270275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10651876032352448,
      "backward_entropy": 0.08289320128304618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.91788482666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03043864481151104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10630065202713013,
      "backward_entropy": 0.08058491774967738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.63571166992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030493011698126793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1060851514339447,
      "backward_entropy": 0.08020172800336565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.2628631591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03055001236498356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10586602240800858,
      "backward_entropy": 0.08190151623317174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.93649291992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030609093606472015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10563953220844269,
      "backward_entropy": 0.08157571724482945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.206298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030674641951918602,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10540252923965454,
      "backward_entropy": 0.08126848936080933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.98582458496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03074430301785469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10515603423118591,
      "backward_entropy": 0.07872873544692993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.59378814697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03081352449953556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1049104779958725,
      "backward_entropy": 0.07836391244615827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.81329345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03088243119418621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10466663539409637,
      "backward_entropy": 0.07799444028309413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.1802215576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030952397733926773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10441979765892029,
      "backward_entropy": 0.07762246472494942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.80524444580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03102605603635311,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10416364669799805,
      "backward_entropy": 0.07972591263907296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.3163070678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03109719231724739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10391021519899368,
      "backward_entropy": 0.0768716675894601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.62947845458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03116321563720703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10366538166999817,
      "backward_entropy": 0.07646581104823522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.9541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031227421015501022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10342174023389816,
      "backward_entropy": 0.0760472331728254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.02764129638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031293485313653946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10318051278591156,
      "backward_entropy": 0.07564094236918859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.20594787597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03135967254638672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10294070839881897,
      "backward_entropy": 0.07523526464189802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.41671752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0314258337020874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10269975662231445,
      "backward_entropy": 0.07482612984521049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.76942443847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031487490981817245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10246655344963074,
      "backward_entropy": 0.07439471142632621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.77725219726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03155668452382088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10221897065639496,
      "backward_entropy": 0.07398330313818795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.42247772216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03162408247590065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10197506844997406,
      "backward_entropy": 0.07356020382472447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.3226089477539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031688522547483444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10173775255680084,
      "backward_entropy": 0.07312433208738055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.40367126464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0317520834505558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10150396823883057,
      "backward_entropy": 0.07585150854928153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.96620178222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031814370304346085,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10127188265323639,
      "backward_entropy": 0.07545715570449829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.21005249023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03187701106071472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10103917866945267,
      "backward_entropy": 0.07506211314882551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.2635498046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031938422471284866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10080723464488983,
      "backward_entropy": 0.07133741889681135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.6510009765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03200178220868111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10057273507118225,
      "backward_entropy": 0.07088155405861991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.28057098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03206569701433182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10034091025590897,
      "backward_entropy": 0.0704310919557299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.3294677734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03212707117199898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10011598467826843,
      "backward_entropy": 0.06996907080922808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.04638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032182954251766205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09989827871322632,
      "backward_entropy": 0.06948137709072658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.73898315429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03224017098546028,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09968104958534241,
      "backward_entropy": 0.09776771920067924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.02056884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032296907156705856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09946458041667938,
      "backward_entropy": 0.06851741245814733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.62069702148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032360419631004333,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09923325479030609,
      "backward_entropy": 0.07173796210970197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.27264404296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03242141753435135,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09900610148906708,
      "backward_entropy": 0.09771474770137242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.97029876708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03248455747961998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09877566248178482,
      "backward_entropy": 0.06710811172212873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.28158569335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03254666551947594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09854742884635925,
      "backward_entropy": 0.0666237643786839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.93648529052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03261062875390053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09831422567367554,
      "backward_entropy": 0.06613945109503609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.6741485595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03267376497387886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09808601438999176,
      "backward_entropy": 0.06565561039107186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.32229614257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03274453431367874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09784474968910217,
      "backward_entropy": 0.06919555153165545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.66233825683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03281348571181297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09760516881942749,
      "backward_entropy": 0.064731878893716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.92029571533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03288675472140312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09736066311597824,
      "backward_entropy": 0.06837403348514012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.29900360107422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032953839749097824,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09713104367256165,
      "backward_entropy": 0.09762498310634068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.04469299316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03302251547574997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09689844399690628,
      "backward_entropy": 0.06331752879279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.15158081054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03309263288974762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09666458517313004,
      "backward_entropy": 0.06284372295652117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.82235717773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033162713050842285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09643282741308212,
      "backward_entropy": 0.06237188407352993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.5391616821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03323398530483246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09619708359241486,
      "backward_entropy": 0.0662077282156263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.00485229492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033301979303359985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09596644341945648,
      "backward_entropy": 0.061406148331505914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.08855438232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033371519297361374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09573435038328171,
      "backward_entropy": 0.06091954026903425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.900634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033435262739658356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09551463276147842,
      "backward_entropy": 0.06041106155940464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.03421783447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0334981232881546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09529754519462585,
      "backward_entropy": 0.05989926627704075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.53982543945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03356160968542099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09507816284894943,
      "backward_entropy": 0.05939235006059919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.70973205566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03362111747264862,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0948646143078804,
      "backward_entropy": 0.06341639586857387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.97650146484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03368155658245087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09464878588914871,
      "backward_entropy": 0.058343734060014994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.64008331298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03373580425977707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0944490134716034,
      "backward_entropy": 0.05780421836035592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.43328094482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0337928868830204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09424138069152832,
      "backward_entropy": 0.05727262156350272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.70057678222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033848416060209274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09403979778289795,
      "backward_entropy": 0.05673388923917498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.64681243896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03390083834528923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09383910894393921,
      "backward_entropy": 0.06088643414633615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.1105728149414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03395344316959381,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09363663196563721,
      "backward_entropy": 0.09729981422424316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.81341552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03400339186191559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0934395045042038,
      "backward_entropy": 0.05505941595349993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.4964141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03406136482954025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09323317557573318,
      "backward_entropy": 0.059343657323292325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.73978424072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034126538783311844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09301821887493134,
      "backward_entropy": 0.058876940182277133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.60109329223633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034193601459264755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0927991196513176,
      "backward_entropy": 0.05356440373829433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.14962768554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03425510227680206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0925883799791336,
      "backward_entropy": 0.05305113536970956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.14437866210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034317485988140106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09237600862979889,
      "backward_entropy": 0.052539169788360596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.434566497802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034378208220005035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09217379987239838,
      "backward_entropy": 0.05202984809875488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.26226806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03443439304828644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0919836163520813,
      "backward_entropy": 0.05150797537394932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.69499969482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03449489548802376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09178388118743896,
      "backward_entropy": 0.0510041458266122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.71434783935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03455481678247452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0915791392326355,
      "backward_entropy": 0.05049493057387216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.3734130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03461596742272377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09137427806854248,
      "backward_entropy": 0.04999273589679173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.15559005737305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03467963635921478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09116469323635101,
      "backward_entropy": 0.049501585108893256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.22346878051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03473833575844765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.090964175760746,
      "backward_entropy": 0.04899142895426069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.08580017089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0347924679517746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09077060967683792,
      "backward_entropy": 0.09701170240129743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.6855239868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034845661371946335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0905817449092865,
      "backward_entropy": 0.04793327195303781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.70690155029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03489813208580017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09039980918169022,
      "backward_entropy": 0.047410198620387485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.499755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034951165318489075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09021350741386414,
      "backward_entropy": 0.046894035169056485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.742656707763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035007789731025696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09002432227134705,
      "backward_entropy": 0.04640356131962368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.0174560546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03505617007613182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08985564857721329,
      "backward_entropy": 0.04589087622506278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.6556396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03510987386107445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08967643231153488,
      "backward_entropy": 0.04539884413991656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.01444244384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03516419231891632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08949635922908783,
      "backward_entropy": 0.04491091200283596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.06465911865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03522052988409996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08931370824575424,
      "backward_entropy": 0.04443115847451346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.49456787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035275593400001526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08913056552410126,
      "backward_entropy": 0.048888487475258965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.48867797851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03533557057380676,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08894087374210358,
      "backward_entropy": 0.09675790582384382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.7839584350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03540267050266266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08873943984508514,
      "backward_entropy": 0.04303330183029175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.32791900634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03546612709760666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08854267746210098,
      "backward_entropy": 0.04257669619151524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.72163772583008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03552762046456337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08834575861692429,
      "backward_entropy": 0.042108544281550815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.64627075195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03558476269245148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08815868943929672,
      "backward_entropy": 0.04655194708279201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.38444519042969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03564075753092766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08797574788331985,
      "backward_entropy": 0.04606834479740688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.33078002929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03569852188229561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08778437972068787,
      "backward_entropy": 0.04067943777356829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.37593078613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03575506806373596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08759241551160812,
      "backward_entropy": 0.0402041631085532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.07667541503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035812027752399445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08740225434303284,
      "backward_entropy": 0.04466662236622402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.35628509521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035863496363162994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08722037076950073,
      "backward_entropy": 0.044182964733668735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.67536163330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03591303899884224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08704216778278351,
      "backward_entropy": 0.03874222721372332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.60592269897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03596796095371246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08685402572154999,
      "backward_entropy": 0.04323295184544155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.58245849609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03601931035518646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08667422831058502,
      "backward_entropy": 0.04275909491947719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.18914794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03607150912284851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08648975193500519,
      "backward_entropy": 0.037308377879006524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.12772750854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03613170236349106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08629153668880463,
      "backward_entropy": 0.03686546853610447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.3697738647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036186333745718,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08610562980175018,
      "backward_entropy": 0.036403800759996684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.85812377929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03624185547232628,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08591938018798828,
      "backward_entropy": 0.040979972907475064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.78785705566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036303743720054626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08572353422641754,
      "backward_entropy": 0.03553570594106402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.812171936035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03636293113231659,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0855349600315094,
      "backward_entropy": 0.0401467638356345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.66573333740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03641809895634651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08535114675760269,
      "backward_entropy": 0.03466862865856716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.70284271240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036474041640758514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08516531437635422,
      "backward_entropy": 0.039281679051262994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.20878601074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03653053566813469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08497610688209534,
      "backward_entropy": 0.03379792400768825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.92019653320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03658343479037285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08479367941617966,
      "backward_entropy": 0.03335283270903996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.77268981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03663744032382965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08460995554924011,
      "backward_entropy": 0.032918427671704976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.21226501464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03669379651546478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08442080765962601,
      "backward_entropy": 0.03249693555491311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.13711547851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03675248846411705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08423080295324326,
      "backward_entropy": 0.037173177514757426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.80838012695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03681317716836929,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08403840661048889,
      "backward_entropy": 0.03170169677053179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.9104995727539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036877043545246124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08384105563163757,
      "backward_entropy": 0.0313251188823155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.68605041503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0369395986199379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08364741504192352,
      "backward_entropy": 0.030946803944451467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.12619018554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037002287805080414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08345258235931396,
      "backward_entropy": 0.030568589057241167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.57905578613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03706659376621246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08325494825839996,
      "backward_entropy": 0.030199783188956126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.22584533691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03712688758969307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08306791633367538,
      "backward_entropy": 0.029823669365474155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.71163940429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03719054162502289,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08287587761878967,
      "backward_entropy": 0.02946418523788452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.63381958007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03725428879261017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0826820582151413,
      "backward_entropy": 0.029105005519730703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.753144264221191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03731684759259224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08249133825302124,
      "backward_entropy": 0.028745791741779873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.31952667236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03737159073352814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08232442289590836,
      "backward_entropy": 0.02837561070919037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.55919647216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03742600977420807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08215388655662537,
      "backward_entropy": 0.032994627952575684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.38465881347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037478722631931305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08198262751102448,
      "backward_entropy": 0.027639218739100864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.49110412597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037529926747083664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08181411027908325,
      "backward_entropy": 0.02726822452885764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.091167449951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03758534416556358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08163508772850037,
      "backward_entropy": 0.026912789259638106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.33251953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037635087966918945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08147195726633072,
      "backward_entropy": 0.0265500545501709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.67977142333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03768512234091759,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0813075453042984,
      "backward_entropy": 0.031097978353500366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.93960571289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037739548832178116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0811307281255722,
      "backward_entropy": 0.030749723315238953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.53250122070312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0377938412129879,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08095377683639526,
      "backward_entropy": 0.09633861269269671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.38504028320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03785087540745735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0807720273733139,
      "backward_entropy": 0.025196758764130727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.02259063720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0379076823592186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08059407770633698,
      "backward_entropy": 0.024877663169588362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.59349060058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037962738424539566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08041740953922272,
      "backward_entropy": 0.024551102093287876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.22286987304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038018982857465744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08023601770401001,
      "backward_entropy": 0.024227612784930637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.21565246582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038076434284448624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08005288243293762,
      "backward_entropy": 0.02874400360243661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.14151763916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03813072666525841,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07987348735332489,
      "backward_entropy": 0.02841678261756897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.94232177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03818775340914726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07968824356794357,
      "backward_entropy": 0.028104024274008616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.99541473388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03824329376220703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0795072615146637,
      "backward_entropy": 0.02297217079571315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.1128921508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038298893719911575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07932926714420319,
      "backward_entropy": 0.022672050765582492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.0588264465332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038355838507413864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07914800941944122,
      "backward_entropy": 0.022378853389195034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.82704734802246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038408633321523666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07897873222827911,
      "backward_entropy": 0.02685066206114633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.48184204101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038456305861473083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07882203161716461,
      "backward_entropy": 0.021776831575802395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.04798889160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0385061539709568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07865889370441437,
      "backward_entropy": 0.021483566079820906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.93375396728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038555264472961426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07849637418985367,
      "backward_entropy": 0.021192961505481174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.60137176513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03860513120889664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07833166420459747,
      "backward_entropy": 0.025591628892081126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.472415924072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03865158557891846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07817421853542328,
      "backward_entropy": 0.02062304743698665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.4091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03869780898094177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07802050560712814,
      "backward_entropy": 0.020342567137309482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.2520751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038745127618312836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07786150276660919,
      "backward_entropy": 0.020070180296897888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.01062774658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03878939151763916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07770999521017075,
      "backward_entropy": 0.01979585417679378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.74559783935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038835037499666214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07755431532859802,
      "backward_entropy": 0.01953173109463283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.72770690917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03888333588838577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07739531993865967,
      "backward_entropy": 0.019278794527053833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.69084930419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03893131762742996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07723850011825562,
      "backward_entropy": 0.019029730132647922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.65183639526367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038977671414613724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0770861804485321,
      "backward_entropy": 0.01878109574317932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.99828338623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03902127966284752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07694271206855774,
      "backward_entropy": 0.0185324741261346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.51728820800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039067771285772324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07679152488708496,
      "backward_entropy": 0.022708586284092495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.83119201660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03911148011684418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07664665579795837,
      "backward_entropy": 0.0180551324571882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.14076614379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03915673494338989,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07649624347686768,
      "backward_entropy": 0.017822759492056712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.50012969970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03920067474246025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07634755969047546,
      "backward_entropy": 0.017589181661605835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.5789794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039246171712875366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07619380205869675,
      "backward_entropy": 0.01736107575041907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.05904388427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03929177299141884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07603935897350311,
      "backward_entropy": 0.017136826046875546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.9728012084961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933892399072647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07588330656290054,
      "backward_entropy": 0.016923460577215468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.79835891723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039387382566928864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0757220908999443,
      "backward_entropy": 0.020963455949510847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.33502197265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039433062076568604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07556910812854767,
      "backward_entropy": 0.016506959285054888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.05181121826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03948827087879181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07539385557174683,
      "backward_entropy": 0.01632031798362732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.2200927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03954533860087395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07521092891693115,
      "backward_entropy": 0.01613756375653403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.37816619873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03960280865430832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0750269740819931,
      "backward_entropy": 0.015957498124667575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.81777572631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03965669125318527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07485388219356537,
      "backward_entropy": 0.01577402970620564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.680694580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039711352437734604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07467877864837646,
      "backward_entropy": 0.019751563668251038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.05524444580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039761412888765335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07451775670051575,
      "backward_entropy": 0.019547013299805776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.29555892944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03980870172381401,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07436584681272507,
      "backward_entropy": 0.01933800961290087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.688720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03985746577382088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0742093026638031,
      "backward_entropy": 0.015050519789968218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.70084381103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03990628570318222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07405372709035873,
      "backward_entropy": 0.014878201697553908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.11085510253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0399591289460659,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07388819754123688,
      "backward_entropy": 0.014717553343091692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.52992248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04001427814364433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07371637970209122,
      "backward_entropy": 0.0145638393504279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.76844787597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0400741770863533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07353438436985016,
      "backward_entropy": 0.01843295991420746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.92426300048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04013175517320633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07336027175188065,
      "backward_entropy": 0.01826945585863931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.23377990722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04018855094909668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07318524271249771,
      "backward_entropy": 0.01413305742400033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.368465423583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040247298777103424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07300460338592529,
      "backward_entropy": 0.013992935419082642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.43648147583008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04030389338731766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07283152639865875,
      "backward_entropy": 0.013851815036364965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.12088394165039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04035985469818115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07265964895486832,
      "backward_entropy": 0.013710497745445796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.74223327636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040413953363895416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07249139249324799,
      "backward_entropy": 0.013568568442549025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.3304672241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04047423228621483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07230618596076965,
      "backward_entropy": 0.013438516429492406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.654855728149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040538765490055084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07210975885391235,
      "backward_entropy": 0.013316475919314794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.64345932006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04059932008385658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07192395627498627,
      "backward_entropy": 0.013190152389662606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.44284439086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040660224854946136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07173746079206467,
      "backward_entropy": 0.013066700526646205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.22708129882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04071885347366333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07155907154083252,
      "backward_entropy": 0.012942768633365631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.06138610839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040779344737529755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0713765099644661,
      "backward_entropy": 0.012824890869004386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.13416862487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04084022715687752,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07119318842887878,
      "backward_entropy": 0.016496076115540097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.03422737121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04089757055044174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07101882994174957,
      "backward_entropy": 0.01259030933891024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.79191589355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040951743721961975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0708528608083725,
      "backward_entropy": 0.012469097971916199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.32268524169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04100438207387924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0706905722618103,
      "backward_entropy": 0.012348178241934096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.938720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041058249771595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07052432000637054,
      "backward_entropy": 0.012231326528957911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.47631072998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041120924055576324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07033634930849075,
      "backward_entropy": 0.012129347239221846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.74488830566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041186410933732986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07014000415802002,
      "backward_entropy": 0.012032032012939453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.82395553588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04125185310840607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06994443386793137,
      "backward_entropy": 0.011935938681874956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.00465774536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04131600633263588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06975069642066956,
      "backward_entropy": 0.011839213115828378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.582509994506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041377682238817215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06956467777490616,
      "backward_entropy": 0.011740946343966894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.34720230102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04143458604812622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0693921446800232,
      "backward_entropy": 0.0116384785090174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.35002136230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0414910614490509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06922172009944916,
      "backward_entropy": 0.011536890906947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.69711303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04154973104596138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06904297322034836,
      "backward_entropy": 0.011439620384148188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.92327117919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041611623018980026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06885719299316406,
      "backward_entropy": 0.011347182095050812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.730712890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0416751392185688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06866812705993652,
      "backward_entropy": 0.011257704879556383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.46829223632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041735049337148666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06848940253257751,
      "backward_entropy": 0.011165716818400792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.51148223876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04179680347442627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06830601394176483,
      "backward_entropy": 0.011077911726066045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.78619384765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04186401888728142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06810787320137024,
      "backward_entropy": 0.010997486965996879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.8072738647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041934866458177567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0679011344909668,
      "backward_entropy": 0.01092229357787541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.15986633300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04201024770736694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06768225133419037,
      "backward_entropy": 0.010852132524762834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.20265197753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042084671556949615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06746652722358704,
      "backward_entropy": 0.010781794786453247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.4387435913086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04215952381491661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06724922358989716,
      "backward_entropy": 0.010713036571230208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.66922760009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04223724082112312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.067024365067482,
      "backward_entropy": 0.010647714138031006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.2762451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0423150509595871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0667991042137146,
      "backward_entropy": 0.010583098445619856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.29777526855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0423915833234787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06657938659191132,
      "backward_entropy": 0.013918571174144745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.89188766479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042469486594200134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06635746359825134,
      "backward_entropy": 0.013839054320539747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.37377166748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04254738241434097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06613574922084808,
      "backward_entropy": 0.010390406208378928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.40623474121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04262033849954605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06592816114425659,
      "backward_entropy": 0.01032411732843944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.12898635864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04269624501466751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06571352481842041,
      "backward_entropy": 0.010261493069784982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.8527717590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04277226701378822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06549979746341705,
      "backward_entropy": 0.01019981929234096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.66407012939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04284730926156044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06528819352388382,
      "backward_entropy": 0.010138631931373052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.927566528320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04292138293385506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06508010625839233,
      "backward_entropy": 0.010076191808496202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.55938720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042989689856767654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06488801538944244,
      "backward_entropy": 0.010009826294013433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.85284423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043055225163698196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06470446288585663,
      "backward_entropy": 0.009941590683800834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.58572006225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04312193766236305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06451807916164398,
      "backward_entropy": 0.00987455461706434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.63340950012207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04318978264927864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06432799994945526,
      "backward_entropy": 0.009809271565505437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.44932556152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04325254634022713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06415214389562607,
      "backward_entropy": 0.009741619229316711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.2081298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043315522372722626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06397674977779388,
      "backward_entropy": 0.00967481519494738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.40534210205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04338252916932106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06378872692584991,
      "backward_entropy": 0.00961306584732873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.22650146484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043448109179735184,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06360600888729095,
      "backward_entropy": 0.09797516890934535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.75611877441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043512437492609024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06342736631631851,
      "backward_entropy": 0.009487920573779516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.47210693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04357936978340149,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06324101984500885,
      "backward_entropy": 0.009427678372178758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.213199615478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04364866763353348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06304756551980972,
      "backward_entropy": 0.009370185434818268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.052749633789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043717578053474426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06285600364208221,
      "backward_entropy": 0.009312752102102553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.964134216308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043781448155641556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06267815083265305,
      "backward_entropy": 0.009254320391586848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.81351089477539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043842948973178864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0625084862112999,
      "backward_entropy": 0.009194813668727875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.40718460083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043902382254600525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062345847487449646,
      "backward_entropy": 0.009134850331715174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.85679244995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04396248236298561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06218091398477554,
      "backward_entropy": 0.00907732972076961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.71312713623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044022027403116226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062017086893320084,
      "backward_entropy": 0.009021522743361337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.13973617553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04408104345202446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06185455247759819,
      "backward_entropy": 0.008966955755438124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.16602325439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044141970574855804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06168653070926666,
      "backward_entropy": 0.008914805948734283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.12940216064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04420582950115204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06151001900434494,
      "backward_entropy": 0.008865510778767722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.919227600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0442734993994236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06132293492555618,
      "backward_entropy": 0.008819501314844404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.20045471191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04433850944042206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061144836246967316,
      "backward_entropy": 0.008771928293364388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.60029602050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04440484941005707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06096290796995163,
      "backward_entropy": 0.008726380233253752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.46824645996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04446881636977196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060787975788116455,
      "backward_entropy": 0.008680747555834907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.36521530151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04453064873814583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06061932072043419,
      "backward_entropy": 0.008635235684258597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.24903106689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044590484350919724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06045708805322647,
      "backward_entropy": 0.008589305515800203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.01892852783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044651031494140625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060292478650808334,
      "backward_entropy": 0.008545728134257453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.10504913330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04471467435359955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060117803514003754,
      "backward_entropy": 0.008506468364170619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.08247184753418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044773634523153305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05995887890458107,
      "backward_entropy": 0.008463909583432334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.55980682373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04482825845479965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059815309941768646,
      "backward_entropy": 0.008417460535253798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.358673095703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04488395154476166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0596688874065876,
      "backward_entropy": 0.008373217923300607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.053871154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04494069144129753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05951923131942749,
      "backward_entropy": 0.008331209421157837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.85201644897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04499945044517517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05936431884765625,
      "backward_entropy": 0.008291171597582954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.57905960083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04505998268723488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059205081313848495,
      "backward_entropy": 0.008252275841576713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.1322021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04512227699160576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059040673077106476,
      "backward_entropy": 0.008216136268207006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841455936431885,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04518255218863487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05888257175683975,
      "backward_entropy": 0.008179694414138794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.877824783325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04523753374814987,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05874061584472656,
      "backward_entropy": 0.010477708918707711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.817291259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04529127478599548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05860243737697601,
      "backward_entropy": 0.008105030549424035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.85116577148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04534371942281723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058469198644161224,
      "backward_entropy": 0.00806681705372674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.113712310791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04540088027715683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05832270532846451,
      "backward_entropy": 0.008031107485294342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.374061584472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545783996582031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058176495134830475,
      "backward_entropy": 0.007997372852904456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.924312591552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045513514429330826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05803338438272476,
      "backward_entropy": 0.007965650941644396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.7522087097168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04556875303387642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0578932911157608,
      "backward_entropy": 0.0100928395986557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.493080139160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045623693615198135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0577552355825901,
      "backward_entropy": 0.00789699171270643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.41654968261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568098485469818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0576096773147583,
      "backward_entropy": 0.007865845092705317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.266841888427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045737918466329575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057465579360723495,
      "backward_entropy": 0.007835229592663901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.13117980957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045794527977705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05732297524809837,
      "backward_entropy": 0.0078051888516971046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.31230545043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04585079476237297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05718206614255905,
      "backward_entropy": 0.007775436554636274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.10453414916992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045908037573099136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05703819543123245,
      "backward_entropy": 0.00774770336491721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.317203521728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0459662564098835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05689101666212082,
      "backward_entropy": 0.007723103144339153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.08841323852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046023041009902954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05674783140420914,
      "backward_entropy": 0.007700157484837941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.40485763549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04608170688152313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05660016089677811,
      "backward_entropy": 0.007676961166518075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.79110336303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04613969847559929,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056455858051776886,
      "backward_entropy": 0.007652038442237037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.45446014404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046194933354854584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05632029473781586,
      "backward_entropy": 0.007626384496688843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.90065002441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046252183616161346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05617981031537056,
      "backward_entropy": 0.007601144058363778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.678627014160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046309106051921844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05604006350040436,
      "backward_entropy": 0.007576907319681985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.826385498046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04636439308524132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05590641871094704,
      "backward_entropy": 0.007551320429359164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.55809783935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04642166942358017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055767666548490524,
      "backward_entropy": 0.0075267212731497625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.175167083740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046480946242809296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05562291666865349,
      "backward_entropy": 0.007505228476864951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.14484405517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0465363934636116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05548930913209915,
      "backward_entropy": 0.0074847351227487835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.91476821899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0465962216258049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055343084037303925,
      "backward_entropy": 0.0074671437697751185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.7570686340332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665876179933548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05518978089094162,
      "backward_entropy": 0.007450430520943233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.92697525024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046720702201128006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055037450045347214,
      "backward_entropy": 0.00743727119905608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.37918472290039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04677854850888252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05489727854728699,
      "backward_entropy": 0.007424347102642059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.20989990234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04683712497353554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05475533753633499,
      "backward_entropy": 0.007412150502204895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.86968231201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04689628630876541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05461229756474495,
      "backward_entropy": 0.007399943790265492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.653554916381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04695694148540497,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05446615815162659,
      "backward_entropy": 0.0073865050716059545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.82509231567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047013744711875916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05433090031147003,
      "backward_entropy": 0.007374715059995651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.98338508605957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047070492058992386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05419492349028587,
      "backward_entropy": 0.007366524743182319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.54637908935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04712596908211708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05406252294778824,
      "backward_entropy": 0.0073596978826182225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.831050872802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047181449830532074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05392976850271225,
      "backward_entropy": 0.007354875760419028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.564537048339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047235459089279175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05380246788263321,
      "backward_entropy": 0.007347786000796727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.946983337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047291651368141174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053669076412916183,
      "backward_entropy": 0.007341504096984863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.16022491455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04734538868069649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05354316160082817,
      "backward_entropy": 0.007334933217082705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.32490348815918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047401316463947296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05341130495071411,
      "backward_entropy": 0.007329128682613373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.7138786315918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047455888241529465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05328376218676567,
      "backward_entropy": 0.007323117128440312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.112709045410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047510381788015366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05315660685300827,
      "backward_entropy": 0.007317660110337394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.981014251708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047565679997205734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05302821099758148,
      "backward_entropy": 0.007310563964503152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.16563415527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047619666904211044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05290395766496658,
      "backward_entropy": 0.007303276232310704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6117634773254395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04767569527029991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05277442932128906,
      "backward_entropy": 0.007295990628855569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.03486633300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047726821154356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05266030877828598,
      "backward_entropy": 0.007285514048167637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.18515968322754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047778040170669556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05254650115966797,
      "backward_entropy": 0.007274519119943891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.03594207763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047827254980802536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.052438415586948395,
      "backward_entropy": 0.00832948088645935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.597381591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047878019511699677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05232571065425873,
      "backward_entropy": 0.007255229034594127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.74693298339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047929029911756516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05221233516931534,
      "backward_entropy": 0.0072476666952882495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.377912521362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04798125475645065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.052095942199230194,
      "backward_entropy": 0.008224692195653915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.587364196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04803336039185524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051980823278427124,
      "backward_entropy": 0.007231014115469796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.23975372314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04808775335550308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051859378814697266,
      "backward_entropy": 0.0072236710361072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.91135025024414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048142995685338974,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.051735904067754745,
      "backward_entropy": 0.09855752331869942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.094329833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04819792881608009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05161390081048012,
      "backward_entropy": 0.007209126970597676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.61182975769043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048255886882543564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051483772695064545,
      "backward_entropy": 0.007203293698174613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.46171188354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04831324517726898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051355987787246704,
      "backward_entropy": 0.00719712461744036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.257287979125977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0483713261783123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05122608691453934,
      "backward_entropy": 0.007193184856857572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.159103393554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048427797853946686,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.051101021468639374,
      "backward_entropy": 0.098585878099714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.90395736694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04848168417811394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05098368227481842,
      "backward_entropy": 0.007185381438050952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.844242095947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04853854700922966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05085878446698189,
      "backward_entropy": 0.007181483187845775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.37559127807617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04859576001763344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05073429271578789,
      "backward_entropy": 0.007175238004752568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.532188415527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04865572974085808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050602398812770844,
      "backward_entropy": 0.0071711864854608265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.63749122619629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04871489852666855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050473254173994064,
      "backward_entropy": 0.007167366998536246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.10206985473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04877191409468651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050351738929748535,
      "backward_entropy": 0.007159482687711716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.91843032836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882920905947685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0502307154238224,
      "backward_entropy": 0.007149716573102134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.16423225402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048886738717556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05011015012860298,
      "backward_entropy": 0.0071381814777851105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.279075622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04894264042377472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049994148313999176,
      "backward_entropy": 0.007127868809870311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.35990905761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04899619519710541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04988397657871246,
      "backward_entropy": 0.007120371397052493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.241315841674805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04905040189623833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049772873520851135,
      "backward_entropy": 0.007111750543117523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.06404113769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049101945012807846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04967013746500015,
      "backward_entropy": 0.00710054167679378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.78140640258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04915416240692139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049566805362701416,
      "backward_entropy": 0.007086916161434991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.59021759033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049207378178834915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04946061968803406,
      "backward_entropy": 0.00707558382834707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.83829116821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04925895482301712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049360185861587524,
      "backward_entropy": 0.007061201546873365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.350166320800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04930835962295532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04926564171910286,
      "backward_entropy": 0.007047756974186216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.802923679351807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049354374408721924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0491814985871315,
      "backward_entropy": 0.007030602012361799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.560462951660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049396317452192307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04910945147275925,
      "backward_entropy": 0.007263904703514916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.36463928222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04943908005952835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04903503507375717,
      "backward_entropy": 0.006991744041442871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.042780876159668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04948451742529869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048953767865896225,
      "backward_entropy": 0.0069741180964878625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.463481903076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04952738434076309,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048879124224185944,
      "backward_entropy": 0.006958118506840297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.571956157684326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04956870153546333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04880920425057411,
      "backward_entropy": 0.006940904472555433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.599876403808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04960685223340988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048747338354587555,
      "backward_entropy": 0.0069254812385354724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.843642234802246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04964527115225792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048684388399124146,
      "backward_entropy": 0.00691276096871921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.771888732910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968191310763359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04862562566995621,
      "backward_entropy": 0.00690253557903426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.372783660888672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04971989244222641,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04856327921152115,
      "backward_entropy": 0.09856312615530831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.058286666870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04975806921720505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048500269651412964,
      "backward_entropy": 0.006885839360100883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.206796646118164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049795251339673996,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04843985289335251,
      "backward_entropy": 0.09855725084032331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.870319366455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04983270913362503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04837857931852341,
      "backward_entropy": 0.006869410297700337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.67952346801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04986949265003204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04831869527697563,
      "backward_entropy": 0.006863701556410108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.532419204711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04990958049893379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04825013875961304,
      "backward_entropy": 0.006858697959354946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.554753303527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049947816878557205,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.048185884952545166,
      "backward_entropy": 0.006673999130725861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.685382843017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04998413473367691,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04812704399228096,
      "backward_entropy": 0.006853942892381123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.56287670135498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050019629299640656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04807087779045105,
      "backward_entropy": 0.006850004196166992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.441526412963867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500546395778656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04801575094461441,
      "backward_entropy": 0.006847785519702094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28081461787223816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05008946359157562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04796011000871658,
      "backward_entropy": 0.0068500978606087825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.620256423950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05012045428156853,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047915659844875336,
      "backward_entropy": 0.006849004221814019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.56449508666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05015437304973602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047863420099020004,
      "backward_entropy": 0.006849222417388644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.45582580566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050191912800073624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04780179634690285,
      "backward_entropy": 0.006850492741380419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.27912712097168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050233688205480576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04772926867008209,
      "backward_entropy": 0.0068525320717266625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.164121627807617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05027613788843155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047655701637268066,
      "backward_entropy": 0.0068535565265587396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.007978439331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050317298620939255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047585584223270416,
      "backward_entropy": 0.006854737975767681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.01532745361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050359345972537994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047513239085674286,
      "backward_entropy": 0.006856812430279595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.881019592285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05040094628930092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04744282737374306,
      "backward_entropy": 0.006856774645192283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.893184661865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05044230446219444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04737338423728943,
      "backward_entropy": 0.006856829992362431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.40987777709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050482459366321564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0473068505525589,
      "backward_entropy": 0.006857309490442276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.441438674926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052463337779045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047235168516635895,
      "backward_entropy": 0.006859702723366874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.3245792388916,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05056755244731903,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.047161687165498734,
      "backward_entropy": 0.0985802412033081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.573823928833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05061113089323044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04708671569824219,
      "backward_entropy": 0.006866661565644401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.91851806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05065343528985977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047014713287353516,
      "backward_entropy": 0.006872143064226423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.525453567504883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05069723352789879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046939730644226074,
      "backward_entropy": 0.006875900817768914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.834251403808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05073937028646469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04686978831887245,
      "backward_entropy": 0.006877163691180093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.075807571411133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05078228935599327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046797700226306915,
      "backward_entropy": 0.0068801577602113995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.272637367248535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05082467198371887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04672753065824509,
      "backward_entropy": 0.00688172983271735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.10772705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05086568742990494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04666096717119217,
      "backward_entropy": 0.00688304432800838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.108844757080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050908710807561874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04658888280391693,
      "backward_entropy": 0.00688810965844563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.868972778320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05095299705862999,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04651471972465515,
      "backward_entropy": 0.006889965917382922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.446654319763184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050998762249946594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04643693193793297,
      "backward_entropy": 0.006893159023353032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.554279327392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051041651517152786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04636701941490173,
      "backward_entropy": 0.006893734846796308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.368846893310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05108622461557388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04629288613796234,
      "backward_entropy": 0.006896863558462688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05113021284341812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046220093965530396,
      "backward_entropy": 0.006900572351046971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.256010055541992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05117252841591835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046152085065841675,
      "backward_entropy": 0.006902511630739484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.24005699157715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05121419206261635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04608654975891113,
      "backward_entropy": 0.006901668118579047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.07520294189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051254983991384506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046024683862924576,
      "backward_entropy": 0.006895042955875397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.12308692932129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051295261830091476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045964643359184265,
      "backward_entropy": 0.0068865397146769935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.271163940429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05133845657110214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04589696228504181,
      "backward_entropy": 0.006882693086351667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034162521362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051381923258304596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04582907631993294,
      "backward_entropy": 0.00687764585018158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.655643463134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05142270401120186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045768316835165024,
      "backward_entropy": 0.006870700312512261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.002042770385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051463134586811066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045708462595939636,
      "backward_entropy": 0.006864211921180997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.15154266357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05150380730628967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04564923793077469,
      "backward_entropy": 0.006853753966944558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.092670440673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05154581740498543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04558756202459335,
      "backward_entropy": 0.006841750017234257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.50876235961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05158640816807747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04552921652793884,
      "backward_entropy": 0.006830850350005286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.687987327575684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05162777006626129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04546860605478287,
      "backward_entropy": 0.006823025111641202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.75473976135254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05166693404316902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04541297256946564,
      "backward_entropy": 0.006817219512803214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.120868682861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051708757877349854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04535116255283356,
      "backward_entropy": 0.006812659225293568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.955690383911133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05174972116947174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04529251530766487,
      "backward_entropy": 0.006803809532097408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.5042610168457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051790185272693634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04523546248674393,
      "backward_entropy": 0.006794756544487817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.953277587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05183378979563713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045171964913606644,
      "backward_entropy": 0.006783950541700635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.24519348144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05187874287366867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04510514438152313,
      "backward_entropy": 0.006776321679353714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.58852195739746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05192846432328224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045027829706668854,
      "backward_entropy": 0.006770570895501545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.526723861694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05197789520025253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04495137557387352,
      "backward_entropy": 0.006766390587602343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.302020072937012,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05202896520495415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044871389865875244,
      "backward_entropy": 0.006764596062047141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.297025680541992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05207665637135506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04479961842298508,
      "backward_entropy": 0.006762036787612098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.005165100097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05212201923131943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04473411664366722,
      "backward_entropy": 0.006756307823317391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.85750961303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05216847360134125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04466602951288223,
      "backward_entropy": 0.006753164742674146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.8603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05221518874168396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044596731662750244,
      "backward_entropy": 0.006754915629114423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.922135353088379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05226164311170578,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04452872276306152,
      "backward_entropy": 0.00510905629822186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.484609603881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052306149154901505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0444653183221817,
      "backward_entropy": 0.006755146597112928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.48996639251709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05235148221254349,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04440087080001831,
      "backward_entropy": 0.006753676703998021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.140199661254883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052396345883607864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04433652013540268,
      "backward_entropy": 0.006758330123765128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.529733657836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052442166954278946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0442703515291214,
      "backward_entropy": 0.006763216640268054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.117244720458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052490804344415665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04419814795255661,
      "backward_entropy": 0.005001998373440334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.678684711456299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052542734891176224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04411935806274414,
      "backward_entropy": 0.006777992738144738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.516305923461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05259142071008682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04404764622449875,
      "backward_entropy": 0.006787198994840894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.011188507080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05264060199260712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043975431472063065,
      "backward_entropy": 0.006795854440757206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.823823928833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0526883490383625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043906934559345245,
      "backward_entropy": 0.006802953779697418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9575624465942383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0527350939810276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04384036734700203,
      "backward_entropy": 0.0068124160170555115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.480113983154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05277778580784798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.043783366680145264,
      "backward_entropy": 0.004904577774660928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.067954063415527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05282256752252579,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04372187703847885,
      "backward_entropy": 0.006825501365321023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32552215456962585,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052865318953990936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0436653271317482,
      "backward_entropy": 0.006830200552940369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.976062774658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05290352180600166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043619103729724884,
      "backward_entropy": 0.006831568266664233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.75145721435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052942272275686264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043571874499320984,
      "backward_entropy": 0.0068328529596328735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.29274845123291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052981920540332794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04352191090583801,
      "backward_entropy": 0.006839265780789512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.726816177368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053020983934402466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043473467230796814,
      "backward_entropy": 0.006843862789017814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.530078887939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053060270845890045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04342532902956009,
      "backward_entropy": 0.006845286382096154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.7856388092041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05310005694627762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043376073241233826,
      "backward_entropy": 0.006847847253084183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.018271446228027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053142745047807693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04332130402326584,
      "backward_entropy": 0.006849632199321475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.69779396057129,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05318310856819153,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04327088221907616,
      "backward_entropy": 0.09868010452815465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.812664985656738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053224362432956696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043219514191150665,
      "backward_entropy": 0.0068553537130355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.856754302978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05326470360159874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04317064583301544,
      "backward_entropy": 0.006853670946189335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.875343322753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05330654978752136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04312010109424591,
      "backward_entropy": 0.00684635021856853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.706727981567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05334857106208801,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04306904971599579,
      "backward_entropy": 0.004594944949660983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.90981674194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0533890463411808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04302292317152023,
      "backward_entropy": 0.006826753062861306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.838191986083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053430765867233276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042973827570676804,
      "backward_entropy": 0.006816457424845014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.184267044067383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05347338318824768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042923010885715485,
      "backward_entropy": 0.00680711812206677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.84986114501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0535152293741703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04287360608577728,
      "backward_entropy": 0.006800413663898196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.869170188903809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053558554500341415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042822036892175674,
      "backward_entropy": 0.0067916640213557655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.708046913146973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05359997972846031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04277447611093521,
      "backward_entropy": 0.006783467318330493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.618210315704346,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053640011698007584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04272902384400368,
      "backward_entropy": 0.00677955469914845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.2111873626709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0536775216460228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04268892854452133,
      "backward_entropy": 0.006774171122482845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.871822357177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0537169948220253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04264543950557709,
      "backward_entropy": 0.006767320845808301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.67167854309082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0537564679980278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04260251671075821,
      "backward_entropy": 0.00675891392997333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.566033363342285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05379625782370567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04255879297852516,
      "backward_entropy": 0.006753345685345786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.44362735748291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05383632704615593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0425143763422966,
      "backward_entropy": 0.006750434104885373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.292987823486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05387570708990097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042471375316381454,
      "backward_entropy": 0.006748354860714504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.283806800842285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0539156012237072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04242677986621857,
      "backward_entropy": 0.006751183952604022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.272923469543457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05395561829209328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042382195591926575,
      "backward_entropy": 0.006753961954798017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.111319541931152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05399389564990997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04234148561954498,
      "backward_entropy": 0.006754104580198016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12087345123291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054032325744628906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04230089485645294,
      "backward_entropy": 0.006752922066620418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.95621395111084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05406926944851875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04226336628198624,
      "backward_entropy": 0.006751166390521186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.81820297241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05410578101873398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042226679623126984,
      "backward_entropy": 0.006750128098896572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.593416213989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05414258688688278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04218975454568863,
      "backward_entropy": 0.006748228200844356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.062225341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0541800893843174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04215090721845627,
      "backward_entropy": 0.006751396826335362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.991979598999023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054221056401729584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04210616275668144,
      "backward_entropy": 0.006753882659333093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.629581451416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054264433681964874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04205720126628876,
      "backward_entropy": 0.006757293428693499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0931267738342285,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05430623143911362,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04201057553291321,
      "backward_entropy": 0.09865163053785052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.169343948364258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05434456840157509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041970688849687576,
      "backward_entropy": 0.006772034402404513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.242074966430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0543830431997776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041930779814720154,
      "backward_entropy": 0.006777917167970112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.750633239746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054421067237854004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041891422122716904,
      "backward_entropy": 0.006786360272339412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.706791877746582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05445989966392517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04185118526220322,
      "backward_entropy": 0.006791978010109493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.703652381896973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054496437311172485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041815172880887985,
      "backward_entropy": 0.0067974116121019635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.686246871948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054530784487724304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041783396154642105,
      "backward_entropy": 0.0068011464817183355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.16466522216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05456814914941788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041746169328689575,
      "backward_entropy": 0.0068067871034145355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.082653760910034,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05460677668452263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041706256568431854,
      "backward_entropy": 0.006816004535981587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.076982498168945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054641757160425186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04167412966489792,
      "backward_entropy": 0.0068170492138181415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.55487060546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054677754640579224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041640669107437134,
      "backward_entropy": 0.006816089685474124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.164918899536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0547114722430706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04161166399717331,
      "backward_entropy": 0.006812540548188346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.756269454956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054745882749557495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04158099368214607,
      "backward_entropy": 0.006811822099345071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.448128700256348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05478133261203766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04154893010854721,
      "backward_entropy": 0.006809262824910027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.852344036102295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054814547300338745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041521184146404266,
      "backward_entropy": 0.006804395999227252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.86775016784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05484684929251671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04149472713470459,
      "backward_entropy": 0.0068020495985235485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.455656051635742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054881464689970016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041464004665613174,
      "backward_entropy": 0.006802218300955636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.750631332397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05491822212934494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041430868208408356,
      "backward_entropy": 0.00679575332573482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8007068634033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05495207756757736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04140257090330124,
      "backward_entropy": 0.006790774209158761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.469598770141602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05498309060931206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041379451751708984,
      "backward_entropy": 0.006783963314124516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.172145843505859,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05501500144600868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04135431349277496,
      "backward_entropy": 0.006780903254236493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.039613723754883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055045127868652344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04133238270878792,
      "backward_entropy": 0.006776999150003705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.578854084014893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055079083889722824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04130392149090767,
      "backward_entropy": 0.006774464888232095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.85204792022705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05511156842112541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04127863794565201,
      "backward_entropy": 0.003534893106137003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.225099563598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05514368787407875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04125415161252022,
      "backward_entropy": 0.006760561040469578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.822599411010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055175989866256714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04123018682003021,
      "backward_entropy": 0.006749437323638371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.583696365356445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05521003529429436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04120340943336487,
      "backward_entropy": 0.006736912897654942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.096147537231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055243778973817825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04117696359753609,
      "backward_entropy": 0.00672805096421923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.868663787841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05527685955166817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041150592267513275,
      "backward_entropy": 0.0067271824393953595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.417240142822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05530815199017525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041127126663923264,
      "backward_entropy": 0.006727571998323713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.86919641494751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05533928424119949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04110397398471832,
      "backward_entropy": 0.006728538445064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.29574966430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055368587374687195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041084203869104385,
      "backward_entropy": 0.006727133478437152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.173714637756348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055397920310497284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041064321994781494,
      "backward_entropy": 0.006726262824875968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.072723865509033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05542749539017677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041043661534786224,
      "backward_entropy": 0.00672911001103265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.43136978149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05545588582754135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04102564603090286,
      "backward_entropy": 0.0067258259015423915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8903326988220215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05548475310206413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04100746661424637,
      "backward_entropy": 0.0067183029438768116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.688979148864746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055512841790914536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040990620851516724,
      "backward_entropy": 0.006711182849747794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.50719165802002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05553939938545227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04097651317715645,
      "backward_entropy": 0.006703173475606101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.434947967529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055568259209394455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04095878452062607,
      "backward_entropy": 0.006694840001208442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770054817199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05559907108545303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040938280522823334,
      "backward_entropy": 0.0066848258887018475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6961493492126465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05562995746731758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04091699421405792,
      "backward_entropy": 0.006680128829819816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.024654388427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05565974861383438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040897756814956665,
      "backward_entropy": 0.006674452551773616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.743518829345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055691707879304886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040874820202589035,
      "backward_entropy": 0.006671785243919918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.49264144897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05572408810257912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0408511608839035,
      "backward_entropy": 0.006670480327946799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.584521293640137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055756475776433945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04082689434289932,
      "backward_entropy": 0.0066752055925982335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3253042697906494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055789221078157425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0408020094037056,
      "backward_entropy": 0.0030681988490479334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.49837875366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055819377303123474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04078136011958122,
      "backward_entropy": 0.006684342665331704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.317013263702393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05585067346692085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0407591387629509,
      "backward_entropy": 0.006686810404062271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.209479331970215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05588021129369736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04073986038565636,
      "backward_entropy": 0.006688968411513737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.277440071105957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05590919032692909,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04072097688913345,
      "backward_entropy": 0.006695391344172614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.231335639953613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05593789741396904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040702879428863525,
      "backward_entropy": 0.006699135260922568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.206620931625366,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055966928601264954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04068485647439957,
      "backward_entropy": 0.006698718028409141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.044100284576416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05599384009838104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040669962763786316,
      "backward_entropy": 0.006700250719274793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.945622444152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056020431220531464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040655046701431274,
      "backward_entropy": 0.00670615690095084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.079089641571045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05604786425828934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0406387634575367,
      "backward_entropy": 0.006712448384080615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.788147926330566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056074466556310654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040624119341373444,
      "backward_entropy": 0.006715979427099228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.613214492797852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056102003902196884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04060773551464081,
      "backward_entropy": 0.00672159343957901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.012117385864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05613139271736145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04058891534805298,
      "backward_entropy": 0.006723645010164806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.641312599182129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056159283965826035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040572285652160645,
      "backward_entropy": 0.006726847163268498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.177565336227417,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05618773400783539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0405549630522728,
      "backward_entropy": 0.0067288801074028015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.781833648681641,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05621377006173134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.040541838854551315,
      "backward_entropy": 0.0028364131493227823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.960583209991455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056239306926727295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04052922502160072,
      "backward_entropy": 0.006727646504129682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50929594039917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05626349896192551,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04051893949508667,
      "backward_entropy": 0.006726180868489402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9110424518585205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05628814548254013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040507517755031586,
      "backward_entropy": 0.006727587963853564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.523344039916992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05631153658032417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040498286485672,
      "backward_entropy": 0.006727420857974461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3273013234138489,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05633501335978508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04048928618431091,
      "backward_entropy": 0.0067238786390849525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.305849552154541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05635581165552139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04048493504524231,
      "backward_entropy": 0.0027313812502792905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.863505363464355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05637749657034874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04047852009534836,
      "backward_entropy": 0.00671497785619327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.771181106567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056401077657938004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04046894982457161,
      "backward_entropy": 0.00671419980270522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972956657409668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05642646923661232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040456220507621765,
      "backward_entropy": 0.006715941109827587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.861684799194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05645271763205528,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040442049503326416,
      "backward_entropy": 0.006718619061367852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.22718620300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05647994577884674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04042592644691467,
      "backward_entropy": 0.006725553423166275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.755143165588379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05650945007801056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0404057577252388,
      "backward_entropy": 0.002647797976221357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.262157917022705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05653947591781616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040384743362665176,
      "backward_entropy": 0.006750734789030892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.720478057861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05656876787543297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040364574640989304,
      "backward_entropy": 0.006767307009015765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.949309349060059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05659813806414604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04034490883350372,
      "backward_entropy": 0.006778174213000706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9218546152114868,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05662906542420387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04032318666577339,
      "backward_entropy": 0.006786527378218514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.113287925720215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056657422333955765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04030561447143555,
      "backward_entropy": 0.006792314350605011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39973258972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05668676272034645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04028675705194473,
      "backward_entropy": 0.006796075829437801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.9255952835083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05671633780002594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040267668664455414,
      "backward_entropy": 0.006798656923430306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.446870803833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05674685537815094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04024719446897507,
      "backward_entropy": 0.006801530186619077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8260523080825806,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056778840720653534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0402245819568634,
      "backward_entropy": 0.00680435768195561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8408918380737305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056808240711688995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04020584002137184,
      "backward_entropy": 0.006806784974677222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.978362083435059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05683710426092148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04018711298704147,
      "backward_entropy": 0.006816313202892031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.442173480987549,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056864719837903976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04017072916030884,
      "backward_entropy": 0.006820908614567348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.367382049560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056892044842243195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04015493392944336,
      "backward_entropy": 0.006824050098657608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7403693199157715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05691920593380928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04013923183083534,
      "backward_entropy": 0.006827260234526226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30660247802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0569458082318306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04012392461299896,
      "backward_entropy": 0.006834076451403754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634006023406982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056969400495290756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04011363163590431,
      "backward_entropy": 0.006835417555911201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.098798751831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05699421837925911,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040100738406181335,
      "backward_entropy": 0.006843527512890952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7120153903961182,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0570206381380558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040085017681121826,
      "backward_entropy": 0.0068559518882206506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94060230255127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057044994086027145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.040072470903396606,
      "backward_entropy": 0.0024382046290806363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.639129877090454,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05707107111811638,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04005677253007889,
      "backward_entropy": 0.006882922457797187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.982405185699463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05709531530737877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040043555200099945,
      "backward_entropy": 0.00690013010587011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.940437316894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05711972340941429,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04003003239631653,
      "backward_entropy": 0.006917495280504227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.570821762084961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05714426562190056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040016207844018936,
      "backward_entropy": 0.0069345225180898395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0388832092285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057171545922756195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0399981364607811,
      "backward_entropy": 0.006953273500714984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.441131591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05719733238220215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03998233377933502,
      "backward_entropy": 0.006970205477305821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.570676326751709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05722547695040703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03996327146887779,
      "backward_entropy": 0.006985753242458616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.611533761024475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057251524180173874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03994705155491829,
      "backward_entropy": 0.007001814033303942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3515729904174805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05727546289563179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03993409126996994,
      "backward_entropy": 0.00701479400907244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.216930866241455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0572986863553524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03992237150669098,
      "backward_entropy": 0.007024426545415606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.621851444244385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05732167884707451,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03991049528121948,
      "backward_entropy": 0.007037525730473655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.249009132385254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05734473466873169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03989860415458679,
      "backward_entropy": 0.00704837537237576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.488630294799805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05736912041902542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03988485783338547,
      "backward_entropy": 0.007058309657233102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6274194717407227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05739361792802811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039870671927928925,
      "backward_entropy": 0.007069463176386697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.776062488555908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057415805757045746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039860501885414124,
      "backward_entropy": 0.0070723188774926326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22059983015060425,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05743712931871414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.039851151406764984,
      "backward_entropy": 0.002330036035605839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.143557548522949,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057456184178590775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03984515368938446,
      "backward_entropy": 0.00708052037017686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.40968656539917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05747484415769577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03984006494283676,
      "backward_entropy": 0.007079400654350009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.633803844451904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05749373137950897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039834991097450256,
      "backward_entropy": 0.007074447614806039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715633869171143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057513508945703506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039828866720199585,
      "backward_entropy": 0.007067216294152396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2120305299758911,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05753529071807861,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03981902450323105,
      "backward_entropy": 0.007067208843571799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.733555316925049,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05755477771162987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03981250524520874,
      "backward_entropy": 0.007065320121390479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.302291393280029,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057575762271881104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03980395942926407,
      "backward_entropy": 0.007062237709760666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.888618469238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05759642645716667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03979688137769699,
      "backward_entropy": 0.007050693567310061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.103957176208496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05761893093585968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039787158370018005,
      "backward_entropy": 0.007037128720964704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.574989318847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05764148011803627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039777398109436035,
      "backward_entropy": 0.0070244414465768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.976599216461182,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0576648972928524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03976691886782646,
      "backward_entropy": 0.007007823990924018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.73533034324646,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768847465515137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03975581377744675,
      "backward_entropy": 0.006996255900178637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.940651893615723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057711631059646606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03974483907222748,
      "backward_entropy": 0.0069894322327205115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.922830581665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057734765112400055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0397338941693306,
      "backward_entropy": 0.006983368524483272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4969160556793213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057757772505283356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03972325474023819,
      "backward_entropy": 0.006976391055754253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7263031005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05777975171804428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0397137776017189,
      "backward_entropy": 0.0021055505744048525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8975653648376465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05780095234513283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03970573842525482,
      "backward_entropy": 0.006963859711374555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.686093807220459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057823069393634796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03969612345099449,
      "backward_entropy": 0.006959590528692518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.576960325241089,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05784555524587631,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.03968549519777298,
      "backward_entropy": 0.09859470810209002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5493574142456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05786751210689545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03967561572790146,
      "backward_entropy": 0.006963010345186506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2671276330947876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05788898840546608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03966638445854187,
      "backward_entropy": 0.006965487663234983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3263068199157715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0579090341925621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039658889174461365,
      "backward_entropy": 0.006970428994723729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.351278305053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05792853236198425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03965165466070175,
      "backward_entropy": 0.00698037285889898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.808017253875732,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05794733390212059,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0396452322602272,
      "backward_entropy": 0.002027816405253751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2981653213500977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05796821415424347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039635978639125824,
      "backward_entropy": 0.007001213729381561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.438951015472412,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05798834562301636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03962746262550354,
      "backward_entropy": 0.007014093654496329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2447266578674316,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05800887569785118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03961818665266037,
      "backward_entropy": 0.00702868082693645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.671213150024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058028772473335266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03960937261581421,
      "backward_entropy": 0.007046628211225782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.41515588760376,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05805184692144394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0395960733294487,
      "backward_entropy": 0.007066127445016589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.366353988647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058075424283742905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039582159370183945,
      "backward_entropy": 0.007084470774446215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.318689823150635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058098699897527695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03956899791955948,
      "backward_entropy": 0.007098853588104248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.250430583953857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0581231527030468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039553992450237274,
      "backward_entropy": 0.007115289568901062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.28129506111145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05814738571643829,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03953929990530014,
      "backward_entropy": 0.007130775600671768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.198511123657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05817048251628876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03952678292989731,
      "backward_entropy": 0.00713880466563361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.184085845947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05819337069988251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039514634758234024,
      "backward_entropy": 0.007145097745316369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.144489288330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058216486126184464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03950246796011925,
      "backward_entropy": 0.007147839558976037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.074239253997803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05823832377791405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.03949200361967087,
      "backward_entropy": 0.0019602657162717412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.056661128997803,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05826057121157646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039481084793806076,
      "backward_entropy": 0.007150987429278237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840139389038086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05828266218304634,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.039470426738262177,
      "backward_entropy": 0.09866300651005336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.987568736076355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058306869119405746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039456818252801895,
      "backward_entropy": 0.007152671792677471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0331103801727295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058330073952674866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03944391757249832,
      "backward_entropy": 0.007160119180168424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.853194236755371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058352068066596985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03943254053592682,
      "backward_entropy": 0.0071678975863116124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.537251949310303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05837440490722656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03942089155316353,
      "backward_entropy": 0.00717347115278244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.548005104064941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058398857712745667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03940620273351669,
      "backward_entropy": 0.007180996771369662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9140560626983643,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058424804359674454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039389997720718384,
      "backward_entropy": 0.007184229791164398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.082608699798584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05844954773783684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039375655353069305,
      "backward_entropy": 0.007184639573097229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9024696350097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058472197502851486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039364226162433624,
      "backward_entropy": 0.007182808326823371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6341052055358887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058493759483098984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03935389220714569,
      "backward_entropy": 0.007183783820697239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9116325378417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058515433222055435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03934305161237717,
      "backward_entropy": 0.007188412227800914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1998649388551712,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05853590741753578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03933383524417877,
      "backward_entropy": 0.007191673985549382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7645318508148193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05855410918593407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03932790458202362,
      "backward_entropy": 0.00719044783285686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6403989791870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058571845293045044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039322786033153534,
      "backward_entropy": 0.007186685821839741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7711292505264282,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05858945846557617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03931831568479538,
      "backward_entropy": 0.007177118744168963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5041251182556152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058606669306755066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0393136665225029,
      "backward_entropy": 0.0071744125868592945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.294134140014648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05862420052289963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03930851072072983,
      "backward_entropy": 0.007172863398279462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.259969711303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05864259973168373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039301950484514236,
      "backward_entropy": 0.0071739490543093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.830914497375488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058661773800849915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039294227957725525,
      "backward_entropy": 0.007177293832812991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4496843814849854,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058682795614004135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039283670485019684,
      "backward_entropy": 0.007185295224189758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7448770999908447,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05870344117283821,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03927406668663025,
      "backward_entropy": 0.0071880338447434565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5729193687438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05872306972742081,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039265669882297516,
      "backward_entropy": 0.007191280169146401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7529845237731934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05874445289373398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039255380630493164,
      "backward_entropy": 0.007190596844468798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.465181350708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05876454710960388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03924693912267685,
      "backward_entropy": 0.007187593728303909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.279320240020752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05878424271941185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03923875838518143,
      "backward_entropy": 0.0071875495570046565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.964632749557495,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05880375951528549,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03923105448484421,
      "backward_entropy": 0.0071850743676934925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.418701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05882386490702629,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039222411811351776,
      "backward_entropy": 0.007184976977961404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.725224494934082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0588434636592865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03921430557966232,
      "backward_entropy": 0.007185934909752437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.412046194076538,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05886371061205864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039205774664878845,
      "backward_entropy": 0.007182287318365914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3715312480926514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05888323858380318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039198294281959534,
      "backward_entropy": 0.007176958556686129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.504203796386719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058902207762002945,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.039191536605358124,
      "backward_entropy": 0.09863577570234026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6172616481781006,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05892234295606613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03918296471238136,
      "backward_entropy": 0.007171051842825753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.549140453338623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0589413046836853,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03917602077126503,
      "backward_entropy": 0.007168763450213841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.16965389251709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058959491550922394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039169758558273315,
      "backward_entropy": 0.0071694084576198035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.61435604095459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05897897109389305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03916214406490326,
      "backward_entropy": 0.007167144545486995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.875430703163147,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05899916589260101,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039153166115283966,
      "backward_entropy": 0.007170333393982479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.886080741882324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05901762843132019,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03914661705493927,
      "backward_entropy": 0.007170145000730242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9293832778930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0590362511575222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03913964331150055,
      "backward_entropy": 0.007172408380678722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5004751682281494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05905463919043541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039133310317993164,
      "backward_entropy": 0.007170592035566058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.199331760406494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05907372757792473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03912575542926788,
      "backward_entropy": 0.007173090640987668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.816182851791382,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05909207835793495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039119426161050797,
      "backward_entropy": 0.007171959749289921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7304403781890869,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05911039188504219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03911318629980087,
      "backward_entropy": 0.007170612790754863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4660758972167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05912771821022034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03910759091377258,
      "backward_entropy": 0.007175612130335399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.057825803756714,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05914412811398506,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.03910331800580025,
      "backward_entropy": 0.09862107889992851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.35341477394104,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059160422533750534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039098914712667465,
      "backward_entropy": 0.007184396364859172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.373875379562378,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05917739123106003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03909365087747574,
      "backward_entropy": 0.007190587265150887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6428027153015137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05919468030333519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03908836469054222,
      "backward_entropy": 0.007192734628915787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3573007583618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059212181717157364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03908258676528931,
      "backward_entropy": 0.007197052772556033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.003330707550049,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059229008853435516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039077356457710266,
      "backward_entropy": 0.007204046206814902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7300593852996826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05924546718597412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039072632789611816,
      "backward_entropy": 0.007209953452859606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.833080768585205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05926082283258438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.03906913101673126,
      "backward_entropy": 0.001553842265691076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1746885776519775,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059277139604091644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03906470164656639,
      "backward_entropy": 0.007220307098967689,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.74707425609231,
    "avg_log_Z": -0.05829637385904789,
    "success_rate": 1.0,
    "avg_reward": 82.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.05,
      "2": 0.91
    },
    "avg_forward_entropy": 0.03947148121893406,
    "avg_backward_entropy": 0.010520376179899484,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}