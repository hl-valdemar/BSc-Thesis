{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07699599530961779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07695629199345906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.147345542907715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958466529846192,
      "backward_entropy": 0.07685003678003947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.143509864807129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958807468414307,
      "backward_entropy": 0.07684444056616889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.920796394348145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019999980577267706,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959131717681884,
      "backward_entropy": 0.07683874501122369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.841371536254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0002999636926688254,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959373712539673,
      "backward_entropy": 0.07698917388916016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.208272933959961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00039988680509850383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959601402282715,
      "backward_entropy": 0.07682676447762384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.280289649963379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004998790100216866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959811210632324,
      "backward_entropy": 0.07693941725624932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41769027709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005999401328153908,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109599769115448,
      "backward_entropy": 0.07698135905795628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.121108055114746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007000667392276227,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960166454315186,
      "backward_entropy": 0.07697854439417522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.166950225830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008001643582247198,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960347652435302,
      "backward_entropy": 0.07697559727562799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.381047248840332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008999605197459459,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960482358932495,
      "backward_entropy": 0.07697249783409967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.744904518127441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00099958258215338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096061110496521,
      "backward_entropy": 0.07692012521955702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.452082633972168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010991888120770454,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960752964019775,
      "backward_entropy": 0.07678106096055773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46918773651123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011986959725618362,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960886478424073,
      "backward_entropy": 0.07691142294141981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.811962127685547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012984487693756819,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961005687713624,
      "backward_entropy": 0.07676741811964247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.445625305175781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013981955125927925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961105823516845,
      "backward_entropy": 0.07676039801703559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.233393669128418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014978130348026752,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096119999885559,
      "backward_entropy": 0.0767532189687093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.516022682189941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015975662972778082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961350202560424,
      "backward_entropy": 0.07689257462819417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.375479698181152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016972225857898593,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961467027664185,
      "backward_entropy": 0.07688752147886488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.234062194824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017970786429941654,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961576700210571,
      "backward_entropy": 0.07693840397728814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50918197631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018970778910443187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961627960205078,
      "backward_entropy": 0.07687720987531874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.718253135681152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001996936509385705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961637496948243,
      "backward_entropy": 0.07687195142110188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.075140953063965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020967372693121433,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961657762527466,
      "backward_entropy": 0.07670723067389594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502376556396484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021966230124235153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961675643920898,
      "backward_entropy": 0.07669891251458062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.500115394592285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022963823284953833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961660146713256,
      "backward_entropy": 0.0766903559366862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929598808288574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023960331454873085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961620807647705,
      "backward_entropy": 0.07684962617026435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.421778678894043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002495766617357731,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109615159034729,
      "backward_entropy": 0.07690376705593532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.415933609008789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002595356432721019,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096143126487732,
      "backward_entropy": 0.07666326893700494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5698652267456055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026952065527439117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961346626281739,
      "backward_entropy": 0.07665382491217719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770904541015625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002794574946165085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961209535598755,
      "backward_entropy": 0.076824598842197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.269768714904785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002893991768360138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961074829101562,
      "backward_entropy": 0.0766341421339247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.974996566772461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029936714563518763,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960862636566163,
      "backward_entropy": 0.07681071758270264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9198689460754395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003093863371759653,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960570573806763,
      "backward_entropy": 0.07686781220965916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6874418258667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00319366785697639,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960240364074707,
      "backward_entropy": 0.07686122920778063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.390276908874512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032934213522821665,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959970951080322,
      "backward_entropy": 0.0768544011645847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.474754333496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0033934246748685837,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959738492965698,
      "backward_entropy": 0.07684736119376288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.031312942504883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0034932796843349934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959508419036865,
      "backward_entropy": 0.07677250438266331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61392593383789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035932245664298534,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959303379058838,
      "backward_entropy": 0.07676420609156291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.654051780700684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036931063514202833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095902681350708,
      "backward_entropy": 0.076547020011478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.649734497070312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037933343555778265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958772897720337,
      "backward_entropy": 0.07653521166907416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.462714195251465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003893864806741476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958538055419922,
      "backward_entropy": 0.07673798004786174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.71212100982666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003994172904640436,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958294868469239,
      "backward_entropy": 0.07651091284222072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.457685470581055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004094812087714672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109580397605896,
      "backward_entropy": 0.07649838924407959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.355345726013184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00419521052390337,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10957787036895753,
      "backward_entropy": 0.07678306102752686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.758998394012451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004295775666832924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957540273666382,
      "backward_entropy": 0.07647249433729383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.867196083068848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004395791329443455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095733880996704,
      "backward_entropy": 0.07645906342400445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.351009368896484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004495831672102213,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957056283950806,
      "backward_entropy": 0.0764453477329678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0012898445129395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004596129525452852,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956628322601318,
      "backward_entropy": 0.0764313538869222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65327262878418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004695589654147625,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095617413520813,
      "backward_entropy": 0.07673503292931451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92416763305664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00479506328701973,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955653190612794,
      "backward_entropy": 0.07664638095431858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.094131469726562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004894665442407131,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955085754394531,
      "backward_entropy": 0.07663495673073663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.051932334899902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004993980284780264,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095456600189209,
      "backward_entropy": 0.07662324110666911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.598738670349121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0050934781320393085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954058170318604,
      "backward_entropy": 0.07661118772294787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.841004371643066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005193417891860008,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10953459739685059,
      "backward_entropy": 0.07659878995683458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.496089935302734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005293389782309532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952838659286498,
      "backward_entropy": 0.07632393307156032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.379185676574707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005393228959292173,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952215194702149,
      "backward_entropy": 0.0766568382581075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89854907989502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005493347067385912,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095159411430359,
      "backward_entropy": 0.07664431465996636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.419402122497559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005593514535576105,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950919389724731,
      "backward_entropy": 0.07663147317038642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.638394355773926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005693481303751469,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950281620025634,
      "backward_entropy": 0.07661812835269505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.956563949584961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005793828517198563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949655771255493,
      "backward_entropy": 0.07651706536610921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07299518585205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005894191563129425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949085950851441,
      "backward_entropy": 0.07650213771396214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.557592391967773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005994163919240236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948569774627685,
      "backward_entropy": 0.07619939910040961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.675540924072266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006094473414123058,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948082208633422,
      "backward_entropy": 0.07618079582850139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.406438827514648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006194678600877523,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10947624444961548,
      "backward_entropy": 0.07654481463962132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.344571113586426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00629462581127882,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094733715057373,
      "backward_entropy": 0.07652903927697076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.991308212280273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006394788157194853,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10947142839431763,
      "backward_entropy": 0.07651284005906847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79831314086914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00649457611143589,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946851968765259,
      "backward_entropy": 0.07640582323074341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.927122116088867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006594353821128607,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946643352508545,
      "backward_entropy": 0.07608301772011651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7199296951293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006694203708320856,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10946440696716309,
      "backward_entropy": 0.07646315627627903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052031517028809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006793543696403503,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946290493011475,
      "backward_entropy": 0.07635414600372314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.849713325500488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006893087178468704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946075916290283,
      "backward_entropy": 0.07601977719200982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.844025611877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006992686539888382,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945899486541748,
      "backward_entropy": 0.07640988959206475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.506302833557129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007092823274433613,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945668220520019,
      "backward_entropy": 0.07597579558690389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.837597846984863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007193272467702627,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945415496826172,
      "backward_entropy": 0.07595314582188924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.435395240783691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007293670438230038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10945202112197876,
      "backward_entropy": 0.07625648048188952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.68869400024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007393859326839447,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10944944620132446,
      "backward_entropy": 0.07633467515309651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.352938652038574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007494474295526743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10944566726684571,
      "backward_entropy": 0.076212035285102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.347779273986816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00759525690227747,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944241285324097,
      "backward_entropy": 0.07585710949367946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.342458724975586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00769623089581728,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943834781646729,
      "backward_entropy": 0.07583171791500515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.483670234680176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007797371596097946,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943350791931153,
      "backward_entropy": 0.07580594221750896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21694564819336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007898250594735146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10942809581756592,
      "backward_entropy": 0.07611572742462158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.979591369628906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007998725399374962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10942370891571045,
      "backward_entropy": 0.07575305965211657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.013162612915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008099696598947048,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10941932201385499,
      "backward_entropy": 0.0761880808406406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12075138092041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008200121112167835,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10941694974899292,
      "backward_entropy": 0.07616504695680407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.853545188903809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008300681598484516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941311120986938,
      "backward_entropy": 0.07601121399137709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.460907936096191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008401192724704742,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094093918800354,
      "backward_entropy": 0.07611754867765638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.260529518127441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008501497097313404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10940501689910889,
      "backward_entropy": 0.07560757133695814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646127700805664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008601488545536995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10940121412277222,
      "backward_entropy": 0.0759286019537184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.187545776367188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008701407350599766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939714908599854,
      "backward_entropy": 0.07554439703623454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.441413879394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008801009505987167,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939406156539917,
      "backward_entropy": 0.0760153399573432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.531646728515625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008900451473891735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10939188003540039,
      "backward_entropy": 0.0758410029941135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.367026329040527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009000281803309917,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938987731933594,
      "backward_entropy": 0.07596056991153294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.749471664428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009099881164729595,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938888788223267,
      "backward_entropy": 0.07593228419621785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.845560073852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009199480526149273,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938808917999268,
      "backward_entropy": 0.0759033891889784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8489227294921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009298623539507389,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938851833343506,
      "backward_entropy": 0.07587369283040364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988982200622559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009397407993674278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938825607299804,
      "backward_entropy": 0.07568241490258111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.162749290466309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009496400132775307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938808917999268,
      "backward_entropy": 0.07526910967297024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.657698631286621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009595214389264584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938684940338135,
      "backward_entropy": 0.07561436626646253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972174644470215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00969406496733427,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938624143600464,
      "backward_entropy": 0.07574758264753553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.512187480926514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009793112054467201,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093856930732727,
      "backward_entropy": 0.07571432325575086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.665462493896484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009891638532280922,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938506126403809,
      "backward_entropy": 0.07511264748043484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.834796905517578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009990769438445568,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938317775726318,
      "backward_entropy": 0.07547616958618164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.059991836547852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010090027004480362,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938074588775634,
      "backward_entropy": 0.07561073038313124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.253971099853516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010188974440097809,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937952995300293,
      "backward_entropy": 0.07540346516503228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.387834548950195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010287776589393616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937817096710205,
      "backward_entropy": 0.07536609967549641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495410919189453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010387024842202663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937561988830566,
      "backward_entropy": 0.07532739639282227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4725871086120605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01048621442168951,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937297344207764,
      "backward_entropy": 0.0752878122859531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.317307472229004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01058480329811573,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937176942825318,
      "backward_entropy": 0.07481292883555095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.413088798522949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010683867149055004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936799049377441,
      "backward_entropy": 0.07520644532309638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9743971824646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010782349854707718,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936503410339356,
      "backward_entropy": 0.07471924357944065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.714777946472168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010880603455007076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936216115951539,
      "backward_entropy": 0.07512219746907552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.27542781829834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010979510843753815,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093586802482605,
      "backward_entropy": 0.07462179660797119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704855918884277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011078798212110996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935442447662354,
      "backward_entropy": 0.07503341303931342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698325157165527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011178133077919483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935004949569702,
      "backward_entropy": 0.07498742474450006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.38536262512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011277507990598679,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10934556722640991,
      "backward_entropy": 0.07512479358249241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.437581062316895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011377292685210705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933957099914551,
      "backward_entropy": 0.07489222950405544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.250444412231445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011476940475404263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093336820602417,
      "backward_entropy": 0.07484311527676052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.607168197631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011576386168599129,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093275785446167,
      "backward_entropy": 0.07479349772135417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.106627464294434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011676346883177757,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10931998491287231,
      "backward_entropy": 0.07424694961971706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.590338706970215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011776519939303398,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10931123495101928,
      "backward_entropy": 0.07418798075781928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.893073081970215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01187658030539751,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930323600769043,
      "backward_entropy": 0.07463626066843669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527466773986816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011976703070104122,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092953085899353,
      "backward_entropy": 0.07478289471732245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698060989379883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012076723389327526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10928678512573242,
      "backward_entropy": 0.07452280653847589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41891860961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012176725082099438,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10927805900573731,
      "backward_entropy": 0.07467522886064318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.196525573730469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012277070432901382,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10926878452301025,
      "backward_entropy": 0.0738706456290351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.012077331542969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012377113103866577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10925966501235962,
      "backward_entropy": 0.07434052891201443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.759449005126953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012476803734898567,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10925037860870361,
      "backward_entropy": 0.0742772552702162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.627228260040283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012577066197991371,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10923957824707031,
      "backward_entropy": 0.07365626758999294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.951205253601074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01267673633992672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10922987461090088,
      "backward_entropy": 0.07414580716027154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.917363166809082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012776566669344902,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10921943187713623,
      "backward_entropy": 0.07350456714630127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.957379341125488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01287600863724947,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920941829681396,
      "backward_entropy": 0.074008928404914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.814543724060059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012975091114640236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920107364654541,
      "backward_entropy": 0.0739383962419298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.720542907714844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013074821792542934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10919170379638672,
      "backward_entropy": 0.07386538717481825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.662535667419434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01317455992102623,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10918292999267579,
      "backward_entropy": 0.07379057672288683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.839873313903809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01327430922538042,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10917346477508545,
      "backward_entropy": 0.07396230432722303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.851925373077393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013374662958085537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10916255712509156,
      "backward_entropy": 0.07388583819071452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.166911125183105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013474495150148869,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10915385484695435,
      "backward_entropy": 0.07291713025834826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74645709991455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01357459556311369,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1091436505317688,
      "backward_entropy": 0.07348050011528863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54614543914795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013674733228981495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10913200378417968,
      "backward_entropy": 0.07339831855561998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7060651779174805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013774770312011242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10912041664123535,
      "backward_entropy": 0.07331433561113146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.759232044219971,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013874266296625137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10911046266555786,
      "backward_entropy": 0.07322911421457927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.808162689208984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013973317109048367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10910152196884156,
      "backward_entropy": 0.07314254177941217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.858153343200684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014072529971599579,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909169912338257,
      "backward_entropy": 0.07305375734965007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.356619834899902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014171923510730267,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10908061265945435,
      "backward_entropy": 0.07296272118886311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770161628723145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014271702617406845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10906908512115479,
      "backward_entropy": 0.07209516233868069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988137245178223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014371547847986221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10905687808990479,
      "backward_entropy": 0.07277353604634602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.743064880371094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014471564441919327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904384851455688,
      "backward_entropy": 0.07186412149005467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621627807617188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01457160897552967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10903022289276124,
      "backward_entropy": 0.07257425122790867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.531317710876465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014671637676656246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10901539325714112,
      "backward_entropy": 0.07162109348509046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.989815711975098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014771552756428719,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10900155305862427,
      "backward_entropy": 0.07236368126339382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471238136291504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014871644787490368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10898646116256713,
      "backward_entropy": 0.07136746909883288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.428474426269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014971660450100899,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1089697003364563,
      "backward_entropy": 0.07239137755499946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47415542602539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015071501024067402,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1089545726776123,
      "backward_entropy": 0.07202972968419392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.27133846282959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01517121959477663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10894043445587158,
      "backward_entropy": 0.07191391123665704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.908064842224121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015271306037902832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10892386436462402,
      "backward_entropy": 0.07179494036568536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.09652328491211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015371511690318584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10890624523162842,
      "backward_entropy": 0.07167316807640924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.424051284790039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015471382066607475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1088894248008728,
      "backward_entropy": 0.07154938909742567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.007203102111816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015571143478155136,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10887210369110108,
      "backward_entropy": 0.07038817140791151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.624136924743652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01567055843770504,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10885615348815918,
      "backward_entropy": 0.07155190573798285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.321945190429688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0157705619931221,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10883722305297852,
      "backward_entropy": 0.07008081012301975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.297276496887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015870923176407814,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10881627798080444,
      "backward_entropy": 0.07128523455725776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.336837768554688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015971047803759575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10879563093185425,
      "backward_entropy": 0.0697604152891371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.20376205444336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01607099175453186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10877480506896972,
      "backward_entropy": 0.07073786523607042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.18535041809082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016170684248209,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10875483751296997,
      "backward_entropy": 0.07058821121851604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.774561882019043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016270142048597336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10873564481735229,
      "backward_entropy": 0.07043532530466716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.739527702331543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016369730234146118,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10871498584747315,
      "backward_entropy": 0.07056012418535021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.071837425231934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016469966620206833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10869085788726807,
      "backward_entropy": 0.06889614793989393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.162888526916504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016569841653108597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10866838693618774,
      "backward_entropy": 0.0699519779947069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.901256561279297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016669461503624916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10864640474319458,
      "backward_entropy": 0.06978423727883233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.905233383178711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01676926389336586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10862277746200562,
      "backward_entropy": 0.06961233086056179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259744644165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016868682578206062,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10860015153884887,
      "backward_entropy": 0.06974512338638306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399176597595215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016967935487627983,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1085779070854187,
      "backward_entropy": 0.0679401159286499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.467636585235596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01706714555621147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1085540771484375,
      "backward_entropy": 0.06773720847235785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.244397163391113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017165806144475937,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10853145122528077,
      "backward_entropy": 0.06888882319132487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.74311637878418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017264384776353836,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10850865840911865,
      "backward_entropy": 0.06901568174362183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.407637596130371,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01736261136829853,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10848729610443116,
      "backward_entropy": 0.06709422005547418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700591087341309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017460891976952553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10846521854400634,
      "backward_entropy": 0.06830788983239068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.77177619934082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017559362575411797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1084429144859314,
      "backward_entropy": 0.0666458010673523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.699663162231445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01765809766948223,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10841739177703857,
      "backward_entropy": 0.06641458140479194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.560563087463379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017756450921297073,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10839294195175171,
      "backward_entropy": 0.0661788781483968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.789643287658691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01785494014620781,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10836707353591919,
      "backward_entropy": 0.06779326332939996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.729919910430908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01795368827879429,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10833926200866699,
      "backward_entropy": 0.06569439172744751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.182311534881592,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018052052706480026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10831358432769775,
      "backward_entropy": 0.06544639004601373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.489643096923828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018149789422750473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10829020738601684,
      "backward_entropy": 0.06678850120968288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2867207527160645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018247703090310097,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10826451778411865,
      "backward_entropy": 0.06655475828382704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.933029651641846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01834508590400219,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10824130773544312,
      "backward_entropy": 0.06665617227554321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.053338050842285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018442325294017792,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10822018384933471,
      "backward_entropy": 0.06607742442025079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.407155990600586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018540119752287865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10819429159164429,
      "backward_entropy": 0.06582906511094835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.829139232635498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018637463450431824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10817028284072876,
      "backward_entropy": 0.0638694100909763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.053211688995361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01873464696109295,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10814616680145264,
      "backward_entropy": 0.06567881504694621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.352340698242188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018831228837370872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10812586545944214,
      "backward_entropy": 0.06506186723709106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.379176139831543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018928060308098793,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10810151100158691,
      "backward_entropy": 0.06516204939948188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.852332592010498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019024543464183807,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10807768106460572,
      "backward_entropy": 0.0627327627605862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.548529624938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019120967015624046,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10805380344390869,
      "backward_entropy": 0.06462839576933119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.464212417602539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019217757508158684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10802624225616456,
      "backward_entropy": 0.06396649943457709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.70950698852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019314821809530258,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10799593925476074,
      "backward_entropy": 0.06408178806304932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.708548069000244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019412290304899216,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10796135663986206,
      "backward_entropy": 0.06380114952723186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.150779724121094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01950952038168907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10792756080627441,
      "backward_entropy": 0.061205115583207875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.955506801605225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019606193527579308,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10789787769317627,
      "backward_entropy": 0.06322490506702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.00052547454834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019702879711985588,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10786595344543456,
      "backward_entropy": 0.06292990843454997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.10542106628418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019799621775746346,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10783078670501708,
      "backward_entropy": 0.06213098764419556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.985097885131836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01989646814763546,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10779266357421875,
      "backward_entropy": 0.059885905848609075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.799950122833252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019992737099528313,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10775699615478515,
      "backward_entropy": 0.06147721078660753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.512267589569092,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02008838765323162,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10772373676300048,
      "backward_entropy": 0.05919263097974989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.323081970214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020183900371193886,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10768979787826538,
      "backward_entropy": 0.06139244635899862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.03752326965332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020279189571738243,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10765522718429565,
      "backward_entropy": 0.060456408394707575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.927335739135742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02037406712770462,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10762399435043335,
      "backward_entropy": 0.06010324425167508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.741976737976074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02046792209148407,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10759990215301514,
      "backward_entropy": 0.057736370298597545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6227922439575195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020561980083584785,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10757200717926026,
      "backward_entropy": 0.057357192039489746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.931053161621094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020655525848269463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10754705667495727,
      "backward_entropy": 0.0569738679462009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.421949863433838,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0207494106143713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10751814842224121,
      "backward_entropy": 0.05658614635467529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.927194118499756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0208426583558321,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10749434232711792,
      "backward_entropy": 0.05822892983754476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.013984680175781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020935678854584694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10747017860412597,
      "backward_entropy": 0.05580149756537543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.046072006225586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021027909591794014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10745173692703247,
      "backward_entropy": 0.05540377232763502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2094035148620605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0211201012134552,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10743143558502197,
      "backward_entropy": 0.057042188114590116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.768375873565674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021212367340922356,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10740785598754883,
      "backward_entropy": 0.05459083120028178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.994267463684082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021304424852132797,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10738464593887329,
      "backward_entropy": 0.05717790126800537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.874528884887695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021396422758698463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10736000537872314,
      "backward_entropy": 0.05579994122187296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.403701305389404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021488316357135773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10733301639556884,
      "backward_entropy": 0.053334838814205594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.316212177276611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021579809486865997,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10730690956115722,
      "backward_entropy": 0.054942058192359075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5609331130981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021670883521437645,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10728224515914916,
      "backward_entropy": 0.05556607246398926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.548434734344482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021762391552329063,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10725083351135253,
      "backward_entropy": 0.055150482389662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.189779281616211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021853629499673843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10721943378448487,
      "backward_entropy": 0.051603337128957115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835186958312988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021944405511021614,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1071898102760315,
      "backward_entropy": 0.05316268735461765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0784759521484375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02203518897294998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10715728998184204,
      "backward_entropy": 0.05071401596069336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.744523525238037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02212548814713955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10712701082229614,
      "backward_entropy": 0.05224394136004978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.280127048492432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02221580222249031,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10709232091903687,
      "backward_entropy": 0.04980414443545871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.617928981781006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022305119782686234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10706706047058105,
      "backward_entropy": 0.05131231413947211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.553520679473877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02239447645843029,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10703694820404053,
      "backward_entropy": 0.052120731936560735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.297123908996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022483831271529198,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10700209140777588,
      "backward_entropy": 0.05166754126548767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.885539531707764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022573010995984077,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10696280002593994,
      "backward_entropy": 0.04794041977988349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.135986804962158,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022661754861474037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10692425966262817,
      "backward_entropy": 0.04939673013157315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.565129280090332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022750278934836388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10688416957855225,
      "backward_entropy": 0.04890430967013041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.616562366485596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022838907316327095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10683987140655518,
      "backward_entropy": 0.04840500487221612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.267922401428223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0229276642203331,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1067913293838501,
      "backward_entropy": 0.0478987627559238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.345954895019531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023015601560473442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10674815177917481,
      "backward_entropy": 0.04739424917432997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.647916316986084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02310357242822647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10670032501220703,
      "backward_entropy": 0.0468837751282586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.987817764282227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02319108508527279,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10665291547775269,
      "backward_entropy": 0.04456325703197055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.018383502960205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023278454318642616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10660090446472167,
      "backward_entropy": 0.04585576057434082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.928696155548096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023364976048469543,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10655461549758911,
      "backward_entropy": 0.046921120749579534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.683849811553955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023451412096619606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10650403499603271,
      "backward_entropy": 0.0430800285604265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.07450532913208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023537594825029373,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10645122528076172,
      "backward_entropy": 0.04430411590470208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.337168216705322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023623120039701462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10640017986297608,
      "backward_entropy": 0.042083683941099376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.67673921585083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023708263412117958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10634725093841553,
      "backward_entropy": 0.043264647324879967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.301057815551758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023793315514922142,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10628931522369385,
      "backward_entropy": 0.04274040460586548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8337483406066895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023878009989857674,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10622963905334473,
      "backward_entropy": 0.040571630001068115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.873366832733154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023962005972862244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10617414712905884,
      "backward_entropy": 0.041692369514041476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.624294757843018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02404540218412876,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10612208843231201,
      "backward_entropy": 0.03956949710845947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.472609996795654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024128060787916183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10607584714889526,
      "backward_entropy": 0.040653473801083036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.032744884490967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02420995384454727,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1060346245765686,
      "backward_entropy": 0.04013924466239081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.531522750854492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0242916252464056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10599020719528199,
      "backward_entropy": 0.039622896247439914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7904257774353027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024372698739171028,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10594772100448609,
      "backward_entropy": 0.03759926888677809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4927191734313965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024452639743685722,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10591552257537842,
      "backward_entropy": 0.03711015648312039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.054082870483398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024532128125429153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10588312149047852,
      "backward_entropy": 0.03809696435928345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9628496170043945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024610858410596848,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10585494041442871,
      "backward_entropy": 0.03759549061457316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.539105415344238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024689683690667152,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10581670999526978,
      "backward_entropy": 0.03901424010594686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.365994453430176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024768225848674774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10577574968338013,
      "backward_entropy": 0.03658187058236864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7639353275299072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024846380576491356,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10573259592056275,
      "backward_entropy": 0.03607531057463752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.062717914581299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024923671036958694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10569522380828858,
      "backward_entropy": 0.035574760701921254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.544117450714111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025000441819429398,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.105660080909729,
      "backward_entropy": 0.035076396332846746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.538165092468262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02507719211280346,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10561600923538209,
      "backward_entropy": 0.03325201736556159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7914130687713623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025153914466500282,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10556519031524658,
      "backward_entropy": 0.036072621742884316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.519155263900757,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02522996999323368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10551587343215943,
      "backward_entropy": 0.03230608503023783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.169006824493408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025305192917585373,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10547056198120117,
      "backward_entropy": 0.033079187075297035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3375701904296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025380238890647888,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10541887283325195,
      "backward_entropy": 0.03136897749370999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.044136047363281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025455297902226448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10535759925842285,
      "backward_entropy": 0.03208987580405341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.305160999298096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02553011104464531,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10529050827026368,
      "backward_entropy": 0.030443224642011855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.427934408187866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025604965165257454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10521305799484253,
      "backward_entropy": 0.031097991598976985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.370776891708374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025679022073745728,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10513882637023926,
      "backward_entropy": 0.030607859293619793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.117847204208374,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025752317160367966,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10506700277328491,
      "backward_entropy": 0.032237115833494395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5587923526763916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025824692100286484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10500004291534423,
      "backward_entropy": 0.028616620434655085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0738844871520996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02589668333530426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10492873191833496,
      "backward_entropy": 0.02816681729422675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1479904651641846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025967849418520927,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10486096143722534,
      "backward_entropy": 0.028705179691314697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4637715816497803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038335636258125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10479526519775391,
      "backward_entropy": 0.02728136546081967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8009607791900635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026107531040906906,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10474216938018799,
      "backward_entropy": 0.02994720803366767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6844322681427,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026175888255238533,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10469473600387573,
      "backward_entropy": 0.02950151761372884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8308584690093994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026243388652801514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10465198755264282,
      "backward_entropy": 0.02690914273262024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9971747398376465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026310287415981293,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10460810661315918,
      "backward_entropy": 0.02557973563671112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.64963436126709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026376817375421524,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10455974340438842,
      "backward_entropy": 0.026045244601037767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0443079471588135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02644263580441475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10451328754425049,
      "backward_entropy": 0.025620068113009136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6822237968444824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0265082735568285,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10445833206176758,
      "backward_entropy": 0.027337941858503554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4153640270233154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026573333889245987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10440263748168946,
      "backward_entropy": 0.02477539579073588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4303836822509766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026637597009539604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10434855222702026,
      "backward_entropy": 0.0235676947567198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.491483449935913,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670116536319256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10429437160491943,
      "backward_entropy": 0.023179877135488722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.349855899810791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026764167472720146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10423870086669922,
      "backward_entropy": 0.02355214787854089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1373465061187744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02682649902999401,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10418317317962647,
      "backward_entropy": 0.022422562042872112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.06890869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02688797563314438,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10413093566894531,
      "backward_entropy": 0.024892672896385193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.242913246154785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02694859728217125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10408223867416382,
      "backward_entropy": 0.021688222885131836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.031447410583496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027008676901459694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10403082370758057,
      "backward_entropy": 0.022004927198092144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.749866008758545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0270680021494627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10398060083389282,
      "backward_entropy": 0.021633257468541462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9236422777175903,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02712627872824669,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10393741130828857,
      "backward_entropy": 0.021270790033870272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9999611377716064,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02718385122716427,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10389401912689208,
      "backward_entropy": 0.02028591765297784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0212743282318115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027240896597504616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10384728908538818,
      "backward_entropy": 0.020561443434821233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7134671211242676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729750983417034,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10379489660263061,
      "backward_entropy": 0.01961545315053728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6881675720214844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027353322133421898,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10374311208724976,
      "backward_entropy": 0.01986946827835507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8519302606582642,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027408357709646225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10369279384613037,
      "backward_entropy": 0.019533362653520372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6434327363967896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027462953701615334,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10363669395446777,
      "backward_entropy": 0.0212501949734158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.356491208076477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027516836300492287,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10358073711395263,
      "backward_entropy": 0.018335845735338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4658507108688354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02756965532898903,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1035311460494995,
      "backward_entropy": 0.020589676168229844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5571866035461426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027621708810329437,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1034810185432434,
      "backward_entropy": 0.017731217874421015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5168732404708862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02767319604754448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1034279465675354,
      "backward_entropy": 0.01792997618516286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5249935388565063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027724124491214752,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10337132215499878,
      "backward_entropy": 0.017625162998835247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4020905494689941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774574235081673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10330955982208252,
      "backward_entropy": 0.01732401384247674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2003693580627441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027824383229017258,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10324625968933106,
      "backward_entropy": 0.019045415851804946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2984004020690918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027873283252120018,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10318601131439209,
      "backward_entropy": 0.01630964709652795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2775079011917114,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0279215257614851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10312490463256836,
      "backward_entropy": 0.016043701105647616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3109461069107056,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02796917036175728,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10306053161621094,
      "backward_entropy": 0.018182176682684157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0829490423202515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028016328811645508,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10299191474914551,
      "backward_entropy": 0.01590179569191403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1426358222961426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028062647208571434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10292470455169678,
      "backward_entropy": 0.015276097589068942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3183073997497559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02810833603143692,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10285475254058837,
      "backward_entropy": 0.015030317836337619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0537532567977905,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02815379947423935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1027755618095398,
      "backward_entropy": 0.014788258406851027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.87343430519104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02819855883717537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10269511938095092,
      "backward_entropy": 0.016836608449618023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.012521743774414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028242312371730804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10261950492858887,
      "backward_entropy": 0.014321062299940322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0166866779327393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285464271903038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10254101753234864,
      "backward_entropy": 0.014348347981770834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.895404040813446,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028328100219368935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10245797634124756,
      "backward_entropy": 0.013873962892426385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8559067249298096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028370017185807228,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10237412452697754,
      "backward_entropy": 0.013869615892569223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7779108285903931,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028411203995347023,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10228984355926514,
      "backward_entropy": 0.015624420510398017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6510072350502014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028451554477214813,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10220744609832763,
      "backward_entropy": 0.013413490520583259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6530523896217346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028490878641605377,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10212957859039307,
      "backward_entropy": 0.013196152117517259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6845728754997253,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028529280796647072,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1020547866821289,
      "backward_entropy": 0.014964494440290663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5982494354248047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02856692112982273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10198067426681519,
      "backward_entropy": 0.012780264847808413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6583196520805359,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028603676706552505,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1019089698791504,
      "backward_entropy": 0.012471843096945021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6312626600265503,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286397822201252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10183608531951904,
      "backward_entropy": 0.012292067209879557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40347906947135925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028675241395831108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10176186561584473,
      "backward_entropy": 0.012196248604191674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4926590621471405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02870950661599636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10169579982757568,
      "backward_entropy": 0.012014278107219271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5518879890441895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02874293550848961,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10163198709487915,
      "backward_entropy": 0.013792488310072158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5274190306663513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028775783255696297,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1015660285949707,
      "backward_entropy": 0.011665089262856377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4801056981086731,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028808044269680977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10149809122085571,
      "backward_entropy": 0.011495983435047997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4590030610561371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02883964590728283,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10142933130264283,
      "backward_entropy": 0.01133107559548484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3897104561328888,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0288705937564373,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10135960578918457,
      "backward_entropy": 0.013108346197340224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3693602383136749,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028900733217597008,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10129172801971435,
      "backward_entropy": 0.012949157920148637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3101726174354553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028930073603987694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10122582912445069,
      "backward_entropy": 0.010882003439797295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43956229090690613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028958499431610107,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1011635422706604,
      "backward_entropy": 0.01074711067808999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1951432079076767,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02898654155433178,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10109695196151733,
      "backward_entropy": 0.012499078280395932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28470519185066223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029013365507125854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1010394811630249,
      "backward_entropy": 0.010489746100372739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30889713764190674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029039420187473297,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10098367929458618,
      "backward_entropy": 0.01036820974614885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.259138822555542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029064875096082687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10092701911926269,
      "backward_entropy": 0.010183021426200867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22811442613601685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02908960171043873,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10087132453918457,
      "backward_entropy": 0.010059994128015306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23328112065792084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029113540425896645,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1008177399635315,
      "backward_entropy": 0.011840201914310455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3038412630558014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029136784374713898,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10076508522033692,
      "backward_entropy": 0.009825645221604241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2427724301815033,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029159702360630035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10070817470550537,
      "backward_entropy": 0.009812965989112854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16942098736763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918206714093685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1006502628326416,
      "backward_entropy": 0.009600198931164212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24967841804027557,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029203595593571663,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10059561729431152,
      "backward_entropy": 0.011381934914324019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23736143112182617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02922474965453148,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10053775310516358,
      "backward_entropy": 0.011275303860505423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1992195099592209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02924550697207451,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10047720670700074,
      "backward_entropy": 0.009425318075550927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26755452156066895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02926572784781456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10041589736938476,
      "backward_entropy": 0.009184092283248901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18020549416542053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029285818338394165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10034868717193604,
      "backward_entropy": 0.009083396858639188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14663384854793549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02930534817278385,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10028108358383178,
      "backward_entropy": 0.009160488016075559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20839987695217133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029324188828468323,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10021504163742065,
      "backward_entropy": 0.008891631331708696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16515298187732697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029342761263251305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10014524459838867,
      "backward_entropy": 0.008798792958259583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14591087400913239,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029360853135585785,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1000744342803955,
      "backward_entropy": 0.008918522132767571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16889022290706635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937839739024639,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10000371932983398,
      "backward_entropy": 0.008620924419826932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14087596535682678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02939560078084469,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09993060231208802,
      "backward_entropy": 0.008535071379608579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13366632163524628,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029412323608994484,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09985700845718384,
      "backward_entropy": 0.010349116391605802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1091320738196373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029428571462631226,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09978290796279907,
      "backward_entropy": 0.01027068661318885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11190531402826309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029444225132465363,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09970985651016236,
      "backward_entropy": 0.008292989598380195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09028469771146774,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02945937030017376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09963693618774414,
      "backward_entropy": 0.008498801125420464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08554914593696594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02947390265762806,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09956534504890442,
      "backward_entropy": 0.010053207476933798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09575363993644714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029487844556570053,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09949501156806946,
      "backward_entropy": 0.009986832737922668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10478832572698593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02950134128332138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09942445755004883,
      "backward_entropy": 0.00801007780763838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09296859055757523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02951451949775219,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09935258626937866,
      "backward_entropy": 0.008268877863883972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06947848945856094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029527315869927406,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09928022623062134,
      "backward_entropy": 0.009800564911630418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07197128981351852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0295395664870739,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0992090344429016,
      "backward_entropy": 0.009743248422940573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0912332758307457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029551347717642784,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09913832545280457,
      "backward_entropy": 0.009688310325145721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06504607945680618,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029562901705503464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09906585812568665,
      "backward_entropy": 0.0077051520347595215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06701592355966568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029573997482657433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09899395704269409,
      "backward_entropy": 0.007650088104936812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0686550959944725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02958470769226551,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09892206192016602,
      "backward_entropy": 0.00798222174247106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06996868550777435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02959509752690792,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09884967803955078,
      "backward_entropy": 0.007545188069343567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.062110159546136856,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02960522286593914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09877638816833496,
      "backward_entropy": 0.007899906900193956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05066737160086632,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02961502969264984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09870271682739258,
      "backward_entropy": 0.0074457211626900565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03229500725865364,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029624421149492264,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09862968921661378,
      "backward_entropy": 0.009353195627530416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05738075077533722,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029633209109306335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855902194976807,
      "backward_entropy": 0.007354769441816542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07265264540910721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029641784727573395,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09848754405975342,
      "backward_entropy": 0.007311726609865825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05198434740304947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02965039759874344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09841331243515014,
      "backward_entropy": 0.007721241149637435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04621031507849693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029658770188689232,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09833863377571106,
      "backward_entropy": 0.0076885513133472866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04701654613018036,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029666852205991745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0982639729976654,
      "backward_entropy": 0.007657115658124288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050439175218343735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029674699530005455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09818905591964722,
      "backward_entropy": 0.007145431306627061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04246536269783974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968241088092327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09811315536499024,
      "backward_entropy": 0.007106228835052914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04032975807785988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029689880087971687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09803720712661743,
      "backward_entropy": 0.0070681704415215384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035909347236156464,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029697110876441002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09796122908592224,
      "backward_entropy": 0.0070312172174453735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03181435912847519,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029704060405492783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09788565635681153,
      "backward_entropy": 0.006995599302980635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03676535561680794,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029710697010159492,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09781073331832886,
      "backward_entropy": 0.007488499085108439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02486584149301052,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029717160388827324,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09773561954498292,
      "backward_entropy": 0.007463970118098789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027537941932678223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029723232612013817,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09766191244125366,
      "backward_entropy": 0.007441193693213993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03164521977305412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029729023575782776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09758894443511963,
      "backward_entropy": 0.006866463356547886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025027543306350708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029734669253230095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09751589298248291,
      "backward_entropy": 0.0068369706471761065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017541518434882164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029740044847130775,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09744362831115723,
      "backward_entropy": 0.007379078202777439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01971800997853279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02974499948322773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09737312197685241,
      "backward_entropy": 0.006782485379113091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028759049251675606,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02974964864552021,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09730364084243774,
      "backward_entropy": 0.008808273408148024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01952693611383438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029754286631941795,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09723353385925293,
      "backward_entropy": 0.007327626976701949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019930150359869003,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02975866198539734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09716439247131348,
      "backward_entropy": 0.00670927431848314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025046033784747124,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02976282872259617,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09709596633911133,
      "backward_entropy": 0.008754297263092466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019230477511882782,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029766978695988655,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09702731370925903,
      "backward_entropy": 0.008737295866012573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01731216162443161,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02977095916867256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09695918560028076,
      "backward_entropy": 0.007268564568625556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011451765894889832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02977474220097065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09689177274703979,
      "backward_entropy": 0.00725537786881129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013900524005293846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029778165742754936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09682585000991821,
      "backward_entropy": 0.00660233489341206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023059600964188576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029781360179185867,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09676086902618408,
      "backward_entropy": 0.00658421301179462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015340114012360573,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029784712940454483,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09669504761695862,
      "backward_entropy": 0.008666775292820401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010545327328145504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029787926003336906,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09662986993789673,
      "backward_entropy": 0.006547212600708008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010934647172689438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0297908503562212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09656595587730407,
      "backward_entropy": 0.006530364354451497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011994185857474804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02979353629052639,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09650312662124634,
      "backward_entropy": 0.006514627900388505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013568168506026268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029796063899993896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09644113779067993,
      "backward_entropy": 0.00718299796183904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011621625162661076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02979853004217148,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09637963771820068,
      "backward_entropy": 0.00648491664065255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009455614723265171,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02980087883770466,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09631884694099427,
      "backward_entropy": 0.006470771299468147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013019672594964504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029803022742271423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09625920057296752,
      "backward_entropy": 0.00645758170220587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010058503597974777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029805181547999382,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09619982242584228,
      "backward_entropy": 0.006444353196356032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009813680313527584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02980724349617958,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09614109396934509,
      "backward_entropy": 0.007147596942053901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010814392007887363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02980920672416687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09608312845230102,
      "backward_entropy": 0.00641929234067599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010810346342623234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029811158776283264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09602559208869935,
      "backward_entropy": 0.0071355973680814104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008955621160566807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029813120141625404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09596843719482422,
      "backward_entropy": 0.007129571504063076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011802016757428646,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029815007001161575,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09591199159622192,
      "backward_entropy": 0.008555149038632711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009684627875685692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02981702797114849,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09585552215576172,
      "backward_entropy": 0.006370694273047977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0060083987191319466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029819060117006302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09579948782920837,
      "backward_entropy": 0.0063583093384901685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009076707996428013,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029820872470736504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09574466943740845,
      "backward_entropy": 0.0063469550675816005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007515850942581892,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029822727665305138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09569022655487061,
      "backward_entropy": 0.006335448887613084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007279494311660528,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029824549332261086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09563637375831605,
      "backward_entropy": 0.006324138078424666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007984400726854801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02982633002102375,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09558321237564087,
      "backward_entropy": 0.006313068585263358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00633761752396822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029828161001205444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09553042650222779,
      "backward_entropy": 0.007082452376683553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006115783471614122,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02982991561293602,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09547847509384155,
      "backward_entropy": 0.006290971404976315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005973347928375006,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029831591993570328,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09542732834815978,
      "backward_entropy": 0.007071678837140401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005673388950526714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029833216220140457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09537694454193116,
      "backward_entropy": 0.0062703341245651245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00591340521350503,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029834790155291557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09532729983329773,
      "backward_entropy": 0.007061744729677836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004999155178666115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029836347326636314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09527834057807923,
      "backward_entropy": 0.007056972218884362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004313207231462002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029837826266884804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0952302098274231,
      "backward_entropy": 0.0070525043540530736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003977772314101458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0298391692340374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09518303275108338,
      "backward_entropy": 0.006232469860050414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003916680812835693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029840366914868355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09513685703277588,
      "backward_entropy": 0.00622437811560101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004285708069801331,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029841478914022446,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09509150981903076,
      "backward_entropy": 0.008459740214877658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003669806057587266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984255738556385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09504663944244385,
      "backward_entropy": 0.006209202524688508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030922635924071074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984355017542839,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0950016975402832,
      "backward_entropy": 0.006202141029967202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034545762464404106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029844438657164574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09495725631713867,
      "backward_entropy": 0.007035038537449307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00370879378169775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984527312219143,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09491333961486817,
      "backward_entropy": 0.006189252353376812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033720312640070915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984612248837948,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09486992359161377,
      "backward_entropy": 0.006182956198851268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030343851540237665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984699234366417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09482702612876892,
      "backward_entropy": 0.006176618238290151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031959079205989838,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029847800731658936,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09478483200073243,
      "backward_entropy": 0.008438749445809258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029588639736175537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984861470758915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09474323987960816,
      "backward_entropy": 0.006164588034152985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002219383604824543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029849454760551453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09470225572586059,
      "backward_entropy": 0.007023599412706163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023343567736446857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029850197955965996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09466208219528198,
      "backward_entropy": 0.0061529117325941724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021680945064872503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029850894585251808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09462265968322754,
      "backward_entropy": 0.006147550212012397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022682242561131716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029851512983441353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0945840299129486,
      "backward_entropy": 0.006142576121621662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021455371752381325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029852135106921196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09454606771469116,
      "backward_entropy": 0.00613762272728814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017248369986191392,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02985275909304619,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0945088028907776,
      "backward_entropy": 0.006132721900939941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017112914938479662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029853304848074913,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09447232484817505,
      "backward_entropy": 0.006128203123807907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014853255124762654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029853805899620056,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09443660378456116,
      "backward_entropy": 0.008419632083839841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016622644616290927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02985422872006893,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09440168738365173,
      "backward_entropy": 0.006120008726914723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013618423836305737,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02985462360084057,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09436749815940856,
      "backward_entropy": 0.007014447616206275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015257622580975294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029854966327548027,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09433407187461854,
      "backward_entropy": 0.006112783319420285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014554206281900406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02985534444451332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09430131912231446,
      "backward_entropy": 0.00610920497112804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013759616995230317,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02985573746263981,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09426924586296082,
      "backward_entropy": 0.006105610893832313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014096563681960106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02985614351928234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09423784017562867,
      "backward_entropy": 0.006102006468507979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011443155817687511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029856575652956963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09420707821846008,
      "backward_entropy": 0.006098349061277177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009741187677718699,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029856953769922256,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0941770315170288,
      "backward_entropy": 0.006094939178890652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000880828476510942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029857296496629715,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09414772987365723,
      "backward_entropy": 0.0060917358431551195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010537815978750587,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02985759824514389,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09411916732788086,
      "backward_entropy": 0.0070110418730311925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009916623821482062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029857924208045006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09409124851226806,
      "backward_entropy": 0.006085698389344745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008045503636822104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029858261346817017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09406396150588989,
      "backward_entropy": 0.00840939829746882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008647693903185427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029858574271202087,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09403735399246216,
      "backward_entropy": 0.00607974992858039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007746652117930353,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029858876019716263,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09401138424873352,
      "backward_entropy": 0.008407993449105157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007024904480203986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02985917218029499,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09398604035377503,
      "backward_entropy": 0.008407300545109643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005963195580989122,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029859455302357674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396135807037354,
      "backward_entropy": 0.00607151413957278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006133290589787066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029859714210033417,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.093937349319458,
      "backward_entropy": 0.007008666793505351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006260748486965895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02985997498035431,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09391397833824158,
      "backward_entropy": 0.007008367114596897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006126025691628456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029860250651836395,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0938912034034729,
      "backward_entropy": 0.006064001884725358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005450114840641618,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029860535636544228,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09386898279190063,
      "backward_entropy": 0.008404310378763411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047221689601428807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029860813170671463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09384733438491821,
      "backward_entropy": 0.006059053871366713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041661213617771864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029861081391572952,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09382629990577698,
      "backward_entropy": 0.006056683758894603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004670789639931172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029861319810152054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09380587339401245,
      "backward_entropy": 0.00700636539194319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004909401759505272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986154332756996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09378596544265747,
      "backward_entropy": 0.006052367389202118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004549688892439008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986178733408451,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09376651048660278,
      "backward_entropy": 0.006050208376513587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003956930013373494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029862040653824806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0937475323677063,
      "backward_entropy": 0.0070053694976700675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000339390680892393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0298623014241457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09372904300689697,
      "backward_entropy": 0.007004924118518829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036504448507912457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029862534254789352,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09371109008789062,
      "backward_entropy": 0.0083993309073978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002822180395014584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029862741008400917,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0936935544013977,
      "backward_entropy": 0.006041910913255479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029727662331424654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029862944036722183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09367657899856567,
      "backward_entropy": 0.006040055718686845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029321733745746315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029863152652978897,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0936600923538208,
      "backward_entropy": 0.0060382141835159725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002620724553707987,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986335940659046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09364405274391174,
      "backward_entropy": 0.006036401622825199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025288830511271954,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029863549396395683,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09362845420837403,
      "backward_entropy": 0.00839652700556649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024808579473756254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029863722622394562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09361326694488525,
      "backward_entropy": 0.006033070799377229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023140855773817748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029863903298974037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09359850287437439,
      "backward_entropy": 0.006031445331043667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001963862159755081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029864076524972916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09358412027359009,
      "backward_entropy": 0.006029874500301149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017442874377593398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986423298716545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0935701847076416,
      "backward_entropy": 0.006028393076525794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017974105139728636,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029864376410841942,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09355669021606446,
      "backward_entropy": 0.008394102255503336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000164442477398552,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029864514246582985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09354358911514282,
      "backward_entropy": 0.006025639673074086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001545962004456669,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986465021967888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09353091716766357,
      "backward_entropy": 0.0060243308544158936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015465723117813468,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029864782467484474,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09351862668991089,
      "backward_entropy": 0.008392917613188425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001112738682422787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029864920303225517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09350670576095581,
      "backward_entropy": 0.006021774063507716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012347115261945873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029865043237805367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09349523782730103,
      "backward_entropy": 0.00602059480216768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013796142593491822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029865169897675514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0934841513633728,
      "backward_entropy": 0.006019402709272172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011375059693818912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986530214548111,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09347337484359741,
      "backward_entropy": 0.006018215169509252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.818356193136424e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029865432530641556,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09346290826797485,
      "backward_entropy": 0.008390896850162081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011318612814648077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029865572229027748,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09345285892486573,
      "backward_entropy": 0.00601590010854933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.016757394419983e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986571006476879,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09344307184219361,
      "backward_entropy": 0.006014747338162528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010051834397017956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029865842312574387,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09343360662460327,
      "backward_entropy": 0.006013638857338164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251120743807405e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986598201096058,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09342440366744995,
      "backward_entropy": 0.006012529962592655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.505219400627539e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029866119846701622,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09341552257537841,
      "backward_entropy": 0.007000776628653209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.588947144336998e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029866259545087814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09340694546699524,
      "backward_entropy": 0.006010355220900642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.284914656542242e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029866386204957962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09339868426322936,
      "backward_entropy": 0.007000313864813911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4145777539815754e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029866516590118408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09339061975479127,
      "backward_entropy": 0.006008329490820567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5579919717274606e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029866637662053108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09338287115097046,
      "backward_entropy": 0.006007373746898439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.701213715132326e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02986675687134266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09337540864944457,
      "backward_entropy": 0.006999688843886058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.15991375525482e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029866879805922508,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09336813092231751,
      "backward_entropy": 0.006005500339799457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4306605306919664e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029867000877857208,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0933610439300537,
      "backward_entropy": 0.008385180599159665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.337232505553402e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029867110773921013,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0933541476726532,
      "backward_entropy": 0.006003728343380822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.445197191671468e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029867222532629967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09334744811058045,
      "backward_entropy": 0.006002864076031579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4252163206692785e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029867324978113174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09334096908569336,
      "backward_entropy": 0.006998716957039303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.978926906711422e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029867421835660934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0933346688747406,
      "backward_entropy": 0.006001289106077618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6065015592612326e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029867513105273247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09332858324050904,
      "backward_entropy": 0.006000551084677379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.908916187356226e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986760064959526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09332270622253418,
      "backward_entropy": 0.005999842451678382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.972740887547843e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029867690056562424,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09331700801849366,
      "backward_entropy": 0.005999137957890828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.99935582006583e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029867783188819885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09331144094467163,
      "backward_entropy": 0.0059984322223398424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4570864954730496e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0298678707331419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09330607056617737,
      "backward_entropy": 0.005997754633426666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7037993277190253e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029867958277463913,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09330084323883056,
      "backward_entropy": 0.008381194538540311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7054118618252687e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029868045821785927,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09329580068588257,
      "backward_entropy": 0.008380788895818923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8751766876666807e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029868129640817642,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09329091310501099,
      "backward_entropy": 0.008380415538946787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4075759938568808e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029868213459849358,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09328614473342896,
      "backward_entropy": 0.005995163487063514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1729547370341606e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029868295416235924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09328153133392333,
      "backward_entropy": 0.006997310452991062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1036405087215826e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986837737262249,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0932770848274231,
      "backward_entropy": 0.005993935796949599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0543629943858832e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02986845374107361,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09327278137207032,
      "backward_entropy": 0.006997052994039323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.570240237924736e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986852265894413,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09326858520507812,
      "backward_entropy": 0.005992831869257821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6112944649648853e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0298685934394598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09326460361480712,
      "backward_entropy": 0.005992305361562305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7712496628519148e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029868660494685173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09326075911521911,
      "backward_entropy": 0.0059918070005046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4760810699954163e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029868725687265396,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0932570219039917,
      "backward_entropy": 0.008377638128068712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5637302567483857e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02986879274249077,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09325342178344727,
      "backward_entropy": 0.008377311958207024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3098447197990026e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02986885793507099,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09324990510940552,
      "backward_entropy": 0.006996480955017937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2723808140435722e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029868919402360916,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09324653148651123,
      "backward_entropy": 0.006996402310000526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1326683306833729e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986897900700569,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09324325323104858,
      "backward_entropy": 0.005989452203114827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1616019946814049e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986903116106987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09324010014533997,
      "backward_entropy": 0.00598904656039344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.844184205576312e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02986908331513405,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09323704242706299,
      "backward_entropy": 0.00837584998872545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.2091477199574e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869133606553078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09323410987854004,
      "backward_entropy": 0.005988261765903897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.542625437257811e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869187623262405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09323128461837768,
      "backward_entropy": 0.005987875163555145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61982971400721e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029869239777326584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09322858452796937,
      "backward_entropy": 0.008375049465232424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.191991011903156e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869291931390762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09322596192359925,
      "backward_entropy": 0.005987139211760627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.72419264446944e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02986934222280979,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09322340488433838,
      "backward_entropy": 0.00837451716264089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.743036919942824e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02986939251422882,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09322094917297363,
      "backward_entropy": 0.008374250597423978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0893274823902175e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986943908035755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09321860074996949,
      "backward_entropy": 0.005986088679896461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2823719417792745e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029869483783841133,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09321632385253906,
      "backward_entropy": 0.008373758859104581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.474061370274285e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869524762034416,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0932141363620758,
      "backward_entropy": 0.005985471523470349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7488556447206065e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0298695657402277,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09321205615997315,
      "backward_entropy": 0.0069955579108662075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.500183306139661e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869606718420982,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09321009516716003,
      "backward_entropy": 0.005984887066814635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.952349172526738e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869647696614265,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09320817589759826,
      "backward_entropy": 0.005984613051017125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.753892881126376e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02986968494951725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09320632219314576,
      "backward_entropy": 0.0069954122106234235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.433718004293041e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869718477129936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09320452213287353,
      "backward_entropy": 0.005984096477429072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8470784602395725e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869752004742622,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09320278167724609,
      "backward_entropy": 0.005983855161401961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.429988621268421e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029869787395000458,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09320108890533448,
      "backward_entropy": 0.00699530045191447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4680249427765375e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029869819059967995,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09319943189620972,
      "backward_entropy": 0.006995260715484619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5539569580578245e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986985258758068,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09319783449172973,
      "backward_entropy": 0.00598313742213779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.571810339053627e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869884252548218,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09319626092910767,
      "backward_entropy": 0.0059829263223542106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8727931749017444e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869912192225456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09319475293159485,
      "backward_entropy": 0.005982707771990035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1549907362204976e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869940131902695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931932806968689,
      "backward_entropy": 0.0059825074341562055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3231422094104346e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029869966208934784,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09319185018539429,
      "backward_entropy": 0.006995103425449795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8323006543141673e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029869988560676575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09319044351577759,
      "backward_entropy": 0.005982136560810937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5032875328179216e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870012775063515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09318912029266357,
      "backward_entropy": 0.005981959816482332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.409949729553773e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870033264160156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09318786859512329,
      "backward_entropy": 0.005981794248024623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.094014007525402e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987005189061165,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09318664073944091,
      "backward_entropy": 0.006995100114080641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8857416534956428e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987007051706314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0931854486465454,
      "backward_entropy": 0.006995118326610989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9464935121504823e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870089143514633,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09318430423736572,
      "backward_entropy": 0.008370178441206614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9560900454962393e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870107769966125,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09318318367004394,
      "backward_entropy": 0.008370065854655372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6128383322211448e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987012453377247,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09318206906318664,
      "backward_entropy": 0.006995118326610989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9116412204311928e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987014129757881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09318101406097412,
      "backward_entropy": 0.005980936189492543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8379028006165754e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870156198740005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0931799590587616,
      "backward_entropy": 0.006995124949349297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5482538628930342e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0298701673746109,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09317895174026489,
      "backward_entropy": 0.005980706877178616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6893517340577091e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870176687836647,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09317796230316162,
      "backward_entropy": 0.008369566665755378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00923282642907e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870182275772095,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09317700862884522,
      "backward_entropy": 0.008369487192895677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0600836048979545e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987018972635269,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09317613244056702,
      "backward_entropy": 0.008369415998458862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.253653749699879e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870199039578438,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09317526817321778,
      "backward_entropy": 0.008369324935807122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1079108617195743e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870206490159035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09317444562911988,
      "backward_entropy": 0.006995319492287106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.957428008216084e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987021394073963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09317362308502197,
      "backward_entropy": 0.005980170435375637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.63865090852778e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987022139132023,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09317286014556884,
      "backward_entropy": 0.006995382408301036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.833572676143376e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870228841900826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09317214488983154,
      "backward_entropy": 0.0059800247351328535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.798989827279001e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870234429836273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09317142963409424,
      "backward_entropy": 0.0059799568520651925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.292343298104242e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987024001777172,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09317073822021485,
      "backward_entropy": 0.0059798819323380785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.101873731902742e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987024560570717,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09317009449005127,
      "backward_entropy": 0.006995505756802029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.273730370296107e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870251193642616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316946268081665,
      "backward_entropy": 0.005979761067363951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.427554583548044e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870254918932915,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0931688368320465,
      "backward_entropy": 0.008368751241101159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.789099191133573e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870258644223213,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09316823482513428,
      "backward_entropy": 0.008368702398406135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.442916742344096e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987026236951351,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09316767454147339,
      "backward_entropy": 0.006995650629202525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.228259911087662e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987026609480381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316710829734802,
      "backward_entropy": 0.00597955369287067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.846958745474694e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870271682739258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316658973693848,
      "backward_entropy": 0.005979500710964203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.963113380857976e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870277270674706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931660771369934,
      "backward_entropy": 0.005979451454348034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.290812398721755e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870280995965004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931655764579773,
      "backward_entropy": 0.0059793976445992785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.766457095684018e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870284721255302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316507577896119,
      "backward_entropy": 0.005979359149932861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.561736375308101e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0298702884465456,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09316459894180298,
      "backward_entropy": 0.00836834063132604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.044243328531593e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987029030919075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316412210464478,
      "backward_entropy": 0.005979265603754256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5186278068977117e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987029403448105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316369891166687,
      "backward_entropy": 0.005979220072428386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4845027130359085e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870297759771347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931632936000824,
      "backward_entropy": 0.0059791865448156995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.951346687041223e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870301485061646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316291809082031,
      "backward_entropy": 0.0059791480501492815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.292678911748226e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870305210351944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316257238388062,
      "backward_entropy": 0.005979098793533113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.344349295275606e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870308935642242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316223859786987,
      "backward_entropy": 0.005979073130422168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.63852768966899e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987031266093254,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09316192865371704,
      "backward_entropy": 0.006995966037114461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.59547221048706e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987031638622284,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316161870956421,
      "backward_entropy": 0.00597900648911794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5175273183085665e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870320111513138,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09316133260726929,
      "backward_entropy": 0.008367938299973806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3656284042772313e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870321974158287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316104054450988,
      "backward_entropy": 0.0059789444009462995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7769806959222478e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870323836803436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09316077232360839,
      "backward_entropy": 0.005978915012545056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4762474026829295e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870325699448586,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09316051006317139,
      "backward_entropy": 0.006996083590719435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.876034190217979e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870327562093735,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09316025972366333,
      "backward_entropy": 0.008367782665623559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.218820469579441e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870329424738884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931600272655487,
      "backward_entropy": 0.005978845059871674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7876099889235775e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870331287384033,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315977096557618,
      "backward_entropy": 0.005978826847341325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5834412181447988e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870333150029182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315955638885498,
      "backward_entropy": 0.0059787970450189375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3475231241955044e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987033501267433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315933585166931,
      "backward_entropy": 0.005978782971700032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6155291859831777e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987033687531948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315913915634155,
      "backward_entropy": 0.006996225979593065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2927179682264978e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987033873796463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315894246101379,
      "backward_entropy": 0.005978734956847297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1078555672838775e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987034060060978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.093158757686615,
      "backward_entropy": 0.005978720055686103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0483688583917683e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987034246325493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315857887268067,
      "backward_entropy": 0.005978707638051774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2174001540188328e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870344325900078,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0931584119796753,
      "backward_entropy": 0.006996288895606995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3206843618718267e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870346188545227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315823316574097,
      "backward_entropy": 0.005978666659858491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.354315060098088e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315807819366455,
      "backward_entropy": 0.006996330287721422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0823218588029704e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315789937973022,
      "backward_entropy": 0.005978640996747547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.042332666491347e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315773248672485,
      "backward_entropy": 0.00597863354616695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.913809068644696e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315756559371949,
      "backward_entropy": 0.006996392375893063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417165986429609e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315741062164307,
      "backward_entropy": 0.0059786029160022736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.468571456252903e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315726757049561,
      "backward_entropy": 0.005978591326210234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.49612993899973e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931571364402771,
      "backward_entropy": 0.00597858221994506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.678505570789639e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315699934959412,
      "backward_entropy": 0.005978575183285607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3965344193329656e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870348051190376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315687417984009,
      "backward_entropy": 0.005978553659386105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9582021094684023e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870349913835526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315676689147949,
      "backward_entropy": 0.005978542069594066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6239741752506234e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870351776480675,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315667152404786,
      "backward_entropy": 0.008367197381125556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.365109328498875e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029870353639125824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315657615661621,
      "backward_entropy": 0.0059785205456945635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9266134283243446e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870355501770973,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0931564748287201,
      "backward_entropy": 0.006996516552236345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.201747572096792e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029870357364416122,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315638542175293,
      "backward_entropy": 0.008367128670215607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.224366989546979e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987035922706127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315629601478577,
      "backward_entropy": 0.0059784820510281455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5771884888144996e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036108970642,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315621852874756,
      "backward_entropy": 0.006996537248293559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.308874679281871e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036295235157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931561529636383,
      "backward_entropy": 0.005978463424576653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.871931480465719e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315608143806457,
      "backward_entropy": 0.005978455973996056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4375916274930205e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315600395202636,
      "backward_entropy": 0.0059784505930211805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.053607144920534e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315593242645263,
      "backward_entropy": 0.005978431966569688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6406372199971884e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931558609008789,
      "backward_entropy": 0.005978426585594813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.688681715630082e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931557834148407,
      "backward_entropy": 0.005978420790698793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.465350673081957e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315571784973145,
      "backward_entropy": 0.006996617548995548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8089932158081865e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315564632415771,
      "backward_entropy": 0.005978409614827897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.120733538253262e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315556287765503,
      "backward_entropy": 0.005978405889537599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.879551175283268e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931554913520813,
      "backward_entropy": 0.005978402578168445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7796886570286006e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315541982650757,
      "backward_entropy": 0.005978400922483868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2649324193935172e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315535426139832,
      "backward_entropy": 0.005978396783272426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8272505286631713e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931552767753601,
      "backward_entropy": 0.005978395127587848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8175342120230198e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315521717071533,
      "backward_entropy": 0.0069966986775398254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.667422111495398e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315515756607055,
      "backward_entropy": 0.006996706955962711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9066170864334708e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315509796142578,
      "backward_entropy": 0.006996715234385597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3478034688318985e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.093155038356781,
      "backward_entropy": 0.005978371534082625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9266128248318637e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315497875213623,
      "backward_entropy": 0.006996744208865696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3037800172810421e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931549310684204,
      "backward_entropy": 0.005978364083502028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5431057320824948e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0931548833847046,
      "backward_entropy": 0.008366806639565362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0996132004947867e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315482378005982,
      "backward_entropy": 0.005978356632921431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4520922242411416e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.093154776096344,
      "backward_entropy": 0.005978354977236854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2634410850864697e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315472245216369,
      "backward_entropy": 0.008366794221931033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3114583197193497e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0931546688079834,
      "backward_entropy": 0.008366788427035013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2292965756444119e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315462112426758,
      "backward_entropy": 0.005978349182340834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.127098414599459e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315457940101624,
      "backward_entropy": 0.005978349182340834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.895039288996486e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0931545376777649,
      "backward_entropy": 0.006996816231144799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.099519277493528e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315450787544251,
      "backward_entropy": 0.0069968245095676845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.580393119293149e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315447211265564,
      "backward_entropy": 0.005978345043129391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2535789879802905e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315444231033325,
      "backward_entropy": 0.008366742067866854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.843397042961442e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315440058708191,
      "backward_entropy": 0.005978341731760237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.779405564178887e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315437078475952,
      "backward_entropy": 0.006996858451101515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.307619398488896e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315433502197265,
      "backward_entropy": 0.008366715576913621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.786038397876837e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315431118011475,
      "backward_entropy": 0.006996867557366689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1287969426994096e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315427541732788,
      "backward_entropy": 0.00597833428117964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.058030521671753e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315426349639892,
      "backward_entropy": 0.005978332625495063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.823324045195477e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315423369407654,
      "backward_entropy": 0.0069968799750010175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.925652774545597e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315420389175415,
      "backward_entropy": 0.005978330969810486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.129951491904649e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315418004989624,
      "backward_entropy": 0.008366683291064369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.390432988860994e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315415620803832,
      "backward_entropy": 0.008366680807537503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4701983508966805e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315413236618042,
      "backward_entropy": 0.005978311101595561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.781778445954842e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315412044525147,
      "backward_entropy": 0.008366675840483772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8048142414481845e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315409660339355,
      "backward_entropy": 0.005978308618068695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7021513915315154e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0931540846824646,
      "backward_entropy": 0.006996918055746291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.740087268193747e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315405488014221,
      "backward_entropy": 0.005978308618068695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1153035706665833e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315403699874877,
      "backward_entropy": 0.005978307790226406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.643322088464629e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315403699874877,
      "backward_entropy": 0.005978307790226406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4811157572912634e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315401315689087,
      "backward_entropy": 0.008366632792684767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9192896161257522e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315398931503296,
      "backward_entropy": 0.005978303651014964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2584245584766904e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315398335456848,
      "backward_entropy": 0.005978303651014964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4759003736107843e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315396547317505,
      "backward_entropy": 0.006996939579645793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8733601336862193e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931539535522461,
      "backward_entropy": 0.005978303651014964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.861096166067e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315394163131714,
      "backward_entropy": 0.008366603818204667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0572770154103637e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0931539237499237,
      "backward_entropy": 0.008366598851150937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0828778701798e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315391778945922,
      "backward_entropy": 0.0069969478580686785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.76717662725423e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315390586853027,
      "backward_entropy": 0.00699696358707216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8568471205071546e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931538999080658,
      "backward_entropy": 0.005978296200434367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3957190958535648e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315388798713684,
      "backward_entropy": 0.00699696358707216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2436203178367577e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315387606620788,
      "backward_entropy": 0.005978296200434367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2465335430533742e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315387010574341,
      "backward_entropy": 0.008366581466462877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6226309185185528e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315386414527893,
      "backward_entropy": 0.008366576499409147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3187460012886731e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315385818481445,
      "backward_entropy": 0.006996970209810469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.314653275130695e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931538462638855,
      "backward_entropy": 0.005978292061222924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.320686444880266e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931538462638855,
      "backward_entropy": 0.005978292061222924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1787619769165758e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931538462638855,
      "backward_entropy": 0.005978292061222924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0600587074804935e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315383434295654,
      "backward_entropy": 0.005978290405538347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0486047585800407e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315384030342103,
      "backward_entropy": 0.008366545041402182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.187281880760565e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315383434295654,
      "backward_entropy": 0.00597828874985377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.394334033961059e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315383434295654,
      "backward_entropy": 0.00597828874985377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.348290864683804e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315383434295654,
      "backward_entropy": 0.005978286266326904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.911591299285647e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315382242202759,
      "backward_entropy": 0.005978284610642327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.994706953060813e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315382838249206,
      "backward_entropy": 0.00836653427945243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.278799785126466e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315382838249206,
      "backward_entropy": 0.006996985110971663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.817142323394364e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315382242202759,
      "backward_entropy": 0.005978284610642327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.366978138634295e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315382242202759,
      "backward_entropy": 0.005978284610642327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.172271582727262e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315381050109864,
      "backward_entropy": 0.005978283782800038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.524736141320318e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315381050109864,
      "backward_entropy": 0.005978283782800038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.427267524282797e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315381050109864,
      "backward_entropy": 0.005978281299273173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5836933420796413e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315381050109864,
      "backward_entropy": 0.005978281299273173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3513458674860885e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.005978281299273173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.546123477666697e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.006996991733709971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0677150536794215e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315380454063416,
      "backward_entropy": 0.005978281299273173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0613023227488156e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.006996995872921414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.65323762960179e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.006996997528605991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2647307079969323e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0931537926197052,
      "backward_entropy": 0.006996997528605991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.808633325912524e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.005978281299273173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8749980174325174e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.005978281299273173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1025138014229015e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.006996997528605991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.029612116733915e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315379858016967,
      "backward_entropy": 0.008366487920284271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0310153558966704e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0931537926197052,
      "backward_entropy": 0.008366485436757406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.448317104608577e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315378665924072,
      "backward_entropy": 0.005978279643588596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8712142946242238e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315378665924072,
      "backward_entropy": 0.006997002495659722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6963497273536632e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315378069877625,
      "backward_entropy": 0.005978279643588596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.971613983187126e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315378665924072,
      "backward_entropy": 0.005978279643588596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2660628928861115e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315378665924072,
      "backward_entropy": 0.00836647798617681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1461232790898066e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315378069877625,
      "backward_entropy": 0.005978279643588596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4794920843996806e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09315378069877625,
      "backward_entropy": 0.005978279643588596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7254109252462513e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09315377473831177,
      "backward_entropy": 0.008366473019123077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2779111102645402e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315377473831177,
      "backward_entropy": 0.006997006634871165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7191581491715624e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987036481499672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09315377473831177,
      "backward_entropy": 0.006997006634871165,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.70530588667384e-09,
    "avg_log_Z": 0.02987036479637027,
    "success_rate": 1.0,
    "avg_reward": 46.1,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.19,
      "1": 0.25,
      "2": 0.56
    },
    "avg_forward_entropy": 0.09315430557727813,
    "avg_backward_entropy": 0.006686747728122604,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}