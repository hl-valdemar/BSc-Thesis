{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290581172162837,
      "exploration_ratio": 0.47826086956521746
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290607614950701,
      "exploration_ratio": 0.6608695652173913
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0629070536656813,
      "exploration_ratio": 0.6869565217391304
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0629085291515697,
      "exploration_ratio": 0.7913043478260869
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290267597545277,
      "exploration_ratio": 0.8434782608695652
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0629040246660059,
      "exploration_ratio": 0.8434782608695652
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06288878971880134,
      "exploration_ratio": 0.9217391304347826
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291549910198559,
      "exploration_ratio": 0.9478260869565217
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290239095687866,
      "exploration_ratio": 0.9739130434782609
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291068954901263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06292562105438926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290438283573498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290324113585731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291259689764543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0628942597996105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290098699656399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291774782267484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291464567184449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0629228028384122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291849342259495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0629095744002949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0628929230299863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290901303291321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290737553076312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06292788332158869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291675188324668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290212761272083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 14.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06290929263288324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.0629119179465554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06289231777191162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291674375534058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.985802459716798,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141965210437775,
      "backward_entropy": 0.06291400519284336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.921794128417968,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 9.999999529100023e-05,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.09141961832841236,
      "backward_entropy": 0.0629182062365792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.912222194671632,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00019998834177386015,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09141957263151804,
      "backward_entropy": 0.06290958307006142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.96298589706421,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.00029997013916727155,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09141954580942789,
      "backward_entropy": 0.06290062069892884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919831228256225,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00039995700353756547,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09141947428385416,
      "backward_entropy": 0.06289688565514305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.844108533859252,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.000499935238622129,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141932129859924,
      "backward_entropy": 0.06290688135407188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.041782188415528,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0005998902663122863,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141912857691448,
      "backward_entropy": 0.06289279298348861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.715332269668579,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0006998895900323987,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141874114672344,
      "backward_entropy": 0.0628784185106104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.999711799621583,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0007998228131327779,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.0914182682832082,
      "backward_entropy": 0.06289899999445134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24763069152832,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0008997905242722481,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0914178063472112,
      "backward_entropy": 0.06286938894878734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71272416114807,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0009998594410717486,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0914173016945521,
      "backward_entropy": 0.06288047270341353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.767655038833619,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0010998432291671634,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09141676326592764,
      "backward_entropy": 0.0628820847381245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.859481477737427,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.0011997779947705567,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141619900862376,
      "backward_entropy": 0.06286059455438094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.691159296035767,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0012996985809877516,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.0914155105749766,
      "backward_entropy": 0.06286722963506525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.809109735488892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.0013995534158311785,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09141486585140228,
      "backward_entropy": 0.06283343325961721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.835382270812989,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.001499394851271063,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09141422410806019,
      "backward_entropy": 0.06284869909286499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.946821260452271,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.001599241397343576,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09141359329223632,
      "backward_entropy": 0.06284303773533215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.875854873657227,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0016991253476589918,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09141286412874858,
      "backward_entropy": 0.06282260363752193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.922957277297973,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0017990164342336357,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09141206045945485,
      "backward_entropy": 0.0628343029455705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.130946779251099,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0018989323871210217,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0914110799630483,
      "backward_entropy": 0.06281836737285959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.893116521835328,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.001998951379209757,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09140994747479755,
      "backward_entropy": 0.06279597824270075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.911174488067626,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0020989617332816124,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09140880107879637,
      "backward_entropy": 0.06281513896855441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.231346797943115,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.002198968501761556,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09140762984752655,
      "backward_entropy": 0.06282148415392096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930077600479127,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0022991047939285637,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09140631755193075,
      "backward_entropy": 0.06279666261239485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.020554304122925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0023992278380319475,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09140493373076121,
      "backward_entropy": 0.06279925866560503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.978248691558838,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.002499380148947239,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0914034992456436,
      "backward_entropy": 0.06279303214766761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.091401624679566,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.002599547756835818,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09140199919541678,
      "backward_entropy": 0.06277227022431113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.850440788269044,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0026997576467692854,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09140043954054514,
      "backward_entropy": 0.06278702887621793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.142089366912842,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0027999236481264234,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09139895637830099,
      "backward_entropy": 0.06274346004832874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.190405893325806,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0029001588234677913,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09139734804630281,
      "backward_entropy": 0.06274578029459173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.142348289489746,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.003000473603606224,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09139576454957327,
      "backward_entropy": 0.06272647922689263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.309508180618286,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0031008404679596425,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09139411548773449,
      "backward_entropy": 0.06277812719345092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99787459373474,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.003201323840767145,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0913923998673757,
      "backward_entropy": 0.06274359117854725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.933531427383423,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0033017769921571015,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09139068524042765,
      "backward_entropy": 0.06273085800084202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.793700551986694,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0034021678846329452,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09138880868752797,
      "backward_entropy": 0.06269856799732555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.228843498229981,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0035024526063352824,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09138690729935964,
      "backward_entropy": 0.06271489587697117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.754562473297119,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.003602840518578887,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09138485789299011,
      "backward_entropy": 0.06274007125334305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.236799383163453,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.0037031178129836918,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09138278961181641,
      "backward_entropy": 0.06271444396539168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20719347000122,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0038034903351217507,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09138055741786957,
      "backward_entropy": 0.06270402832464739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.175021648406982,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0039039410185068846,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09137822488943734,
      "backward_entropy": 0.06269746585325761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447620964050293,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.004004450934007764,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09137576520442964,
      "backward_entropy": 0.06271036375652661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.696590662002563,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.0041051462292671205,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09137320518493652,
      "backward_entropy": 0.06269849105314776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.094772052764892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.004205643991008401,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09137072563171386,
      "backward_entropy": 0.06266177188266407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12541389465332,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.004306148877367378,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09136815170447032,
      "backward_entropy": 0.0626555778763511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.051699256896972,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.004406687058508396,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09136551618576051,
      "backward_entropy": 0.06264784661206332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.962282371520995,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.004507231619209051,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09136287569999695,
      "backward_entropy": 0.06260078874501315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972479772567748,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.004607726307585836,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09136024018128713,
      "backward_entropy": 0.06264056996865706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.880128192901612,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.004708161810413003,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09135764042536418,
      "backward_entropy": 0.06260679364204406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.868333292007446,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.004808533703908324,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09135507047176361,
      "backward_entropy": 0.06257102164355191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.0075758934021,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.004908820427954197,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09135252833366395,
      "backward_entropy": 0.06257696043361316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.096673774719239,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.005009101051837206,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09134999612967173,
      "backward_entropy": 0.06256405169313603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.215302085876464,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.005109424283728003,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09134738147258759,
      "backward_entropy": 0.06253635070540689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.345139026641846,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.005209840228781104,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09134466449419656,
      "backward_entropy": 0.06251486864956943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.014548826217652,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.005310412868857384,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09134180148442586,
      "backward_entropy": 0.06252266710454767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24361457824707,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0054109618999063965,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09133881231149038,
      "backward_entropy": 0.06250333406708457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.07996425628662,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.005511591630056501,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09133570492267609,
      "backward_entropy": 0.06250693906437266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.285088777542114,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.005612206272780895,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09133264919122061,
      "backward_entropy": 0.06249974911863153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67180118560791,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.005712916003540158,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.09132958054542542,
      "backward_entropy": 0.06250742186199534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.364191055297852,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.005813413951545954,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09132649997870128,
      "backward_entropy": 0.062434691732580004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.982802295684815,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.005914046801626683,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09132317403952281,
      "backward_entropy": 0.062426811456680296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.169644641876221,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0060146140400320295,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09131981134414673,
      "backward_entropy": 0.06241145459088413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.788307857513427,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.006115228496491909,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09131629665692646,
      "backward_entropy": 0.062420448931780725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.075348091125488,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.006215687375515699,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0913127342859904,
      "backward_entropy": 0.06237232197414745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731133460998535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.006316160876303911,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09130909939606985,
      "backward_entropy": 0.06240602352402426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.047422504425048,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.006416480010375381,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09130557974179586,
      "backward_entropy": 0.06242918372154236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02672619819641,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0065168109722435474,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09130210280418395,
      "backward_entropy": 0.06234217990528453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.825279045104981,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.006617140723392367,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09129852851231893,
      "backward_entropy": 0.062362084063616666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.562058639526366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0067173694260418415,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09129490951697032,
      "backward_entropy": 0.06231931014494463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.844458961486817,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.006817386625334621,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09129133423169453,
      "backward_entropy": 0.06229217919436368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.604791593551635,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0069173572584986685,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.0912877211968104,
      "backward_entropy": 0.0622486255385659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.045973587036134,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.007017166400328278,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09128446479638416,
      "backward_entropy": 0.062314174392006615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.975785446166991,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.007117049209773541,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09128117561340332,
      "backward_entropy": 0.06227081472223456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.774749708175658,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0072169587016105655,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09127780894438425,
      "backward_entropy": 0.062199857018210666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.958906888961792,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.007316794246435165,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09127454260985056,
      "backward_entropy": 0.06220405264334246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.652179765701295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.007416656147688628,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09127103189627331,
      "backward_entropy": 0.06217401298609647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.812076711654663,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0075163919478654865,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09126766026020051,
      "backward_entropy": 0.06217739094387401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.931286144256593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.007616091845557093,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09126417934894562,
      "backward_entropy": 0.06217997453429482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.678546047210693,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0077158031985163685,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09126045902570089,
      "backward_entropy": 0.06213249401612716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721511030197144,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.007815417228266596,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09125685890515646,
      "backward_entropy": 0.06215454719283364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.047826147079467,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.007914965832605958,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09125339488188425,
      "backward_entropy": 0.06203145113858309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.859527206420898,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0080146218650043,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.09124975303808848,
      "backward_entropy": 0.06208726005120711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.908509063720704,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.008114265277981758,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09124607940514881,
      "backward_entropy": 0.06198830929669467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.809791374206544,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00821392834186554,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09124227464199067,
      "backward_entropy": 0.06199586174704811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988565826416016,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.008313575852662325,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09123834868272145,
      "backward_entropy": 0.06185027523474259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.829344177246094,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.008413286600261926,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09123427867889404,
      "backward_entropy": 0.061894564195112745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034282636642455,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.008512976299971341,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0912300040324529,
      "backward_entropy": 0.06183735619891774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.009070301055909,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00861274879425764,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09122573137283327,
      "backward_entropy": 0.061860676245255895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.171898937225341,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.008712588157504798,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09122124214967092,
      "backward_entropy": 0.0618405813520605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854998016357422,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.008812566939741372,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09121645589669546,
      "backward_entropy": 0.06186803796074607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.140464973449706,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.008912507351487875,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09121174414952596,
      "backward_entropy": 0.061702175032008776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.881390857696534,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00901256212964654,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09120680689811705,
      "backward_entropy": 0.061764692176472055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09947829246521,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.009112580213695765,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09120185971260071,
      "backward_entropy": 0.061629105156118226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.649282836914063,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.009212684631347657,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09119677444299062,
      "backward_entropy": 0.06178585995327342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.867831230163574,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.009312635008245706,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09119170010089875,
      "backward_entropy": 0.06160235296596182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.393301868438721,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.009412561263889074,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09118657410144806,
      "backward_entropy": 0.06158308603546836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.830285358428956,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.009512727614492178,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.0911808302005132,
      "backward_entropy": 0.06155102415518328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.605244207382203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.009612822532653808,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09117505848407745,
      "backward_entropy": 0.06149626916105098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.103911924362183,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.009712746553122997,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09116951525211334,
      "backward_entropy": 0.06152645945549011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.237933826446532,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.009812763426452875,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09116394023100535,
      "backward_entropy": 0.061465108394622804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.935874748229981,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.00991295576095581,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09115794797738394,
      "backward_entropy": 0.06147348501465537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.975439262390136,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.010013116523623466,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0911518971125285,
      "backward_entropy": 0.061338264291936694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981594467163086,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.01011328436434269,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09114581445852916,
      "backward_entropy": 0.06126110878857699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.701958513259887,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.010213454440236091,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.091139750679334,
      "backward_entropy": 0.06128385446288368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67658486366272,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.010313511639833451,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09113390843073527,
      "backward_entropy": 0.06126682379029014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.068489408493042,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.010413448419421911,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09112806419531505,
      "backward_entropy": 0.0612780440937389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.903603649139404,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.010513469856232405,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09112199246883393,
      "backward_entropy": 0.0612026182087985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.997039842605592,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.010613476391881704,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09111581941445669,
      "backward_entropy": 0.061085654930634926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93640570640564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.010713529586791993,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09110970695813497,
      "backward_entropy": 0.061073036627335986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69303503036499,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.010813583806157111,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09110342860221862,
      "backward_entropy": 0.06102128570730035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.005621862411498,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.01091351369395852,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09109718402226766,
      "backward_entropy": 0.06108565601435575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85276403427124,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.011013510450720788,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09109059274196626,
      "backward_entropy": 0.06104333183982156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.877475833892822,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.011113489139825105,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.09108388225237528,
      "backward_entropy": 0.061014026945287535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.837340068817138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.011213446222245693,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09107702771822611,
      "backward_entropy": 0.060913693363016296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.771810293197632,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.011313374247401952,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09107012152671813,
      "backward_entropy": 0.06070827570828524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.384610080718994,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.011413246020674705,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09106312890847526,
      "backward_entropy": 0.06064192761074413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.689744567871093,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.011512855533510447,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09105650087197623,
      "backward_entropy": 0.06057794961062345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.748766660690308,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.01161239892244339,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09104999899864197,
      "backward_entropy": 0.06060966199094599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.045005798339844,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.011711897049099206,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09104335109392801,
      "backward_entropy": 0.06046527190641924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.926077747344971,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.011811536457389592,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09103634158770244,
      "backward_entropy": 0.06047044342214412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.451900720596313,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.011911229696124792,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.091029026110967,
      "backward_entropy": 0.06040199019692161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.574902725219726,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.012010711617767811,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09102181295553843,
      "backward_entropy": 0.060485079071738515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.743406343460084,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.01211008233949542,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09101449549198151,
      "backward_entropy": 0.060269786552949386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.834654617309571,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.012209426146000624,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09100713630517324,
      "backward_entropy": 0.06017127416350625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.774401664733887,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.012308795005083084,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0909994622071584,
      "backward_entropy": 0.06012564301490784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.858553075790406,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0124081676825881,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09099172055721282,
      "backward_entropy": 0.06023372574286027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.664020776748657,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.012507598474621772,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.0909835934638977,
      "backward_entropy": 0.05996107133952054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.544609022140502,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.012606958951801061,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09097515841325124,
      "backward_entropy": 0.059944294257597494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.745383787155152,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.012706197332590818,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09096685349941254,
      "backward_entropy": 0.06007300994612953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.961653327941894,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.012805434316396714,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09095831612745921,
      "backward_entropy": 0.05996122631159695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.042109107971191,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.012904803734272718,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09094957907994587,
      "backward_entropy": 0.05963296673514625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.584243822097779,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.013004333060234786,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.0909404695034027,
      "backward_entropy": 0.0595178717916662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.474432849884034,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.013103757798671723,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0909315526485443,
      "backward_entropy": 0.05966345180164684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.048622417449952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.01320303613319993,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09092275102933249,
      "backward_entropy": 0.059587704593485044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.656651878356934,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.01330247027799487,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09091363847255707,
      "backward_entropy": 0.059572621909054845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.643116569519043,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.013401836715638637,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09090442558129629,
      "backward_entropy": 0.0593822571364316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.670404529571533,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.01350114932283759,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09089532097180683,
      "backward_entropy": 0.05920645811341026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.559814691543579,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.013600439950823783,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09088599781195324,
      "backward_entropy": 0.0590993957086043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85869927406311,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.013699631299823522,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09087658226490021,
      "backward_entropy": 0.058904731273651124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.255560064315796,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.013798887748271227,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09086677034695942,
      "backward_entropy": 0.05898075916550376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.802524852752686,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.01389789329841733,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09085725943247477,
      "backward_entropy": 0.05893969535827637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7037193775177,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.01399696795269847,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0908475250005722,
      "backward_entropy": 0.058946750380776146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.810352420806884,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.014096083026379347,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09083780944347382,
      "backward_entropy": 0.05864740881052884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469905900955201,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.014195272233337164,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09082775513331096,
      "backward_entropy": 0.058620639280839396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.647886991500854,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.01429433524608612,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09081794917583466,
      "backward_entropy": 0.058623386513103136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.556294679641724,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.014393398351967335,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09080801606178285,
      "backward_entropy": 0.05815164771946994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.466959714889526,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.014492402598261834,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09079784452915192,
      "backward_entropy": 0.05800876834175804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827657890319824,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.014591293968260288,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09078784386316935,
      "backward_entropy": 0.058365633270957264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.371182346343994,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.01469029374420643,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.0907772680123647,
      "backward_entropy": 0.05832345539873297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.375883102416992,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.014789123646914959,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09076676269372304,
      "backward_entropy": 0.057986377586017955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.442118978500366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.01488780127838254,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.090756560365359,
      "backward_entropy": 0.05789991508830676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38970308303833,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.014986400119960308,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09074614942073823,
      "backward_entropy": 0.057608077200976285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.36712327003479,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.01508489353582263,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09073550601800282,
      "backward_entropy": 0.05755747014825994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.623655080795288,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.015183298382908106,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09072504540284476,
      "backward_entropy": 0.05739774595607411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438851404190064,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.015281758829951286,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09071401953697204,
      "backward_entropy": 0.057250403816049754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.124148607254028,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.015380169916898011,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09070261816183725,
      "backward_entropy": 0.05728338306600398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372952079772949,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.01547837108373642,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09069144825140635,
      "backward_entropy": 0.05710831988941539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.303853988647461,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.015576506778597832,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09067981739838918,
      "backward_entropy": 0.057068773291327736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.992428970336914,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.015674559399485588,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09066805640856425,
      "backward_entropy": 0.05687194195660679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.427620220184327,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.01577236335724592,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09065700868765514,
      "backward_entropy": 0.05695931152863935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.123493814468384,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.015870186686515807,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09064565400282541,
      "backward_entropy": 0.056678706407547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.488858556747436,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.01596786342561245,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.09063456455866496,
      "backward_entropy": 0.056443258307196875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.194004249572753,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0160655977204442,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09062302907307943,
      "backward_entropy": 0.05650215690786189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.962751626968384,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.016163223423063755,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09061123629411062,
      "backward_entropy": 0.05623194846239956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.040871191024781,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.016260629892349242,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09060010115305583,
      "backward_entropy": 0.05618212385611101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.548710346221924,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.016357888653874397,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09058911403020223,
      "backward_entropy": 0.05596099712631919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.066069602966309,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.01645530480891466,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09057738184928894,
      "backward_entropy": 0.05533293864943765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.033586406707764,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.016552581638097762,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09056595067183178,
      "backward_entropy": 0.05581683462316339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8757318496704105,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.016649721935391427,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.090554607907931,
      "backward_entropy": 0.055492415211417456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225557804107666,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.01674665417522192,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09054372708002725,
      "backward_entropy": 0.05493601235476407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.923606872558594,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.016843592934310436,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09053253630797069,
      "backward_entropy": 0.05487536733800715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.066600656509399,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.016940373927354813,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09052121539910633,
      "backward_entropy": 0.05470058376138861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.82748064994812,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.01703710537403822,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09050972163677215,
      "backward_entropy": 0.054815012216567996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919772052764893,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.017133641801774502,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09049815833568574,
      "backward_entropy": 0.05457038608464328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.026627683639527,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.017230065166950227,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09048600594202677,
      "backward_entropy": 0.054308449138294565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.832780599594116,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.01732647158205509,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09047357042630513,
      "backward_entropy": 0.05463533997535706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.034288787841797,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.017422746866941452,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09046127100785573,
      "backward_entropy": 0.053959684480320326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.141025257110595,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.017519009485840797,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.0904481550057729,
      "backward_entropy": 0.05382683222944086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.68688850402832,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.01761532500386238,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09043437540531159,
      "backward_entropy": 0.05370644927024841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763833284378052,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.017711424827575685,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09042047361532847,
      "backward_entropy": 0.05314407457004894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.790632963180542,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.017807389609515667,
      "trajectory_length": 13.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.09040633042653401,
      "backward_entropy": 0.05360614115541631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.509608030319214,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.017903250642120838,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09039212266604106,
      "backward_entropy": 0.05320540883324363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.585318183898925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0179988581687212,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09037849803765614,
      "backward_entropy": 0.053138404542749575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.557554912567139,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.018094271421432495,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09036508997281392,
      "backward_entropy": 0.05260850841348821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.545181798934936,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.018189492635428905,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0903516173362732,
      "backward_entropy": 0.052356884154406466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.75548791885376,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0182845339179039,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09033829271793364,
      "backward_entropy": 0.052477345141497524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.696422910690307,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.018379556387662886,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09032442470391591,
      "backward_entropy": 0.052218836545944225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6216846942901615,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018474524281919,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0903102199236552,
      "backward_entropy": 0.05209695588458668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.224405717849732,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.018569407053291798,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09029547770818075,
      "backward_entropy": 0.0518805135380138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.543491554260254,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.018663980625569822,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09028141299883524,
      "backward_entropy": 0.05171173810958862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.558923673629761,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.018758461996912956,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09026732842127483,
      "backward_entropy": 0.05127238956364718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.431707048416138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.018852861784398555,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09025249083836873,
      "backward_entropy": 0.05116199580105869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.224359512329102,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.018947132304310797,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09023802379767101,
      "backward_entropy": 0.05076203454624523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.555238533020019,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.019041166454553605,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09022402067979177,
      "backward_entropy": 0.05091071562333541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.756914710998535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.019135176204144955,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.090209432442983,
      "backward_entropy": 0.049829462983391505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.364970779418945,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.019229303672909738,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09019341468811035,
      "backward_entropy": 0.04972145069729199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.284822082519531,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.019323306903243066,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09017702937126161,
      "backward_entropy": 0.049941466613249344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.131401586532593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.019417136721313,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09016044437885284,
      "backward_entropy": 0.050262917713685476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.540062952041626,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.019510712847113608,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09014422694842021,
      "backward_entropy": 0.04956334937702526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.024077224731445,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.01960432343184948,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09012688000996907,
      "backward_entropy": 0.04910062903707678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.205430936813355,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.019697650521993636,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09010974168777466,
      "backward_entropy": 0.04869455017826774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.07049298286438,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.01979082655161619,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0900919775168101,
      "backward_entropy": 0.04836176823485981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.22787389755249,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.019883798062801362,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.09007447560628254,
      "backward_entropy": 0.04898902936415239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.320985269546509,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.01997669357806444,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09005669057369232,
      "backward_entropy": 0.048037861152128734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.040159368515015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.020069584250450134,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0900373766819636,
      "backward_entropy": 0.048372193900021634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.844427680969238,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.020162299647927283,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09001752932866415,
      "backward_entropy": 0.04771967123855244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.747431755065918,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.020254739746451377,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08999817371368408,
      "backward_entropy": 0.04674301987344569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.686299467086792,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.020346861518919467,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0899789333343506,
      "backward_entropy": 0.04689922874624079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.928085851669311,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02043864205479622,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08996069530646006,
      "backward_entropy": 0.047111124883998524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.970499420166016,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.0205302856862545,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08994202713171642,
      "backward_entropy": 0.045939293232831094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.493963384628296,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02062183804810047,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08992263575394947,
      "backward_entropy": 0.046671205759048456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7672261714935305,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02071299869567156,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0899045060078303,
      "backward_entropy": 0.04621835676106539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.676523876190186,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.020803994312882424,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08988555471102397,
      "backward_entropy": 0.045591491460800174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.481320858001709,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.020894807204604147,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08986589908599854,
      "backward_entropy": 0.0455345714634115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.754469680786133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.020985308103263378,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08984596232573192,
      "backward_entropy": 0.04536105231805281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.539853239059449,
      "terminal_state_reached": 1.0,
      "terminal_reward": 16.0,
      "log_Z": 0.021075716800987722,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.08982481062412262,
      "backward_entropy": 0.04530226750807329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.486785268783569,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02116591427475214,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08980331420898437,
      "backward_entropy": 0.04468381865458055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.566564512252808,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02125589791685343,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0897817611694336,
      "backward_entropy": 0.044334498860619284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.39900393486023,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.021345746889710426,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08976008892059327,
      "backward_entropy": 0.04392006695270538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.28367919921875,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.021435347944498064,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08973871370156605,
      "backward_entropy": 0.044220692461187185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.465272665023804,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02152464259415865,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08971735437711079,
      "backward_entropy": 0.04340400912544944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.373939561843872,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02161381710320711,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08969552318255107,
      "backward_entropy": 0.04315548024394296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.390916872024536,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.02170281335711479,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.08967360258102418,
      "backward_entropy": 0.04293696636503393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.375008392333984,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.021791665256023406,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08965128163496652,
      "backward_entropy": 0.04301531531594017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.360929775238037,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02188038397580385,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08962775071461995,
      "backward_entropy": 0.04255072474479675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.104615116119385,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02196898143738508,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08960334161917369,
      "backward_entropy": 0.04195711368864233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.859219551086426,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.022057287208735944,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08957962791124979,
      "backward_entropy": 0.04083937812935222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.923150157928466,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.022145164757966997,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08955670396486917,
      "backward_entropy": 0.040764883431521334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.064199829101563,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02223271317780018,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08953425685564677,
      "backward_entropy": 0.04109179025346583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.823137092590332,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02232005037367344,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0895111491282781,
      "backward_entropy": 0.04073504941029982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.800851154327392,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.022407024167478085,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08948793411254882,
      "backward_entropy": 0.04080577790737152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.913381862640381,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02249365355819464,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08946428497632344,
      "backward_entropy": 0.0400946478952061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.835997676849365,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.022580089047551155,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.08943982521692911,
      "backward_entropy": 0.04003040329976515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.898566675186157,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.022666279040277005,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.08941429058710734,
      "backward_entropy": 0.03839666003530676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.530353832244873,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.022752315178513526,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08938780625661213,
      "backward_entropy": 0.03817146583036943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.550963640213013,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.022837932221591473,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.0893616000811259,
      "backward_entropy": 0.038855277950113475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.486877465248108,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.022923183254897596,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.0893364171187083,
      "backward_entropy": 0.038555282896215265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.138610744476319,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.023008087649941444,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08931149542331696,
      "backward_entropy": 0.036930040337822656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5377908706665036,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.02309242505580187,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.08928759495417277,
      "backward_entropy": 0.03769588091156699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.463526940345764,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02317656669765711,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08926257093747457,
      "backward_entropy": 0.03706115484237671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.201441287994385,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.023260439187288283,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.08923718929290772,
      "backward_entropy": 0.036968847025524484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.212425231933594,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.023343886807560922,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08921192288398742,
      "backward_entropy": 0.036289550499482584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.333187007904053,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.023426950536668302,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08918624718983967,
      "backward_entropy": 0.036635709621689536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.026923561096192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.023509777151048183,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08916031320889792,
      "backward_entropy": 0.03584756011312658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.934063267707825,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.023592172749340536,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0891342838605245,
      "backward_entropy": 0.0358693548224189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9732136011123655,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.02367409486323595,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.0891092171271642,
      "backward_entropy": 0.03606121242046356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.029165148735046,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.023755631968379022,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08908440868059794,
      "backward_entropy": 0.03504258204590191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.820871090888977,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.023836897127330302,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.08905910750230153,
      "backward_entropy": 0.03499929525635459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.910974073410034,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.023917724192142487,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08903397719065348,
      "backward_entropy": 0.03430997512557289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.759276533126831,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.023998259752988815,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08900845150152842,
      "backward_entropy": 0.03452742262320085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756193995475769,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02407841756939888,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08898320496082307,
      "backward_entropy": 0.033627541227774185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.70014169216156,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.024158228747546674,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08895713984966278,
      "backward_entropy": 0.03333356570113789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.629176545143127,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.024237680062651635,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08893106877803802,
      "backward_entropy": 0.03326285020871596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5225060939788815,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.024316751584410667,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08890447318553925,
      "backward_entropy": 0.03215338425202803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.499661064147949,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.024395391531288623,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08887752691904703,
      "backward_entropy": 0.03262373479929837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.302627730369568,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.024473640881478787,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08885013262430827,
      "backward_entropy": 0.032054108110341165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.415837240219116,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.024551381543278693,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08882282972335817,
      "backward_entropy": 0.03120195879177614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.27169942855835,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02462874222546816,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0887951374053955,
      "backward_entropy": 0.030882158604535193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.045765972137451,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.024705668725073338,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08876778185367584,
      "backward_entropy": 0.03119887465780431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.060081815719604,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.024781974777579308,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.088741934299469,
      "backward_entropy": 0.030949709903110155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1952447414398195,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02485775351524353,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08871680597464245,
      "backward_entropy": 0.02975792017850009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.937470865249634,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.024933172203600407,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08869126737117768,
      "backward_entropy": 0.03073800531300631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.086744403839111,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.025008067674934863,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0886661559343338,
      "backward_entropy": 0.02939636300910603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.738170099258423,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.025082601979374886,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0886397103468577,
      "backward_entropy": 0.029338641735640436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.023593282699585,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.025156531482934952,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08861479560534159,
      "backward_entropy": 0.02870302986014973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8909384965896607,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.025230155698955058,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.08858869075775147,
      "backward_entropy": 0.028671996430917217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7283902406692504,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.025303384661674498,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0885617862145106,
      "backward_entropy": 0.028045391494577583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8721832752227785,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.025376125425100326,
      "trajectory_length": 13.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.08853546877702077,
      "backward_entropy": 0.028130462765693663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.716539764404297,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02544854823499918,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08850766917069754,
      "backward_entropy": 0.027468259632587432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.708659267425537,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.025520548969507218,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08847927053769429,
      "backward_entropy": 0.026656776666641235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6119169354438783,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.025592180714011193,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08844973047574362,
      "backward_entropy": 0.026401159167289735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.466460394859314,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.025663341395556927,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.08842008610566457,
      "backward_entropy": 0.025985558466477827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.37419912815094,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.025734016299247743,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0883905013402303,
      "backward_entropy": 0.026574885709719227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3269144535064696,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.025804100558161736,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.08836089173952738,
      "backward_entropy": 0.025565436482429503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4337591886520387,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02587360832840204,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08833153247833252,
      "backward_entropy": 0.026203733411702245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3695404171943664,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.025942757539451123,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08830106556415558,
      "backward_entropy": 0.024611927975307812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2096837997436523,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.026011467911303043,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08827122151851653,
      "backward_entropy": 0.024764961952512914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.052405667304993,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.026079661585390566,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0882411003112793,
      "backward_entropy": 0.024042937159538272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0583537220954895,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.026147218234837056,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08821110626061758,
      "backward_entropy": 0.02540382864800366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0906596064567564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.026214200630784036,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08818096617857615,
      "backward_entropy": 0.025025885078040034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.076869344711304,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026280697993934156,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08814994891484579,
      "backward_entropy": 0.023797895827076653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0972769379615785,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02634676806628704,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08811875085035961,
      "backward_entropy": 0.02275090380148454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.829031538963318,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02641247268766165,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08808573385079702,
      "backward_entropy": 0.022494038397615608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9727436304092407,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.026477564498782157,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08805278042952219,
      "backward_entropy": 0.023123128441247073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.890283262729645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.026542268879711627,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08801834185918171,
      "backward_entropy": 0.02356275347146121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.677684414386749,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026606496423482895,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08798237045605976,
      "backward_entropy": 0.02304245707663623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8500648617744444,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02667010687291622,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.0879470725854238,
      "backward_entropy": 0.02262154682116075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5969221353530885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.026733287051320075,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08791041672229767,
      "backward_entropy": 0.02252704988826405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5726346373558044,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02679582554847002,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08787470757961274,
      "backward_entropy": 0.021791764551943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4646103143692017,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02685783039778471,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08783813814322154,
      "backward_entropy": 0.02116694463924928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3877009630203245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02691916227340698,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08780258297920226,
      "backward_entropy": 0.02095588581128554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3912863612174986,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.026979809068143366,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08776762386163076,
      "backward_entropy": 0.020637507194822484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.59055917263031,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027039844542741776,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08773277898629506,
      "backward_entropy": 0.01973643980242989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.509002375602722,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027099526859819888,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08769572675228118,
      "backward_entropy": 0.019849777086214583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4019412636756896,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.02715882137417793,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.08765711188316345,
      "backward_entropy": 0.019651621986519204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.219071626663208,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027217662893235683,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08761709729830425,
      "backward_entropy": 0.01934789229523052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.217373287677765,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02727589812129736,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08757702509562175,
      "backward_entropy": 0.018977983973243018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2306665658950804,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.027333539724349976,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08753697872161866,
      "backward_entropy": 0.018878135626966303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.989049255847931,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027390622161328794,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0874966651201248,
      "backward_entropy": 0.01813203570517627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.182908129692078,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02744689267128706,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08745718697706859,
      "backward_entropy": 0.017573278465054253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0017628908157348,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027502762340009212,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08741623461246492,
      "backward_entropy": 0.018722445043650542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0303070545196533,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027558038756251336,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08737537860870362,
      "backward_entropy": 0.018345793268897313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0749870777130126,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02761281132698059,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08733498752117157,
      "backward_entropy": 0.017553631690415468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9883224010467528,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.027667148783802987,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.08729301790396372,
      "backward_entropy": 0.018103719705885105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.821746826171875,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027720997110009193,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0872494786977768,
      "backward_entropy": 0.017422758449207654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.774392956495285,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02777418736368418,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08720604280630748,
      "backward_entropy": 0.016225416687401857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.871674782037735,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027826683595776558,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08716273903846741,
      "backward_entropy": 0.016475618495182556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6324330866336823,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027878710813820363,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0871178646882375,
      "backward_entropy": 0.017128759080713443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.615423333644867,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027930028550326825,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08707336187362671,
      "backward_entropy": 0.016392834010449324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5395391881465912,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02798062264919281,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08702887097994487,
      "backward_entropy": 0.015937773476947435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.628882348537445,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.02803044281899929,
      "trajectory_length": 13.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.08698528011639914,
      "backward_entropy": 0.016744139858267525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.665920615196228,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028079689480364323,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08694152732690176,
      "backward_entropy": 0.01631292992017486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.501054733991623,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028128436021506786,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08689685265223186,
      "backward_entropy": 0.016852459514682942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4871281921863555,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02817652337253094,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0868518630663554,
      "backward_entropy": 0.01573940928686749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3929687678813933,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028224005922675134,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08680754800637563,
      "backward_entropy": 0.014771552112969485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2773993492126465,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028270815126597883,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08676308393478394,
      "backward_entropy": 0.014986291392283005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.334788715839386,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02831683922559023,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08671960930029551,
      "backward_entropy": 0.014297279105945065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3057184040546417,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028362243063747884,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08667642374833424,
      "backward_entropy": 0.014214204793626612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2134758949279785,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028407046943902968,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08663271963596345,
      "backward_entropy": 0.014270350946621463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3625966727733612,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028451070189476013,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08659052550792694,
      "backward_entropy": 0.01415882957252589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.153509908914566,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028494690917432307,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08654634654521941,
      "backward_entropy": 0.013750605556097898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2131348371505737,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02853762675076723,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0865019291639328,
      "backward_entropy": 0.013421180505644193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1351350665092468,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028580001927912234,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08645784755547842,
      "backward_entropy": 0.013532764735546978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0936811804771422,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028621778823435307,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0864130397637685,
      "backward_entropy": 0.01377239152789116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9756331831216812,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0286629069596529,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.086368594566981,
      "backward_entropy": 0.01382353346456181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0650149822235107,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028703234903514386,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08632563352584838,
      "backward_entropy": 0.013448501513762905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0973672330379487,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.028743036091327667,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08628225723902384,
      "backward_entropy": 0.013356724720109594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0560726314783095,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02878233455121517,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08623840908209482,
      "backward_entropy": 0.012712892415848645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9700028508901596,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028821208886802195,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08619368175665537,
      "backward_entropy": 0.012691955132917923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9657189309597015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028859498165547847,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0861481080452601,
      "backward_entropy": 0.013023649020628497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0179198697209357,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028897238709032536,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08610161244869233,
      "backward_entropy": 0.012045489658008921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9901349827647209,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02893450502306223,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08605422178904215,
      "backward_entropy": 0.011828174035657536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9405156552791596,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02897127587348223,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0860060602426529,
      "backward_entropy": 0.011963384666226127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8958521321415901,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029007553309202194,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08595714271068572,
      "backward_entropy": 0.012104237282818014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8128895580768585,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.0290433457121253,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08590679168701171,
      "backward_entropy": 0.011761453612284227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8842053800821305,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0290785176679492,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08585657080014548,
      "backward_entropy": 0.01192660717801614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7516937106847763,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02911327499896288,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0858050286769867,
      "backward_entropy": 0.011910549822178753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7724603563547134,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029147397354245187,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08575400511423746,
      "backward_entropy": 0.010992848805405877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7323645994067192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.029180964455008507,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08570254445075988,
      "backward_entropy": 0.011202359605919232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7111530363559723,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02921394295990467,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0856518268585205,
      "backward_entropy": 0.011223843490535564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6380261480808258,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.029246375896036625,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08560056785742441,
      "backward_entropy": 0.011263301088051361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6946861356496811,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029277992621064185,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08555033306280772,
      "backward_entropy": 0.01059945198622617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6569304674863815,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029309133440256117,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08549909691015879,
      "backward_entropy": 0.010974111678925428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6640934437513352,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02933969423174858,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08544737646977105,
      "backward_entropy": 0.01001228392124176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6425327256321907,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02936978917568922,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08539454340934753,
      "backward_entropy": 0.010490537570281462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5808904692530632,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029399374127388002,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08534157772858937,
      "backward_entropy": 0.01033056838945909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6078541576862335,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029428355768322943,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08528882165749868,
      "backward_entropy": 0.009568282081322236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6058009192347527,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029456890560686587,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08523533244927724,
      "backward_entropy": 0.009954935244538568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.564815154671669,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029484970867633818,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08518092234929403,
      "backward_entropy": 0.009156228195537219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.515651524066925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.029512570425868034,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08512585063775382,
      "backward_entropy": 0.010079754279418426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5083898589015007,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.029539662785828112,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.08507074614365896,
      "backward_entropy": 0.009696663645180788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.511145569384098,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02956623211503029,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08501579711834589,
      "backward_entropy": 0.009353433955799451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45865861475467684,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029592332988977434,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0849598283569018,
      "backward_entropy": 0.009925947202877565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5152590222656727,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029617920704185962,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08490398625532786,
      "backward_entropy": 0.010018557784232227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.417473603785038,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.02964314687997103,
      "trajectory_length": 13.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.08484715074300767,
      "backward_entropy": 0.009785804017023607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4269899070262909,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029667813330888748,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08479035645723343,
      "backward_entropy": 0.009069991924545983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42059270218014716,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02969202194362879,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08473300337791442,
      "backward_entropy": 0.008944260870868508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40358215272426606,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02971570398658514,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08467564930518469,
      "backward_entropy": 0.009698817811229013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4183317519724369,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02973888851702213,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08461829274892807,
      "backward_entropy": 0.009476383030414582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38498678654432295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029761699587106706,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0845601459344228,
      "backward_entropy": 0.009007436443458906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3327942490577698,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02978407498449087,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08450180739164352,
      "backward_entropy": 0.0088386822830547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3799859009683132,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02980594988912344,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08444423228502272,
      "backward_entropy": 0.009339015795425936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30726567655801773,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029827455058693886,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0843856597940127,
      "backward_entropy": 0.008411034873940727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.351553500816226,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029848436266183852,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0843276376525561,
      "backward_entropy": 0.00877616615457968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27513321228325366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029868972674012183,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0842692216237386,
      "backward_entropy": 0.008429346504536544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3202683158218861,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029888934828341006,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08421176572640737,
      "backward_entropy": 0.008803088217973709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3464563854038715,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.029908511601388455,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08415355334679285,
      "backward_entropy": 0.008532117713581432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2615343354642391,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029927817173302174,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08409444938103358,
      "backward_entropy": 0.007938537204807453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27159893698990345,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02994662560522556,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08403561015923819,
      "backward_entropy": 0.007760581103238193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23963900282979012,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.029964978434145452,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0839767615000407,
      "backward_entropy": 0.008114661411805587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2657077617943287,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.029982860758900644,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08391859531402587,
      "backward_entropy": 0.008083053678274155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24914635717868805,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.03000045381486416,
      "trajectory_length": 13.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.08385963042577108,
      "backward_entropy": 0.008878706260160966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25121439844369886,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03001769483089447,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08380020459493001,
      "backward_entropy": 0.008065293356776238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2489645317196846,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030034642294049264,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0837404156724612,
      "backward_entropy": 0.007619196718389338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22677868343889712,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.03005125317722559,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08368020554383596,
      "backward_entropy": 0.007832379910078915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2114408414810896,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030067574977874757,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08362014442682267,
      "backward_entropy": 0.007825858416882428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2648743946105242,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030083498172461986,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08356046577294667,
      "backward_entropy": 0.007774730094454505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22128464989364147,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030099258944392204,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08349914799133937,
      "backward_entropy": 0.007376776737245646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19894541203975677,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.030114706419408322,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08343703746795655,
      "backward_entropy": 0.007435670630498367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.203008284419775,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.0301298625767231,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.08337486137946445,
      "backward_entropy": 0.0073660016737201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1920961294323206,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030144707672297953,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08331269770860672,
      "backward_entropy": 0.007480902326377955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21392765417695045,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03015922214835882,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08325010190407435,
      "backward_entropy": 0.007585650377652862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20018669925630092,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030173575319349766,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08318673173586527,
      "backward_entropy": 0.007262077521194112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16130320969969034,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030187722109258176,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08312249034643174,
      "backward_entropy": 0.007307379591194066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1593851074576378,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03020148053765297,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08305885245402654,
      "backward_entropy": 0.007476706023920665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17918229904025793,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030214861780405045,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08299551606178283,
      "backward_entropy": 0.007431411235169931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16829912215471268,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030227973684668542,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08293174107869465,
      "backward_entropy": 0.007297552343119275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15930486507713795,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030240814201533794,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08286762734254202,
      "backward_entropy": 0.007197380133650519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1600191669538617,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03025341350585222,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08280332932869593,
      "backward_entropy": 0.007205432111566717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13877353835850953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.0302657512947917,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08273903181155522,
      "backward_entropy": 0.00737016810612245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12463234290480614,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030277755670249464,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08267503331104914,
      "backward_entropy": 0.007262311232360927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13205421715974808,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030289349146187305,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08261204411586126,
      "backward_entropy": 0.006888893415982073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12229025419801473,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030300699546933173,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08254900226990383,
      "backward_entropy": 0.006786387481472709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1250101553276181,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030311711505055426,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08248612483342488,
      "backward_entropy": 0.0069261265410618346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1054609002545476,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03032246232032776,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08242282966772715,
      "backward_entropy": 0.006974385611035606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11342076184228063,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.030332931876182558,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.08235995968182883,
      "backward_entropy": 0.006486797298897397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10894983913749456,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030343141593039035,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08229709366957347,
      "backward_entropy": 0.006362810053608635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10467917853966355,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.03035310488194227,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08223464737335841,
      "backward_entropy": 0.007095931131731381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10457197818905115,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.03036277275532484,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08217252542575201,
      "backward_entropy": 0.00702240111475641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09829998947679996,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.030372182838618755,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08211096574862799,
      "backward_entropy": 0.006460030139847235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10401876177638769,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030381348356604575,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08204989631970723,
      "backward_entropy": 0.006802679395133798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10257955510169267,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030390284582972528,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08198900173107784,
      "backward_entropy": 0.006374302912842143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07417959701269865,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.03039903249591589,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08192769785722095,
      "backward_entropy": 0.006567531079053879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07468870133161545,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.03040753211826086,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08186700791120528,
      "backward_entropy": 0.006905364820902998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08784381477162242,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.030415779910981655,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.08180665671825409,
      "backward_entropy": 0.006231203201142224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07264105789363384,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.03042386155575514,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08174631893634796,
      "backward_entropy": 0.006604161215099422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07633548732846976,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03043163549154997,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08168670038382211,
      "backward_entropy": 0.006375093825838783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07334966100752353,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030439153872430326,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08162753780682881,
      "backward_entropy": 0.006627016785469922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06105501027777791,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03044652510434389,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0815688744187355,
      "backward_entropy": 0.006541202860799703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06397931911051273,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03045363202691078,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08151041766007741,
      "backward_entropy": 0.006219573014161803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06479570074006916,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030460547283291818,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08145232399304708,
      "backward_entropy": 0.0063165957616134125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06783407228067517,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030467223562300205,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08139454921086628,
      "backward_entropy": 0.006060665439475667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06587586998939514,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.03047377858310938,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08133693337440491,
      "backward_entropy": 0.006528874012556943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07023818558081985,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030480194464325906,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08127940793832143,
      "backward_entropy": 0.0061661403626203535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06181218503043055,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030486525036394596,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0812216654419899,
      "backward_entropy": 0.006532187726009974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05762146608904004,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030492698773741722,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08116390208403268,
      "backward_entropy": 0.006192605976353991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050403119157999755,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030498719587922097,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08110643029212952,
      "backward_entropy": 0.006446522067893636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053709694743156434,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.03050451371818781,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08104948550462723,
      "backward_entropy": 0.006159674376249313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045275417435914275,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.030510159209370613,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08099253873030346,
      "backward_entropy": 0.006636730615388264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06156172435730696,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03051558118313551,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08093589196602503,
      "backward_entropy": 0.006462172249501403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046342913853004576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.030520955845713616,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08087914486726125,
      "backward_entropy": 0.006378665024583991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056572941271588205,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030526192486286165,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08082262674967448,
      "backward_entropy": 0.006292904777960344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0508969790302217,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03053136095404625,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08076608379681906,
      "backward_entropy": 0.006513214720921083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049499751068651676,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03053649216890335,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0807095875342687,
      "backward_entropy": 0.006360182030634447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028641184465959667,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030541601404547692,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0806531066695849,
      "backward_entropy": 0.006224068423563784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041702772863209246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030546364933252336,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08059776276350021,
      "backward_entropy": 0.006092840737917207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038803830510005355,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030551020056009293,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08054273575544357,
      "backward_entropy": 0.006015456941994754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0358784562908113,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030555537156760692,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08048833260933559,
      "backward_entropy": 0.0060727158392017535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0355171584058553,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030559917725622655,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.080434421201547,
      "backward_entropy": 0.006160278889265928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04177813273854554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03056420274078846,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0803808922568957,
      "backward_entropy": 0.006289193406701088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0380269811488688,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030568424239754678,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08032743185758591,
      "backward_entropy": 0.00578269667246125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0328841183334589,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.030572581477463244,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08027393370866777,
      "backward_entropy": 0.005791018395261331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03058958062902093,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03057662136852741,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0802208791176478,
      "backward_entropy": 0.006014380333098498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03236209400929511,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030580507591366768,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08016839524110157,
      "backward_entropy": 0.005724801190874794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029296961799263953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03058430477976799,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08011625508467356,
      "backward_entropy": 0.0058361986482685264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027256880328059195,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03058801032602787,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08006438314914703,
      "backward_entropy": 0.006297698007388548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02713424381799996,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03059154227375984,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08001313010851543,
      "backward_entropy": 0.006249394572593949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028284192131832243,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03059496935456991,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07996235787868498,
      "backward_entropy": 0.005716323446143757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02921557272784412,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03059832230210304,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07991204112768172,
      "backward_entropy": 0.005951989475976338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031320718280039725,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030601603165268897,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07986211131016414,
      "backward_entropy": 0.005833972888914021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025452186749316753,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.030604816414415835,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.07981227984031042,
      "backward_entropy": 0.006310598755424673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022717027994804084,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030607966519892216,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07976291626691819,
      "backward_entropy": 0.005604150688106363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02390912496484816,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03061099089682102,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0797139436006546,
      "backward_entropy": 0.00601440854370594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024090962205082177,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030613958649337292,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07966535190741222,
      "backward_entropy": 0.0061910517513751985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02271565676201135,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.030616875737905502,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.07961711486180624,
      "backward_entropy": 0.006154772503809495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020914692617952823,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.03061970937997103,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0795692816376686,
      "backward_entropy": 0.006146885251457041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01700188578106463,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0306224524974823,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07952189097801844,
      "backward_entropy": 0.0056149949742989105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01945512241218239,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030625087581574915,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07947525183359781,
      "backward_entropy": 0.005693773654374209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018333328876178712,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.030627672933042048,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.07942931801080703,
      "backward_entropy": 0.005517952923070301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018883271957747638,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030630206502974034,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07938395490248998,
      "backward_entropy": 0.0059306744824756275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017788504622876643,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.030632679536938667,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07933892756700515,
      "backward_entropy": 0.005878971144557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019971184385940432,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030635114759206772,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07929444660743078,
      "backward_entropy": 0.006173687495968558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017857747862581163,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030637539364397524,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07925013701121013,
      "backward_entropy": 0.006068909202109684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016809015139006078,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030639905110001565,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0792062188188235,
      "backward_entropy": 0.006138723987069997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012966529210098087,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03064218983054161,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07916272977987926,
      "backward_entropy": 0.005746125734665177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014672306005377323,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.030644356086850167,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07911975433429082,
      "backward_entropy": 0.005601204186677933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011129133112262934,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03064646553248167,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07907717923323312,
      "backward_entropy": 0.005751319940794598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014121154742315411,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030648479983210564,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07903547386328379,
      "backward_entropy": 0.005684346536343749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01417861389927566,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.030650429986417295,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07899411668380102,
      "backward_entropy": 0.005643444068052552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014264499850105495,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030652317963540555,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07895319710175197,
      "backward_entropy": 0.00565494370054115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013710667355917394,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.0306541895493865,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07891257703304291,
      "backward_entropy": 0.0053866390477527275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013172800093889237,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030656045489013194,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.078872383137544,
      "backward_entropy": 0.005675438994711096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013042642932850868,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.03065787795931101,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.07883256276448568,
      "backward_entropy": 0.0057769120416857975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010134468786418438,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030659680627286433,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07879328330357868,
      "backward_entropy": 0.005460263111374595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013895679294364527,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030661392770707608,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07875456114610035,
      "backward_entropy": 0.005572247403589163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009175601974129676,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.030663094855844973,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07871617178122202,
      "backward_entropy": 0.006002963368188252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009943575120996685,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.03066470455378294,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07867839833100637,
      "backward_entropy": 0.00592483478513631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0072932066163048145,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03066625613719225,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07864100386699042,
      "backward_entropy": 0.005483429167758335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01018545699189417,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030667706206440926,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07860439668099087,
      "backward_entropy": 0.005952628871256655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011235625314293429,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030669122561812402,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07856826335191727,
      "backward_entropy": 0.005388265170834281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008332382945809513,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030670556239783764,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07853248318036397,
      "backward_entropy": 0.005482153425162489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008404460363090038,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030671949684619903,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07849726925293606,
      "backward_entropy": 0.0058861958709630095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008150500297779218,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030673268623650073,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0784624695777893,
      "backward_entropy": 0.005682880025018345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00891149322851561,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.03067456465214491,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07842834641536077,
      "backward_entropy": 0.005469322848049077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009534662461373956,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.03067585974931717,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0783945585290591,
      "backward_entropy": 0.0057466175745834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008641096984501929,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03067716080695391,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07836115956306458,
      "backward_entropy": 0.006031901490959254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006986785167828202,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030678448267281055,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07832816590865453,
      "backward_entropy": 0.005592183497819033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008187490611453541,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030679704435169698,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0782956307133039,
      "backward_entropy": 0.005716221745718611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006248871868592687,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030680937878787517,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07826342185338338,
      "backward_entropy": 0.005767082084308971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007233547046780586,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030682113580405714,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07823169380426406,
      "backward_entropy": 0.005712538957595825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007539427277515642,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030683286115527154,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0782003844777743,
      "backward_entropy": 0.005825735933401368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006704484039801173,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030684461817145348,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07816951324542364,
      "backward_entropy": 0.005295709757642313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006412044566241093,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.03068560902029276,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07813902298609417,
      "backward_entropy": 0.005481318926269357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00600382320699282,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030686745047569276,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07810897628466289,
      "backward_entropy": 0.0059060745618560095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006149396984255873,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030687854439020158,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07807940095663071,
      "backward_entropy": 0.005115157704461705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0066368631145451214,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030688957683742045,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0780503422021866,
      "backward_entropy": 0.005541927943175489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00484141735942103,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03069006558507681,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07802162418762842,
      "backward_entropy": 0.005421523546630685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005998040834674612,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03069112151861191,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07799332588911055,
      "backward_entropy": 0.0058268313380804935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005479455122258514,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.03069216888397932,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07796542296806971,
      "backward_entropy": 0.0055871099572290086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005432041987660341,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03069319184869528,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07793784737586976,
      "backward_entropy": 0.005393527685241266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005017274590500165,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030694212578237057,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07791063785552979,
      "backward_entropy": 0.005268952081149275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034018167949398047,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030695226788520814,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07788389176130295,
      "backward_entropy": 0.005498349700461735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003805528106749989,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03069618809968233,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07785776257514952,
      "backward_entropy": 0.005241492018103599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004271075397264212,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030697121657431124,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0778321181734403,
      "backward_entropy": 0.005561838265169751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00403909953602124,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030698028579354285,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07780682394901912,
      "backward_entropy": 0.005342769893732937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003512243698060047,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030698932707309723,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0777819409966469,
      "backward_entropy": 0.0051868781786073345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003530272768693976,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030699811689555646,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07775750309228897,
      "backward_entropy": 0.005419360744682225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031414829136338085,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030700663477182387,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07773343473672867,
      "backward_entropy": 0.005395374006845734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003337914039730094,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030701474845409395,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07770971457163492,
      "backward_entropy": 0.005301052298058163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038689517648890616,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030702264793217183,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07768648763497671,
      "backward_entropy": 0.005732710693370212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003349388016795274,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030703062750399114,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07766358653704326,
      "backward_entropy": 0.0056697535582564094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034469789316062815,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030703854002058505,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07764105200767518,
      "backward_entropy": 0.0056329960850152105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003254245352582075,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03070465363562107,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07761894067128498,
      "backward_entropy": 0.005521629242734476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002561806089943275,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030705435015261174,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07759708762168885,
      "backward_entropy": 0.005369221757758748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027419009391451256,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.03070618715137243,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07757567316293716,
      "backward_entropy": 0.005530785803090443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027073856297647582,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030706907249987127,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07755468388398488,
      "backward_entropy": 0.005592186545783823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002704635645932285,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030707618594169615,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07753402690092723,
      "backward_entropy": 0.005311311307278546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024860350393282717,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030708332546055317,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07751367141803105,
      "backward_entropy": 0.005152395198290998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002745580198825337,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030709039606153964,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07749364376068116,
      "backward_entropy": 0.005373394184491851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002679311521933414,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030709750950336456,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.077473879357179,
      "backward_entropy": 0.005443259768865326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022273988332017327,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030710449814796446,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07745436082283655,
      "backward_entropy": 0.005797923694957386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024734919687034564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03071112893521786,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07743524710337321,
      "backward_entropy": 0.005472388660365885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001824697182746604,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030711784958839417,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.07741631865501404,
      "backward_entropy": 0.006050989472053267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002435902284923941,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030712409317493437,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07739777167638143,
      "backward_entropy": 0.005681578645651992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017410508706234395,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03071302119642496,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.077379513780276,
      "backward_entropy": 0.005691629817539996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002090132318699034,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030713610351085663,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07736158072948456,
      "backward_entropy": 0.0051844229413704436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024667283665621652,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03071419894695282,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07734400083621343,
      "backward_entropy": 0.005149965530092065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001763973834022181,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.03071479145437479,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0773265615105629,
      "backward_entropy": 0.006073333763263441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019801579677732662,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03071536831557751,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07730942219495773,
      "backward_entropy": 0.005368821864778345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018632072959007928,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030715936608612538,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07729249993960063,
      "backward_entropy": 0.005187446624040604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015525912309385602,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030716485902667047,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07727579722801844,
      "backward_entropy": 0.005627706274390221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012667360868363175,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030717015080153943,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07725944519042968,
      "backward_entropy": 0.005426572568037293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014990526309702546,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030717528611421584,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07724356601635615,
      "backward_entropy": 0.0057996844703500925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015798461427039001,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03071803357452154,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07722800572713216,
      "backward_entropy": 0.0053107155994935465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012562412146507995,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030718531087040903,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07721269975105922,
      "backward_entropy": 0.005313633991913362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014050326550204772,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.030719017423689366,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07719774097204209,
      "backward_entropy": 0.005777052654461428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014120138130238047,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030719495937228204,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07718305836121242,
      "backward_entropy": 0.005463105169209568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001080061174070579,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.03071997072547674,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07716859926780065,
      "backward_entropy": 0.0061265163123607625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011832041203888367,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.03072042241692543,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.07715440839529038,
      "backward_entropy": 0.005494363775307482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011981861156527885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030720871686935425,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07714049567778905,
      "backward_entropy": 0.005550183017145502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010666236219549318,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030721318908035755,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07712687402963639,
      "backward_entropy": 0.005563420531424609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000960191062404192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03072175905108452,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07711349974075953,
      "backward_entropy": 0.005968105623667891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009442159998798161,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030722185410559176,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07710038075844447,
      "backward_entropy": 0.0054679428989237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010311457013813196,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03072259947657585,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07708755979935329,
      "backward_entropy": 0.00556712577288801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009440864512725966,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030723016522824765,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07707498123248417,
      "backward_entropy": 0.005523033406246792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007866024583563558,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03072341773658991,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07706265548864999,
      "backward_entropy": 0.005360290306535634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007281435007826075,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03072380181401968,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07705059150854747,
      "backward_entropy": 0.005673841556364839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008941310938098468,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030724178440868853,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07703885386387507,
      "backward_entropy": 0.0053305692632089965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008134511142998235,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030724545754492284,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07702729851007463,
      "backward_entropy": 0.005083613233132796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007237639691993536,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030724918469786644,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07701600740353266,
      "backward_entropy": 0.00574726861986247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007675230623135576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030725282989442347,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0770049437880516,
      "backward_entropy": 0.005212188308889215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007353455970587674,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.030725644342601298,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07699409127235411,
      "backward_entropy": 0.005800904401324013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006490754989499692,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030725990980863573,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.07698339571555454,
      "backward_entropy": 0.0054834080690687355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006423186157917371,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03072632886469364,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07697289139032364,
      "backward_entropy": 0.005076086521148682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000692655058537639,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030726663209497927,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07696257680654525,
      "backward_entropy": 0.00504808866164901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005059578776126728,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03072699885815382,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07695242861906687,
      "backward_entropy": 0.00562319311905991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005653308732689766,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03072731923311949,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0769425203402837,
      "backward_entropy": 0.00553666925565763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006105903557909187,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030727626010775565,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07693280180295307,
      "backward_entropy": 0.005926032398234714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005325318361428799,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.0307279285043478,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07692325562238693,
      "backward_entropy": 0.005417153205383908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005073305536825501,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030728228390216827,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0769139140844345,
      "backward_entropy": 0.005324141342531551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036949692084817796,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030728523246943952,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07690478662649791,
      "backward_entropy": 0.005492137880487876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004811968385183718,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03072879947721958,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07689588268597922,
      "backward_entropy": 0.005362725698135115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042649399238143816,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030729066208004953,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07688710788885753,
      "backward_entropy": 0.005191520770842379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004457476176867203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030729327350854874,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0768785188595454,
      "backward_entropy": 0.005146077376875009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004657124256937095,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030729587003588677,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07687012155850728,
      "backward_entropy": 0.005332770537246357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037193183006820616,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030729844979941846,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07686189611752828,
      "backward_entropy": 0.005224173583767631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003989534536231076,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030730094760656357,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07685384700695674,
      "backward_entropy": 0.005291329629041932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032919740597208146,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030730340257287027,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07684592207272849,
      "backward_entropy": 0.0053791323846036744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004204805654808297,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030730579048395157,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07683819383382798,
      "backward_entropy": 0.005459873987869782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003062745007355261,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030730821937322617,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07683057337999342,
      "backward_entropy": 0.005338221720673822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032737194724177245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.03073105700314045,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07682315558195114,
      "backward_entropy": 0.005672980133782734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000326044729035857,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03073128703981638,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07681587040424347,
      "backward_entropy": 0.0052239668640223415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031291204936678696,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030731517635285855,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07680873721837998,
      "backward_entropy": 0.00524800382554531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003276747629570309,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030731750093400477,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0768018012245496,
      "backward_entropy": 0.005305711078372868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002582213661753485,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.03073198106139898,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07679498791694642,
      "backward_entropy": 0.005149729753082448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002176726679181229,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030732202902436258,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0767883191506068,
      "backward_entropy": 0.005700428445230831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025036607053152693,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030732414312660696,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07678181529045106,
      "backward_entropy": 0.005261059714989229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022596895430524456,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030732621625065803,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07677542219559351,
      "backward_entropy": 0.005485884269530123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025923790128672407,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030732822604477406,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07676918307940164,
      "backward_entropy": 0.005291334370320493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001926760958099294,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03073302563279867,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07676306813955307,
      "backward_entropy": 0.005714268745346502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001658463896774265,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.03073322046548128,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07675708631674447,
      "backward_entropy": 0.005526644397865642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020589753619333352,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.03073340319097042,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07675125549236934,
      "backward_entropy": 0.005231989039616151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002127875836322346,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03073358293622732,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07674550066391628,
      "backward_entropy": 0.005704529278657653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015382637332095328,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030733766965568066,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07673984269301097,
      "backward_entropy": 0.00524308979511261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015780512503624778,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030733943358063696,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07673430840174357,
      "backward_entropy": 0.00574978884648193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018720623647823232,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030734112858772276,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07672887494166693,
      "backward_entropy": 0.005231659182093359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001584296500027449,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0307342778891325,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07672348966201147,
      "backward_entropy": 0.005159407346086069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014817629565868628,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030734437890350817,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07671819279591244,
      "backward_entropy": 0.005689893662929535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012909921122172818,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030734593234956264,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07671298881371816,
      "backward_entropy": 0.005317054519599134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014342833860609973,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030734741128981113,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07670787076155346,
      "backward_entropy": 0.005563444102352317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013265356537885963,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030734881386160852,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.07670286297798157,
      "backward_entropy": 0.005798211287368427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012399516946288714,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030735021643340587,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07669797937075297,
      "backward_entropy": 0.005499949848110025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013488620323869326,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030735157243907452,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07669319709142049,
      "backward_entropy": 0.00522928075356917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010038403494263548,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030735290609300137,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07668848633766175,
      "backward_entropy": 0.005035995692014694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011170142129230953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03073541633784771,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07668386350075403,
      "backward_entropy": 0.005314681103283709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001130054860141172,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03073553927242756,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07667931864658992,
      "backward_entropy": 0.005609731647101315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.655726677237908e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030735662020742894,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07667486270268759,
      "backward_entropy": 0.005466061254793947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010381235908880626,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03073578290641308,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07667051553726197,
      "backward_entropy": 0.005493048476901922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69925708716346e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030735901556909084,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07666625877221425,
      "backward_entropy": 0.005267546867782419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.496739516521303e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.030736018531024457,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.0766621043284734,
      "backward_entropy": 0.005678744986653328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.744282478687638e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030736132897436617,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07665803581476212,
      "backward_entropy": 0.00495690947229212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93626837012107e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03073624540120363,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07665405968825022,
      "backward_entropy": 0.005230467698790811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183161597798971e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.0307363573461771,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07665017197529475,
      "backward_entropy": 0.005039280145005746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.090841665762128e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.03073646891862154,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.07664636919895809,
      "backward_entropy": 0.005333831601522185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495045800032131e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.03073657937347889,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07664264688889186,
      "backward_entropy": 0.005567102947018363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.157105379112181e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03073669336736202,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07663900405168533,
      "backward_entropy": 0.004956750131466172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.364066673540947e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030736800469458102,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07663547992706299,
      "backward_entropy": 0.005505772849375552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1758520797639e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030736904963850974,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07663204769293468,
      "backward_entropy": 0.005550723692232912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.003636404694589e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03073700573295355,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07662869691848755,
      "backward_entropy": 0.005436697195876728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.060683393229738e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03073710110038519,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07662543108065924,
      "backward_entropy": 0.005082029341296717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.840059489765736e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030737198144197463,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07662224670251211,
      "backward_entropy": 0.005194192007184028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7839411121231026e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030737292766571046,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07661914974451065,
      "backward_entropy": 0.005131721530448307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.034064185702846e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03073738534003496,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07661613325277963,
      "backward_entropy": 0.005343671176921238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.780459462063845e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.03073747493326664,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07661319822072983,
      "backward_entropy": 0.0050690542567859995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.377700122086935e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030737560242414474,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0766103391846021,
      "backward_entropy": 0.0051810172471133155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5921414576355345e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030737644247710704,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07660758048295975,
      "backward_entropy": 0.005367526649074121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.082498720630156e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030737727507948877,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07660486698150634,
      "backward_entropy": 0.005184757743369449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.051903203787788e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030737804993987084,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07660223146279652,
      "backward_entropy": 0.005180000310594386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1042058816410643e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.030737881362438203,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.07659963766733806,
      "backward_entropy": 0.005908537012609569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.705443965031918e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030737954936921597,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07659711390733719,
      "backward_entropy": 0.0052411595528776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.606467767554022e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030738029070198535,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07659464925527573,
      "backward_entropy": 0.005073676766319709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.495440216880752e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030738101899623872,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0765922283132871,
      "backward_entropy": 0.005323124202814969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.674877275410381e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030738174356520175,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07658985008796057,
      "backward_entropy": 0.005615156550299038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2766417799857663e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030738244764506817,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0765875443816185,
      "backward_entropy": 0.005475899543274532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4085991785227635e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030738311633467675,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07658529231945674,
      "backward_entropy": 0.005212468213655732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4505268864061237e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030738377012312412,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07658310234546663,
      "backward_entropy": 0.005328579009933905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9906506054212514e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03073844201862812,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07658097396294275,
      "backward_entropy": 0.005440001189708709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6142943741547243e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03073850441724062,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07657891114552814,
      "backward_entropy": 0.005567958443002267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1734301445519576e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.03073856756091118,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07657689054807026,
      "backward_entropy": 0.0051168617877093234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.057772119457013e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.030738630145788193,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.07657493700583776,
      "backward_entropy": 0.004958262836391275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1154522561062094e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03073869235813618,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.0765730435649554,
      "backward_entropy": 0.0050756091082637955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8459209160681668e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03073875345289707,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0765711893637975,
      "backward_entropy": 0.005686492269689386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.266467276115236e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.030738812685012818,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07656938483317693,
      "backward_entropy": 0.005280000547116452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6838672763697105e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030738872848451136,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07656760911146801,
      "backward_entropy": 0.005314080552621321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4474586734536388e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030738933011889458,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07656588405370712,
      "backward_entropy": 0.005373911965977062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.546726521439723e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030738991126418112,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07656420866648356,
      "backward_entropy": 0.005108835277232257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.735431249514363e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030739049427211285,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0765625829497973,
      "backward_entropy": 0.005157877166162837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4494347293236843e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030739106796681882,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0765609751145045,
      "backward_entropy": 0.005468266728249463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2575638857015292e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030739163421094416,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0765594134728114,
      "backward_entropy": 0.005326658588918773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0151628600141294e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030739217437803744,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07655788213014604,
      "backward_entropy": 0.0050751909952272065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1420746583468144e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03073926828801632,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07655639449755351,
      "backward_entropy": 0.00514836429872296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0390681976701899e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030739317834377288,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07655494709809621,
      "backward_entropy": 0.005271878601475196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.053659454157696e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03073936589062214,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0765535444021225,
      "backward_entropy": 0.005918995121663267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.149555059356544e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030739411897957324,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07655216405789059,
      "backward_entropy": 0.00535314990715547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.006837635183728e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030739457160234452,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07655081649621329,
      "backward_entropy": 0.004909809949723157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.323561914698076e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030739501863718034,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07654950072367986,
      "backward_entropy": 0.005375411090525714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860635526275474e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030739545449614526,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07654821475346883,
      "backward_entropy": 0.0052973786876960235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.330699189722623e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030739588476717473,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07654695610205332,
      "backward_entropy": 0.005905266918919304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.936936460239963e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030739629827439784,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07654573768377304,
      "backward_entropy": 0.005119665712118149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8024788685884235e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030739671550691128,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07654455453157424,
      "backward_entropy": 0.005671921304681084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.040173387233949e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.03073971178382635,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07654341657956441,
      "backward_entropy": 0.005242799053137953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.102875199331947e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030739749781787395,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07654230644305546,
      "backward_entropy": 0.0054212728345935995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.466042380599447e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030739786103367805,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07654122213522593,
      "backward_entropy": 0.00528874739327214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.259710807337115e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.03073982149362564,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07654014825820923,
      "backward_entropy": 0.005298167873512614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.389846535841514e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030739855021238327,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07653910517692566,
      "backward_entropy": 0.005793977359479123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.119272540492603e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.030739888176321985,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07653809189796448,
      "backward_entropy": 0.00559377216479995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.722231167875179e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03073991984128952,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07653711338837942,
      "backward_entropy": 0.00512174249372699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.978502181212207e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03073994889855385,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0765361582239469,
      "backward_entropy": 0.005517612431537021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.183653169675949e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030739976838231087,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07653522888819375,
      "backward_entropy": 0.00530236614021388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6620048993185605e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030740004777908326,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07653433233499526,
      "backward_entropy": 0.005446693741462448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6746636599360728e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.03074003178626299,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.07653346409400305,
      "backward_entropy": 0.006274844367395747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.060815991024924e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030740058980882168,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07653262466192247,
      "backward_entropy": 0.005464211377230558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.880964560210032e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030740086734294892,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07653181503216426,
      "backward_entropy": 0.00536001209508289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.393494611003689e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740114487707616,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.076531021296978,
      "backward_entropy": 0.005218189785426312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.952163113789652e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030740141309797762,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07653024792671204,
      "backward_entropy": 0.005277274041013284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1107611464520346e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03074016682803631,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07652949144442875,
      "backward_entropy": 0.00551132813773372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.893115260516055e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030740190856158735,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.0765287458896637,
      "backward_entropy": 0.005064967376264658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2333299278365358e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030740214325487614,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07652802218993505,
      "backward_entropy": 0.005227291685613719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4328088334968356e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03074023649096489,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0765273188551267,
      "backward_entropy": 0.005782924219965934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.668651978332548e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03074025772511959,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0765266388654709,
      "backward_entropy": 0.005190437693487514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.464679646863033e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030740279518067837,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07652596880992255,
      "backward_entropy": 0.005238541588187218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8113734833846707e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.030740300938487054,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07652531663576762,
      "backward_entropy": 0.005143496021628379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1329516005863526e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030740321800112724,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07652468681335449,
      "backward_entropy": 0.005797570909966123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8579840729060492e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030740341544151305,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07652407189210256,
      "backward_entropy": 0.005613106150518765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6911778477179951e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030740360170602797,
      "trajectory_length": 13.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.07652346541484198,
      "backward_entropy": 0.005581817911429839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8154530288860825e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030740378610789775,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07652288029591242,
      "backward_entropy": 0.005180214751850475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6526143253869918e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030740396678447725,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07652230759461723,
      "backward_entropy": 0.005595582723617555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2915272105118447e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030740414559841157,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07652175029118856,
      "backward_entropy": 0.0055396629328077485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4008078845328953e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.03074043206870556,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07652121484279632,
      "backward_entropy": 0.00510662126947533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5622233433987276e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030740449391305446,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07652069528897605,
      "backward_entropy": 0.005260964245958762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4481297415436244e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030740466713905335,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07652018715937932,
      "backward_entropy": 0.005449746244333008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1563098970768238e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740483477711678,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0765196924408277,
      "backward_entropy": 0.005182266133752737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.560685312770544e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740499123930932,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0765192116300265,
      "backward_entropy": 0.005356361987915906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2610719984706974e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740515142679215,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07651874919732411,
      "backward_entropy": 0.005209982598369771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.154432122429938e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03074053078889847,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07651829570531844,
      "backward_entropy": 0.005327211388132788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69117511470563e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030740545503795146,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07651784767707188,
      "backward_entropy": 0.005309850417754866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.76282394543415e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740559101104736,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07651741405328115,
      "backward_entropy": 0.005153975534168157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634799388256397e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740571953356267,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07651698887348175,
      "backward_entropy": 0.00539587140083313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981196337742858e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030740584433078765,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0765165795882543,
      "backward_entropy": 0.005426217615604401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.82613341243632e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.03074059635400772,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.07651618172725042,
      "backward_entropy": 0.005637628957629203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.266545530626445e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030740608647465705,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07651579429705938,
      "backward_entropy": 0.005258479172533208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.862535186196283e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.03074062056839466,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07651541183392208,
      "backward_entropy": 0.005242437293583696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.006693823223941e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030740632116794585,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07651505023241043,
      "backward_entropy": 0.0053817506202242585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.722207745861851e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03074064292013645,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0765146940946579,
      "backward_entropy": 0.0052205878225239834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.152234937355616e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030740653164684772,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0765143518646558,
      "backward_entropy": 0.005164072899655862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.186970021497927e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03074066322296858,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07651401509841285,
      "backward_entropy": 0.005120615830475633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756218888957164e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740672908723354,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07651369025309881,
      "backward_entropy": 0.005277059802954847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596398786167356e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03074068184942007,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07651337484518686,
      "backward_entropy": 0.005115522308783098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7281475943350417e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030740691535174846,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07651306887467703,
      "backward_entropy": 0.005168081515214661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.730472919016847e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030740701034665106,
      "trajectory_length": 13.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.07651276936133704,
      "backward_entropy": 0.005604534257542003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3800439470942364e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030740709975361824,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07651247978210449,
      "backward_entropy": 0.004905063523487611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.815918450555955e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.03074071854352951,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07651219914356869,
      "backward_entropy": 0.00546724864027717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.917635375216832e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03074072692543268,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07651192496220269,
      "backward_entropy": 0.005434560809623111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4177445957794815e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030740735307335853,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07651166071494421,
      "backward_entropy": 0.005500937422568148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3109787658247567e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030740743689239024,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07651139845450719,
      "backward_entropy": 0.005693609369072048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3648436676969594e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030740751326084136,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07651114612817764,
      "backward_entropy": 0.005739308758215471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.69592505119931e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.03074075896292925,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.07651089876890184,
      "backward_entropy": 0.005730604109438982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6496486391636156e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03074076622724533,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07651065836350122,
      "backward_entropy": 0.0054125166413458905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6979241809499397e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030740773491561412,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07651042342185974,
      "backward_entropy": 0.005060046301646666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0688022051018606e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030740780383348466,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.07651019692420959,
      "backward_entropy": 0.005722527713938193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1681207300616735e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030740787275135517,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07650997638702393,
      "backward_entropy": 0.005568128824234009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6934978059879312e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.03074079379439354,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07650976230700811,
      "backward_entropy": 0.005495593933896584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.134755622051898e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.030740799941122533,
      "trajectory_length": 13.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.07650956014792125,
      "backward_entropy": 0.005692626434293661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0390203303577437e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030740806460380556,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07650936047236123,
      "backward_entropy": 0.005279178307815031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.374933003894796e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030740812420845032,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.076509165763855,
      "backward_entropy": 0.005222481082786214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7883397145368464e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030740818381309508,
      "trajectory_length": 13.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.07650897800922393,
      "backward_entropy": 0.00525476878339594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.799547595382478e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030740823969244956,
      "trajectory_length": 13.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0765087942282359,
      "backward_entropy": 0.005611067434603518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4499709894977285e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740829557180403,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07650861392418544,
      "backward_entropy": 0.005306701463731853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3851070912451746e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030740834772586823,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07650843759377798,
      "backward_entropy": 0.0055622249164364555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2143844152490146e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030740839801728724,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07650826871395111,
      "backward_entropy": 0.005618567426096309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0954946709773594e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03074084483087063,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0765081043044726,
      "backward_entropy": 0.005350009487433867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1727619169121794e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.03074084911495447,
      "trajectory_length": 13.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.07650794833898544,
      "backward_entropy": 0.005107977512207898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.780566105315301e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030740853399038315,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07650779436031978,
      "backward_entropy": 0.005054084482518109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.804324436757384e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030740857310593128,
      "trajectory_length": 13.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.07650764336188634,
      "backward_entropy": 0.005578821491111409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0123272140560857e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740860849618912,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07650749782721203,
      "backward_entropy": 0.00537773272530599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.477724507434005e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.030740864202380182,
      "trajectory_length": 13.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.0765073537826538,
      "backward_entropy": 0.005072757804935629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589186588636721e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.03074086755514145,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07650721569856009,
      "backward_entropy": 0.005581688609990207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.957227028398961e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03074087090790272,
      "trajectory_length": 13.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.07650708009799322,
      "backward_entropy": 0.0054828877814791415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.904178064814915e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030740873888134956,
      "trajectory_length": 13.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.07650694847106934,
      "backward_entropy": 0.005787435478784821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.295715921922352e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030740876495838166,
      "trajectory_length": 13.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.07650682032108307,
      "backward_entropy": 0.0055408640341325244,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.7695478300516785e-06,
    "avg_log_Z": 0.03074024338647723,
    "success_rate": 1.0,
    "avg_reward": 49.059999999999995,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.13899999999999998,
      "1": 0.252,
      "2": 0.6089999999999999
    },
    "avg_forward_entropy": 0.07652675554653007,
    "avg_backward_entropy": 0.0053850925066931685,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}