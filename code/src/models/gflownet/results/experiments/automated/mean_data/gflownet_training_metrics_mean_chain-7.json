{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893516216959272,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892230033874513,
      "exploration_ratio": 0.6266666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09894013149397714,
      "exploration_ratio": 0.76
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.0989464683192117,
      "exploration_ratio": 0.8400000000000001
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.0989315288407462,
      "exploration_ratio": 0.8666666666666668
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893179365566798,
      "exploration_ratio": 0.8933333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.0989335596561432,
      "exploration_ratio": 0.9199999999999999
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893636788640704,
      "exploration_ratio": 0.9466666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.0989334625857217,
      "exploration_ratio": 0.9733333333333334
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892657995224,
      "exploration_ratio": 0.9733333333333334
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.0989175660269601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.0989229006426675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09891914299556187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09894144790513174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09894931997571674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09894908922059195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09891864912850518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893299341201782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892829145703996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893160206930977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892933538981846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892891134534564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892655185290745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09891955511910575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893400413649422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892274056162154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09895185913358416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893251146589008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893101028033666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892401099205018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09892723986080715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.091230201721192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13707688450813293,
      "backward_entropy": 0.09893371377672468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.090127849578858,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 9.999999892897903e-05,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13708055019378662,
      "backward_entropy": 0.09892194441386633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.217690896987914,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.00019999843934783711,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13708410859107972,
      "backward_entropy": 0.09890808207648141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.041728353500366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.0003000220167450607,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1370869532227516,
      "backward_entropy": 0.09891533766474044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.180094385147095,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.00040001064189709723,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1370900422334671,
      "backward_entropy": 0.09892398118972778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.385115671157838,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.000500016612932086,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13709298819303511,
      "backward_entropy": 0.09890776021139963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.290581226348877,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.000600084278266877,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13709535747766494,
      "backward_entropy": 0.09890591417040143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41610507965088,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0007001685036811978,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13709733337163926,
      "backward_entropy": 0.09890254395348684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.038375663757325,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0008002971822861582,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13709917515516282,
      "backward_entropy": 0.09890091930116926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.490771770477295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0009003542421851307,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1371005117893219,
      "backward_entropy": 0.09887865356036594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.36157054901123,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.001000491250306368,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1371014818549156,
      "backward_entropy": 0.0988523176738194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.309564781188964,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0011006456334143877,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13710236549377441,
      "backward_entropy": 0.09885698897497995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.29782075881958,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0012007987592369319,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1371029272675514,
      "backward_entropy": 0.09888462339128767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.295093107223511,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0013009488116949796,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1371031418442726,
      "backward_entropy": 0.09883970277650016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.162307739257812,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.001401096221525222,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1371031731367111,
      "backward_entropy": 0.0988475433417729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.367114639282226,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0015011971117928624,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1371030643582344,
      "backward_entropy": 0.09884913648877827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9726318359375,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0016013298416510224,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13710275590419768,
      "backward_entropy": 0.09885306273187909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.310579013824462,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0017013472737744451,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13710242360830308,
      "backward_entropy": 0.09884815386363437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.015777349472046,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0018013852532021701,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13710205405950546,
      "backward_entropy": 0.09880934613091605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.169755125045777,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0019013458979316056,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13710176795721055,
      "backward_entropy": 0.09879979916981288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.613836002349853,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0020012904424220324,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1371014639735222,
      "backward_entropy": 0.09882687755993433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.314810943603515,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0021013784455135463,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13710099309682847,
      "backward_entropy": 0.09877743124961853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.102185726165771,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0022014918038621547,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13710005283355714,
      "backward_entropy": 0.09877926196370806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.36220064163208,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.002301542297936976,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13709889650344848,
      "backward_entropy": 0.09877468262399947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.473304843902588,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0024016337003558872,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1370975822210312,
      "backward_entropy": 0.09876570361001151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42367696762085,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0025018064538016916,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13709599375724793,
      "backward_entropy": 0.09872534700802395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.313358497619628,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.002602030849084258,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13709427565336227,
      "backward_entropy": 0.09875214525631497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.322670364379883,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0027022687252610924,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.137092424929142,
      "backward_entropy": 0.098763735805239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31074333190918,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0028025183361023664,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13709037899971008,
      "backward_entropy": 0.09874864646366664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.540936613082886,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0029027653858065606,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13708842545747757,
      "backward_entropy": 0.09874940770012992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.060350704193116,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0030030897352844475,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13708641082048417,
      "backward_entropy": 0.09868173514093673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.469834280014037,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.003103305958211422,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13708432465791703,
      "backward_entropy": 0.09868837339537484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.372163677215577,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0032035850221291185,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13708189725875855,
      "backward_entropy": 0.09870364325387138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.624702739715577,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.0033038876252248885,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1370791584253311,
      "backward_entropy": 0.09867598073823111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.028880310058593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0034043208695948126,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1370762899518013,
      "backward_entropy": 0.09868415934698921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.274365901947021,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.0035046149510890245,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13707335293293,
      "backward_entropy": 0.09864534480231149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.912215518951417,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.00360488835722208,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1370703771710396,
      "backward_entropy": 0.09864484752927508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.510916662216186,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0037050027633085845,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1370675042271614,
      "backward_entropy": 0.0986488435949598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.061477994918823,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.003805210185237229,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1370644226670265,
      "backward_entropy": 0.0986318962914603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.141253566741943,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0039053187938407063,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13706115186214446,
      "backward_entropy": 0.09856625625065395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71583800315857,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.0040053692646324635,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13705763816833497,
      "backward_entropy": 0.09853004472596304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.968007564544678,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.004105187999084592,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1370544135570526,
      "backward_entropy": 0.09861001883234297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.785922384262085,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.004204904660582542,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13705128133296968,
      "backward_entropy": 0.09857511690684725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840760374069214,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.004304469423368573,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13704822361469268,
      "backward_entropy": 0.09848072784287588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.248089790344238,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.004403927875682711,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13704503178596497,
      "backward_entropy": 0.09843297430447169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.302053880691528,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.004503473825752735,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1370417669415474,
      "backward_entropy": 0.09848686030932834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.717858934402466,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.004603115050122142,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13703857511281967,
      "backward_entropy": 0.09843166470527649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167370414733886,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.004702583700418472,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13703519999980926,
      "backward_entropy": 0.0984825074672699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.961480140686035,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.004802096495404839,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13703185468912124,
      "backward_entropy": 0.09838911124638149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.302216243743896,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.004901555273681879,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13702867925167084,
      "backward_entropy": 0.09831130930355617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.079328155517578,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0050011279061436655,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13702535778284072,
      "backward_entropy": 0.09835255571774074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.027013731002807,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.005100701609626413,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1370221421122551,
      "backward_entropy": 0.0983133818422045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14098081588745,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.00520024923607707,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13701881617307662,
      "backward_entropy": 0.09834089619772776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.13540015220642,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.005299814138561487,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13701542913913728,
      "backward_entropy": 0.0982908879007612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.463873434066773,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.005399404792115092,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13701222389936446,
      "backward_entropy": 0.09818839515958513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.095838260650634,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.005499166715890169,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13700849264860154,
      "backward_entropy": 0.09828096372740609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.34954113960266,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.005598915321752429,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13700469583272934,
      "backward_entropy": 0.09827907000269209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.906687831878662,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.005698773683980108,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1370006024837494,
      "backward_entropy": 0.09828202128410339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.158445501327515,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.005798530392348766,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1369964748620987,
      "backward_entropy": 0.09819309541157314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.998223209381104,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.005898302281275391,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13699219524860382,
      "backward_entropy": 0.09813583237784249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.604314613342286,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.005998013401404023,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13698789179325105,
      "backward_entropy": 0.09807702047484261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.491060543060303,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.00609749173745513,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13698383569717407,
      "backward_entropy": 0.09802356532641819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.372944593429565,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.00619670762680471,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13697997629642486,
      "backward_entropy": 0.09804525886263166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.924649238586426,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.00629610288888216,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13697596341371537,
      "backward_entropy": 0.09806361539023264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.01987690925598,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.006395467836409807,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1369716614484787,
      "backward_entropy": 0.09798205239432198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.915224981307983,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.006494843913242221,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13696714490652084,
      "backward_entropy": 0.09808701957975115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.96829171180725,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0065941687673330305,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1369627147912979,
      "backward_entropy": 0.0978912787778037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.801382970809936,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.00669349255040288,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13695808500051498,
      "backward_entropy": 0.0979990644114358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.165525531768798,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.006792726321145892,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13695382922887803,
      "backward_entropy": 0.09796386872019086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.125170707702637,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.00689206700772047,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13694918751716614,
      "backward_entropy": 0.09774714878627233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31251540184021,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.0069914842955768105,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.13694456666707994,
      "backward_entropy": 0.0977992492062705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.977556133270264,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.007091036718338728,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1369399830698967,
      "backward_entropy": 0.09786417824881419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.834564590454102,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.007190569397062063,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1369349777698517,
      "backward_entropy": 0.0976989005293165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.751818132400512,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0072900180239230394,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.136929751932621,
      "backward_entropy": 0.0978152734892709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.077197647094726,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.007389348791912198,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13692483007907869,
      "backward_entropy": 0.09758626903806414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.821355485916138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.007488725334405899,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1369200125336647,
      "backward_entropy": 0.09751134855406626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.882787942886353,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0075880282558500765,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13691501021385194,
      "backward_entropy": 0.09769612550735474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.194601440429688,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.007687290385365486,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13691016435623168,
      "backward_entropy": 0.09733742220061165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.05588264465332,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.007786672515794635,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13690520375967025,
      "backward_entropy": 0.0976075623716627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.549403381347656,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.007886093948036433,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13690008968114853,
      "backward_entropy": 0.09749991723469326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.345904922485351,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.007985810283571482,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13689456284046173,
      "backward_entropy": 0.09714735320636204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.039157104492187,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.008085671067237853,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13688900619745253,
      "backward_entropy": 0.0972307767186846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.057658243179322,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.008185508660972118,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1368834137916565,
      "backward_entropy": 0.09744361468723842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.724415683746338,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.008285342901945113,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13687775135040284,
      "backward_entropy": 0.09711156146866934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.025205421447755,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.008385015837848186,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1368723228573799,
      "backward_entropy": 0.09725739189556667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.33872184753418,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.008484691008925438,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13686666488647461,
      "backward_entropy": 0.0971632148538317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775041389465333,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.008584520220756531,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13686069399118422,
      "backward_entropy": 0.09697781716074264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.998979902267456,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.008684199210256338,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13685493767261506,
      "backward_entropy": 0.09706837449754988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.887785243988038,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.00878385230898857,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13684878796339034,
      "backward_entropy": 0.09682808944157191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79944486618042,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.008883455861359834,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13684262186288834,
      "backward_entropy": 0.09673366120883396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429764318466187,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.00898295883089304,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1368367314338684,
      "backward_entropy": 0.0969387343951634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.174505853652954,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.009082173556089401,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13683136105537413,
      "backward_entropy": 0.09667870317186629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.828098773956299,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.009181497991085053,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13682566732168197,
      "backward_entropy": 0.09643910271780831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.175871276855469,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.009280745591968297,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13682011514902115,
      "backward_entropy": 0.09661093609673638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034647274017335,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.009380131587386131,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1368143990635872,
      "backward_entropy": 0.09669236625943865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6752103805542,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.009479558933526278,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13680859804153442,
      "backward_entropy": 0.09664118034499032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.948566341400147,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.009578848164528609,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13680298030376434,
      "backward_entropy": 0.09674805147307261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53295726776123,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.009678151458501816,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13679686784744263,
      "backward_entropy": 0.09641963839530945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.900485610961914,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.009777278546243906,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.13679106831550597,
      "backward_entropy": 0.09602209329605103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95871877670288,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.009876407403498887,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13678539991378785,
      "backward_entropy": 0.09624530502728053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.098639965057373,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.009975564107298851,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13677907437086106,
      "backward_entropy": 0.09607460924557276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.813781452178954,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.01007481710985303,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13677242398262024,
      "backward_entropy": 0.09622015953063966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.670812129974365,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.010174024756997824,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13676600605249406,
      "backward_entropy": 0.09592452560152327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.939694118499755,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.010273127071559428,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13675947934389115,
      "backward_entropy": 0.09578424096107482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262979888916016,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.010372264869511127,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13675300031900406,
      "backward_entropy": 0.09558036923408508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.682157611846923,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.010471084341406822,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13674694299697876,
      "backward_entropy": 0.09560425962720598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.202728080749512,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.010569835919886828,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13674109429121017,
      "backward_entropy": 0.09555528845105853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.098417663574219,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.01066880403086543,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13673454523086548,
      "backward_entropy": 0.09573930416788373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.744652605056762,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.010767912957817316,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1367278978228569,
      "backward_entropy": 0.09541895900453841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.81398606300354,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.010866948682814837,
      "trajectory_length": 9.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.1367211788892746,
      "backward_entropy": 0.09542245524270193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721690559387207,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.010965979192405939,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1367138683795929,
      "backward_entropy": 0.09533108047076636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.636791133880616,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.011064934078603983,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13670676946640015,
      "backward_entropy": 0.0951623695237296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.966857957839967,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.011163812037557364,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1366995766758919,
      "backward_entropy": 0.09488420486450196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.945337533950806,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.011262781452387571,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13669214099645616,
      "backward_entropy": 0.09489289266722543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.97907600402832,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.011361819505691529,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1366844967007637,
      "backward_entropy": 0.09506920490946089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.774672937393188,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.011460925452411175,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13667609840631484,
      "backward_entropy": 0.09479116286550247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.102964401245117,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.011560005228966474,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13666719943284988,
      "backward_entropy": 0.09460019554410662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.666244792938233,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.011659225914627314,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13665775060653687,
      "backward_entropy": 0.09459292122295924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860730266571045,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.011758346203714609,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1366485059261322,
      "backward_entropy": 0.09446943231991359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.380419635772705,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.011857473384588956,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13663905411958693,
      "backward_entropy": 0.09439747163227627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.522159051895141,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.01195637034252286,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13662994503974915,
      "backward_entropy": 0.09409943989345006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.505487489700318,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.01205512136220932,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13662113547325133,
      "backward_entropy": 0.0942205650465829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839668035507202,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.012153748609125613,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13661285489797592,
      "backward_entropy": 0.09367975933211191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.59942684173584,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.012252455204725265,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.136603844165802,
      "backward_entropy": 0.09363951342446464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.720763969421387,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.01235110117122531,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1365948036313057,
      "backward_entropy": 0.0932988294533321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827086925506592,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.012449749372899532,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13658569306135177,
      "backward_entropy": 0.09334054418972561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.783137655258178,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.012548462487757206,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13657644391059875,
      "backward_entropy": 0.092994966677257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.639522552490234,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.012647198233753442,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13656696379184724,
      "backward_entropy": 0.09309816360473631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.48383059501648,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0127458899281919,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13655754327774047,
      "backward_entropy": 0.09335649950163706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.526183700561523,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.012844462599605321,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13654840290546416,
      "backward_entropy": 0.09339990700994219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.631056642532348,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.012942953035235405,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13653919100761414,
      "backward_entropy": 0.09285240258489337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.610017871856689,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.013041413109749555,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1365295171737671,
      "backward_entropy": 0.09268993309565951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.439698123931885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.013139837980270385,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13651922047138215,
      "backward_entropy": 0.09237461771283831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.552439069747924,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.013238152395933867,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1365089923143387,
      "backward_entropy": 0.0916169387953622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.695437622070312,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.013336430117487908,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13649874776601792,
      "backward_entropy": 0.092002101455416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00141716003418,
      "terminal_state_reached": 1.0,
      "terminal_reward": 15.0,
      "log_Z": 0.013434739597141743,
      "trajectory_length": 9.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.136487977206707,
      "backward_entropy": 0.09248388665063041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700437593460084,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.013533273059874774,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13647647053003312,
      "backward_entropy": 0.09182362726756504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485745000839234,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.01363183381035924,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.136464424431324,
      "backward_entropy": 0.09153287410736084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.633551979064942,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.013730301707983016,
      "trajectory_length": 9.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.13645220249891282,
      "backward_entropy": 0.09197288496153695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29610447883606,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.013828773610293865,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1364394336938858,
      "backward_entropy": 0.09084448984691075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.452086448669434,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.013927050959318876,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13642719388008118,
      "backward_entropy": 0.0910368059362684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295056581497192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.014025242533534765,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13641525208950042,
      "backward_entropy": 0.09169160212789264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.511667442321777,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.014123276900500059,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13640349060297013,
      "backward_entropy": 0.09062574335506983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.325066661834716,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.01422127429395914,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13639201670885087,
      "backward_entropy": 0.0902535481112344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.164528322219848,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.014319149311631918,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1363808736205101,
      "backward_entropy": 0.09008557881627763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.587832736968995,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.014416849799454212,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13636983782052994,
      "backward_entropy": 0.0907882537160601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.270777130126953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.01451462721452117,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13635879009962082,
      "backward_entropy": 0.09048460381371634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.955233192443847,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.014612280577421189,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1363475352525711,
      "backward_entropy": 0.09039791141237531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.344530773162841,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.014709648676216602,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13633725941181182,
      "backward_entropy": 0.08983400634356907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.428414726257325,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.014806988183408976,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13632636070251464,
      "backward_entropy": 0.08836894205638342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.998912048339844,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.014904353395104408,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.13631491661071776,
      "backward_entropy": 0.08948879837989807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.492346239089965,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.015001492574810982,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1363039955496788,
      "backward_entropy": 0.08983308162008014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.660148239135742,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.015098716598004103,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13629239350557326,
      "backward_entropy": 0.08933445726122176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.293177604675293,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.015196098759770394,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13627987504005432,
      "backward_entropy": 0.08822267907006401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.14949164390564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.015293426718562842,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1362670600414276,
      "backward_entropy": 0.08846065146582469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.249237203598023,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.015390630252659321,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1362548589706421,
      "backward_entropy": 0.08693316749164036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.134660005569458,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.015487762540578843,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13624235689640046,
      "backward_entropy": 0.08914651785578045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.380520105361938,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.015584771707653999,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1362298995256424,
      "backward_entropy": 0.08795597212655204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.400259828567505,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.015681822691112755,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1362166851758957,
      "backward_entropy": 0.08739157744816371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.780892181396484,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.015778935607522727,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13620285093784332,
      "backward_entropy": 0.08593605160713196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.267632341384887,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.01587574854493141,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13618972301483154,
      "backward_entropy": 0.08661903142929077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256956863403321,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.015972562320530414,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13617561459541322,
      "backward_entropy": 0.08645558953285216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.724889469146729,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.016069385036826134,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1361604318022728,
      "backward_entropy": 0.08601689083235603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.089672803878784,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.016165909357368946,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1361459106206894,
      "backward_entropy": 0.08538644654410225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.880947732925415,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.016262401826679707,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13613124191761017,
      "backward_entropy": 0.0841626388686044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.014095449447632,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.016358714364469052,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1361175000667572,
      "backward_entropy": 0.08471694248063225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.350279331207275,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.01645495668053627,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13610291182994844,
      "backward_entropy": 0.08565804021699089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.687616777420044,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.016551336646080016,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1360876441001892,
      "backward_entropy": 0.08540624720709664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.268044471740723,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.01664744857698679,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.136072738468647,
      "backward_entropy": 0.08508549502917698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.493108081817627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.016743665002286433,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13605651557445525,
      "backward_entropy": 0.08558952042034694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.796070146560669,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.01683951560407877,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13604077994823455,
      "backward_entropy": 0.08315166149820599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.530727338790894,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.016935220547020437,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1360245317220688,
      "backward_entropy": 0.08346828349999019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13159499168396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.017030640877783297,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13600872009992598,
      "backward_entropy": 0.08307492647852216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6347513675689695,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.017126168124377728,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13599120378494262,
      "backward_entropy": 0.08313479168074471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5223473072052,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.01722149774432182,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13597412705421447,
      "backward_entropy": 0.08133907914161684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5879254817962645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.01731658447533846,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13595670014619826,
      "backward_entropy": 0.08143380795206343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.657316732406616,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.01741149239242077,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1359388455748558,
      "backward_entropy": 0.08175179319722312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.515200901031494,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.01750627886503935,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13592108190059662,
      "backward_entropy": 0.08135542273521423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603371667861938,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.017600879818201066,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13590284436941147,
      "backward_entropy": 0.08085484845297677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.314104318618774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.017695380561053752,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13588507771492003,
      "backward_entropy": 0.07934148950236183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.711515426635742,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.017789611779153346,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13586851954460144,
      "backward_entropy": 0.08104335665702819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.626483678817749,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.01788385398685932,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13585201501846314,
      "backward_entropy": 0.07980982661247253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.703764295578003,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0179780550301075,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13583456426858903,
      "backward_entropy": 0.07804908241544452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.972096633911133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.01807226352393627,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13581540882587434,
      "backward_entropy": 0.08081314734050206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.439675521850586,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.018166046217083932,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13579706102609634,
      "backward_entropy": 0.07890583702496119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.370252561569214,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018259735591709614,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13577833473682405,
      "backward_entropy": 0.07949871335710798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.347346544265747,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01835329905152321,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1357594385743141,
      "backward_entropy": 0.07913469927651542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.308164024353028,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.01844672579318285,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13574022203683853,
      "backward_entropy": 0.07803763278893061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.06107268333435,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01854001674801111,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13572085797786712,
      "backward_entropy": 0.07617863672120231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.31090726852417,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.0186330309137702,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1357019856572151,
      "backward_entropy": 0.07745479260172164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.665966749191284,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.01872597597539425,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13568276315927505,
      "backward_entropy": 0.07786860508578163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.291313695907593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.018819058686494826,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13566183894872666,
      "backward_entropy": 0.07538855203560421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.00146484375,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.01891206931322813,
      "trajectory_length": 9.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.1356397122144699,
      "backward_entropy": 0.07546615302562713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.906201696395874,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.01900481227785349,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13561870604753495,
      "backward_entropy": 0.07685145565441677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.498940181732178,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.019097254797816276,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13559816479682923,
      "backward_entropy": 0.07444297415869575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.81882758140564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.019189812429249286,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1355759769678116,
      "backward_entropy": 0.075553993667875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.853220510482788,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.019282038882374765,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13555375933647157,
      "backward_entropy": 0.07319750700678145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.059099340438843,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.019373976439237595,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13553175032138826,
      "backward_entropy": 0.07410406342574528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.902532911300659,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.019465812109410764,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13550955057144165,
      "backward_entropy": 0.0732224008866719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.670605802536011,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.019557477720081807,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13548710197210312,
      "backward_entropy": 0.07251468556267873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6626549243927,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.01964882407337427,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13546439558267592,
      "backward_entropy": 0.07161713242530823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.725970792770386,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.01973989438265562,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.13544201701879502,
      "backward_entropy": 0.07274434268474579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.801942443847656,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.019830749183893204,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13541922718286514,
      "backward_entropy": 0.07142343095370703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.338318538665772,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.019921458140015603,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.13539591282606125,
      "backward_entropy": 0.07042614136423384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.617383861541748,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02001174110919237,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13537345826625824,
      "backward_entropy": 0.07170876434871129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.60535626411438,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.020101812668144703,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13535072654485703,
      "backward_entropy": 0.0697801262140274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4002988815307615,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.020191675797104836,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13532686084508896,
      "backward_entropy": 0.0699394281421389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.133516931533814,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.02028125710785389,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13530271351337433,
      "backward_entropy": 0.07008631399699619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.538019704818725,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02037042994052172,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1352801352739334,
      "backward_entropy": 0.06816866951329367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.438501930236816,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02045948840677738,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13525708317756652,
      "backward_entropy": 0.06757573315075464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.204766464233399,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.020548361726105212,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1352330654859543,
      "backward_entropy": 0.06782331338950566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.090580654144287,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02063692957162857,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13520935773849488,
      "backward_entropy": 0.06598332950047084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.176729679107666,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.020725145190954208,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1351860821247101,
      "backward_entropy": 0.06729035079479216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1876708507537845,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02081310898065567,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13516155630350113,
      "backward_entropy": 0.06871765170778546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.111058378219605,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.020900860801339148,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13513638824224472,
      "backward_entropy": 0.06486717590263912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.038662242889404,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.020988385006785393,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13511019349098205,
      "backward_entropy": 0.06553256469113486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.748468685150146,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.021075640432536603,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13508372902870178,
      "backward_entropy": 0.06541180568081993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.080734634399414,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.021162459254264833,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13505795001983642,
      "backward_entropy": 0.06501568513257162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.777094173431396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.021249153837561607,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1350311130285263,
      "backward_entropy": 0.06381596199103765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.752786302566529,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.021335486322641373,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1350045919418335,
      "backward_entropy": 0.06136493895735061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.997725582122802,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02142148930579424,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13497812747955323,
      "backward_entropy": 0.06426655522414618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8658874988555905,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.021507374197244643,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13495021015405656,
      "backward_entropy": 0.062036247338567455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.673283386230469,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02159308847039938,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1349217563867569,
      "backward_entropy": 0.060735083477837716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.609348344802856,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.021678484603762628,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.13489332646131516,
      "backward_entropy": 0.06155299629483905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.452962803840637,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.021763555146753787,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13486519157886506,
      "backward_entropy": 0.06153013450758797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.620669651031494,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.021848206408321857,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13483645617961884,
      "backward_entropy": 0.06056425528866903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.306813144683838,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02193262577056885,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.13480760157108307,
      "backward_entropy": 0.058408835530281075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.285303354263306,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.022016607597470282,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1347793757915497,
      "backward_entropy": 0.05859567310128892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.26066837310791,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.022100188955664634,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13475093990564346,
      "backward_entropy": 0.05970040006296975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.090754890441895,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.022183379158377647,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1347225308418274,
      "backward_entropy": 0.05904500527041299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.460972332954407,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0222661092877388,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13469482362270355,
      "backward_entropy": 0.05654804280826024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.324402976036072,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.022348695807158946,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13466519564390184,
      "backward_entropy": 0.05620932579040527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.329893589019775,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02243105825036764,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1346352756023407,
      "backward_entropy": 0.055435277734484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.951348972320557,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.022513256035745145,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1346032977104187,
      "backward_entropy": 0.05514105473245893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.086865377426148,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02259502187371254,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1345716491341591,
      "backward_entropy": 0.057084678752081744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.879652643203736,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02267647851258516,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13453958481550216,
      "backward_entropy": 0.05508493738515037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.775397896766663,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.022757512144744398,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13450747579336167,
      "backward_entropy": 0.054513967888695856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7456093549728395,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02283807285130024,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13447647243738176,
      "backward_entropy": 0.05362145560128349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.762704515457154,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.022918208129704,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1344456747174263,
      "backward_entropy": 0.05456138338361468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.745193362236023,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02299794740974903,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1344154253602028,
      "backward_entropy": 0.05289598447935921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.586425375938416,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02307733129709959,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13438401073217393,
      "backward_entropy": 0.05313454525811332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.329188418388367,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.02315629757940769,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13435264229774474,
      "backward_entropy": 0.05233728332178933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.509555983543396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02323463875800371,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1343223348259926,
      "backward_entropy": 0.052539853538785666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.472047805786133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.023312573693692683,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13429200500249863,
      "backward_entropy": 0.049805405097348356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.470117473602295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.02339014708995819,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1342610388994217,
      "backward_entropy": 0.0502228000334331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.243918609619141,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0234673622995615,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13422932624816894,
      "backward_entropy": 0.047138135773794984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.33446729183197,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02354411892592907,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13419755697250366,
      "backward_entropy": 0.05002451028142656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.280749249458313,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02362054754048586,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13416557759046555,
      "backward_entropy": 0.048097561299800876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.377156949043274,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.023696624860167503,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13413189649581908,
      "backward_entropy": 0.04784768117325647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.031166338920594,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.023772446624934673,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1340954437851906,
      "backward_entropy": 0.046279477008751464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9435771226882936,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.023847752064466477,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13405941128730775,
      "backward_entropy": 0.04718990219490869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.759991979598999,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.023922481946647166,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13402445167303084,
      "backward_entropy": 0.04420044251850673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.053838467597961,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.023996573872864246,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13399045169353485,
      "backward_entropy": 0.0460827716759273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.937509822845459,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02407031487673521,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13395479023456575,
      "backward_entropy": 0.043790578416415635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.832762289047241,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.024143692478537558,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13391783088445663,
      "backward_entropy": 0.04430319155965532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.748810625076294,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.024216642417013646,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13387967497110367,
      "backward_entropy": 0.043118447065353394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7023203372955322,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.024289135821163654,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.13384143859148026,
      "backward_entropy": 0.04176692898784364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5933836102485657,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.024361166171729565,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13380263298749923,
      "backward_entropy": 0.04308649535690036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4413553953170775,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.024432680010795592,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13376414328813552,
      "backward_entropy": 0.04273829587868282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.642208456993103,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.0245036443695426,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13372627645730972,
      "backward_entropy": 0.04207142123154232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.554086518287659,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.024574250914156437,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1336866721510887,
      "backward_entropy": 0.0403939425945282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.430773973464966,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02464443501085043,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13364628553390503,
      "backward_entropy": 0.04249253315585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2933342099189757,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.024714144133031368,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.13360492140054703,
      "backward_entropy": 0.0393979828272547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3037330985069273,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02478331346064806,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13356370925903321,
      "backward_entropy": 0.040826824094567976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.297601068019867,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02485203295946121,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13352226912975312,
      "backward_entropy": 0.038858436260904586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1953210711479185,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02492025326937437,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13348035961389543,
      "backward_entropy": 0.03771310576370785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.169280636310577,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.024987975135445595,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1334378495812416,
      "backward_entropy": 0.03836059293576649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9678301930427553,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02505526002496481,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13339464515447616,
      "backward_entropy": 0.038565119462353845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.825691449642181,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.025121917575597764,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13335178345441817,
      "backward_entropy": 0.038222768264157436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.890004241466522,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.025187820941209794,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13330895751714705,
      "backward_entropy": 0.036060234265668054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0177958488464354,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.025253086537122726,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13326673954725266,
      "backward_entropy": 0.036234039493969514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9312035918235777,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02531797643750906,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13322225511074065,
      "backward_entropy": 0.03648901070867266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7780874609947204,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.025382382236421107,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13317688554525375,
      "backward_entropy": 0.033903938319001875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6488324284553526,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.025446214340627195,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13313184380531312,
      "backward_entropy": 0.034726891985961364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.666787886619568,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.025509449653327465,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13308703154325485,
      "backward_entropy": 0.0336343805704798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.84100888967514,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02557212170213461,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1330424040555954,
      "backward_entropy": 0.03128973437207085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.58727046251297,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.025634497590363025,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13299486488103868,
      "backward_entropy": 0.034344622067042765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.340576648712158,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02569629866629839,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13294668346643448,
      "backward_entropy": 0.03178469176803317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.370475006103516,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.025757293030619622,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13290067464113237,
      "backward_entropy": 0.031746434952531544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.289499521255493,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.025817643292248248,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13285519182682037,
      "backward_entropy": 0.03136262787239892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3629434168338777,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.025877348706126214,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13280933648347854,
      "backward_entropy": 0.029993189658437457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.309153640270233,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.025936489924788475,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13276305496692659,
      "backward_entropy": 0.030404717688049594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.266468381881714,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.025995093025267126,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13271610140800477,
      "backward_entropy": 0.028501726261207033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1648931443691253,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.026053193397819994,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13266853243112564,
      "backward_entropy": 0.02957635575107166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0964326083660128,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.026110696978867053,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1326202929019928,
      "backward_entropy": 0.03068518180932318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.923525297641754,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02616752777248621,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13257189989089965,
      "backward_entropy": 0.027448787220886776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.106413114070892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.026223589107394217,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13252424597740173,
      "backward_entropy": 0.0288739803646292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.127713704109192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026279133558273316,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13247567117214204,
      "backward_entropy": 0.028665988892316818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8712429761886598,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026334304176270962,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13242528438568116,
      "backward_entropy": 0.027139450928994585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.851056295633316,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.026388741470873354,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13237560987472535,
      "backward_entropy": 0.027086980534451348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8125090420246124,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.026442474126815795,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13232581913471222,
      "backward_entropy": 0.028561014682054527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9100789368152618,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.026495534181594848,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13227560818195344,
      "backward_entropy": 0.0273317603128297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8482486069202424,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02654812727123499,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13222311288118363,
      "backward_entropy": 0.027816075299467356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6920450150966644,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.026600206084549428,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13216926753520966,
      "backward_entropy": 0.02634864108903067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6966211259365083,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026651690527796746,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13211609423160553,
      "backward_entropy": 0.02657850725310189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.754014140367508,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02670256271958351,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1320616751909256,
      "backward_entropy": 0.02666066544396537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5864933669567107,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.026752913370728493,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13200524002313613,
      "backward_entropy": 0.025396312347480233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7581148028373719,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02680258881300688,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13194890767335893,
      "backward_entropy": 0.026786659019333976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5360475838184358,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.026851904392242432,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1318898767232895,
      "backward_entropy": 0.024825405755213328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.497347918152809,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.026900605671107768,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1318314015865326,
      "backward_entropy": 0.023386777724538534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.50496586561203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.026948626898229123,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.131772743165493,
      "backward_entropy": 0.02369817325047084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4482601284980774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026996060647070406,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1317128747701645,
      "backward_entropy": 0.02330265002591269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3521912574768067,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027042935974895953,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.13165143579244615,
      "backward_entropy": 0.022821025124617984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4036358445882797,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027089112810790537,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13159015625715256,
      "backward_entropy": 0.023090022589479176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.389099156856537,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027134814858436586,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13152829855680465,
      "backward_entropy": 0.021700731771332877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2468205094337463,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027180050499737263,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13146518021821976,
      "backward_entropy": 0.021030199314866747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2683325320482255,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02722453009337187,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13140180259943007,
      "backward_entropy": 0.022222442073481424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0872582733631133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027268447168171405,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1313372403383255,
      "backward_entropy": 0.02288141676357814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1528522551059723,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.027311501279473304,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.13127481788396836,
      "backward_entropy": 0.02155302113720349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0991868078708649,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027353920228779315,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.13121194392442703,
      "backward_entropy": 0.021355372454438894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.117820319533348,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.027395631931722165,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13114877045154572,
      "backward_entropy": 0.02185430462871279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0807065814733505,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.027436795830726623,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13108478039503096,
      "backward_entropy": 0.020006831309625082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0555799633264542,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02747733425348997,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.13102037608623504,
      "backward_entropy": 0.02030966079660824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0358405441045762,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.027517296187579632,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13095543086528777,
      "backward_entropy": 0.021093616847481046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.017568004131317,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02755670677870512,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1308898761868477,
      "backward_entropy": 0.01921218378203256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.991077895462513,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.027595558576285838,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.13082366734743117,
      "backward_entropy": 0.019863250106573103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9905866116285325,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027633859775960445,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1307564377784729,
      "backward_entropy": 0.01985199110848563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8831356942653656,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02767167817801237,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.13068689703941344,
      "backward_entropy": 0.020194575296980995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9230725973844528,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.027708811685442924,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13061736822128295,
      "backward_entropy": 0.019182921946048738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8762275308370591,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027745444700121878,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1305461749434471,
      "backward_entropy": 0.01787708635841097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8366577506065369,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.02778150010854006,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.13047431111335756,
      "backward_entropy": 0.016655018925666808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9228766247630119,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027816996909677982,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.13040169030427934,
      "backward_entropy": 0.017381177097558976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7383034452795982,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02785209212452173,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1303262248635292,
      "backward_entropy": 0.01756080250654902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6927831843495369,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.027886560000479222,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.13025135099887847,
      "backward_entropy": 0.017363270478589193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6516711980104446,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027920310199260712,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.13017740249633789,
      "backward_entropy": 0.01594604275056294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7098763577640057,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027953272871673106,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1301047295331955,
      "backward_entropy": 0.016778609795229778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6223183736205101,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.027985686622560024,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.13003190606832504,
      "backward_entropy": 0.01685089341231755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6278320148587226,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028017358295619486,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12995996922254563,
      "backward_entropy": 0.016205874936921258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6821176879107952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02804842535406351,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1298890382051468,
      "backward_entropy": 0.017637285803045546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5652755431830883,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.028079034946858882,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.12981605231761933,
      "backward_entropy": 0.016279079552207677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5622789271175861,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028109010495245456,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1297441840171814,
      "backward_entropy": 0.015291103720664978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5520029425621032,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028138413652777673,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1296727478504181,
      "backward_entropy": 0.015073499509266444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5366306267678738,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028167269192636013,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12960089445114137,
      "backward_entropy": 0.015202410625559942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5163680516183377,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028195566684007644,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12952915579080582,
      "backward_entropy": 0.01630681870239122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5225061863660813,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02822334598749876,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12945724576711654,
      "backward_entropy": 0.016574242391756602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49167573153972627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028250598907470705,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12938476651906966,
      "backward_entropy": 0.014610182706798824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.508055429160595,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0282772833481431,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1293120115995407,
      "backward_entropy": 0.01443834900856018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46395030692219735,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0283035472035408,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12923868894577026,
      "backward_entropy": 0.015178143445934569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44680665507912637,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02832936551421881,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12916530072689056,
      "backward_entropy": 0.015016221042190279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4262344241142273,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.028354663960635663,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12909154891967772,
      "backward_entropy": 0.014181729618992125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3803605265915394,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.028379394859075546,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12901764661073684,
      "backward_entropy": 0.014583570616585866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3836598310619593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028403509967029096,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12894436120986938,
      "backward_entropy": 0.01425427310168743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.427146415412426,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028427058085799217,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12887141108512878,
      "backward_entropy": 0.013856413960456847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3527376800775528,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02845019418746233,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1287967622280121,
      "backward_entropy": 0.01427490540913173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38215230889618396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028472865372896193,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12872318625450135,
      "backward_entropy": 0.014168164772646766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39311852492392063,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02849506717175245,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12864768356084824,
      "backward_entropy": 0.01354970649949142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3028014894574881,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.028516986034810544,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12857044786214827,
      "backward_entropy": 0.014368375497204919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35453499518334863,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028538316115736963,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12849396765232085,
      "backward_entropy": 0.013337495497294835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30800036936998365,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.028559145331382752,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1284157380461693,
      "backward_entropy": 0.013766227130378996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2888782523572445,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02857948262244463,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12833725214004515,
      "backward_entropy": 0.013618796638080053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2856118641793728,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028599331341683864,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12825962752103806,
      "backward_entropy": 0.012683170075927461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2954329073429108,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028618730418384076,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12818217873573304,
      "backward_entropy": 0.012396485518131937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24921122379601002,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028637773357331753,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12810433208942412,
      "backward_entropy": 0.011872974463871548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24517155960202217,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02865628693252802,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12802671194076537,
      "backward_entropy": 0.01176294003214155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24052400086075068,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028674337826669217,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12794940173625946,
      "backward_entropy": 0.012064917598451888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26418148130178454,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02869192436337471,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12787211388349534,
      "backward_entropy": 0.012366775103977748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23385295122861863,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0287091426551342,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12779350206255913,
      "backward_entropy": 0.01358003978218351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22697895467281343,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.02872589062899351,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1277140349149704,
      "backward_entropy": 0.012358683773449489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2292926287278533,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028742193058133126,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12763473391532898,
      "backward_entropy": 0.012025105793561254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23869209866970778,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028758099302649498,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.127554814517498,
      "backward_entropy": 0.012597720697522163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21786813102662564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028773813880980013,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12747385501861572,
      "backward_entropy": 0.011975196642535076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1959710381925106,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02878920193761587,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12739210575819016,
      "backward_entropy": 0.011345201517854418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2007690852507949,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028804180771112443,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12731030434370041,
      "backward_entropy": 0.011779699261699405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1726098509505391,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028818823955953123,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1272281751036644,
      "backward_entropy": 0.011441848906023162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20042369747534394,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028832982853055,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12714600339531898,
      "backward_entropy": 0.010879335233143399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18389395149424673,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028846928477287294,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1270630568265915,
      "backward_entropy": 0.01177525669336319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1683377105742693,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.028860587626695633,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.12697983533143997,
      "backward_entropy": 0.011876552339111055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1601045552175492,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028873890265822412,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.126896932721138,
      "backward_entropy": 0.011309659268174854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15351313119754195,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.028886834159493446,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.12681375592947006,
      "backward_entropy": 0.011937642842531206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1485365112312138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.028899463824927807,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12673100233078002,
      "backward_entropy": 0.01186797437923295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14545725621283054,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02891174890100956,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12664840072393418,
      "backward_entropy": 0.011564961501530238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12651121690869332,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028923797607421874,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12656586468219758,
      "backward_entropy": 0.010987944049494606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15505779054947197,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028935488499701022,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12648375183343888,
      "backward_entropy": 0.011811464492763792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13022873927839101,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028946959227323533,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1264003798365593,
      "backward_entropy": 0.010273555559771401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12916248231194913,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.02895818166434765,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1263170436024666,
      "backward_entropy": 0.011208036435501917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1414542930200696,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028969158977270128,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12623351216316223,
      "backward_entropy": 0.010864820597427233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11332694534212351,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028979912959039213,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12614893913269043,
      "backward_entropy": 0.010561940819025041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12068188921548426,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.028990366496145725,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.12606442123651504,
      "backward_entropy": 0.010687245162469999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10027082590386271,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029000569507479666,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12597975879907608,
      "backward_entropy": 0.01097853934126241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11018723868764937,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029010416008532047,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1258954919874668,
      "backward_entropy": 0.009515386234436716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11036412362009287,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029020071402192114,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12581111565232278,
      "backward_entropy": 0.010876619496515817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09647466130554676,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029029480740427972,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1257262222468853,
      "backward_entropy": 0.010583058212484633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09889384796842933,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.029038619808852674,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.12564197406172753,
      "backward_entropy": 0.011030265742114614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09413495836779476,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029047484509646893,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12555734366178511,
      "backward_entropy": 0.009490449779800006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08474488165229559,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029056157916784286,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12547279447317122,
      "backward_entropy": 0.01000921433525426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08751720343716443,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029064574092626572,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12538881301879884,
      "backward_entropy": 0.010547986360532896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07591268089599908,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029072742722928525,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12530475109815598,
      "backward_entropy": 0.010037342192871229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08090297393500805,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.0290805596858263,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1252211645245552,
      "backward_entropy": 0.010136202509914125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08263586242683232,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029088137671351433,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12513724714517593,
      "backward_entropy": 0.009700124710798261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0744139114394784,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.029095548391342162,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12505269348621367,
      "backward_entropy": 0.010690549441746303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07798765185289085,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029102700762450695,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1249681331217289,
      "backward_entropy": 0.01009992914540427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06638157728593796,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02910966780036688,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12488348856568336,
      "backward_entropy": 0.009971114141600472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07049161077011376,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02911638282239437,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12479971945285798,
      "backward_entropy": 0.009742547784532821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06092205203603953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029122967459261417,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12471622005105018,
      "backward_entropy": 0.010431309470108577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06499391316901892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029129302129149437,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12463326752185822,
      "backward_entropy": 0.010213126455034529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06008029386866838,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029135451093316077,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12455054298043251,
      "backward_entropy": 0.009455419438225882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058680274174548686,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029141399078071117,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12446805983781814,
      "backward_entropy": 0.010483161892209734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06221566339954734,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029147258028388023,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.12438636794686317,
      "backward_entropy": 0.011010681305612837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05224649203009903,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.0291529705747962,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12430417388677598,
      "backward_entropy": 0.010543158969708852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05456527073401958,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029158467799425124,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12422252744436264,
      "backward_entropy": 0.009989753152642932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05738406488671899,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029163852334022522,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12414154335856438,
      "backward_entropy": 0.010159641025321823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05314901296515018,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02916917372494936,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12406079322099686,
      "backward_entropy": 0.010008280245321136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042915358894970265,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029174364171922207,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12398029565811157,
      "backward_entropy": 0.01013668387063912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0473925115307793,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029179326072335244,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.12390088886022568,
      "backward_entropy": 0.009737484582832882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04346424040850252,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029184098914265634,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12382184863090515,
      "backward_entropy": 0.010138585099152156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04928224318427965,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02918868660926819,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12374327629804611,
      "backward_entropy": 0.009392311264361653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03958072853274643,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029193158261477947,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12366459220647812,
      "backward_entropy": 0.009805245537843022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04230485428124666,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029197435453534128,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12358670607209206,
      "backward_entropy": 0.009608969145587514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04185572271235287,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12350947931408882,
      "backward_entropy": 0.008868162280746869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040326725773047654,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02920571994036436,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12343227639794349,
      "backward_entropy": 0.009486897928374153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038916344125755134,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.029209690727293493,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.12335554733872414,
      "backward_entropy": 0.00933260704789843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03374070884892717,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02921357098966837,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12327923849225045,
      "backward_entropy": 0.008603078818746977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03465965677751228,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02921736314892769,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12320399582386017,
      "backward_entropy": 0.00872267915734223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030710884579457344,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.029221018590033055,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12312925904989243,
      "backward_entropy": 0.00999814404972962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03137376030208543,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029224522411823273,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12305520251393318,
      "backward_entropy": 0.00907395945063659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03243021742673591,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029227915219962597,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12298160418868065,
      "backward_entropy": 0.009442728864295142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030324432294582947,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029231247678399085,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12290850207209587,
      "backward_entropy": 0.009851864193167005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028735913708806037,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02923451978713274,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12283603549003601,
      "backward_entropy": 0.00960291192999908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029815502755809575,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029237751103937625,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1227642722427845,
      "backward_entropy": 0.00929629211979253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028596829058369622,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02924090065062046,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1226927861571312,
      "backward_entropy": 0.009335457107850484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02590739342267625,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029243960790336133,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12262165769934655,
      "backward_entropy": 0.009977369968380247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02360726961051114,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029246879741549492,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12255087792873383,
      "backward_entropy": 0.0092942832836083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024513453902909533,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029249604791402817,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12248048335313796,
      "backward_entropy": 0.008786698058247567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025285790144698693,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029252255335450172,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1224106378853321,
      "backward_entropy": 0.00934087990650109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022639329702360555,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.029254868626594543,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12234118133783341,
      "backward_entropy": 0.00951139149921281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021670590178109704,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029257422685623168,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12227250933647156,
      "backward_entropy": 0.009995875667248454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02256979331141338,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029259880259633064,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12220447659492492,
      "backward_entropy": 0.010084785627467292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02280970566207543,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029262311570346356,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12213683575391769,
      "backward_entropy": 0.008516209732208934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01928281084401533,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02926473617553711,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.12206952646374702,
      "backward_entropy": 0.009922592980521065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019778341526398437,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.029267045855522155,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.12200283035635948,
      "backward_entropy": 0.010047599513615882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017994761699810624,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02926928158849478,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12193661034107209,
      "backward_entropy": 0.010634500799434527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019342551642330362,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029271468333899976,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12187134176492691,
      "backward_entropy": 0.009371708173836982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017997088190168143,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.02927360702306032,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.121806550770998,
      "backward_entropy": 0.009550468357545989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01699184252647683,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.029275672510266304,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12174210250377655,
      "backward_entropy": 0.009007782808371953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016833767513162456,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.02927765864878893,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1216783843934536,
      "backward_entropy": 0.009896192061049598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01485200646566227,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02927956935018301,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12161514908075333,
      "backward_entropy": 0.009790086692997389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013806909389677458,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029281408153474332,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12155290246009827,
      "backward_entropy": 0.010104494435446604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015489720940240658,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.0292831527069211,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12149147167801858,
      "backward_entropy": 0.009562587844473974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013749328386620619,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029284882918000223,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12143064141273499,
      "backward_entropy": 0.009094317150967462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013754405954387039,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02928659375756979,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.12137066572904587,
      "backward_entropy": 0.009499076008796691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014835814421530813,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029288255795836448,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.12131132632493973,
      "backward_entropy": 0.009537156458411898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012728975786012597,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029289906099438667,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12125222384929657,
      "backward_entropy": 0.009404204093984195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013086036039749161,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02929151076823473,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.12119380235671998,
      "backward_entropy": 0.00957577968282359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010780508286552503,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02929310258477926,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1211357519030571,
      "backward_entropy": 0.009681603897895134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011546299036126584,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029294603690505027,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12107860073447227,
      "backward_entropy": 0.009158229774662425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01199272472586017,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029296044446527957,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.121022180467844,
      "backward_entropy": 0.008676649523632866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011079291778150946,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02929746899753809,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1209662452340126,
      "backward_entropy": 0.010141280612775257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010051819228101522,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02929885722696781,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12091094478964806,
      "backward_entropy": 0.008487101271748544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010528163105482236,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.029300188273191453,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12085634991526603,
      "backward_entropy": 0.009796262745346342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010021385189611464,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029301486164331435,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.12080238685011864,
      "backward_entropy": 0.009369385561772756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009459009562851861,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.029302749410271646,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.12074893712997437,
      "backward_entropy": 0.009653280835066525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008500865841051563,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029304016195237637,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.120696260035038,
      "backward_entropy": 0.008997102241430964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009288569827913307,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.029305222816765307,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12064430266618728,
      "backward_entropy": 0.00962648248033864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008619159698719158,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02930643446743488,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1205928459763527,
      "backward_entropy": 0.009018177432673316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008498442762356718,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02930761929601431,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12054225951433181,
      "backward_entropy": 0.008894057944416998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008255175878002775,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029308759421110154,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.12049218192696572,
      "backward_entropy": 0.009359002060123852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006987434871552978,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029309873655438422,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12044282332062721,
      "backward_entropy": 0.009236804928098407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007006756879854947,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02931092493236065,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.12039439976215363,
      "backward_entropy": 0.008537661071334567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007205572228122037,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02931193970143795,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12034672647714614,
      "backward_entropy": 0.00881699760045324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006505814363481477,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029312929883599282,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12029956877231598,
      "backward_entropy": 0.009299387144190926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005759327151463367,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02931390833109617,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.12025303915143012,
      "backward_entropy": 0.008448539088879313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006334941281238571,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029314815439283846,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12020731717348099,
      "backward_entropy": 0.009614859893918037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005759135022526607,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02931567095220089,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12016213312745094,
      "backward_entropy": 0.009466684396777834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0058232110168319196,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02931649051606655,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12011772245168686,
      "backward_entropy": 0.0093971206673554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005778417953115423,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02931732255965471,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.12007396966218949,
      "backward_entropy": 0.009007821764264786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005105157947400585,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02931813560426235,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.12003059908747674,
      "backward_entropy": 0.009093769586512021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0052333893167087805,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.029318925552070142,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11998800188302994,
      "backward_entropy": 0.009186318729604993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004862408387998585,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029319709166884422,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1199459545314312,
      "backward_entropy": 0.009160031750798225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005110931825038278,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02932044565677643,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11990448087453842,
      "backward_entropy": 0.00972250694675105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004309735915012425,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029321184381842613,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11986350268125534,
      "backward_entropy": 0.00851891849722181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004496446650591679,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029321898706257343,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11982333287596703,
      "backward_entropy": 0.00898406415113381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004031600199959939,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029322577640414238,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11978369578719139,
      "backward_entropy": 0.008713160402008466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003947859913023421,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029323255829513072,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11974471360445023,
      "backward_entropy": 0.009322020251836096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003811515107372543,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029323936253786088,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11970641165971756,
      "backward_entropy": 0.0083761421165296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00372315959102707,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02932460755109787,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11966874226927757,
      "backward_entropy": 0.008379208083663669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003617066551669268,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029325269162654877,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11963163465261459,
      "backward_entropy": 0.008717360720038415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034885602064605335,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02932592611759901,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11959500536322594,
      "backward_entropy": 0.008008675330451558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033378864944097588,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029326584190130234,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11955886632204056,
      "backward_entropy": 0.008893102354237011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033630180900217966,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.029327239282429217,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11952332779765129,
      "backward_entropy": 0.009726770594716074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002954675702494569,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.029327906668186188,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1194884017109871,
      "backward_entropy": 0.009421173802443913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029178386939747725,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.0293285358697176,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11945409402251243,
      "backward_entropy": 0.007924733683466911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027913395588257117,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0293291587382555,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.11942037642002105,
      "backward_entropy": 0.009808319860271045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002848619122960372,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029329764284193517,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11938729137182236,
      "backward_entropy": 0.009320705596889769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027979293849057286,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02933034934103489,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1193547360599041,
      "backward_entropy": 0.008227582222649028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023954781991051277,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.029330947808921336,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11932265982031823,
      "backward_entropy": 0.0077689254390341895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002477922889011097,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02933152820914984,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11929125711321831,
      "backward_entropy": 0.009178642130323818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023824358078854855,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029332089796662332,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1192603088915348,
      "backward_entropy": 0.009749318552868706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021567516276263634,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02933264523744583,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11922988817095756,
      "backward_entropy": 0.008684305527380535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021500508439203257,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029333182983100413,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11920012459158898,
      "backward_entropy": 0.008818233332463673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002286145033212961,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02933370750397444,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11917090117931366,
      "backward_entropy": 0.009283585739987237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020351074730569963,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029334216564893722,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11914207264780999,
      "backward_entropy": 0.008523227380854741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001817895350905019,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029334707371890544,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11911377534270287,
      "backward_entropy": 0.009131331528936113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018687426971155218,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029335173964500427,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11908597052097321,
      "backward_entropy": 0.008041392107095037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001984090624318924,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02933562230318785,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1190585397183895,
      "backward_entropy": 0.008920901002628465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001719067827798426,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.029336070455610753,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11903142184019089,
      "backward_entropy": 0.00826752143246787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017655304851359687,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0293365066871047,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11900479048490524,
      "backward_entropy": 0.009118444632206643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017128727997260285,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029336928576231002,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1189784862101078,
      "backward_entropy": 0.008350921581898417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016126666843774729,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.02933735102415085,
      "trajectory_length": 9.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.11895257011055946,
      "backward_entropy": 0.007880035255636488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014251310802137595,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02933776341378689,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11892710253596306,
      "backward_entropy": 0.008221290526645525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014088884909142507,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02933817356824875,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11890222355723382,
      "backward_entropy": 0.009510912214006696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001425023654337565,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.0293385723605752,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11887779906392097,
      "backward_entropy": 0.008604975470474788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011936926892303745,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029338978230953217,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11885374188423156,
      "backward_entropy": 0.00989944908235754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012816233587727766,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029339384473860263,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11883028149604798,
      "backward_entropy": 0.008803385123610497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011247792726862826,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02933979853987694,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11880726888775825,
      "backward_entropy": 0.008652078998940332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001154964328634378,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.02934020757675171,
      "trajectory_length": 9.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.11878480687737465,
      "backward_entropy": 0.007589896023273468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010651134263753193,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.029340618662536143,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.11876282542943954,
      "backward_entropy": 0.009610074758529662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011283715235549606,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029341019131243228,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11874127835035324,
      "backward_entropy": 0.00964937460209642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00106516711639415,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029341410845518112,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1187200702726841,
      "backward_entropy": 0.00824201963841915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009431621734620421,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02934180349111557,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11869919523596764,
      "backward_entropy": 0.009355421257870537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009756152408954222,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02934218980371952,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11867872849106789,
      "backward_entropy": 0.008668343030980656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008831143518364115,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02934257797896862,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1186586432158947,
      "backward_entropy": 0.007880365795322825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008302743992317119,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.029342941008508205,
      "trajectory_length": 9.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.11863893494009972,
      "backward_entropy": 0.008082599671823638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008062695126682228,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02934330012649298,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1186196394264698,
      "backward_entropy": 0.00917229290519442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007757305091217858,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02934365961700678,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11860073283314705,
      "backward_entropy": 0.008964889603001732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000786501606580714,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029344016686081886,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1185822144150734,
      "backward_entropy": 0.008729399048856328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006993119252911128,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.029344365932047367,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11856405287981034,
      "backward_entropy": 0.009104066076023239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006217918778929743,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029344699531793594,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11854621097445488,
      "backward_entropy": 0.008707672783306667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000677240280128899,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029345035366714,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11852891817688942,
      "backward_entropy": 0.008496885746717453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006263745426622336,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029345377162098885,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11851194873452187,
      "backward_entropy": 0.008953358978033066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006594137606953154,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.029345694184303283,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.11849533617496491,
      "backward_entropy": 0.008682630902954512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005995614244056924,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02934600319713354,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11847896575927734,
      "backward_entropy": 0.0095165705042226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005792786630991031,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029346295446157456,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11846285760402679,
      "backward_entropy": 0.008940341270395688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005218665059601336,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029346579127013682,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11844704672694206,
      "backward_entropy": 0.009361820721200533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005368853543586738,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02934685070067644,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1184315912425518,
      "backward_entropy": 0.00841680025415761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047465903180636814,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.029347131960093975,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.11841643676161766,
      "backward_entropy": 0.008761076522724969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004626533589544124,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029347410798072814,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11840162053704262,
      "backward_entropy": 0.008310364346419062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004719392629340291,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029347677156329154,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11838706433773041,
      "backward_entropy": 0.008997941176806176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040068522453111654,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0293479286134243,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11837274432182313,
      "backward_entropy": 0.009625399378793581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040186504797929957,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029348174482583998,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11835873201489448,
      "backward_entropy": 0.009036522837621828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003981663850481709,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02934840340167284,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11834504827857018,
      "backward_entropy": 0.008156079639281546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036295331096880545,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029348617792129515,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11833157166838645,
      "backward_entropy": 0.009936900064349174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003450649980095477,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029348824918270112,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11831842362880707,
      "backward_entropy": 0.008371839938419206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032901690728976974,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02934901639819145,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11830552592873574,
      "backward_entropy": 0.007939494720527103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032178303172258893,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02934919819235802,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11829291507601739,
      "backward_entropy": 0.008819170562284333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003152053402573074,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029349375143647195,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11828057691454888,
      "backward_entropy": 0.009402648891721453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002891059833473264,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02934955507516861,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11826852187514306,
      "backward_entropy": 0.008294825042997087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000279373491662227,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.029349732957780362,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11825675889849663,
      "backward_entropy": 0.009058325205530439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002692886760542024,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02934990804642439,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11824525892734528,
      "backward_entropy": 0.007739809368337902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002571099760416473,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029350068792700766,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11823398023843765,
      "backward_entropy": 0.008718932579670633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025653096761288905,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029350226745009422,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11822291240096092,
      "backward_entropy": 0.009093096426555088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002644168326241925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029350377805531024,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11821206286549568,
      "backward_entropy": 0.009163079730101994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022091912012456305,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029350526444613934,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11820137277245521,
      "backward_entropy": 0.007985830785972732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022605155720611947,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029350673966109752,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11819094642996789,
      "backward_entropy": 0.00861626991203853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002097641418913554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029350822046399116,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11818078979849815,
      "backward_entropy": 0.007852543837257793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020750650789977954,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02935097198933363,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11817084550857544,
      "backward_entropy": 0.008798544907144138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019922845640394372,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029351119697093964,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11816108450293542,
      "backward_entropy": 0.009011079370975495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020812549992115236,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029351263120770455,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.11815154477953911,
      "backward_entropy": 0.009307778892772539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017091378156237625,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02935140561312437,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11814217641949654,
      "backward_entropy": 0.009418259348188128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017055933255960554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029351546615362167,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11813305243849755,
      "backward_entropy": 0.008267769270709583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001748130783198576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029351681098341943,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11812413036823273,
      "backward_entropy": 0.008770121527569634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001467368211365283,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02935180775821209,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11811535805463791,
      "backward_entropy": 0.008729816707117219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017012900566442112,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029351937212049962,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11810683459043503,
      "backward_entropy": 0.009447208791971206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001365175342925795,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029352061823010443,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11809845268726349,
      "backward_entropy": 0.00952597755406584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014742524916755428,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02935218270868063,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11809025406837463,
      "backward_entropy": 0.008214272824781283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014405677054583066,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029352299124002456,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11808220222592354,
      "backward_entropy": 0.008844656124711036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012960834475279627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.029352406039834023,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11807426139712333,
      "backward_entropy": 0.008889033911483627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011557301610309878,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029352506063878535,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11806654408574105,
      "backward_entropy": 0.009319644474557468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011159876465853813,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02935260273516178,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11805902421474457,
      "backward_entropy": 0.008014585077762603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010590235059453335,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029352698288857938,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11805172637104988,
      "backward_entropy": 0.007601601098264967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010486022945315199,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029352791793644428,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1180446207523346,
      "backward_entropy": 0.007911960088780947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010243932922548993,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02935288045555353,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11803765222430229,
      "backward_entropy": 0.008810038704957283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.742046272549487e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02935296408832073,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11803081929683686,
      "backward_entropy": 0.008231187824692045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.697209302430564e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029353049769997596,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11802412346005439,
      "backward_entropy": 0.00934817088501794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.170513291361203e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02935313545167446,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11801760122179986,
      "backward_entropy": 0.009276756324938367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.550870407726506e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029353222250938414,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1180112563073635,
      "backward_entropy": 0.008167209369795663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.21905825344038e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02935330793261528,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1180050551891327,
      "backward_entropy": 0.0077109475220952725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.164011996110275e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029353396594524385,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11799902841448784,
      "backward_entropy": 0.00799543687275478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.377067800575787e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029353480972349643,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11799314618110657,
      "backward_entropy": 0.008731567274246895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.195443305045956e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.029353566467761993,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11798739284276963,
      "backward_entropy": 0.009169697548661914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.268894653658209e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029353648982942106,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11798177883028985,
      "backward_entropy": 0.00797591959791524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.211746314761512e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02935372795909643,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11797629222273827,
      "backward_entropy": 0.008736040656055722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7967386771906605e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029353803396224974,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11797094196081162,
      "backward_entropy": 0.00877933284001691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5528690859318884e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0293538773432374,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11796571537852288,
      "backward_entropy": 0.009509015828371048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.158256749382417e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029353947006165983,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11796062290668488,
      "backward_entropy": 0.008246588334441186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.370131827930891e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029354017786681653,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1179556556046009,
      "backward_entropy": 0.008877750007169586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.899682325003596e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029354084841907026,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1179507963359356,
      "backward_entropy": 0.009271275092448506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.935717721537003e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02935415245592594,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1179460570216179,
      "backward_entropy": 0.008225541242531368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4946751157226575e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029354216530919075,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11794140934944153,
      "backward_entropy": 0.008477766332881793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.592619765162453e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029354281909763812,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11793687865138054,
      "backward_entropy": 0.008100349988256181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4056169647888056e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029354342259466648,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11793243139982224,
      "backward_entropy": 0.00785853091095175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.956400849460806e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029354399256408214,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11792807579040528,
      "backward_entropy": 0.008474336511322431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8898918518270875e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029354455508291723,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1179238200187683,
      "backward_entropy": 0.00937750775899206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.911940454770502e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02935451064258814,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11791965886950492,
      "backward_entropy": 0.00887953218604837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4005827760097415e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029354566149413584,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11791557595133781,
      "backward_entropy": 0.008421498111316136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6780009543235793e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029354621097445487,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11791160628199578,
      "backward_entropy": 0.008482709420578822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2613764025768434e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02935467567294836,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11790769323706626,
      "backward_entropy": 0.007985785922833853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2110630669990314e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.029354732111096384,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11790385320782662,
      "backward_entropy": 0.008388207746403557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9989352111670086e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02935478538274765,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11790009886026383,
      "backward_entropy": 0.008165260989751134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7051792307020152e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029354838840663432,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11789642125368119,
      "backward_entropy": 0.0077674036047288356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.406198442628238e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02935489099472761,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11789284944534302,
      "backward_entropy": 0.009398156085184642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5349890880477232e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029354941099882126,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11788939237594605,
      "backward_entropy": 0.009105067806584495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2578697341657515e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029354988038539885,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11788600534200669,
      "backward_entropy": 0.008165851128952845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1423574963819192e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029355032742023467,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11788270696997642,
      "backward_entropy": 0.007967367448977062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1300940208845986e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.029355077445507048,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11787952333688737,
      "backward_entropy": 0.007738959842494557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1766858438354575e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029355123825371265,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11787642985582351,
      "backward_entropy": 0.008186352572270801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8538909377241452e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029355169646441935,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11787340939044952,
      "backward_entropy": 0.008196576897587095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.00738967564007e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029355216212570666,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11787048131227493,
      "backward_entropy": 0.009140911006501742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8348481683005956e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02935526315122843,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11786759942770005,
      "backward_entropy": 0.009130717973623956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.761176143730836e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029355308413505553,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11786481365561485,
      "backward_entropy": 0.008799823799303599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7269313092072024e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029355353116989134,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11786209121346473,
      "backward_entropy": 0.008815724668758256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5165264149175072e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.029355396516621113,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11785942688584328,
      "backward_entropy": 0.008966088614293505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5167643771718531e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029355438053607942,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11785683780908585,
      "backward_entropy": 0.008760542954717364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6371547590665615e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029355477541685104,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1178543098270893,
      "backward_entropy": 0.007931050019604818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2274313043292295e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029355514235794543,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11785182356834412,
      "backward_entropy": 0.008631436526775362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4323491079437645e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029355551674962045,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11784942075610161,
      "backward_entropy": 0.008728827057140214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2072288130582365e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.029355587810277937,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.11784706860780716,
      "backward_entropy": 0.009050657280853818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.222039467663194e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029355624690651894,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11784478127956391,
      "backward_entropy": 0.008674679909433637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1578829271741142e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029355658777058126,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1178425446152687,
      "backward_entropy": 0.008408456402165549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1110065051411766e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02935569081455469,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11784035712480545,
      "backward_entropy": 0.008161898170198714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.032611563118735e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0293557221069932,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11783822923898697,
      "backward_entropy": 0.009291547164320946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.762172394938262e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029355753026902676,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11783613711595535,
      "backward_entropy": 0.008257143305880683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.628002887041021e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.029355784133076667,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11783411875367164,
      "backward_entropy": 0.008522039917962892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.283675510829425e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029355813376605512,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11783214062452316,
      "backward_entropy": 0.008417890114443643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.146322269515395e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029355841875076293,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11783019974827766,
      "backward_entropy": 0.008409513905644418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.131030125468896e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029355869628489017,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11782829090952873,
      "backward_entropy": 0.007986355626157352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.571791954319451e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029355895705521107,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11782642304897309,
      "backward_entropy": 0.008660968126995221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.967565024496025e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029355922527611256,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1178245984017849,
      "backward_entropy": 0.009194401811276164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.878360593276511e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02935594953596592,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11782281696796418,
      "backward_entropy": 0.008971635837640081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.80822242142176e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.029355975799262524,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11782109066843986,
      "backward_entropy": 0.009129911927240237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.949220270551336e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029356002807617188,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11781941130757331,
      "backward_entropy": 0.009007576959473745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.665201953381938e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029356028884649277,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11781778335571289,
      "backward_entropy": 0.009212264312165125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.50739517564125e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.029356054216623306,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11781618297100067,
      "backward_entropy": 0.008279292657971383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.265475551003874e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029356079548597334,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11781464293599128,
      "backward_entropy": 0.008371677622199059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756493644819671e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0293561028316617,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11781313195824623,
      "backward_entropy": 0.00894287015710558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.61174321234148e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029356125555932523,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11781166195869446,
      "backward_entropy": 0.008897567380751882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.916851567493552e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.029356145672500132,
      "trajectory_length": 9.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.11781021654605865,
      "backward_entropy": 0.0074521572994334356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.15344586435873e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.029356164298951624,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.11780881360173226,
      "backward_entropy": 0.00992706801210131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.67985658154646e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.029356181435287,
      "trajectory_length": 9.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.11780743822455406,
      "backward_entropy": 0.007607766400490488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.095616306187822e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02935619615018368,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11780609115958214,
      "backward_entropy": 0.00848198016839368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.217543818185732e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.02935621067881584,
      "trajectory_length": 9.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.11780479326844215,
      "backward_entropy": 0.009916764657412256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.19293461959569e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.029356225021183492,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11780353337526321,
      "backward_entropy": 0.008484408365828651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6876374011285407e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029356237687170505,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11780229136347771,
      "backward_entropy": 0.008429338091186116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.863401479087258e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356250539422035,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11780108064413071,
      "backward_entropy": 0.008747883620006697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3579754635582048e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02935626283288002,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11779990121722221,
      "backward_entropy": 0.008892080986074037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.282549079841601e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029356274753808975,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11779874488711357,
      "backward_entropy": 0.008326837473681995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4389218392050226e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029356285370886324,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11779762357473374,
      "backward_entropy": 0.008732300943561961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.755559852829492e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02935629542917013,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11779653429985046,
      "backward_entropy": 0.00801457901086126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.846913583276489e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.029356305673718452,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1177954763174057,
      "backward_entropy": 0.00954660044184753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7026959443787746e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029356315918266773,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11779445111751556,
      "backward_entropy": 0.008474891153829437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5627922667581516e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.029356326162815093,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11779344081878662,
      "backward_entropy": 0.009185590754662243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.737470472879977e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029356336779892446,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11779246926307678,
      "backward_entropy": 0.008806894240634782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.116943233687607e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029356346279382706,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11779151409864426,
      "backward_entropy": 0.007370458543300628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.523494364936596e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02935635596513748,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11779058873653411,
      "backward_entropy": 0.008287070212619645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.986066608594683e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029356365092098713,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11778968051075936,
      "backward_entropy": 0.008898085568632396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.940597372396269e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029356374591588973,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11778880208730698,
      "backward_entropy": 0.008686634578875132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8760214548052545e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.029356383346021177,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1177879311144352,
      "backward_entropy": 0.00866111580814634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8462141646580221e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029356391914188863,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11778709217905999,
      "backward_entropy": 0.009721993069563593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.610621447412086e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02935640048235655,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11778627336025238,
      "backward_entropy": 0.009056557289191653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7254929581156375e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02935640849173069,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.11778548210859299,
      "backward_entropy": 0.009602192736097744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6929451135183625e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029356415569782256,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11778470650315284,
      "backward_entropy": 0.00858111253806523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5518998306873754e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029356421902775764,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11778395548462868,
      "backward_entropy": 0.008247326633759908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.491527994090802e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02935642786324024,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11778321862220764,
      "backward_entropy": 0.0093211795602526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4617884755097067e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02935643345117569,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1177824966609478,
      "backward_entropy": 0.008141284169895308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2894426211218502e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029356439039111136,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11778180375695228,
      "backward_entropy": 0.008719345767583165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3576885901755987e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029356443881988527,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11778112351894379,
      "backward_entropy": 0.00814552115542548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2122945507453409e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0293564485386014,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11778045743703842,
      "backward_entropy": 0.009001672640442849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2522960858518673e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029356452636420727,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11777980402112007,
      "backward_entropy": 0.008685716401253426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1281886880709635e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029356455989181997,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11777916625142097,
      "backward_entropy": 0.009279458331210274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2407510062928396e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356459341943263,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11777853891253472,
      "backward_entropy": 0.008456663840583393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0577327822058891e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.0293564610183239,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11777792647480964,
      "backward_entropy": 0.007826007264001029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.134237245689292e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.029356463439762594,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11777732595801353,
      "backward_entropy": 0.009247326318706785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.015342380929269e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02935646567493677,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11777675226330757,
      "backward_entropy": 0.007872216084173747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.554104108744354e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.029356468841433524,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11777619644999504,
      "backward_entropy": 0.00804601503270013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.431895826888081e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029356471821665765,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.11777564585208893,
      "backward_entropy": 0.009318449720740318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.669196840254244e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029356474801898003,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11777511313557625,
      "backward_entropy": 0.00782574542931148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.814350363981703e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356477595865727,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11777459681034089,
      "backward_entropy": 0.008542600220867565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.164076892607341e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02935648113489151,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11777410209178925,
      "backward_entropy": 0.008504040432827814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.038393306402213e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02935648411512375,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11777361258864402,
      "backward_entropy": 0.008377032886658397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8476476897672e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029356487095355988,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11777313798666,
      "backward_entropy": 0.008900553892765726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.454251176180037e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.029356489703059197,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11777267530560494,
      "backward_entropy": 0.00911721656365054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.191091517810833e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029356492683291435,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.117772226780653,
      "backward_entropy": 0.008118652020181928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.338033277624277e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.029356494545936584,
      "trajectory_length": 9.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.11777178570628166,
      "backward_entropy": 0.00987438059278897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.988464842232588e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.029356496408581734,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11777136027812958,
      "backward_entropy": 0.009287917188235692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.928708085216726e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02935649864375591,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11777094006538391,
      "backward_entropy": 0.009147931262850762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.853772082924479e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02935650069266558,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11777053475379944,
      "backward_entropy": 0.008658617947782788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6743250265990354e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029356502555310728,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11777014508843422,
      "backward_entropy": 0.008822911392365183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.605755449915705e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02935650423169136,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11776977181434631,
      "backward_entropy": 0.00797666699758598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.615507876337688e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029356506280601026,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1177693985402584,
      "backward_entropy": 0.009036964869924955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.817079582191241e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029356507770717143,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11776903495192528,
      "backward_entropy": 0.008655648465667451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.889610098894991e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356509633362293,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776868030428886,
      "backward_entropy": 0.007942863500544002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6854785498974254e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029356512054800988,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11776834055781364,
      "backward_entropy": 0.008178344581808362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.981972124478261e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.029356514289975166,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11776800975203514,
      "backward_entropy": 0.008842976178441729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.383667793954714e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02935651671141386,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11776768192648887,
      "backward_entropy": 0.008688797801733017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.745710062119656e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.029356519505381585,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11776736453175544,
      "backward_entropy": 0.010172316378780775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5867933974031984e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356521926820277,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776705235242843,
      "backward_entropy": 0.007897879236510821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.025788013033548e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029356524161994458,
      "trajectory_length": 9.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.11776675060391426,
      "backward_entropy": 0.009899831669671195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5602954991654767e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029356526397168636,
      "trajectory_length": 9.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.11776645854115486,
      "backward_entropy": 0.008080369287303516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4912703580071136e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.0293565284460783,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776616796851158,
      "backward_entropy": 0.008238642769200461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.865278084129841e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02935653068125248,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11776588931679725,
      "backward_entropy": 0.008077252709439823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1939596734910082e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.029356533102691172,
      "trajectory_length": 9.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.11776561439037322,
      "backward_entropy": 0.008796027675271035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4468777457542503e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02935653515160084,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776535362005233,
      "backward_entropy": 0.008571829380733626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3113117180173505e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02935653757303953,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11776509508490562,
      "backward_entropy": 0.007980454180921828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0644451943496732e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02935653943568468,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11776484474539757,
      "backward_entropy": 0.009508190889443671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.939521689919843e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029356541484594344,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11776460558176041,
      "backward_entropy": 0.008972505586487906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8271006183567806e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02935654353350401,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11776437088847161,
      "backward_entropy": 0.009594549824084555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8551004288269723e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356545582413674,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776414215564728,
      "backward_entropy": 0.007924058341554234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8066357476698158e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02935654707252979,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11776392608880996,
      "backward_entropy": 0.00797058716416359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5387466500982327e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02935654893517494,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.11776370778679848,
      "backward_entropy": 0.008343948477080892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6146636987457442e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029356551170349122,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11776350066065788,
      "backward_entropy": 0.008440233500940458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3624416546065276e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0293565534055233,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11776329725980758,
      "backward_entropy": 0.00963107437959739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4177211298260773e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029356555826961995,
      "trajectory_length": 9.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.11776310428977013,
      "backward_entropy": 0.008069234394601414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5309340390956548e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.029356558248400687,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11776290535926819,
      "backward_entropy": 0.007996800754751478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3157626010951162e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029356560297310354,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1177627183496952,
      "backward_entropy": 0.008446652601872173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4020806347048164e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.029356562346220017,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.11776253432035447,
      "backward_entropy": 0.009376469414149012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4126542531300855e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.029356563836336134,
      "trajectory_length": 9.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.11776235327124596,
      "backward_entropy": 0.010064910405448504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1975904978811514e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02935656514018774,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776217594742774,
      "backward_entropy": 0.008162160111325128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.277512351904875e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02935656625777483,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11776200458407401,
      "backward_entropy": 0.008397352589028222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1815600533537918e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02935656737536192,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11776182875037193,
      "backward_entropy": 0.007983589065926415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0311999236733982e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356568492949008,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776166334748268,
      "backward_entropy": 0.008155319360750061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0763165221305826e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.0293565696105361,
      "trajectory_length": 9.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.11776150092482567,
      "backward_entropy": 0.007961733426366533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.899850350019278e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02935657072812319,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11776134371757507,
      "backward_entropy": 0.008772420936397145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.530660036143445e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029356571845710278,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1177611880004406,
      "backward_entropy": 0.008227489782231194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.274929286817724e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029356572963297366,
      "trajectory_length": 9.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.11776103153824806,
      "backward_entropy": 0.00924761795571872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.201088324000238e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029356574080884455,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776088401675225,
      "backward_entropy": 0.00823838540485927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.111743522969505e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029356575198471548,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11776074320077896,
      "backward_entropy": 0.008614499068685942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.18809856689495e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029356576129794122,
      "trajectory_length": 9.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.11776060312986374,
      "backward_entropy": 0.009163530756320272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.124167235554978e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.02935657724738121,
      "trajectory_length": 9.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.11776046678423882,
      "backward_entropy": 0.008531842966164863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.53467706612787e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.029356578178703786,
      "trajectory_length": 9.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.11776033341884613,
      "backward_entropy": 0.008692021295428277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.514616745472267e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02935657911002636,
      "trajectory_length": 9.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1177602045238018,
      "backward_entropy": 0.009268667761768615,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.4328912504026902e-06,
    "avg_log_Z": 0.029356435548514127,
    "success_rate": 1.0,
    "avg_reward": 47.92,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.14800000000000002,
      "1": 0.26399999999999996,
      "2": 0.588
    },
    "avg_forward_entropy": 0.11777841074019671,
    "avg_backward_entropy": 0.008668821057038647,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}