{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07664142714606391,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07664142714606391,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07664142714606391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07664142714606391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07664142714606391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07664142714606391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07669121689266628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07664142714606391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.386341094970703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967011451721191,
      "backward_entropy": 0.07677051093843248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.116942405700684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966775417327881,
      "backward_entropy": 0.07668258746465047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.113241195678711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019996354239992797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966529846191406,
      "backward_entropy": 0.0766735937860277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.187877655029297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00029991619521752,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966277122497559,
      "backward_entropy": 0.0767555766635471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.291993141174316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003998854663223028,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966013669967652,
      "backward_entropy": 0.07661530706617567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.444436073303223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004998742369934916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965754985809326,
      "backward_entropy": 0.07674541738298205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.704401016235352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005999229033477604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965504646301269,
      "backward_entropy": 0.07674023177888659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.095172882080078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000700071279425174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096524715423584,
      "backward_entropy": 0.07662660545772976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.540303230285645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008001363021321595,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096498727798462,
      "backward_entropy": 0.07661679718229505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.110530853271484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009002441656775773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964729785919189,
      "backward_entropy": 0.07672428422504002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.502745628356934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0010005541844293475,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964460372924804,
      "backward_entropy": 0.07657391495174831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.89633846282959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011008591391146183,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964208841323853,
      "backward_entropy": 0.07656674914889866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.660393714904785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012009855126962066,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963948965072631,
      "backward_entropy": 0.07655945751402113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.937430381774902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013008741661906242,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096369743347168,
      "backward_entropy": 0.07656701405843098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.286050796508789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014009567676112056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096344232559204,
      "backward_entropy": 0.07655706670549181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.174233436584473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015007093315944076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963177680969238,
      "backward_entropy": 0.07669054137335883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.21866226196289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016004395438358188,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962923765182495,
      "backward_entropy": 0.07653670178519355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.877089500427246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017002006061375141,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962656736373902,
      "backward_entropy": 0.07652636369069417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.796751022338867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017998752882704139,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962381362915039,
      "backward_entropy": 0.07667266660266453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.63953685760498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018994437996298075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962101221084594,
      "backward_entropy": 0.07666654719246759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.559592247009277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019988548010587692,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961829423904419,
      "backward_entropy": 0.07666035493214925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.23004150390625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020980974659323692,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961594581604003,
      "backward_entropy": 0.07665407657623291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.890152931213379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021974355913698673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961363315582276,
      "backward_entropy": 0.07664771212471856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955686569213867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002296736929565668,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961135625839233,
      "backward_entropy": 0.0766412549548679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.449790954589844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002395672257989645,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960921049118041,
      "backward_entropy": 0.07645036114586724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.516709327697754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002494859043508768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960688591003417,
      "backward_entropy": 0.07643912235895793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.112589836120605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002593929646536708,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960447788238525,
      "backward_entropy": 0.07642759217156304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587751388549805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002693481743335724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960184335708618,
      "backward_entropy": 0.07661443286471897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.692728996276855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002792902523651719,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959911346435547,
      "backward_entropy": 0.07660738627115886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.094733238220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028926036320626736,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959630012512207,
      "backward_entropy": 0.07642840014563666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.017088890075684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002991946879774332,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959357023239136,
      "backward_entropy": 0.07641984356774224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.860868453979492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030913299415260553,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959079265594482,
      "backward_entropy": 0.07636737823486328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.267043113708496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00319067295640707,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958807468414307,
      "backward_entropy": 0.07640230655670166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.674015045166016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0032901496160775423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958532094955445,
      "backward_entropy": 0.07657013999091254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.338403701782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0033895184751600027,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958256721496581,
      "backward_entropy": 0.07638408078087701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.33556842803955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003488659393042326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957984924316407,
      "backward_entropy": 0.07655317915810479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66457462310791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003587600775063038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957715511322022,
      "backward_entropy": 0.07654417885674371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.759108543395996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036865032743662596,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10957444906234741,
      "backward_entropy": 0.07635434468587239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.238040924072266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037857936695218086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957167148590088,
      "backward_entropy": 0.07652544975280762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.757442474365234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003885634709149599,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10956861972808837,
      "backward_entropy": 0.07651573419570923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.338756561279297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00398534070700407,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095656156539917,
      "backward_entropy": 0.0765058199564616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.902111053466797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004085161257535219,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956284999847413,
      "backward_entropy": 0.07623657915327284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.406012535095215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004184926860034466,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956013202667236,
      "backward_entropy": 0.07622257868448894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.62945556640625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004284838680177927,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095572829246521,
      "backward_entropy": 0.07647481229570177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.472823143005371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004384997766464949,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955426692962647,
      "backward_entropy": 0.07646373907725017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.392098426818848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0044852932915091515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955111980438233,
      "backward_entropy": 0.07645226849450006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.791582107543945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004585666581988335,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10954790115356446,
      "backward_entropy": 0.07625622219509548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.306378364562988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004686285741627216,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10954452753067016,
      "backward_entropy": 0.07624449994828966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.032432556152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004786898847669363,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10954111814498901,
      "backward_entropy": 0.07623255252838135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.448203086853027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004887823015451431,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095375657081604,
      "backward_entropy": 0.07611788643731011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.92170524597168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004988780710846186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10953390598297119,
      "backward_entropy": 0.07610195875167847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.111504554748535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005089986603707075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10952999591827392,
      "backward_entropy": 0.07637817992104425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.258430480957031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005191044416278601,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10952605009078979,
      "backward_entropy": 0.07636494106716579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.702364921569824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005292448680847883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952198505401611,
      "backward_entropy": 0.0760523345735338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.173288345336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0053930822759866714,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951812267303467,
      "backward_entropy": 0.07615624533759223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.092748641967773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0054936655797064304,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951414108276367,
      "backward_entropy": 0.07601744598812527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.260687828063965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005594159942120314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095100998878479,
      "backward_entropy": 0.07631005181206597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.091065406799316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005694632418453693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10950607061386108,
      "backward_entropy": 0.07629626327090794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.297229766845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005794615019112825,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950207710266113,
      "backward_entropy": 0.07610080639521281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.331931114196777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005895102862268686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949784517288208,
      "backward_entropy": 0.07626797093285455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.563547134399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0059951962903141975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094936490058899,
      "backward_entropy": 0.07607157362831964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.798317909240723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00609545037150383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948938131332397,
      "backward_entropy": 0.07589881949954563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.477140426635742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006195563357323408,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1094849705696106,
      "backward_entropy": 0.07587636841668023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.206432342529297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0062957885675132275,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948073863983154,
      "backward_entropy": 0.0758538047472636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.237786293029785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006396034732460976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10947647094726562,
      "backward_entropy": 0.0761925180753072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.479564666748047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006495858076959848,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10947232246398926,
      "backward_entropy": 0.07617712020874023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.079585075378418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0065954080782830715,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946820974349976,
      "backward_entropy": 0.07616174221038818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69784927368164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006694522686302662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946427583694458,
      "backward_entropy": 0.0761461787753635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.938323020935059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0067935725674033165,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946023464202881,
      "backward_entropy": 0.07573268148634169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.933870315551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006892669480293989,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945607423782348,
      "backward_entropy": 0.07592502567503187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.309319496154785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006991807371377945,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1094517707824707,
      "backward_entropy": 0.07567998435762194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630785942077637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007090657018125057,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10944766998291015,
      "backward_entropy": 0.07588884565565321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.376694679260254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0071890042163431644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10944364070892335,
      "backward_entropy": 0.07606388462914361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.252760887145996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007287194952368736,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1094396710395813,
      "backward_entropy": 0.0755969418419732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.443683624267578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007385651580989361,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943557024002075,
      "backward_entropy": 0.07556849055820042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.906929969787598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007483983878046274,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943140983581542,
      "backward_entropy": 0.07581255171034071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72591781616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0075824446976184845,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942698717117309,
      "backward_entropy": 0.07579272323184544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.214693069458008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007680434733629227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10942287445068359,
      "backward_entropy": 0.07597471608055963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.178019523620605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0077787418849766254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941836833953858,
      "backward_entropy": 0.07595582803090413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.906198501586914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007877752184867859,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941342115402222,
      "backward_entropy": 0.0759365161259969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.176606178283691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007976788096129894,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940858125686645,
      "backward_entropy": 0.07571014430787829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.470051765441895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008075527846813202,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10940382480621338,
      "backward_entropy": 0.07536020543840197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.521796226501465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00817418098449707,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939890146255493,
      "backward_entropy": 0.07566662629445393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.553157806396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008273199200630188,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939412117004395,
      "backward_entropy": 0.07564432091183132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.584249496459961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008372115902602673,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938941240310669,
      "backward_entropy": 0.07526590426762898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.229333877563477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008471410721540451,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938444137573242,
      "backward_entropy": 0.07580897543165419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.72014331817627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008570420555770397,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937952995300293,
      "backward_entropy": 0.0751981602774726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.343864440917969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008669884875416756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093742847442627,
      "backward_entropy": 0.07576262288623387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.933032989501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00876952987164259,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936896800994873,
      "backward_entropy": 0.07552053531010945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.68836498260498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008869166485965252,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936362743377685,
      "backward_entropy": 0.07571421729193793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.370478630065918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008968686684966087,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935822725296021,
      "backward_entropy": 0.07568927605946858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.677348136901855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009067950770258904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935293436050415,
      "backward_entropy": 0.07501804828643799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.074085235595703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009167136624455452,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934760570526122,
      "backward_entropy": 0.07498019271426731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.690332412719727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00926641933619976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934211015701294,
      "backward_entropy": 0.07561182975769043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.151482582092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009366088546812534,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933631658554077,
      "backward_entropy": 0.07534888055589464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.201720237731934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009465815499424934,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933040380477906,
      "backward_entropy": 0.07531852192348903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.81495189666748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009565663523972034,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10932433605194092,
      "backward_entropy": 0.07482585642072889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.733575820922852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009665917605161667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093179702758789,
      "backward_entropy": 0.0747857756084866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.78265380859375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009766485542058945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093112587928772,
      "backward_entropy": 0.07547283834881252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.085260391235352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009866905398666859,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10930449962615967,
      "backward_entropy": 0.07470305760701497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.092839241027832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009966842830181122,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10929793119430542,
      "backward_entropy": 0.0751466088824802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.851033210754395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010066818445920944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10929125547409058,
      "backward_entropy": 0.0746164321899414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.375760078430176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010166719555854797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10928453207015991,
      "backward_entropy": 0.0745719936158922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.74987506866455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010266337543725967,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10927791595458984,
      "backward_entropy": 0.07503410180409749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.363237380981445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010365897789597511,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10927119255065917,
      "backward_entropy": 0.07447856664657593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.123778343200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010465207509696484,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10926448106765747,
      "backward_entropy": 0.07495427131652832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.656271934509277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010564184747636318,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925788879394531,
      "backward_entropy": 0.07437854342990452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.430315017700195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010663121938705444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10925122499465942,
      "backward_entropy": 0.07518329885270861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79988956451416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010761886835098267,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1092444658279419,
      "backward_entropy": 0.07514792680740356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.403158187866211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010860219597816467,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10923795700073242,
      "backward_entropy": 0.07421117358737522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.555059432983398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010958469472825527,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10923138856887818,
      "backward_entropy": 0.07507511642244127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.547797203063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011056706309318542,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10922467708587646,
      "backward_entropy": 0.07469244798024495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471482276916504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011154929175972939,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10921783447265625,
      "backward_entropy": 0.07403170400195652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6961088180542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01125261839479208,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092113971710205,
      "backward_entropy": 0.07459733221266004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.611531257629395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011349937878549099,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10920522212982178,
      "backward_entropy": 0.07390532228681776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.80005168914795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011447354219853878,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10919890403747559,
      "backward_entropy": 0.07488053374820286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.122650146484375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011545492336153984,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10919125080108642,
      "backward_entropy": 0.0737747351328532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.056642532348633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01164345070719719,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10918351411819457,
      "backward_entropy": 0.07439478900697497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.422209739685059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011741173453629017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10917593240737915,
      "backward_entropy": 0.07434145609537761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.557662010192871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01183888129889965,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10916813611984252,
      "backward_entropy": 0.07428717613220215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.634291648864746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011936664581298828,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091599702835083,
      "backward_entropy": 0.07423181666268243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.168992042541504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012034530751407146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10915150642395019,
      "backward_entropy": 0.0746199819776747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.691688537597656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012132253497838974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10914304256439208,
      "backward_entropy": 0.07335207197401258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.853472709655762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012229660525918007,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10913481712341308,
      "backward_entropy": 0.0732763475841946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.754510879516602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012326817028224468,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1091267704963684,
      "backward_entropy": 0.0744783944553799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.639252662658691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01242417749017477,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10911829471588134,
      "backward_entropy": 0.07312171326743232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.04207706451416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012522172182798386,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10910897254943848,
      "backward_entropy": 0.07386334074868096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.381200790405273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012619983404874802,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10909974575042725,
      "backward_entropy": 0.07379611333211263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.34666919708252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012717248871922493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909109115600586,
      "backward_entropy": 0.07427585124969482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31139087677002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012814080342650414,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10908297300338746,
      "backward_entropy": 0.0736566252178616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.794002532958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012910997495055199,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1090746283531189,
      "backward_entropy": 0.0735846757888794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.2623872756958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013007700443267822,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10906648635864258,
      "backward_entropy": 0.07411313056945801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.396601676940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013104970566928387,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1090573787689209,
      "backward_entropy": 0.07405645317501491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.752396583557129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013201814144849777,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10904873609542846,
      "backward_entropy": 0.07399886184268528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.462685585021973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01329847238957882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10904018878936768,
      "backward_entropy": 0.07394017113579644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.90146255493164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01339478138834238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1090320348739624,
      "backward_entropy": 0.07388056649102105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.32436752319336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013490991666913033,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10902388095855713,
      "backward_entropy": 0.07381986247168647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.434576034545898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013587353751063347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1090153694152832,
      "backward_entropy": 0.07375878757900661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.664754867553711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01368339080363512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10900725126266479,
      "backward_entropy": 0.07369685173034668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.291449546813965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01377979014068842,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10899816751480103,
      "backward_entropy": 0.07180404663085938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4581880569458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013876313343644142,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10898879766464234,
      "backward_entropy": 0.07169410255220202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42172622680664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01397255714982748,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10897977352142334,
      "backward_entropy": 0.07268277141782972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.213534355163574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014068998396396637,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.108970308303833,
      "backward_entropy": 0.07258988751305474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.711870193481445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014166022650897503,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1089597225189209,
      "backward_entropy": 0.07249527507358128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.230988502502441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014263822697103024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10894792079925537,
      "backward_entropy": 0.07327728139029609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.197278022766113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014361578971147537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10893607139587402,
      "backward_entropy": 0.07230044735802545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.493683815002441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014458772726356983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10892491340637207,
      "backward_entropy": 0.07312417030334473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.038494110107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014556129463016987,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10891355276107788,
      "backward_entropy": 0.07209665245480007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.68606185913086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014652867801487446,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10890321731567383,
      "backward_entropy": 0.07073664665222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.739142417907715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014749916270375252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10889208316802979,
      "backward_entropy": 0.07060646348529392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.078295707702637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014847280457615852,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10888004302978516,
      "backward_entropy": 0.0704733861817254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.4224214553833,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014945116825401783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1088668704032898,
      "backward_entropy": 0.07033762666914198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314652442932129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015043023973703384,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10885322093963623,
      "backward_entropy": 0.07155143552356297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100467681884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015140451490879059,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1088404655456543,
      "backward_entropy": 0.07143648465474446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.305258750915527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015237311832606792,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10882859230041504,
      "backward_entropy": 0.07131888469060262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.944536209106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015333767049014568,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10881726741790772,
      "backward_entropy": 0.07119876808590359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646225929260254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015430177561938763,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10880551338195801,
      "backward_entropy": 0.06961648994021946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.414763450622559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015526391565799713,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10879381895065307,
      "backward_entropy": 0.07218574815326267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.532305717468262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015622315928339958,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10878252983093262,
      "backward_entropy": 0.06931262546115452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95007610321045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015718065202236176,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10877143144607544,
      "backward_entropy": 0.07069451279110378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.300626754760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01581386663019657,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10875988006591797,
      "backward_entropy": 0.07056215074327257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.486659049987793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01590988039970398,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10874749422073364,
      "backward_entropy": 0.06883844402101305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.909682750701904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01600569300353527,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10873525142669678,
      "backward_entropy": 0.07029211521148682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9501371383667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016101015731692314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10872392654418946,
      "backward_entropy": 0.07159409258100721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.212682723999023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01619645580649376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.108711838722229,
      "backward_entropy": 0.07148888376024035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.408857345581055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01629214733839035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10869879722595215,
      "backward_entropy": 0.06816151407029894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.171120643615723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016388162970542908,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10868465900421143,
      "backward_entropy": 0.07127149899800618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.323150634765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016483861953020096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10867114067077636,
      "backward_entropy": 0.06779810455110338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.585551261901855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016579309478402138,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10865790843963623,
      "backward_entropy": 0.06941843032836914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.672323226928711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016675172373652458,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10864324569702148,
      "backward_entropy": 0.06742197275161743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.885706901550293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016771508380770683,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1086270570755005,
      "backward_entropy": 0.07080745697021484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.250535011291504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016867849975824356,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10861048698425294,
      "backward_entropy": 0.07068378395504421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3845930099487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016963843256235123,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10859467983245849,
      "backward_entropy": 0.06876617007785374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9376301765441895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01705908589065075,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10858104228973389,
      "backward_entropy": 0.06662767463260227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.044330596923828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01715392805635929,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10856812000274658,
      "backward_entropy": 0.07029950618743896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99310302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0172484889626503,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10855557918548583,
      "backward_entropy": 0.06823811928431193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.668601989746094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01734330877661705,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10854169130325317,
      "backward_entropy": 0.06599089834425184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.193551063537598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017437638714909554,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10852895975112915,
      "backward_entropy": 0.06786909368303087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.567850112915039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017531823366880417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1085162878036499,
      "backward_entropy": 0.06974551412794325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.694324970245361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01762610673904419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10850293636322021,
      "backward_entropy": 0.06959989335801867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.463953971862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017719952389597893,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10849058628082275,
      "backward_entropy": 0.06945221953921848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983957290649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017813289538025856,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10847949981689453,
      "backward_entropy": 0.06708800130420262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.752575874328613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017906462773680687,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10846848487854004,
      "backward_entropy": 0.06688320636749268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.999781608581543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017999371513724327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10845793485641479,
      "backward_entropy": 0.06899493270450169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.454354286193848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018092187121510506,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10844731330871582,
      "backward_entropy": 0.06412977642483181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.578278541564941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018185168504714966,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10843555927276612,
      "backward_entropy": 0.06624655591117011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.404770851135254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01827835664153099,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842263698577881,
      "backward_entropy": 0.06851120789845784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.171225547790527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01837165094912052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10840885639190674,
      "backward_entropy": 0.06834318240483601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.204769134521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018464921042323112,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10839459896087647,
      "backward_entropy": 0.06557577186160618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.645327568054199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01855820044875145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10837993621826172,
      "backward_entropy": 0.0679955283800761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.120583534240723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018651172518730164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10836598873138428,
      "backward_entropy": 0.06781448258294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.916322708129883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018744178116321564,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10835175514221192,
      "backward_entropy": 0.06227743625640869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9783735275268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01883707381784916,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10833756923675537,
      "backward_entropy": 0.06462283266915216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53617000579834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01892988570034504,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10832301378250123,
      "backward_entropy": 0.06437400976816814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8638811111450195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019022954627871513,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.108306884765625,
      "backward_entropy": 0.061397274335225425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9893035888671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019115854054689407,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10829060077667237,
      "backward_entropy": 0.06386446952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.337893486022949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019208088517189026,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10827620029449463,
      "backward_entropy": 0.06665204630957709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.627233982086182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019299950450658798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10826259851455688,
      "backward_entropy": 0.06644780768288507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.155651092529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019391655921936035,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10824897289276122,
      "backward_entropy": 0.06306738985909356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.305793285369873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019483501091599464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1082338571548462,
      "backward_entropy": 0.06602854861153497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259354591369629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019575010985136032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10821948051452637,
      "backward_entropy": 0.06581389241748387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33670711517334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019666776061058044,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10820324420928955,
      "backward_entropy": 0.05922343995836046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.322473049163818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019758835434913635,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10818514823913575,
      "backward_entropy": 0.0653711822297838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15719223022461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01985057257115841,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10816781520843506,
      "backward_entropy": 0.058562550279829234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.256093978881836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019942492246627808,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10814889669418334,
      "backward_entropy": 0.058225433031717934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.073564052581787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020034071058034897,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10813080072402954,
      "backward_entropy": 0.06467847691641913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6221699714660645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0201252568513155,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10811398029327393,
      "backward_entropy": 0.0575340191523234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.599146842956543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020215794444084167,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.108099365234375,
      "backward_entropy": 0.06045605076683892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.818680286407471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02030629850924015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10808376073837281,
      "backward_entropy": 0.06395688321855333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3792948722839355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02039690874516964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10806646347045898,
      "backward_entropy": 0.05647223525577121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.538638114929199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02048737183213234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10804879665374756,
      "backward_entropy": 0.06345760160022312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.610733509063721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02057722769677639,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10803327560424805,
      "backward_entropy": 0.06320357984966701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.816638469696045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020667169243097305,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10801632404327392,
      "backward_entropy": 0.05538273188802931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.882068157196045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020756708458065987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10800029039382934,
      "backward_entropy": 0.06268258227242364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.294479846954346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020845945924520493,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10798485279083252,
      "backward_entropy": 0.054635332690344915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9041900634765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020935161039233208,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10796854496002198,
      "backward_entropy": 0.05425508154763116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.911579608917236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021024102345108986,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1079524040222168,
      "backward_entropy": 0.057511713769700795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.372867107391357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02111339010298252,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10793311595916748,
      "backward_entropy": 0.061594208081563316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.677450180053711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021202703937888145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10791198015213013,
      "backward_entropy": 0.061311337682935924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.596818923950195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021292250603437424,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10788867473602295,
      "backward_entropy": 0.05271099673377143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4424591064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021381327882409096,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10786657333374024,
      "backward_entropy": 0.05610297785864936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.658752918243408,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021470502018928528,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10784263610839843,
      "backward_entropy": 0.05191167195638021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4717817306518555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02155931480228901,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10781958103179931,
      "backward_entropy": 0.051503154966566295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.672390937805176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021647663787007332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10779767036437989,
      "backward_entropy": 0.051091131236818105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.330894947052002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021735725924372673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10777593851089477,
      "backward_entropy": 0.059519324037763804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1598358154296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021823352202773094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10775564908981324,
      "backward_entropy": 0.050253980689578585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.260704040527344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021911103278398514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10773388147354127,
      "backward_entropy": 0.049827522701687284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.492272853851318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021999020129442215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10770990848541259,
      "backward_entropy": 0.0493978758653005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.669368267059326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022086594253778458,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10768624544143676,
      "backward_entropy": 0.05824630790286594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.157598495483398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022173361852765083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10766608715057373,
      "backward_entropy": 0.057920383082495794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6948089599609375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022260354831814766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10764338970184326,
      "backward_entropy": 0.05758884218004015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.24006462097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02234721928834915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10761940479278564,
      "backward_entropy": 0.057253864076402455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.677138805389404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022433729842305183,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10759626626968384,
      "backward_entropy": 0.05153213606940375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.947594165802002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022519545629620552,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10757582187652588,
      "backward_entropy": 0.056575496991475425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.775075912475586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022604936733841896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10755668878555298,
      "backward_entropy": 0.04630833864212036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.572575569152832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02269044518470764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10753471851348877,
      "backward_entropy": 0.055884877840677895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.865686416625977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02277594432234764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10751088857650756,
      "backward_entropy": 0.05553311440679762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.315999984741211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022860970348119736,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10748798847198486,
      "backward_entropy": 0.04494982957839966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.223638534545898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022945888340473175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10746395587921143,
      "backward_entropy": 0.0548210342725118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.761594772338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02303064428269863,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10743891000747681,
      "backward_entropy": 0.048665771881739296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1544084548950195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023114293813705444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10741937160491943,
      "backward_entropy": 0.04357391926977369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.479222297668457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023197880014777184,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10739800930023194,
      "backward_entropy": 0.04311122828059726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.42308235168457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02328162081539631,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10737345218658448,
      "backward_entropy": 0.04264802402920193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.763866424560547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02336546964943409,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10734606981277466,
      "backward_entropy": 0.04218434625201755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.554983139038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023448973894119263,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10731855630874634,
      "backward_entropy": 0.04654176367653741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.105556964874268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023532042279839516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1072919487953186,
      "backward_entropy": 0.05223392777972751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.563286304473877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02361436001956463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10726755857467651,
      "backward_entropy": 0.04078141848246256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.201046943664551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023696349933743477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10724289417266845,
      "backward_entropy": 0.051473412248823375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.949023723602295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023778516799211502,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10721487998962402,
      "backward_entropy": 0.05108651187684801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.26608419418335,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023859916254878044,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10718929767608643,
      "backward_entropy": 0.044364737139807806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.512954235076904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023941604420542717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10715961456298828,
      "backward_entropy": 0.05029061105516222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.063353061676025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02402370795607567,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10712475776672363,
      "backward_entropy": 0.043482604953977794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.345027446746826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02410515584051609,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10709147453308106,
      "backward_entropy": 0.03795775440004137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.712152481079102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024186205118894577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10705794095993042,
      "backward_entropy": 0.037488308217790395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.524948596954346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024267172440886497,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10702221393585205,
      "backward_entropy": 0.03702014022403293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.894814968109131,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024347957223653793,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10698502063751221,
      "backward_entropy": 0.041703240738974676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.176046371459961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024427378550171852,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10695476531982422,
      "backward_entropy": 0.04782797892888387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.509347915649414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02450576238334179,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10692890882492065,
      "backward_entropy": 0.04741781287723117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.478744029998779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02458346262574196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10690485239028931,
      "backward_entropy": 0.04700769318474664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.395879745483398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02466053143143654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10688228607177734,
      "backward_entropy": 0.04659731520546807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.696305274963379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024737736210227013,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10685578584671021,
      "backward_entropy": 0.034225778447257146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.57767915725708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024814512580633163,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10682902336120606,
      "backward_entropy": 0.03376626637246874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.964276075363159,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024891579523682594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10679696798324585,
      "backward_entropy": 0.04534616735246447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.94237756729126,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02496771514415741,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10676876306533814,
      "backward_entropy": 0.03813754518826803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9772162437438965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02504374459385872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1067379355430603,
      "backward_entropy": 0.044500384065839976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.641630172729492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025118933990597725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10671042203903199,
      "backward_entropy": 0.04407757520675659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.514801502227783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02519388683140278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10668210983276367,
      "backward_entropy": 0.04365307423803541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2179975509643555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02526850253343582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10665256977081299,
      "backward_entropy": 0.031040678421656292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.208616733551025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025341786444187164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10662943124771118,
      "backward_entropy": 0.04280763202243381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.949337482452393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025415508076548576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10659986734390259,
      "backward_entropy": 0.04238209790653653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.462975025177002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025489412248134613,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10656555891036987,
      "backward_entropy": 0.029710153738657635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.475436687469482,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025563061237335205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10652923583984375,
      "backward_entropy": 0.02927243047290378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.28236198425293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025636525824666023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10649070739746094,
      "backward_entropy": 0.04109256135092841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.088257789611816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0257096104323864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10645096302032471,
      "backward_entropy": 0.04066210985183716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.412906169891357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025782210752367973,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10641076564788818,
      "backward_entropy": 0.027982582648595173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6167311668395996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025854673236608505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10636775493621826,
      "backward_entropy": 0.03980193866623773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.315880298614502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02592630870640278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10632658004760742,
      "backward_entropy": 0.03937465614742703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.727407932281494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025997847318649292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10628215074539185,
      "backward_entropy": 0.038945953051249184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.168788433074951,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026068776845932007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10623795986175537,
      "backward_entropy": 0.03851899835798475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7660748958587646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026139553636312485,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10619082450866699,
      "backward_entropy": 0.03809132840898302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.689197301864624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026209833100438118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10614293813705444,
      "backward_entropy": 0.03766554925176832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.619088888168335,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026279589161276817,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10609458684921265,
      "backward_entropy": 0.03031613098250495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.464789628982544,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026347877457737923,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10605309009552003,
      "backward_entropy": 0.03682385219468011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.868485927581787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02641567401587963,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10601110458374023,
      "backward_entropy": 0.02949723270204332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.62831711769104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026482436805963516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10597259998321533,
      "backward_entropy": 0.0359977748658922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9383795261383057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026548996567726135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10593117475509643,
      "backward_entropy": 0.0355870955520206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1523935794830322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0266147181391716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10589165687561035,
      "backward_entropy": 0.023167418109046087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.888901472091675,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026679862290620804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10585169792175293,
      "backward_entropy": 0.02279389566845364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.911139488220215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02674521878361702,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10580559968948364,
      "backward_entropy": 0.022424446211920843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.473501682281494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268098134547472,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10576051473617554,
      "backward_entropy": 0.022059927384058636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.958235740661621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02687428891658783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10571169853210449,
      "backward_entropy": 0.021699118945333693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.725452423095703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026938140392303467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10566283464431762,
      "backward_entropy": 0.03316447801060147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7164199352264404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027001170441508293,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10561516284942626,
      "backward_entropy": 0.032766918341318764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6363439559936523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027064496651291847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1055605173110962,
      "backward_entropy": 0.020646585358513728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.311563014984131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027126969769597054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.105507230758667,
      "backward_entropy": 0.03197125262684292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2305383682250977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02718939818441868,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10544943809509277,
      "backward_entropy": 0.019968310991923015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4842073917388916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027250614017248154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10539575815200805,
      "backward_entropy": 0.019637796613905165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3091700077056885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027312124148011208,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10533514022827148,
      "backward_entropy": 0.030796004666222468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.924680471420288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02737261913716793,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10527727603912354,
      "backward_entropy": 0.0304110844930013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7319693565368652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027432864531874657,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10521618127822877,
      "backward_entropy": 0.030027568340301514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.169919967651367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027492674067616463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10515315532684326,
      "backward_entropy": 0.01835262609852685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7528743743896484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027551479637622833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10509270429611206,
      "backward_entropy": 0.018042547835244074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8269264698028564,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027610022574663162,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10502922534942627,
      "backward_entropy": 0.017737256156073675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1204774379730225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027668422088027,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10496158599853515,
      "backward_entropy": 0.028526326020558674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9777681827545166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027725856751203537,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1048958420753479,
      "backward_entropy": 0.02816053893831041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.681769847869873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277834665030241,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1048234224319458,
      "backward_entropy": 0.02779379818174574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4805808067321777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027840903028845787,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10474691390991211,
      "backward_entropy": 0.02742837866147359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8112430572509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027897920459508896,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1046684741973877,
      "backward_entropy": 0.02085894015100267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0029489994049072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02795371785759926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10459375381469727,
      "backward_entropy": 0.016002292434374493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.205667734146118,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02800864912569523,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10452002286911011,
      "backward_entropy": 0.026363379425472684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9099376201629639,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028063079342246056,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10444452762603759,
      "backward_entropy": 0.019955615202585857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6232380867004395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028116656467318535,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1043697476387024,
      "backward_entropy": 0.015204240878423056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1721107959747314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028169065713882446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10429816246032715,
      "backward_entropy": 0.02534906069437663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0107765197753906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028221191838383675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10422308444976806,
      "backward_entropy": 0.025020364258024428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.187891960144043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028272844851017,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1041459321975708,
      "backward_entropy": 0.024694969256718952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.137759208679199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02832433022558689,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10406434535980225,
      "backward_entropy": 0.014213821954197355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7614973783493042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028375599533319473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10397880077362061,
      "backward_entropy": 0.024048914511998493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8146198987960815,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02842613123357296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10389318466186523,
      "backward_entropy": 0.013741782969898649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.092833995819092,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028476059436798096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10380674600601196,
      "backward_entropy": 0.013513840734958649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4196444749832153,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028525887057185173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10371550321578979,
      "backward_entropy": 0.023108734024895564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7931119203567505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028574585914611816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1036270022392273,
      "backward_entropy": 0.022805651028951008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4517675638198853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028622861951589584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10353591442108154,
      "backward_entropy": 0.016996776064236958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6082838773727417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02867022156715393,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10344579219818115,
      "backward_entropy": 0.016754849089516535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3789550065994263,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028717007488012314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10335444211959839,
      "backward_entropy": 0.012445036735799577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.718879222869873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028762906789779663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10326383113861085,
      "backward_entropy": 0.01224586202038659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8511917591094971,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028808576986193657,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10316914319992065,
      "backward_entropy": 0.012049852146042718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.454636812210083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028852583840489388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10308129787445068,
      "backward_entropy": 0.021089182959662542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2407456636428833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028896110132336617,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10299144983291626,
      "backward_entropy": 0.015620529651641846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4686161279678345,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028938831761479378,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10290195941925048,
      "backward_entropy": 0.01540946794880761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2604241371154785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028981231153011322,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10280961990356445,
      "backward_entropy": 0.011315670278337266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3996591567993164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02902296371757984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10271693468093872,
      "backward_entropy": 0.020049303770065308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.951045036315918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029064370319247246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10262088775634766,
      "backward_entropy": 0.01979802383316888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9227308630943298,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02910463511943817,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10252783298492432,
      "backward_entropy": 0.014602684312396579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3759212493896484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0291438028216362,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10243736505508423,
      "backward_entropy": 0.010648036168681251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2641657590866089,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02918287180364132,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10234662294387817,
      "backward_entropy": 0.010490948955217997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0029774904251099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029221639037132263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10225214958190917,
      "backward_entropy": 0.018849753671222262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0513819456100464,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029259607195854187,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10215775966644287,
      "backward_entropy": 0.013865893085797628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0238035917282104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029296955093741417,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10206189155578613,
      "backward_entropy": 0.0136914923787117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1413302421569824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029333684593439102,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10196471214294434,
      "backward_entropy": 0.013520860009723239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9009665846824646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937011606991291,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10186374187469482,
      "backward_entropy": 0.009759242335955301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2220492362976074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029405755922198296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10176281929016114,
      "backward_entropy": 0.017752276526557073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7863921523094177,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029441406950354576,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10165669918060302,
      "backward_entropy": 0.01302700572543674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.963203489780426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02947608008980751,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10155220031738281,
      "backward_entropy": 0.009362906217575073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8739646673202515,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029510285705327988,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1014456033706665,
      "backward_entropy": 0.009237571722931333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9770607352256775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029543863609433174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10133841037750244,
      "backward_entropy": 0.009115864005353715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0134085416793823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02957713045179844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10122777223587036,
      "backward_entropy": 0.016745901770061918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.047629952430725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02961021475493908,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10111291408538818,
      "backward_entropy": 0.00887877494096756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6664038896560669,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029643237590789795,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10099314451217652,
      "backward_entropy": 0.016361211736996967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5908453464508057,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029675232246518135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10087521076202392,
      "backward_entropy": 0.011992110146416558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6869334578514099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02970609813928604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10076020956039429,
      "backward_entropy": 0.015997817118962605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7792205810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029736198484897614,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10064553022384644,
      "backward_entropy": 0.011730139454205831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4374915361404419,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029765872284770012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10052869319915772,
      "backward_entropy": 0.01565408706665039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6355863213539124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029794204980134964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10041638612747192,
      "backward_entropy": 0.015491084920035468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6701876521110535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02982189506292343,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10030397176742553,
      "backward_entropy": 0.015331756737497117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8036434054374695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0298490971326828,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10018982887268066,
      "backward_entropy": 0.011253939734564887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4417489767074585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987627685070038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10007129907608033,
      "backward_entropy": 0.015019155210918851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5257481336593628,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02990233525633812,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09995555877685547,
      "backward_entropy": 0.007883275548617045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6986156702041626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029927639290690422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09984017610549926,
      "backward_entropy": 0.014724658595191108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5906041860580444,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02995280921459198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09972131848335267,
      "backward_entropy": 0.007719329661793179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44316360354423523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02997751720249653,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09960086345672607,
      "backward_entropy": 0.010726638966136508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5620744228363037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030001329258084297,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09948168992996216,
      "backward_entropy": 0.0075642574164602495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46403685212135315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03002474643290043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09936090111732483,
      "backward_entropy": 0.014169530736075507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28834447264671326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030047457665205002,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0992404043674469,
      "backward_entropy": 0.01044814040263494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.563080370426178,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03006891719996929,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09912390112876893,
      "backward_entropy": 0.007352594700124528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5106658339500427,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030090246349573135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09900496006011963,
      "backward_entropy": 0.00728688057925966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4989195168018341,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03011127933859825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09888407588005066,
      "backward_entropy": 0.01367706557114919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3747459650039673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0301319919526577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09876101016998291,
      "backward_entropy": 0.013559487958749136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5120653510093689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030151979997754097,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09863885641098022,
      "backward_entropy": 0.013446225060356988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5003407001495361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03017185442149639,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09851415753364563,
      "backward_entropy": 0.013333592149946425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5928480625152588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03019157610833645,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0983867585659027,
      "backward_entropy": 0.013222536279095544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5108449459075928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030211543664336205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09825479388236999,
      "backward_entropy": 0.013109650048944686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3659959137439728,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030231410637497902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09812018275260925,
      "backward_entropy": 0.012997108201185862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3900574743747711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030250610783696175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09798638224601745,
      "backward_entropy": 0.01288856565952301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3182414174079895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03026929683983326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09785231351852416,
      "backward_entropy": 0.00961016615231832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.432783305644989,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03028721548616886,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09771926999092102,
      "backward_entropy": 0.009546109371715121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45210695266723633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030304962769150734,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09758406281471252,
      "backward_entropy": 0.006655566394329071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5563805103302002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030322665348649025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09744640588760375,
      "backward_entropy": 0.006606206711795595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34527352452278137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03034084290266037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09730333089828491,
      "backward_entropy": 0.012381729152467515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4462493062019348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03035847656428814,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09716014862060547,
      "backward_entropy": 0.009296986791822646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30126112699508667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030376121401786804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09701522588729858,
      "backward_entropy": 0.0064587949050797355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32111403346061707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030393097549676895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0968712329864502,
      "backward_entropy": 0.012090171376864115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33866655826568604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030409550294280052,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0967276155948639,
      "backward_entropy": 0.006368329955471886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3318426311016083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030425632372498512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09658362865447997,
      "backward_entropy": 0.011908673577838473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.321832537651062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030441327020525932,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09643875360488892,
      "backward_entropy": 0.011821096142133078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36089131236076355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03045668452978134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09629299640655517,
      "backward_entropy": 0.011735613975259993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4193249046802521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030471956357359886,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09614498615264892,
      "backward_entropy": 0.01165066659450531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4083520770072937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030487503856420517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09599288702011108,
      "backward_entropy": 0.011564303603437211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20783762633800507,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030503269284963608,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09583709239959717,
      "backward_entropy": 0.006122978197203742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28667935729026794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0305180586874485,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0956845760345459,
      "backward_entropy": 0.011395542985863157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23685303330421448,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03053242154419422,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0955330789089203,
      "backward_entropy": 0.006049460834927029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30889996886253357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030546177178621292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0953829288482666,
      "backward_entropy": 0.011239666077825759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3030031621456146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030559848994016647,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09523138999938965,
      "backward_entropy": 0.008640290134482913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25852999091148376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030573392286896706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09507805705070496,
      "backward_entropy": 0.011089188357194265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16411088407039642,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03058655932545662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09492405652999877,
      "backward_entropy": 0.01101668013466729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2636632025241852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030598759651184082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09477235078811645,
      "backward_entropy": 0.010949422915776571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2732682228088379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030610790476202965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09461928009986878,
      "backward_entropy": 0.010883278316921659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25207850337028503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030622778460383415,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09446476697921753,
      "backward_entropy": 0.01081733074453142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2428412288427353,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0306345634162426,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09430971145629882,
      "backward_entropy": 0.008417134483655294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25185301899909973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306461900472641,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09415481090545655,
      "backward_entropy": 0.010688538352648417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23294763267040253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030657773837447166,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09399890303611755,
      "backward_entropy": 0.010624913705719842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21243689954280853,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03066915087401867,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09384219646453858,
      "backward_entropy": 0.005728634281290902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26218071579933167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030680213123559952,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09368590116500855,
      "backward_entropy": 0.008285576270686256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17376254498958588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030691439285874367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09352815747261048,
      "backward_entropy": 0.01044092079003652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21006673574447632,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030702123418450356,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09337233901023864,
      "backward_entropy": 0.010383697847525278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.256102979183197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071262501180172,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09321727752685546,
      "backward_entropy": 0.010326274567180209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12230288982391357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03072337992489338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09306204319000244,
      "backward_entropy": 0.010267173250516256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14473190903663635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030733298510313034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09290949106216431,
      "backward_entropy": 0.010212330354584588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20080448687076569,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030742650851607323,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09275872111320496,
      "backward_entropy": 0.010160436232884726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23029500246047974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030752001330256462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0926069974899292,
      "backward_entropy": 0.005547898925013012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18272390961647034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03076164610683918,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09245355129241943,
      "backward_entropy": 0.010056594179736244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.166091650724411,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030771082267165184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09229965209960937,
      "backward_entropy": 0.010005075070593093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20044074952602386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030780229717493057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09214574098587036,
      "backward_entropy": 0.009955035315619575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1759270280599594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030789557844400406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09199048280715942,
      "backward_entropy": 0.009904163579146067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15014323592185974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030798811465501785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0918354868888855,
      "backward_entropy": 0.009853871332274543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23448628187179565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03080780617892742,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09168170690536499,
      "backward_entropy": 0.0098047802845637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14589902758598328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03081740438938141,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0915258765220642,
      "backward_entropy": 0.007879916164610121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13291200995445251,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03082662634551525,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09137154817581176,
      "backward_entropy": 0.007852545215023888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16227149963378906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030835401266813278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09121841192245483,
      "backward_entropy": 0.00965385635693868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1577935516834259,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03084416873753071,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09106463789939881,
      "backward_entropy": 0.005351608826054467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16843456029891968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0308529119938612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09091058969497681,
      "backward_entropy": 0.009558533628781637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12546168267726898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03086182102560997,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09075628519058228,
      "backward_entropy": 0.00951024227672153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1442873477935791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030870381742715836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0906029224395752,
      "backward_entropy": 0.00946371340089374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.098701111972332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03087889589369297,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0904496192932129,
      "backward_entropy": 0.00769927269882626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15076392889022827,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030886774882674217,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09029786586761475,
      "backward_entropy": 0.005261446866724227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09869387000799179,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030894815921783447,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09014589786529541,
      "backward_entropy": 0.00765432251824273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14957882463932037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03090236522257328,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08999552130699158,
      "backward_entropy": 0.007633629772398207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08841922879219055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030910152941942215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0898450493812561,
      "backward_entropy": 0.005213299973143471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09249366074800491,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030917350202798843,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0896966278553009,
      "backward_entropy": 0.007591111792458428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1356550008058548,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03092408925294876,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08954907655715942,
      "backward_entropy": 0.007572873598999447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10273079574108124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030931120738387108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08940117359161377,
      "backward_entropy": 0.009132045010725657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1008080542087555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030937980860471725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08925418853759766,
      "backward_entropy": 0.009094640612602234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09143510460853577,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030944662168622017,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08910837173461914,
      "backward_entropy": 0.009057985411749946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07539170235395432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030951108783483505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08896401524543762,
      "backward_entropy": 0.009022658069928488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09362757205963135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030957056209445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0888207733631134,
      "backward_entropy": 0.00898985978629854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09529847651720047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030962873250246048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08867784738540649,
      "backward_entropy": 0.00895774116118749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11122026294469833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03096865303814411,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08853517770767212,
      "backward_entropy": 0.008925766580634646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08562744408845901,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03097471408545971,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08839226961135864,
      "backward_entropy": 0.0050895557635360295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08743643760681152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030980614945292473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08825087547302246,
      "backward_entropy": 0.005078612516323726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08989714831113815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030986443161964417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08811055421829224,
      "backward_entropy": 0.008827991783618927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07724304497241974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030992262065410614,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08797038793563842,
      "backward_entropy": 0.008796186910735236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07542334496974945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03099794127047062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08783087730407715,
      "backward_entropy": 0.008765135374334123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0506138950586319,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031003480777144432,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08769205808639527,
      "backward_entropy": 0.008734792470932007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06318007409572601,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031008433550596237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08755497932434082,
      "backward_entropy": 0.008707602818806967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08394207805395126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031013166531920433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08741973042488098,
      "backward_entropy": 0.008681429757012261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08071143925189972,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03101811744272709,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08728606700897217,
      "backward_entropy": 0.008653644058439467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08235359191894531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031023269519209862,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08715352416038513,
      "backward_entropy": 0.008625173734294044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07115355879068375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03102864883840084,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0870212197303772,
      "backward_entropy": 0.00730235046810574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06597349792718887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031033992767333984,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08688911199569702,
      "backward_entropy": 0.004980216423670451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060684140771627426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031039223074913025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08675715923309327,
      "backward_entropy": 0.008537881076335907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0584917813539505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031044278293848038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08662600517272949,
      "backward_entropy": 0.008510293232070075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055627964437007904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031049177050590515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08649577498435974,
      "backward_entropy": 0.008483486043082343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05057531222701073,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031053949147462845,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08636679649353027,
      "backward_entropy": 0.007236872282293107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04537796229124069,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031058546155691147,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08623930215835571,
      "backward_entropy": 0.007225918273131053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0553099624812603,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031062820926308632,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0861131191253662,
      "backward_entropy": 0.0072161538733376395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0424044094979763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03106703609228134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0859881043434143,
      "backward_entropy": 0.004919950332906511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04312629997730255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031070968136191368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08586480617523193,
      "backward_entropy": 0.004913492335213555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.047003988176584244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03107471391558647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08574336171150207,
      "backward_entropy": 0.008342002001073625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03559914603829384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031078403815627098,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08562322854995727,
      "backward_entropy": 0.004901590032709969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051271840929985046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03108181618154049,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0855047881603241,
      "backward_entropy": 0.008301228284835815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04173894226551056,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031085368245840073,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08538692593574523,
      "backward_entropy": 0.004890761027733485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04599631950259209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031088899821043015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08527064323425293,
      "backward_entropy": 0.008261110219690535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03657267242670059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03109249286353588,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08515499234199524,
      "backward_entropy": 0.008240918318430582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041697289794683456,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03109590895473957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08504033088684082,
      "backward_entropy": 0.004873421457078721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04677294194698334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03109932318329811,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08492649793624878,
      "backward_entropy": 0.00820240792300966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03892458602786064,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03110288642346859,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08481375575065613,
      "backward_entropy": 0.007123063835832808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03547070175409317,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031106431037187576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08470240831375123,
      "backward_entropy": 0.004855825669235653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038745757192373276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03110991232097149,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08459198474884033,
      "backward_entropy": 0.008143289221657647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03541106730699539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03111341781914234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08448177576065063,
      "backward_entropy": 0.008123919367790222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029637157917022705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031116897240281105,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08437260389328002,
      "backward_entropy": 0.007088098261091445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03472554683685303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031120188534259796,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08426480293273926,
      "backward_entropy": 0.008086546427673764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030233370140194893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03112351894378662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08415842652320862,
      "backward_entropy": 0.008068175779448615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0248089749366045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03112678788602352,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0840537428855896,
      "backward_entropy": 0.008050061762332916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03200382739305496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031129851937294006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08395068645477295,
      "backward_entropy": 0.008032864994472928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03209719434380531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031132949516177177,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08384863138198853,
      "backward_entropy": 0.007048596938451131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028919918462634087,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031136129051446915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08374741077423095,
      "backward_entropy": 0.004806082281801436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029637260362505913,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031139353290200233,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08364734649658204,
      "backward_entropy": 0.007032048371103074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027667077258229256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031142648309469223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08354835510253907,
      "backward_entropy": 0.007962321241696676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028103535994887352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03114594705402851,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08345059156417847,
      "backward_entropy": 0.007944429914156595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028065411373972893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031149284914135933,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08335365056991577,
      "backward_entropy": 0.004782089756594764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024962536990642548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03115270286798477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08325791358947754,
      "backward_entropy": 0.007908022238148583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028770308941602707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03115609474480152,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08316352367401122,
      "backward_entropy": 0.006987347371048397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02186160907149315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031159617006778717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08306959867477418,
      "backward_entropy": 0.007871146003405253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018121398985385895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031162982806563377,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08297625780105591,
      "backward_entropy": 0.007853312624825371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021476076915860176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03116615116596222,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08288426995277405,
      "backward_entropy": 0.007836394011974335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022634942084550858,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03116929903626442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08279352188110352,
      "backward_entropy": 0.007819598747624291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018495194613933563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031172502785921097,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08270407915115356,
      "backward_entropy": 0.007802526983949874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01734059862792492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031175579875707626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08261562585830688,
      "backward_entropy": 0.0077862607108222116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018934257328510284,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031178558245301247,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08252894878387451,
      "backward_entropy": 0.004726378868023555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01769516058266163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03118150122463703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0824437141418457,
      "backward_entropy": 0.0077544475595156355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019025908783078194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0311843603849411,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08235936164855957,
      "backward_entropy": 0.007738923033078511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019688541069626808,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031187262386083603,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08227578401565552,
      "backward_entropy": 0.007723468873235915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0167035311460495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03119027428328991,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0821927547454834,
      "backward_entropy": 0.007707593341668447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01391610223799944,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03119327314198017,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0821107029914856,
      "backward_entropy": 0.004698398626512951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013420584611594677,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031196095049381256,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08202958106994629,
      "backward_entropy": 0.006876925627390544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014349284581840038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03119875304400921,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194941282272339,
      "backward_entropy": 0.007662862539291382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011234643869102001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031201379373669624,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0818708896636963,
      "backward_entropy": 0.007648824817604489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012665892019867897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031203849241137505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08179399967193604,
      "backward_entropy": 0.007635495728916592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010080062784254551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031206268817186356,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08171828985214233,
      "backward_entropy": 0.007622440656026204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012297103181481361,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031208505854010582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08164354562759399,
      "backward_entropy": 0.004670639004972246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008739205077290535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031210685148835182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08156944513320923,
      "backward_entropy": 0.007598486211564805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010881777852773666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031212734058499336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08149701952934266,
      "backward_entropy": 0.007587360011206733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00848552118986845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03121471218764782,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08142566084861755,
      "backward_entropy": 0.007576439943578508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010317713022232056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031216559931635857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0813557505607605,
      "backward_entropy": 0.007566072046756744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010816763155162334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031218396499753,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08128697872161865,
      "backward_entropy": 0.007555834949016571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008666501380503178,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03122022934257984,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0812188982963562,
      "backward_entropy": 0.004651370561785168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008520592004060745,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031222043558955193,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08115212321281433,
      "backward_entropy": 0.006809592247009277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009881171397864819,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031223783269524574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08108643293380738,
      "backward_entropy": 0.004645569870869319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009432245045900345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03122556209564209,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08102166652679443,
      "backward_entropy": 0.007516032291783227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007605255115777254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03122737817466259,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08095767498016357,
      "backward_entropy": 0.007506074176894294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00639455346390605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03122907131910324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08089419007301331,
      "backward_entropy": 0.007496720386876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008968565613031387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031230609863996506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08083140850067139,
      "backward_entropy": 0.007488111654917399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008562217466533184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03123221918940544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0807695746421814,
      "backward_entropy": 0.007479194965627458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006603032350540161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312338937073946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08070878982543946,
      "backward_entropy": 0.007469942172368367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007065497804433107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031235499307513237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08064910769462585,
      "backward_entropy": 0.007461133102575938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006843733601272106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03123704344034195,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08059008717536927,
      "backward_entropy": 0.007452591425842709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00620695948600769,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031238572672009468,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08053195476531982,
      "backward_entropy": 0.007444071273008983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006352401804178953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031240111216902733,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08047513365745544,
      "backward_entropy": 0.007435530424118042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006191867403686047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031241631135344505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08041897416114807,
      "backward_entropy": 0.007427203986379836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00548255629837513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031243126839399338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08036351203918457,
      "backward_entropy": 0.007419026560253567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005777321290224791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312445517629385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08030878305435181,
      "backward_entropy": 0.007411174476146698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004599710926413536,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031245997175574303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08025503754615784,
      "backward_entropy": 0.007403259476025899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005019932519644499,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031247369945049286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08020226955413819,
      "backward_entropy": 0.004608451906177733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005224293097853661,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031248752027750015,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0801506757736206,
      "backward_entropy": 0.006739800588952171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005812911316752434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125014901161194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08010029792785645,
      "backward_entropy": 0.00738054182794359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004785662516951561,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031251609325408936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08005082011222839,
      "backward_entropy": 0.007372617721557617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0044158268719911575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125307708978653,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08000216484069825,
      "backward_entropy": 0.007364749080604977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003265851642936468,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03125452622771263,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07995432019233703,
      "backward_entropy": 0.004596409698327382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0055061993189156055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125589340925217,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07990764379501343,
      "backward_entropy": 0.007349657515684764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005506051704287529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031257376074790955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0798615574836731,
      "backward_entropy": 0.004591319296095107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037561773788183928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031258974224328995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0798158586025238,
      "backward_entropy": 0.007333542737695906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030278018675744534,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031260497868061066,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07977067232131958,
      "backward_entropy": 0.004585371249251896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003958665765821934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126193955540657,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07972640991210937,
      "backward_entropy": 0.0073181672228707206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035726630594581366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031263403594493866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07968317270278931,
      "backward_entropy": 0.007310538656181759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033366943243891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126487508416176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07964091300964356,
      "backward_entropy": 0.007302836411529117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027010368648916483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126632794737816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07959963083267212,
      "backward_entropy": 0.007295308841599358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031143673695623875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0312676876783371,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07955905795097351,
      "backward_entropy": 0.004571643968423207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002875950885936618,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03126902878284454,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07951924800872803,
      "backward_entropy": 0.0066808296574486625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021354982163757086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031270332634449005,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07948010563850402,
      "backward_entropy": 0.007274371054437425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026906058192253113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0312715508043766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0794418215751648,
      "backward_entropy": 0.004564418974849913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029818611219525337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03127273544669151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07940396070480346,
      "backward_entropy": 0.007261691821946038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031906680669635534,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03127395734190941,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0793666660785675,
      "backward_entropy": 0.0072553083300590515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020985661540180445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031275223940610886,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07932961583137513,
      "backward_entropy": 0.007248752646976047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017570250201970339,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03127642720937729,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07929315567016601,
      "backward_entropy": 0.006659218420584996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002047433052212,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03127752244472504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07925732135772705,
      "backward_entropy": 0.004553416536913978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015119011513888836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312785804271698,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07922230958938599,
      "backward_entropy": 0.0072312553723653155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001859357114881277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03127953037619591,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07918804883956909,
      "backward_entropy": 0.00722618152697881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017282880144193769,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031280457973480225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07915464639663697,
      "backward_entropy": 0.00454849542842971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019550363067537546,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03128137066960335,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07912222146987916,
      "backward_entropy": 0.006645064387056563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014485650463029742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128225728869438,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07909000515937806,
      "backward_entropy": 0.004545554518699646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018318180227652192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128308057785034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07905832529067994,
      "backward_entropy": 0.0072068870067596436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017604525201022625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128392621874809,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07902715802192688,
      "backward_entropy": 0.00454295426607132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001894584042020142,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128478676080704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07899655103683471,
      "backward_entropy": 0.007197682228353288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001231975620612502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128569573163986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0789664626121521,
      "backward_entropy": 0.007192867497603099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00141281564719975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128654137253761,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07893692851066589,
      "backward_entropy": 0.0071883706582917106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00129429972730577,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03128739818930626,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07890820503234863,
      "backward_entropy": 0.006627737234036128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014152394142001867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031288232654333115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07888020277023315,
      "backward_entropy": 0.004535550044642555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010907340329140425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031289078295230865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07885291576385497,
      "backward_entropy": 0.00717494719558292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014280849136412144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128991648554802,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07882657051086425,
      "backward_entropy": 0.007170519067181481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010690501658245921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129076212644577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07880033254623413,
      "backward_entropy": 0.00716609838936064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011943337740376592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031291548162698746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07877429127693177,
      "backward_entropy": 0.007161960005760193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012081378372386098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031292326748371124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07874853014945984,
      "backward_entropy": 0.007157886193858253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011373625602573156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312931202352047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07872329950332642,
      "backward_entropy": 0.00715375112162696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008769683190621436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129391372203827,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07869850397109986,
      "backward_entropy": 0.007149616049395667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009429592173546553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031294673681259155,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07867426276206971,
      "backward_entropy": 0.00714564323425293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008063231944106519,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129541873931885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07865045070648194,
      "backward_entropy": 0.007141767276657952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010097826598212123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031296130269765854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07862718105316162,
      "backward_entropy": 0.007138057715362973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007714098319411278,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129688277840614,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07860476970672607,
      "backward_entropy": 0.007134139537811279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007828884408809245,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129759803414345,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07858275175094605,
      "backward_entropy": 0.007130377822452121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006547580123879015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031298283487558365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07856103181838989,
      "backward_entropy": 0.0071267833312352495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000785969546996057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312989316880703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07853971719741822,
      "backward_entropy": 0.007123404079013401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007390761165879667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031299568712711334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07851870656013489,
      "backward_entropy": 0.007120052973429362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000865401525516063,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130021691322327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07849817276000977,
      "backward_entropy": 0.004514005863004261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007959114154800773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03130089491605759,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07847793102264404,
      "backward_entropy": 0.006587119566069709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007163234404288232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031301576644182205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07845785617828369,
      "backward_entropy": 0.004511471423837874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007080858340486884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031302254647016525,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07843799591064453,
      "backward_entropy": 0.004510212689638138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005531319184228778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130292519927025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07841827869415283,
      "backward_entropy": 0.0071027618315484785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000689085281919688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130357712507248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07839903235435486,
      "backward_entropy": 0.007099443011813694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005484408466145396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313042476773262,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07838023900985717,
      "backward_entropy": 0.00709601491689682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004927390837110579,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130491077899933,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07836188077926635,
      "backward_entropy": 0.004505219558874766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000474819476949051,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031305521726608276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07834363579750062,
      "backward_entropy": 0.007089508904351128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041834547300823033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130612522363663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07832587957382202,
      "backward_entropy": 0.007086421880457137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005154217360541224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313066802918911,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07830834984779358,
      "backward_entropy": 0.00708354264497757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000525810697581619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130722790956497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07829099893569946,
      "backward_entropy": 0.007080700662400987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037401312147267163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031307779252529144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07827383279800415,
      "backward_entropy": 0.007077874408827888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035466175177134573,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03130831569433212,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07825721502304077,
      "backward_entropy": 0.00656372101770507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003350033948663622,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130882978439331,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07824101448059081,
      "backward_entropy": 0.007072398232089149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003745875437743962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031309302896261215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07822505831718445,
      "backward_entropy": 0.007069903943273757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003669857105705887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031309761106967926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07820931673049927,
      "backward_entropy": 0.007067499061425527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031725617009215057,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131021186709404,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0781938076019287,
      "backward_entropy": 0.006557692256238725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000321739207720384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131064027547836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0781785011291504,
      "backward_entropy": 0.007062886324193742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002691501867957413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131107613444328,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07816367745399475,
      "backward_entropy": 0.0070606014794773525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003207583795301616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131149336695671,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07814923524856568,
      "backward_entropy": 0.00705840935309728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025230293977074325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131192550063133,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07813513278961182,
      "backward_entropy": 0.007056154310703278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002724668011069298,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131234645843506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07812141180038452,
      "backward_entropy": 0.0070539481110042995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002596134727355093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031312767416238785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07810801267623901,
      "backward_entropy": 0.007051795721054077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002532800135668367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031313180923461914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07809486985206604,
      "backward_entropy": 0.0044911230603853864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026347438688389957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131357580423355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07808196544647217,
      "backward_entropy": 0.007047546406586965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002304071676917374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031313955783843994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07806910276412964,
      "backward_entropy": 0.004489856461683909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019470589177217335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131432831287384,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0780564308166504,
      "backward_entropy": 0.007043600082397461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019935896852985024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131469339132309,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07804410457611084,
      "backward_entropy": 0.0070416803161303205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001991565222851932,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131506219506264,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07803208827972412,
      "backward_entropy": 0.0065422455469767255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016091790166683495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315430998802185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07802029848098754,
      "backward_entropy": 0.007037883003552754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001881666830740869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315773725509644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07800878286361694,
      "backward_entropy": 0.007036110593212975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000156827547471039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0313161239027977,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0779975950717926,
      "backward_entropy": 0.00448628349436654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018880168499890715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131646662950516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07798669338226319,
      "backward_entropy": 0.007032502028677199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016662298003211617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131682053208351,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0779760241508484,
      "backward_entropy": 0.006536627809206645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011944678408326581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131717070937157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07796550989151001,
      "backward_entropy": 0.007028887669245402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014097253733780235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131749853491783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07795529365539551,
      "backward_entropy": 0.007027205493715074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013300789578352123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313178226351738,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07794525623321533,
      "backward_entropy": 0.007025539875030518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013993150787428021,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131813183426857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07793537974357605,
      "backward_entropy": 0.007023962007628547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854092448018491e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031318433582782745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07792564630508422,
      "backward_entropy": 0.007022378345330556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013851787662133574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031318698078393936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07791608572006226,
      "backward_entropy": 0.007020985086758931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011579817510209978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031318970024585724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07790660262107849,
      "backward_entropy": 0.007019564509391785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011809174611698836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031319234520196915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07789729833602906,
      "backward_entropy": 0.004481113205353419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91346498974599e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313195139169693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07788828611373902,
      "backward_entropy": 0.007016742395030128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.81510675046593e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131978213787079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07787954807281494,
      "backward_entropy": 0.007015349964300792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.552347960881889e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132003918290138,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07787096500396729,
      "backward_entropy": 0.006526176714234882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.711994061945006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031320277601480484,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07786262035369873,
      "backward_entropy": 0.006525390264060762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.548675057478249e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031320516020059586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07785435914993286,
      "backward_entropy": 0.007011496358447605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763612666167319e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031320732086896896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0778462290763855,
      "backward_entropy": 0.00701034234629737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.280116551555693e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031320951879024506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07783830165863037,
      "backward_entropy": 0.007009185022777981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.456970004364848e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031321167945861816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07783059477806091,
      "backward_entropy": 0.007008037633366055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.841650611022487e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132137283682823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07782304286956787,
      "backward_entropy": 0.007006944881545173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.902475822949782e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132157772779465,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07781567573547363,
      "backward_entropy": 0.004477545619010925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.972450501052663e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031321775168180466,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07780849337577819,
      "backward_entropy": 0.007004805737071567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.912086635362357e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132198005914688,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07780146598815918,
      "backward_entropy": 0.004476939224534565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.22311932197772e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031322166323661804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07779445648193359,
      "backward_entropy": 0.007002759310934279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0235797971254215e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132234513759613,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07778775095939636,
      "backward_entropy": 0.004476436310344272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.256375541444868e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132250905036926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07778112888336182,
      "backward_entropy": 0.00700094136926863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6082379665458575e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031322672963142395,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07777478694915771,
      "backward_entropy": 0.007000053922335307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.964020652347244e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132283687591553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07776875495910644,
      "backward_entropy": 0.006999187999301487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.464478843146935e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132300451397896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07776297926902771,
      "backward_entropy": 0.006998307175106472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9501042920164764e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132317215204239,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.077757328748703,
      "backward_entropy": 0.006997427178753747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.513717820169404e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132333979010582,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07775185704231262,
      "backward_entropy": 0.006515187107854419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.582001227186993e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031323499977588654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0777464747428894,
      "backward_entropy": 0.006995699471897549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0452765713562258e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031323663890361786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07774125337600708,
      "backward_entropy": 0.006994860867659251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4261691325809807e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132381662726402,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0777361273765564,
      "backward_entropy": 0.006513570331864887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9359007385210134e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132396563887596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07773106694221496,
      "backward_entropy": 0.006993290450837877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8507922252174467e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313241146504879,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07772616147994996,
      "backward_entropy": 0.006992507312032912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.915252116508782e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132425621151924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07772130966186523,
      "backward_entropy": 0.006991783777872722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4734361431910656e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031324390321969986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07771652936935425,
      "backward_entropy": 0.006991070177819993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4579692762927152e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031324516981840134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07771186232566833,
      "backward_entropy": 0.0069904012812508475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3126305677578785e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132464364171028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0777073085308075,
      "backward_entropy": 0.006989740663104587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2158339561428875e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031324759125709534,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07770282030105591,
      "backward_entropy": 0.006989138821760814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2740558051737025e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132487088441849,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0776984691619873,
      "backward_entropy": 0.006988556020789676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8449796698405407e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132499009370804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07769427895545959,
      "backward_entropy": 0.006987927688492669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.823889215302188e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132510557770729,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0776902198791504,
      "backward_entropy": 0.006987314257356856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5275867554009892e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031325213611125946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0776862621307373,
      "backward_entropy": 0.006986738079124027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7042735635186546e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313253179192543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07768243551254272,
      "backward_entropy": 0.0069861917032135856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.686154428170994e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132542222738266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07767874002456665,
      "backward_entropy": 0.006985642843776279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3663156096299645e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132552281022072,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07767510414123535,
      "backward_entropy": 0.004471917533212238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4496371477434877e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132562339305878,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07767159938812256,
      "backward_entropy": 0.00698458817270067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3665738151757978e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031325723975896835,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07766822576522828,
      "backward_entropy": 0.006984061665005154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3435638720693532e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313258171081543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07766486406326294,
      "backward_entropy": 0.006983574893739488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4137494872557e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132590278983116,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0776615560054779,
      "backward_entropy": 0.006506402459409501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.269493623112794e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132598102092743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0776582419872284,
      "backward_entropy": 0.006982697380913628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2036444786645006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031326062977313995,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07765501737594604,
      "backward_entropy": 0.004471250706248813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0337904313928448e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132614493370056,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07765188217163085,
      "backward_entropy": 0.0065055663386980695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.045533917931607e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132622689008713,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07764884233474731,
      "backward_entropy": 0.0069813910457823015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.588663488102611e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031326308846473694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07764587998390197,
      "backward_entropy": 0.006980976296795739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.804247045191005e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132638335227966,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07764296531677246,
      "backward_entropy": 0.006980579760339525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0553962965786923e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031326450407505035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07764010429382324,
      "backward_entropy": 0.004470802843570709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.96652693679789e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132650628685951,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07763723134994507,
      "backward_entropy": 0.006979919970035553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.317783795064315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132656216621399,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07763445377349854,
      "backward_entropy": 0.00697960290643904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.033621841401327e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132661432027817,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07763173580169677,
      "backward_entropy": 0.006503925141361024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3936995502444915e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132666274905205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07762912511825562,
      "backward_entropy": 0.00697902176115248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.946066721662646e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132671117782593,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07762659788131714,
      "backward_entropy": 0.006978756023777856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.192049113451503e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132675960659981,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07762421369552612,
      "backward_entropy": 0.006978481180138058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.810168204334332e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132680803537369,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0776219129562378,
      "backward_entropy": 0.006503171390957302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.304536443873076e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031326860189437866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07761968374252319,
      "backward_entropy": 0.006977919075224135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.832193437527167e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031326912343502045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0776175618171692,
      "backward_entropy": 0.006502765748235915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.518852049135603e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031326960772275925,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07761545181274414,
      "backward_entropy": 0.006977384289105733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.52747644885676e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031327009201049805,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07761337757110595,
      "backward_entropy": 0.006977120207415687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.356632416602224e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132706135511398,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07761139869689941,
      "backward_entropy": 0.006976842052406735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.471528882277198e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132711350917816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07760950922966003,
      "backward_entropy": 0.006976580454243554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.19662865169812e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132716193795204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07760765552520751,
      "backward_entropy": 0.006976318856080373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.039799023303203e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132721036672592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07760586142539978,
      "backward_entropy": 0.006976066364182366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6987423754908377e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313272587954998,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07760410308837891,
      "backward_entropy": 0.006975820495022668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.708565145643661e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132730722427368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07760241031646728,
      "backward_entropy": 0.006975558069017198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6253709367883857e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132735192775726,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07760074734687805,
      "backward_entropy": 0.004470128566026688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.116388825219474e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031327396631240845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07759911417961121,
      "backward_entropy": 0.006975099444389343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0997457542980555e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031327441334724426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07759752869606018,
      "backward_entropy": 0.004470031708478928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.977341409859946e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132748231291771,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0775959849357605,
      "backward_entropy": 0.0069746507538689505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0037247142900014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031327519565820694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0775944709777832,
      "backward_entropy": 0.0044699617558055455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8228998871782096e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132755681872368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07759299278259277,
      "backward_entropy": 0.0044699423015117645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.537066166041768e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132759407162666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07759153842926025,
      "backward_entropy": 0.004469905462529924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4795308490865864e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132763132452965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07759013175964355,
      "backward_entropy": 0.006973866787221696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.223815272373031e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132766857743263,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07758876085281372,
      "backward_entropy": 0.006499817387925254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2628275928582298e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132770583033562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07758744955062866,
      "backward_entropy": 0.0069734785291883684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.219703674199991e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313277430832386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07758617997169495,
      "backward_entropy": 0.006973268257247077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.831091140047647e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132777661085129,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07758490443229675,
      "backward_entropy": 0.0064993757340643145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6698086255928501e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031327810138463974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07758368849754334,
      "backward_entropy": 0.0044696761502159964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7488192725068075e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132784366607666,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07758254408836365,
      "backward_entropy": 0.0069727351268132525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.496644358667254e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031327877193689346,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07758142948150634,
      "backward_entropy": 0.006972562935617235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5542365190412966e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132791072130203,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07758039236068726,
      "backward_entropy": 0.006972394055790371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5168938034548773e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132794424891472,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757936716079712,
      "backward_entropy": 0.00697222931517495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3966763390271808e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031327977776527405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757837176322938,
      "backward_entropy": 0.006972077820036147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2053537830070127e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132800757884979,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757741212844849,
      "backward_entropy": 0.006971915562947591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3581569646703429e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132804110646248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757650017738342,
      "backward_entropy": 0.0069717516501744585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.178404545498779e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031328070908784866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757560610771179,
      "backward_entropy": 0.006971607605616252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0085936992254574e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031328100711107254,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07757474184036255,
      "backward_entropy": 0.006498023039764828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.820928426051978e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132813051342964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757393121719361,
      "backward_entropy": 0.006971300476127201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0669629091353272e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132816031575203,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07757318019866943,
      "backward_entropy": 0.00446925519241227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0072377563119517e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132819011807442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757244110107422,
      "backward_entropy": 0.006971018181906806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260453452952788e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031328216195106506,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.077571702003479,
      "backward_entropy": 0.004469182756212022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.111728579417104e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031328242272138596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757098078727723,
      "backward_entropy": 0.006970757411585914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.678370815890958e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031328264623880386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07757023572921753,
      "backward_entropy": 0.00446912439333068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.628882142147631e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132828697562218,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756948471069336,
      "backward_entropy": 0.006970536377694871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429600484305411e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132830932736397,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0775687575340271,
      "backward_entropy": 0.006970430413881938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.827086392353522e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132832795381546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756803035736085,
      "backward_entropy": 0.006970325277911292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.376413352882082e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132834658026695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756731510162354,
      "backward_entropy": 0.006970236698786418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.13452982634044e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031328365206718445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756664752960205,
      "backward_entropy": 0.006970135702027215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.901499662286369e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132838383316994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756600975990295,
      "backward_entropy": 0.0069700297382142805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.726992640120443e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132840245962143,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756542563438415,
      "backward_entropy": 0.006969946126143138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.367060905176913e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132842108607292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756484150886536,
      "backward_entropy": 0.006969845129383935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8365708355268e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031328439712524414,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07756426334381103,
      "backward_entropy": 0.00649649484290017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.043618784839055e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132845461368561,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756367921829224,
      "backward_entropy": 0.00696967707739936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.984246970707318e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313284695148468,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07756314873695373,
      "backward_entropy": 0.0069695984323819475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.443571128831536e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031328484416007996,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07756261229515075,
      "backward_entropy": 0.004468971656428443,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.4892417585201656e-05,
    "avg_log_Z": 0.03132614128291607,
    "success_rate": 1.0,
    "avg_reward": 55.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.11,
      "1": 0.16,
      "2": 0.73
    },
    "avg_forward_entropy": 0.07764833277463913,
    "avg_backward_entropy": 0.006527989635037052,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}