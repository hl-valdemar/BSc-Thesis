{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06269305402582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06284351782365279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10446834564209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06279491836374457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.03392219543457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115487337112427,
      "backward_entropy": 0.06283623521978204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776656150817871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0001999868400162086,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115318457285564,
      "backward_entropy": 0.06282901222055609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.451966285705566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0002999190182890743,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115129709243774,
      "backward_entropy": 0.06276952136646617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704324722290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00039974410901777446,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114960829416911,
      "backward_entropy": 0.06281333619898016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.126241683959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004995734198018909,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114826718966167,
      "backward_entropy": 0.06280514326962558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.514650344848633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005992458900436759,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911473532517751,
      "backward_entropy": 0.06274175643920898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259353637695312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006989350658841431,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911458432674408,
      "backward_entropy": 0.06273225220766934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.949464797973633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007985664415173233,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114379684130351,
      "backward_entropy": 0.06277938322587447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625990867614746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008983439765870571,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114210804303487,
      "backward_entropy": 0.06261243603446266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76005744934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009981355397030711,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114088614781697,
      "backward_entropy": 0.06276152350685814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.795517444610596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00109799241181463,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113942583401997,
      "backward_entropy": 0.06275232271714644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.609536170959473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011975807137787342,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911386509736379,
      "backward_entropy": 0.0626823902130127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.180907249450684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012969003291800618,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113805492719014,
      "backward_entropy": 0.06273302164944736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.654377460479736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013961989898234606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113737940788269,
      "backward_entropy": 0.06256258487701416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002317428588867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001495274482294917,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113778670628865,
      "backward_entropy": 0.06255212155255405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.932066917419434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00159465370234102,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113784631093343,
      "backward_entropy": 0.06254147399555553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86160659790039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016942573711276054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911378562450409,
      "backward_entropy": 0.06262728842821988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.743720054626465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017940192483365536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113800525665283,
      "backward_entropy": 0.06261580640619452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878106117248535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001893891952931881,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911378264427185,
      "backward_entropy": 0.06250867518511685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854137420654297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019939208868891,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113689263661702,
      "backward_entropy": 0.06249733404679732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709774971008301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002094041556119919,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113618731498718,
      "backward_entropy": 0.0626475377516313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.848966598510742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021938150748610497,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113612771034241,
      "backward_entropy": 0.0626359148459001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.553422927856445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002293719444423914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113617738087972,
      "backward_entropy": 0.06246250325983221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.410886764526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023940098471939564,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113579988479614,
      "backward_entropy": 0.06261221387169578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.477298736572266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002494205255061388,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911353627840678,
      "backward_entropy": 0.0625294338573109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.519159317016602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025943515356630087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113464752833049,
      "backward_entropy": 0.06242607940327038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.404141426086426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026944433338940144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113429983456929,
      "backward_entropy": 0.06241346489299427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.288324356079102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027944624889642,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113387266794841,
      "backward_entropy": 0.062400622801347214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.534699440002441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028947689570486546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113305807113647,
      "backward_entropy": 0.06238754770972512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646184921264648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029954162891954184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113190571467082,
      "backward_entropy": 0.06237427754835649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.279029846191406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003096003783866763,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113077322642009,
      "backward_entropy": 0.06244616074995561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502687454223633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031967994291335344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112932284673055,
      "backward_entropy": 0.06234705448150635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.086187362670898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003297436749562621,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112826983133952,
      "backward_entropy": 0.062416542660106315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.199942588806152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033985935151576996,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112667044003804,
      "backward_entropy": 0.062401549382643265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770635604858398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003499841084703803,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112486243247986,
      "backward_entropy": 0.062304778532548385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45138931274414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036010064650326967,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112276633580525,
      "backward_entropy": 0.062370679595253685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.782624244689941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037019599694758654,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112062056859334,
      "backward_entropy": 0.06235479224811901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.116625785827637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0038033046294003725,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09111774961153667,
      "backward_entropy": 0.062419978055087005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.828261375427246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0039046667516231537,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09111503760019939,
      "backward_entropy": 0.06240416656840931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.071208000183105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004005954600870609,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111203749974568,
      "backward_entropy": 0.06230726025321267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.036798477172852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0041072736494243145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09110877911249797,
      "backward_entropy": 0.06229062513871626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.171492576599121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004208564292639494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09110583861668904,
      "backward_entropy": 0.06219725175337358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.934676170349121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004309902898967266,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911029080549876,
      "backward_entropy": 0.06233761527321555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.302194595336914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004411634057760239,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109948078791301,
      "backward_entropy": 0.06223859570243142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.229119300842285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004513428546488285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109584490458171,
      "backward_entropy": 0.062220530076460404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.234018325805664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0046152351424098015,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09109214941660564,
      "backward_entropy": 0.06228427453474565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.038578033447266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004717505536973476,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108797709147136,
      "backward_entropy": 0.06218343431299383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.391594886779785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004819188266992569,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108427166938782,
      "backward_entropy": 0.06216421994295987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72655963897705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0049209450371563435,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09108064572016399,
      "backward_entropy": 0.06222777475010265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.273319244384766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005022491794079542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910769800345103,
      "backward_entropy": 0.06205816702409224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.096480369567871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005123624112457037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09107373158137004,
      "backward_entropy": 0.06203952702608975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.958544731140137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005224320571869612,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910707414150238,
      "backward_entropy": 0.06202061609788374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.714460372924805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005325026344507933,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09106763203938802,
      "backward_entropy": 0.062061607837677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.708864212036133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005426106974482536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09106383721033733,
      "backward_entropy": 0.062039310281926933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.188718795776367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005527039989829063,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910600225130717,
      "backward_entropy": 0.06196174838326194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42609691619873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005628050770610571,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09105618794759114,
      "backward_entropy": 0.061993203379891136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.560527801513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005729232914745808,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09105225404103597,
      "backward_entropy": 0.06205645474520596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69363784790039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005830163136124611,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0910486380259196,
      "backward_entropy": 0.06194570931521329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.553079605102539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005930949002504349,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09104493260383606,
      "backward_entropy": 0.06192134727131237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.131298065185547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0060315215960145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09104150533676147,
      "backward_entropy": 0.061858047138560905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.785970687866211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006132215261459351,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910375714302063,
      "backward_entropy": 0.061836053024638786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.881875038146973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006232808344066143,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103391567866008,
      "backward_entropy": 0.061845248395746406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.77780818939209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006333407014608383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09102980295817058,
      "backward_entropy": 0.06179110570387407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.773651123046875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0064339106902480125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09102598826090495,
      "backward_entropy": 0.061791869727048004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.144750595092773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006534327287226915,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0910225510597229,
      "backward_entropy": 0.06176461956717751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.660816192626953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006634855177253485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910189946492513,
      "backward_entropy": 0.0617209022695368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.324091911315918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006735261529684067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09101539850234985,
      "backward_entropy": 0.06170872666619041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65213394165039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006834922358393669,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09101225932439168,
      "backward_entropy": 0.06167279590259899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.470081329345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006934555247426033,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09100906054178874,
      "backward_entropy": 0.06173939054662531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.269521713256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007034517824649811,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100600083669026,
      "backward_entropy": 0.061622576280073685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.900437355041504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0071342200972139835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09100319941838582,
      "backward_entropy": 0.061585523865439674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.260687828063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007234474178403616,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09099995096524556,
      "backward_entropy": 0.06164753437042236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00149917602539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007334429770708084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09099697073300679,
      "backward_entropy": 0.061539292335510254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.147062301635742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00743450690060854,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0909935732682546,
      "backward_entropy": 0.06148331815546209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.40024471282959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007534272037446499,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099022547403972,
      "backward_entropy": 0.0614471977407282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.289717674255371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007634355220943689,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09098645051320393,
      "backward_entropy": 0.061513765291734177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.454776763916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007734690327197313,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09098208944002788,
      "backward_entropy": 0.061478159644386986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839934349060059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00783531554043293,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09097736080487569,
      "backward_entropy": 0.06144148653203791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.612929344177246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007935889065265656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09097261230150859,
      "backward_entropy": 0.06134875254197554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8513007164001465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008036788552999496,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09096747636795044,
      "backward_entropy": 0.061366059563376686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.362127304077148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008137094788253307,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09096318483352661,
      "backward_entropy": 0.06121434948661111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.881612777709961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00823763944208622,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09095853567123413,
      "backward_entropy": 0.06117294051430442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.28250789642334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008338169194757938,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095369776089986,
      "backward_entropy": 0.061205267906188965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10493278503418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00843886286020279,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09094872077306111,
      "backward_entropy": 0.0612033334645358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.615828990936279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00853962916880846,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09094349543253581,
      "backward_entropy": 0.061159686608748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.628571510314941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008639739826321602,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09093864758809407,
      "backward_entropy": 0.06109534610401501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.686330795288086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00874024536460638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09093329310417175,
      "backward_entropy": 0.06095304814251987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.939491271972656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008841140195727348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0909273624420166,
      "backward_entropy": 0.06101916053078391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.540491104125977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008941493928432465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09092192848523457,
      "backward_entropy": 0.06086254119873047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.097764015197754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009042163379490376,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09091609716415405,
      "backward_entropy": 0.06081581115722656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.694825172424316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009142379276454449,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09091090162595113,
      "backward_entropy": 0.06076784567399458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.979977607727051,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009242989122867584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09090539813041687,
      "backward_entropy": 0.0608587535944852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.039813995361328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009343113750219345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09090026219685872,
      "backward_entropy": 0.06081700325012207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.523804664611816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009443338960409164,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09089484810829163,
      "backward_entropy": 0.060615127736871895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.468671798706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009543928317725658,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09088856975237529,
      "backward_entropy": 0.060668869452043014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.060074806213379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009644237346947193,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09088295698165894,
      "backward_entropy": 0.060506668957796966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.60269546508789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009743607603013515,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09087853630383809,
      "backward_entropy": 0.06045136668465354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.999711036682129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009843454696238041,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09087332089742024,
      "backward_entropy": 0.06050471826033159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.334237098693848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009943412616848946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09086779753367107,
      "backward_entropy": 0.06055161085995761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.152169227600098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010043113492429256,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09086263179779053,
      "backward_entropy": 0.06028060479597612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.735492706298828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010143005289137363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09085720777511597,
      "backward_entropy": 0.060458074916492806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.712080955505371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010243372060358524,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09085112810134888,
      "backward_entropy": 0.060409692200747406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6709513664245605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010343611240386963,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0908454159895579,
      "backward_entropy": 0.06036054004322399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.716382026672363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010443244129419327,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09084021051724751,
      "backward_entropy": 0.06015238436785611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.118682861328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010542873293161392,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09083475669225057,
      "backward_entropy": 0.06008976156061346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929839134216309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010642183013260365,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09082961082458496,
      "backward_entropy": 0.06002588705583052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.857687950134277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01074162870645523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09082408746083577,
      "backward_entropy": 0.05984643372622403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.617644309997559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010841150768101215,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09081838528315227,
      "backward_entropy": 0.05977862531488592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.838678359985352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01094062253832817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09081260363260905,
      "backward_entropy": 0.05970948934555054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.430976867675781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01104015950113535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09080664316813152,
      "backward_entropy": 0.05999213457107544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.588919639587402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011139563284814358,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09080056349436443,
      "backward_entropy": 0.059566649523648346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225017547607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011238915845751762,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09079442421595256,
      "backward_entropy": 0.05961511351845481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.922345161437988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01133802067488432,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09078868230183919,
      "backward_entropy": 0.059541068293831566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.391209602355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011437295004725456,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09078242381413777,
      "backward_entropy": 0.0594657226042314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.424837112426758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01153644546866417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09077607591946919,
      "backward_entropy": 0.05926245992833918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.581729888916016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01163547020405531,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09076996644337972,
      "backward_entropy": 0.05917917598377575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.612081527709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011734453029930592,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09076416492462158,
      "backward_entropy": 0.05922963402488015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972003936767578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011832940392196178,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09075877070426941,
      "backward_entropy": 0.05900807814164595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.275679588317871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011931671760976315,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09075297911961873,
      "backward_entropy": 0.05906405774029819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.097148895263672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012030270881950855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0907471776008606,
      "backward_entropy": 0.059362611987374046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.359354019165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012128672562539577,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09074134627978007,
      "backward_entropy": 0.05889206040989269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.180510520935059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012227000668644905,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09073574344317119,
      "backward_entropy": 0.058803525837984955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.895071983337402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012325183488428593,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09073027968406677,
      "backward_entropy": 0.058547550981695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.958478927612305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012424166314303875,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09072327613830566,
      "backward_entropy": 0.05845033038746227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.750241279602051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012523350305855274,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09071584542592366,
      "backward_entropy": 0.058528683402321556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.272613525390625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012622088193893433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09070881207784016,
      "backward_entropy": 0.05892182480205189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.809843063354492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012720141559839249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0907030701637268,
      "backward_entropy": 0.05884131518277255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.021833419799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012818442657589912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09069656332333882,
      "backward_entropy": 0.058758806098591194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.829886436462402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012917074374854565,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09068921208381653,
      "backward_entropy": 0.05813801288604736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.422226905822754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013015873730182648,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09068159262339275,
      "backward_entropy": 0.05782582543113015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51615047454834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01311462465673685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09067380428314209,
      "backward_entropy": 0.058499563824046745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.01038646697998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01321336068212986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09066607554753621,
      "backward_entropy": 0.05840970169414173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.644595146179199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013312348164618015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09065794944763184,
      "backward_entropy": 0.058317785913294014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420243263244629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013410856015980244,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09065011143684387,
      "backward_entropy": 0.05822485685348511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.18648624420166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01350935734808445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09064169724782307,
      "backward_entropy": 0.05813021009618586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.611969947814941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013608229346573353,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09063274661699931,
      "backward_entropy": 0.05712904713370583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.042396545410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013707156293094158,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09062335888544719,
      "backward_entropy": 0.05725985223596746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183069229125977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013806355185806751,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09061335523923238,
      "backward_entropy": 0.057833395221016624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.503002166748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013905322179198265,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09060373902320862,
      "backward_entropy": 0.05701774900609797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.039826393127441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014004267752170563,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09059385458628337,
      "backward_entropy": 0.05762358145280318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46876335144043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014102953486144543,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09058405955632527,
      "backward_entropy": 0.056476387110623444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.282438278198242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014202172867953777,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0905730923016866,
      "backward_entropy": 0.05663742802359841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.539345741271973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014301239512860775,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09056192636489868,
      "backward_entropy": 0.05650621110742742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.571123123168945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01440027542412281,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09055082003275554,
      "backward_entropy": 0.05717586387287487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.666216850280762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014499854296445847,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09053867061932881,
      "backward_entropy": 0.05591142177581787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.645216941833496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014599444344639778,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09052607417106628,
      "backward_entropy": 0.056937824596058235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.130319595336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014698995277285576,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09051366647084554,
      "backward_entropy": 0.05595746365460483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.274526596069336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014798229560256004,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905019740263621,
      "backward_entropy": 0.055466619404879486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.035533905029297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014897247776389122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09049093723297119,
      "backward_entropy": 0.05656739256598733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.525204181671143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014995984733104706,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09047999978065491,
      "backward_entropy": 0.0551621209491383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429479598999023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015094188041985035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09046973784764607,
      "backward_entropy": 0.055005246942693535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19042682647705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015192446298897266,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09045854210853577,
      "backward_entropy": 0.05484442277388139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.708988189697266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015290587209165096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09044724702835083,
      "backward_entropy": 0.05605020306327126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.199868202209473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015388920903205872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09043505787849426,
      "backward_entropy": 0.0559126463803378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.692903995513916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015487145632505417,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09042262037595113,
      "backward_entropy": 0.05577275969765403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.562838077545166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015584990382194519,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0904105802377065,
      "backward_entropy": 0.05417198484594172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.650224685668945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015682445839047432,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09039861957232158,
      "backward_entropy": 0.055487903681668366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.945009708404541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015779541805386543,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09038734436035156,
      "backward_entropy": 0.05425083637237549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.17862606048584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015876535326242447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09037566184997559,
      "backward_entropy": 0.053635261275551536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.430680274963379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015972962602972984,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09036564826965332,
      "backward_entropy": 0.053907914595170456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.555064678192139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016069604083895683,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09035482009251912,
      "backward_entropy": 0.05489348823373968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.059146404266357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01616596058011055,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0903442104657491,
      "backward_entropy": 0.05355378172614358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.294762134552002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016261743381619453,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0903351902961731,
      "backward_entropy": 0.05288503928617998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.011893272399902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016357190907001495,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09032652775446574,
      "backward_entropy": 0.05318873578851873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3020830154418945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016452714800834656,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09031749765078227,
      "backward_entropy": 0.05249346928163008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538405418395996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016547907143831253,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0903091828028361,
      "backward_entropy": 0.054096996784210205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.780707836151123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016642944887280464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09030100703239441,
      "backward_entropy": 0.05392987619746815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.006300926208496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016737405210733414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09029430150985718,
      "backward_entropy": 0.05376133051785556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.04093599319458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01683206856250763,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09028653303782146,
      "backward_entropy": 0.05167927525260232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.338397026062012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016926359385252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090279887119929,
      "backward_entropy": 0.051467651670629326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.981346130371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017019912600517273,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0902750293413798,
      "backward_entropy": 0.05182049491188743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.942424297332764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0171132143586874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09026930729548137,
      "backward_entropy": 0.053066589615561745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.220016479492188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0172068253159523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09026199579238892,
      "backward_entropy": 0.050805259834636345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.56659460067749,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017300890758633614,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09025253852208455,
      "backward_entropy": 0.05119400674646551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.485962867736816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01739499717950821,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09024206797281902,
      "backward_entropy": 0.05251389200037176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4655022621154785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017489084973931313,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09023088216781616,
      "backward_entropy": 0.05010489983992143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7068915367126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017583109438419342,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09021977583567302,
      "backward_entropy": 0.0505445274439725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.16585922241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017676662653684616,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09020954370498657,
      "backward_entropy": 0.050324320793151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.214188575744629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017770640552043915,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09019746383031209,
      "backward_entropy": 0.05010090091011741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.829126834869385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01786443591117859,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09018550316492717,
      "backward_entropy": 0.05153516747734763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360285758972168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017958471551537514,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09017176429430644,
      "backward_entropy": 0.048872394995255905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.474429607391357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018053021281957626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09015574057896932,
      "backward_entropy": 0.051117252219807015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.488929748535156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018146855756640434,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09014235933621724,
      "backward_entropy": 0.04835821281779896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.88615083694458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018240688368678093,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09012851119041443,
      "backward_entropy": 0.04894044724377719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.607670783996582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018334798514842987,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09011269609133403,
      "backward_entropy": 0.05046845566142689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.52824068069458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018428366631269455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09009798367818196,
      "backward_entropy": 0.050246628847989167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.031242847442627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018521392717957497,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09008459250132243,
      "backward_entropy": 0.0482103553685275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6154866218566895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018614258617162704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09007099270820618,
      "backward_entropy": 0.04979694973338734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.024550914764404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01870669797062874,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0900587538878123,
      "backward_entropy": 0.047702301632274284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.03084135055542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018799008801579475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09004651506741841,
      "backward_entropy": 0.04933695901523937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.036069393157959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018891220912337303,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09003396828969319,
      "backward_entropy": 0.04717591675845059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.271089553833008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018983356654644012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09002083539962769,
      "backward_entropy": 0.04886382276361639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6727705001831055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0190749391913414,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09000920255978902,
      "backward_entropy": 0.045612367716702545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.888298988342285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01916627772152424,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08999781807263692,
      "backward_entropy": 0.0463627739386125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.073245048522949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01925693266093731,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08998810251553853,
      "backward_entropy": 0.04813862930644642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.185070991516113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01934770494699478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08997705578804016,
      "backward_entropy": 0.04789130796085705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9823689460754395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019438643008470535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08996464808781941,
      "backward_entropy": 0.04763954335992986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.51448917388916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0195302776992321,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08994832634925842,
      "backward_entropy": 0.04738150943409313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.262956619262695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019621582701802254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08993230263392131,
      "backward_entropy": 0.04712124304337935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.857117652893066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019713101908564568,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08991402387619019,
      "backward_entropy": 0.04466258937662298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7729620933532715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01980452798306942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08989507953325908,
      "backward_entropy": 0.04658873514695601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3420820236206055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01989644207060337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08987363179524739,
      "backward_entropy": 0.04288790442726829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.180710792541504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01998789608478546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08985282977422078,
      "backward_entropy": 0.046035842462019486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.238719463348389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020079493522644043,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08983019987742107,
      "backward_entropy": 0.04347589612007141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.137791633605957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020171239972114563,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08980602025985718,
      "backward_entropy": 0.04193191636692394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.812235355377197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020262446254491806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08978235721588135,
      "backward_entropy": 0.04516697742722251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.474171161651611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02035289630293846,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08976115783055623,
      "backward_entropy": 0.04255868088115345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.542277812957764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02044246904551983,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08974264065424602,
      "backward_entropy": 0.04095410487868569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.213215351104736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020531943067908287,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0897236168384552,
      "backward_entropy": 0.04428512670777061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.220283031463623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020620517432689667,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08970688780148824,
      "backward_entropy": 0.04398945786736228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.46958065032959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020708883181214333,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08969024817148845,
      "backward_entropy": 0.043690632690082894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.92473840713501,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020797254517674446,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08967228730519612,
      "backward_entropy": 0.04098500446839766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.823636054992676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020885923877358437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08965197205543518,
      "backward_entropy": 0.04307975010438399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2365922927856445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02097414806485176,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08963207403818767,
      "backward_entropy": 0.038969121196053245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.361832618713379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021062228828668594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08961188793182373,
      "backward_entropy": 0.04245769706639377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.027583122253418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021150268614292145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08959200978279114,
      "backward_entropy": 0.042141703042117035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1877923011779785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021238069981336594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08957147598266602,
      "backward_entropy": 0.041823376308787956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.782643795013428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02132577635347843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08954936265945435,
      "backward_entropy": 0.0415020693432201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9403815269470215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021413128823041916,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08952697118123372,
      "backward_entropy": 0.03728717565536499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.675388813018799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021500281989574432,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08950334787368774,
      "backward_entropy": 0.0383486422625455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.829563617706299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02158706821501255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08947953581809998,
      "backward_entropy": 0.03659910505468195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.980477333068848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021673642098903656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08945462107658386,
      "backward_entropy": 0.04019896550612016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.378886699676514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02176014520227909,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08942782878875732,
      "backward_entropy": 0.0398675257509405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.93658447265625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021846158429980278,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08940154314041138,
      "backward_entropy": 0.03953564167022705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.863579273223877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021932154893875122,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08937342961629231,
      "backward_entropy": 0.03519426421685652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.941133499145508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022017331793904305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0893477201461792,
      "backward_entropy": 0.03886741941625422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.218017101287842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02210181951522827,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08932387828826904,
      "backward_entropy": 0.03853462230075489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.23158073425293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02218511700630188,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08930535117785136,
      "backward_entropy": 0.035643377087332985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.943613529205322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022268146276474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08928611874580383,
      "backward_entropy": 0.03787350654602051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4083991050720215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022350706160068512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08926751216252644,
      "backward_entropy": 0.03754063086076216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.256533145904541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022433197125792503,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08924715717633565,
      "backward_entropy": 0.03306040980599143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.424513816833496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022515539079904556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08922519286473592,
      "backward_entropy": 0.03270431540229104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8797502517700195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022597894072532654,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08920057614644368,
      "backward_entropy": 0.03234631364995783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.125946998596191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022679807618260384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08917619784673055,
      "backward_entropy": 0.03618348999456926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.86240291595459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02276073768734932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08915553490320842,
      "backward_entropy": 0.03584471344947815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.615950107574463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02284139394760132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08913391828536987,
      "backward_entropy": 0.03127784349701621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.021975994110107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0229216068983078,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08911242087682088,
      "backward_entropy": 0.0351628227667375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.055302143096924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023001734167337418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08908880750338237,
      "backward_entropy": 0.034818730571053245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8990864753723145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02308184653520584,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08906248211860657,
      "backward_entropy": 0.031836566599932586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.867655277252197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02316179685294628,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08903439839680989,
      "backward_entropy": 0.03148996829986572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.62442684173584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023241590708494186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08900439739227295,
      "backward_entropy": 0.03377352519468828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9679675102233887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02332104556262493,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08897358179092407,
      "backward_entropy": 0.03079779581590132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.649317264556885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023399675264954567,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08894517024358113,
      "backward_entropy": 0.030453784899278122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.411139488220215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023478109389543533,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08891499042510986,
      "backward_entropy": 0.03272667798128995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.726469993591309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023556169122457504,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08888420462608337,
      "backward_entropy": 0.029766827821731567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.144502639770508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023634186014533043,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08885058760643005,
      "backward_entropy": 0.029424323277039963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.397460460662842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023711657151579857,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08881738781929016,
      "backward_entropy": 0.02908286994153803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.389239311218262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02378886006772518,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0887825886408488,
      "backward_entropy": 0.03132752667773853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.406375408172607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023865841329097748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08874579270680745,
      "backward_entropy": 0.026696126569401134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9562907218933105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023942675441503525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08870673179626465,
      "backward_entropy": 0.030626023357564754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.33308744430542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02401895262300968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08866792917251587,
      "backward_entropy": 0.030276740139180965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.105294704437256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024095069617033005,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0886266827583313,
      "backward_entropy": 0.025662755424326115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.495389938354492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02417083829641342,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08858417471249898,
      "backward_entropy": 0.029577295888553966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.660405397415161,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024246664717793465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08853772282600403,
      "backward_entropy": 0.024983097206462513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4925858974456787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024321764707565308,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08849259217580159,
      "backward_entropy": 0.02464711124246771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.060977458953857,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024396074935793877,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08844936887423198,
      "backward_entropy": 0.024313601580533115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8699281215667725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02447018027305603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08840360244115193,
      "backward_entropy": 0.0281882719560103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.999878406524658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024542972445487976,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08836363752683003,
      "backward_entropy": 0.023659559813412754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9336369037628174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024615701287984848,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08832011620203654,
      "backward_entropy": 0.0233367844061418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.05238676071167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024688320234417915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08827332655588786,
      "backward_entropy": 0.02717186916958202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.700438976287842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02475997991859913,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08822953701019287,
      "backward_entropy": 0.02445110949602994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.105555534362793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024831440299749374,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08818309505780537,
      "backward_entropy": 0.02238188006661155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.232137441635132,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024902131408452988,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08813828229904175,
      "backward_entropy": 0.02617231011390686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.367936611175537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02497228793799877,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0880935291449229,
      "backward_entropy": 0.025844324718822132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9124319553375244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025042079389095306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08804726600646973,
      "backward_entropy": 0.02144339138811285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8360469341278076,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111069902777672,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08800286054611206,
      "backward_entropy": 0.021135373549027878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7415683269500732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02517925202846527,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08796030282974243,
      "backward_entropy": 0.020831293680451134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.730762243270874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02524658665060997,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08791975180308025,
      "backward_entropy": 0.020530571991747074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.288198947906494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02531425841152668,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08787208795547485,
      "backward_entropy": 0.020229771733283997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6340150833129883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02538176067173481,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08782101670900981,
      "backward_entropy": 0.02168239653110504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5076074600219727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025448404252529144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0877720316251119,
      "backward_entropy": 0.02361407605084506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.723863124847412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02551409602165222,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08772560954093933,
      "backward_entropy": 0.02109579606489702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3043904304504395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025579197332262993,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08767898877461751,
      "backward_entropy": 0.0190618634223938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6287357807159424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025644473731517792,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0876263976097107,
      "backward_entropy": 0.018777434121478687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.447378158569336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025709111243486404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08757394552230835,
      "backward_entropy": 0.022392253984104504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.108053207397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025773029774427414,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08752304315567017,
      "backward_entropy": 0.019957039843906055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1015162467956543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025835856795310974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08747647205988567,
      "backward_entropy": 0.021801062605597755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.424508810043335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025898870080709457,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08742307623227437,
      "backward_entropy": 0.021506890654563904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7489473819732666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02596125937998295,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08736954132715861,
      "backward_entropy": 0.01740272343158722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8713874816894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026023464277386665,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0873119334379832,
      "backward_entropy": 0.01886802911758423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.249880075454712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026084421202540398,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08725931247075398,
      "backward_entropy": 0.018603066151792354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.292388677597046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02614474669098854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08720651268959045,
      "backward_entropy": 0.02036368575963107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8557791709899902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026204558089375496,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08715246121088664,
      "backward_entropy": 0.016373504291881214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.436605453491211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626335248351097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0871017078558604,
      "backward_entropy": 0.01981613581830805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.009330987930298,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026322033256292343,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08704677224159241,
      "backward_entropy": 0.017577599395405163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7078793048858643,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026379980146884918,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.086992214123408,
      "backward_entropy": 0.01564174077727578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0619325637817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026436883956193924,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08694096406300862,
      "backward_entropy": 0.01708583262833682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.754790186882019,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026493359357118607,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08688786625862122,
      "backward_entropy": 0.016845508055253464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9137084484100342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026549041271209717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08683636784553528,
      "backward_entropy": 0.018507360057397323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.416070818901062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02660425752401352,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08678384621938069,
      "backward_entropy": 0.014718497341329401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7551538944244385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026658331975340843,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08673632144927979,
      "backward_entropy": 0.014495571905916388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5806702375411987,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02671181596815586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08668786287307739,
      "backward_entropy": 0.017771170897917313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7781084775924683,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026764553040266037,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08664051691691081,
      "backward_entropy": 0.0157084275375713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7139548063278198,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026816904544830322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08659076690673828,
      "backward_entropy": 0.0172963332046162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4479546546936035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268687941133976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08653892079989116,
      "backward_entropy": 0.01706201379949396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6365864276885986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026919882744550705,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08648846546808879,
      "backward_entropy": 0.013436832211234352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6948453187942505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02697053551673889,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08643580476442973,
      "backward_entropy": 0.016604384238069706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7723724842071533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027020923793315887,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08637991547584534,
      "backward_entropy": 0.013036960905248468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2292649745941162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027071168646216393,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08631900946299235,
      "backward_entropy": 0.0161518319086595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1698880195617676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027120433747768402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08626107374827068,
      "backward_entropy": 0.015930609269575638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6457064151763916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02716868184506893,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08620605866114299,
      "backward_entropy": 0.0157149461182681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6020114421844482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0272168330848217,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08614579836527507,
      "backward_entropy": 0.013873807408592918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.269521713256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027264833450317383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08608074982961018,
      "backward_entropy": 0.01528494195504622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9041925668716431,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027312103658914566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0860155423482259,
      "backward_entropy": 0.015074285593899813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.468507170677185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027358077466487885,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08595619599024455,
      "backward_entropy": 0.011745297095992348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2382702827453613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027403902262449265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08589147528012593,
      "backward_entropy": 0.01466819237578999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.078343391418457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027449186891317368,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08582526445388794,
      "backward_entropy": 0.014468409798362038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2163364887237549,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027493692934513092,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08575983842213948,
      "backward_entropy": 0.01427292146465995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8839220404624939,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027537735179066658,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08569199840227763,
      "backward_entropy": 0.012614928863265297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0357130765914917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027580726891756058,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0856274167696635,
      "backward_entropy": 0.013892525976354425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9892795085906982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027623075991868973,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08556221922238667,
      "backward_entropy": 0.013708588751879606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9135103821754456,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02766471914947033,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08549646536509196,
      "backward_entropy": 0.012124182148413225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8995072841644287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277055986225605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08543118834495544,
      "backward_entropy": 0.013352045958692377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7954921126365662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027745794504880905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08536626895268758,
      "backward_entropy": 0.013179433616724882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9360061883926392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02778509631752968,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08530279000600179,
      "backward_entropy": 0.011664562604644081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1206742525100708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02782391384243965,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08523726463317871,
      "backward_entropy": 0.011517164382067594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7258368730545044,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027862725779414177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08516572912534077,
      "backward_entropy": 0.012680200013247404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0145386457443237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027900628745555878,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08509599169095357,
      "backward_entropy": 0.012519262053749779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9322241544723511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02793842926621437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08502157529195149,
      "backward_entropy": 0.012358914722095837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8635157942771912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027975942939519882,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08494391043980916,
      "backward_entropy": 0.012198964303190058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6405799388885498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028013072907924652,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08486429850260417,
      "backward_entropy": 0.010811998762867668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9313411116600037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028049273416399956,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0847869614760081,
      "backward_entropy": 0.011887385086579756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5416025519371033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028085365891456604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08470463752746582,
      "backward_entropy": 0.011734256690198725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6125144362449646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02812032774090767,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08462575078010559,
      "backward_entropy": 0.011586706746708263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6117637753486633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02815447375178337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0845478077729543,
      "backward_entropy": 0.008958821269598875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6225400567054749,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02818797342479229,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08447099725405376,
      "backward_entropy": 0.008849099278450012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5913310647010803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028220880776643753,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08439402778943379,
      "backward_entropy": 0.011165357448837974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6971877217292786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028253117576241493,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08431661128997803,
      "backward_entropy": 0.011031100695783442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8627261519432068,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828511781990528,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08423601587613423,
      "backward_entropy": 0.009834156794981523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38969141244888306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028317416086792946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08414791027704875,
      "backward_entropy": 0.01076357676224275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3711242079734802,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028348522260785103,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08406410614649455,
      "backward_entropy": 0.008333334191278978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5723690390586853,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02837846428155899,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08398401737213135,
      "backward_entropy": 0.008238800547339699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.490885466337204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028408050537109375,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08390185236930847,
      "backward_entropy": 0.00940872999754819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43320342898368835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028437096625566483,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08381977677345276,
      "backward_entropy": 0.010271707719022577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4181734621524811,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028465403243899345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0837383766969045,
      "backward_entropy": 0.010156349702314897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49590131640434265,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028492992743849754,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08365744352340698,
      "backward_entropy": 0.009120454842394049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33362075686454773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028520213440060616,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08357426524162292,
      "backward_entropy": 0.009029201485893944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46567317843437195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028546566143631935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08349369963010152,
      "backward_entropy": 0.009825745766813105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41727277636528015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02857261151075363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08341095844904582,
      "backward_entropy": 0.009720056571743706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4085896611213684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028598155826330185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08332674702008565,
      "backward_entropy": 0.009616510434584185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3400300145149231,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028623295947909355,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08324163158734639,
      "backward_entropy": 0.008688445118340578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45945632457733154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028647789731621742,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08315721650918324,
      "backward_entropy": 0.007410827008160678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31451332569122314,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028672238811850548,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08306954304377238,
      "backward_entropy": 0.008529801260341297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2534065544605255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028695983812212944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08298250039418538,
      "backward_entropy": 0.009222078052434053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.268342524766922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028718801215291023,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08289737502733867,
      "backward_entropy": 0.007199904458089309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34883520007133484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028740856796503067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08281318346659343,
      "backward_entropy": 0.007134871726686304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2518770098686218,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028762567788362503,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08272650837898254,
      "backward_entropy": 0.007071337916634299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3059097230434418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02878360077738762,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08264113465944926,
      "backward_entropy": 0.008872047066688538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25515642762184143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028804248198866844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08255436023076375,
      "backward_entropy": 0.008789821104569868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3249202370643616,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02882433868944645,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08246797323226929,
      "backward_entropy": 0.008049744773994793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27751487493515015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028844228014349937,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08237856129805247,
      "backward_entropy": 0.00863084467974576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24819661676883698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02886381186544895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08228861292203267,
      "backward_entropy": 0.008553099903193388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14956875145435333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02888292260468006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08219840129216512,
      "backward_entropy": 0.00672428851777857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.214066281914711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028901098296046257,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08211162686347961,
      "backward_entropy": 0.007816148075190458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20697499811649323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028918759897351265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0820248822371165,
      "backward_entropy": 0.008335958827625622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21661005914211273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028935924172401428,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08193814257780711,
      "backward_entropy": 0.008268655701117083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24114547669887543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028952714055776596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08185113469759624,
      "backward_entropy": 0.008202566341920332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21781668066978455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028969310224056244,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08176244795322418,
      "backward_entropy": 0.007614391771229831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1955071985721588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028985610231757164,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08167289694150288,
      "backward_entropy": 0.008072656663981352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17491918802261353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029001601040363312,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0815834105014801,
      "backward_entropy": 0.00800980424339121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16860619187355042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029017100110650063,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08149353166421254,
      "backward_entropy": 0.006348718296397816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1634603887796402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029032204300165176,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08140421410401662,
      "backward_entropy": 0.0063073032281615515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20969103276729584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029046861454844475,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08131487170855205,
      "backward_entropy": 0.006267296996983615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17792433500289917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0290614552795887,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08122316499551137,
      "backward_entropy": 0.007775069637732072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1479409784078598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02907576411962509,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08113040526707967,
      "backward_entropy": 0.007718974216417832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16624583303928375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029089605435729027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08103779951731364,
      "backward_entropy": 0.007664710960604928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12702710926532745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029103176668286324,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08094427486260732,
      "backward_entropy": 0.007611494172703136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11251655966043472,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02911621890962124,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08085156480471294,
      "backward_entropy": 0.006081266836686568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1515215039253235,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029128652065992355,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08075984319051106,
      "backward_entropy": 0.006048455834388733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12480247765779495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02914082072675228,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08066656192143758,
      "backward_entropy": 0.0074636407873847265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1700815111398697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029152635484933853,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08057377735773723,
      "backward_entropy": 0.007102668285369873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10726641118526459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029164502397179604,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08047850430011749,
      "backward_entropy": 0.005954934114759619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13201160728931427,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02917592227458954,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08038438856601715,
      "backward_entropy": 0.005925485356287522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12735900282859802,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029187124222517014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08028969168663025,
      "backward_entropy": 0.007281517440622503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07999403774738312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029198119416832924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08019460240999858,
      "backward_entropy": 0.0072380974888801575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09402413666248322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920854091644287,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08010171353816986,
      "backward_entropy": 0.007197010923515667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12164133042097092,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029218576848506927,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08000979324181874,
      "backward_entropy": 0.0058170468969778585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1200614869594574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029228592291474342,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0799172321955363,
      "backward_entropy": 0.007117929783734408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11543095856904984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029238484799861908,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982319593429565,
      "backward_entropy": 0.0070788799361749125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09652034193277359,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029248269274830818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07972809175650279,
      "backward_entropy": 0.007040253417058425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1012900248169899,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029257813468575478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07963353395462036,
      "backward_entropy": 0.007002534514123743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0779087021946907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029267162084579468,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07953841984272003,
      "backward_entropy": 0.006965549832040613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10007068514823914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029276102781295776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07944422463576,
      "backward_entropy": 0.006930104710839011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07879316806793213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029284972697496414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07934972643852234,
      "backward_entropy": 0.006894940002398057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08218959718942642,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02929353341460228,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07925579945246379,
      "backward_entropy": 0.006748878820375962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07808344066143036,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02930186688899994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07916197180747986,
      "backward_entropy": 0.006827835332263599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08728984743356705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029310021549463272,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.079068789879481,
      "backward_entropy": 0.006795684045011347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07967725396156311,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931811287999153,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0789753794670105,
      "backward_entropy": 0.0067638985135338526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0808115303516388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029326042160391808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07888194918632507,
      "backward_entropy": 0.006732761859893799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07508096098899841,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029333915561437607,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07878880699475606,
      "backward_entropy": 0.006701736287637191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08620695024728775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029341598972678185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078695813814799,
      "backward_entropy": 0.006671115078709342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07393156737089157,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029349302873015404,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07860222458839417,
      "backward_entropy": 0.00661631470376795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0668744370341301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029356883838772774,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07850854595502217,
      "backward_entropy": 0.006598215211521496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0733007863163948,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02936427667737007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07841530442237854,
      "backward_entropy": 0.006579680198972876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0581069216132164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0293715950101614,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07832145690917969,
      "backward_entropy": 0.0054531019519675865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06199074164032936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029378661885857582,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07822815577189128,
      "backward_entropy": 0.006522126495838165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04278377443552017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029385659843683243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07813544074694316,
      "backward_entropy": 0.006494218652898615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05125078931450844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029392238706350327,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07804433504740398,
      "backward_entropy": 0.005405851047147404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04400226101279259,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02939862571656704,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07795427242914836,
      "backward_entropy": 0.005391673608259721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05528312548995018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029404673725366592,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07786522805690765,
      "backward_entropy": 0.005378444425084374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06123504415154457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029410645365715027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07777596016724904,
      "backward_entropy": 0.006393742154945026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05475882440805435,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029416751116514206,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07768634955088298,
      "backward_entropy": 0.005352227863940326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05135781317949295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02942279540002346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07759646574656169,
      "backward_entropy": 0.006345079703764482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03577389568090439,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029428813606500626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0775069644053777,
      "backward_entropy": 0.006321025842970068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029581090435385704,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943451516330242,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07741927107175191,
      "backward_entropy": 0.00531358847563917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04349435865879059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029439803212881088,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0773335446914037,
      "backward_entropy": 0.006410083987496116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04165777936577797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029445042833685875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07724830508232117,
      "backward_entropy": 0.0062552446668798275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038469236344099045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02945023402571678,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0771636168162028,
      "backward_entropy": 0.006387369199232621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023890743032097816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02945529855787754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07707956930001576,
      "backward_entropy": 0.006213797764344649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024840714409947395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02945992723107338,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07699729998906453,
      "backward_entropy": 0.005260457708076997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042893387377262115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029464220628142357,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0769166648387909,
      "backward_entropy": 0.0061769343235275965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0369727686047554,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02946864627301693,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07683551808198293,
      "backward_entropy": 0.005242830989035693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032533496618270874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029473094269633293,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07675472398598988,
      "backward_entropy": 0.006339602172374725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03812786191701889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029477434232831,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07667409876982371,
      "backward_entropy": 0.00612250647761605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024049710482358932,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029481876641511917,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0765936275323232,
      "backward_entropy": 0.006321357732469385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02950362302362919,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02948608435690403,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651467124621074,
      "backward_entropy": 0.006087194112214175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026725172996520996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029490169137716293,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0764357050259908,
      "backward_entropy": 0.006304499777880582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024380160495638847,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029494095593690872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07635709643363953,
      "backward_entropy": 0.006054262545975772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028173359110951424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029497919604182243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07627976934115092,
      "backward_entropy": 0.006038479506969452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02182641439139843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029501769691705704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0762031078338623,
      "backward_entropy": 0.006022626703435724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022818781435489655,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029505446553230286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07612758874893188,
      "backward_entropy": 0.006007324565540661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021453775465488434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029508989304304123,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07605279982089996,
      "backward_entropy": 0.005161602050065994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019655052572488785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029512424021959305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0759791632493337,
      "backward_entropy": 0.005154847421429374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012829992920160294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951570600271225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07590639094511668,
      "backward_entropy": 0.005964276465502652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02226874977350235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029518645256757736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0758351981639862,
      "backward_entropy": 0.005951616574417461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01772071048617363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029521659016609192,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07576465606689453,
      "backward_entropy": 0.0059387284246358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023533988744020462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0295245461165905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07569484909375508,
      "backward_entropy": 0.005926378071308136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02139965444803238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02952755056321621,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07562517126401265,
      "backward_entropy": 0.005913557654077356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016851237043738365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02953062206506729,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07555597027142842,
      "backward_entropy": 0.005900498818267475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018497290089726448,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029533587396144867,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07548746466636658,
      "backward_entropy": 0.00511442632837729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016790254041552544,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02953658625483513,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07541990280151367,
      "backward_entropy": 0.006217592819170518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01999637484550476,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029539577662944794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07535332441329956,
      "backward_entropy": 0.005102687261321328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014678861945867538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029542680829763412,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07528696954250336,
      "backward_entropy": 0.005849682471968911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011931335553526878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954571507871151,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07522155344486237,
      "backward_entropy": 0.0058370869268070565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01166132278740406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029548566788434982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07515718539555867,
      "backward_entropy": 0.005825169384479523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01069344487041235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029551243409514427,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07509375115235646,
      "backward_entropy": 0.005813886496153745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012457836419343948,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02955378219485283,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07503168781598409,
      "backward_entropy": 0.00507578660141338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008494422771036625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029556289315223694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07497053345044453,
      "backward_entropy": 0.005792444402521307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014928266406059265,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029558541253209114,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0749096969763438,
      "backward_entropy": 0.0061788619919256734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01136435754597187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029560932889580727,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0748490293820699,
      "backward_entropy": 0.005772422660480846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010897516272962093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029563279822468758,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07478890816370647,
      "backward_entropy": 0.005762304772030224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013883505016565323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029565582051873207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07472941279411316,
      "backward_entropy": 0.005752444944598458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010312308557331562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0295680221170187,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07467018564542134,
      "backward_entropy": 0.00616304102269086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010214179754257202,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02957044541835785,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07461185256640117,
      "backward_entropy": 0.005044834857637232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007936096750199795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029572827741503716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07455404102802277,
      "backward_entropy": 0.005721930075775494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008914218284189701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029575105756521225,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07449730237325032,
      "backward_entropy": 0.006150849840857766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009207649156451225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029577376320958138,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07444154222806294,
      "backward_entropy": 0.00570283830165863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008693317882716656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02957965061068535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07438645760218303,
      "backward_entropy": 0.005693439732898365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008013149723410606,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029581930488348007,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07433222730954488,
      "backward_entropy": 0.00502328100529584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008864207193255424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02958417683839798,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07427872220675151,
      "backward_entropy": 0.0061345174908638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005690081976354122,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029586464166641235,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0742257038752238,
      "backward_entropy": 0.0056654428216544065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006536505650728941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029588615521788597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07417383790016174,
      "backward_entropy": 0.005656673826954581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007205481640994549,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02959071286022663,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07412309447924297,
      "backward_entropy": 0.006122483448548751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006088185589760542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029592838138341904,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0740733544031779,
      "backward_entropy": 0.006118428978053006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005463764537125826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029594898223876953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07402438918749492,
      "backward_entropy": 0.005630893463438208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006498068571090698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029596874490380287,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07397620876630147,
      "backward_entropy": 0.005622754381461577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004545769188553095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02959885634481907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07392845551172893,
      "backward_entropy": 0.005614654245701703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005240687169134617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02960074506700039,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07388190428415935,
      "backward_entropy": 0.005606922236355868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003918386530131102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02960260771214962,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07383619248867035,
      "backward_entropy": 0.005599314177578146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004045490175485611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029604360461235046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07379157344500224,
      "backward_entropy": 0.005592074922539971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004788551013916731,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029606029391288757,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07374787330627441,
      "backward_entropy": 0.005585130981423638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004513053223490715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029607703909277916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07370491822560628,
      "backward_entropy": 0.005578235469081185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003513140371069312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02960938587784767,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07366286714871724,
      "backward_entropy": 0.004970898682420904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037040726747363806,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02961098589003086,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07362173000971477,
      "backward_entropy": 0.0060862207954580135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004212476778775454,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029612554237246513,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358155647913615,
      "backward_entropy": 0.005558258430524306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003784822765737772,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02961413934826851,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07354191939036052,
      "backward_entropy": 0.005551782182671807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00365129834972322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029615722596645355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07350307206312816,
      "backward_entropy": 0.0055453235452825374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003958369139581919,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029617294669151306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07346489032109578,
      "backward_entropy": 0.005538890646262603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034666929859668016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02961890958249569,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07342735429604848,
      "backward_entropy": 0.005532361567020416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026332479901611805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029620522633194923,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0733903447786967,
      "backward_entropy": 0.00552590089765462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002254537073895335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029622066766023636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07335421442985535,
      "backward_entropy": 0.005519694564017383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035808724351227283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02962351031601429,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07331884404023488,
      "backward_entropy": 0.004943603480404074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029621273279190063,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02962501533329487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07328379154205322,
      "backward_entropy": 0.00494065135717392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002704270649701357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029626527801156044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07324930032094319,
      "backward_entropy": 0.005501816895875064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023169645573943853,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029628027230501175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07321534554163615,
      "backward_entropy": 0.005495852367444472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020876633934676647,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029629481956362724,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07318198680877686,
      "backward_entropy": 0.006051180037585172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002243404509499669,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029630880802869797,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07314928372701009,
      "backward_entropy": 0.0054845701564442025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017398952040821314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029632246121764183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07311710715293884,
      "backward_entropy": 0.005479129539294677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017079295357689261,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029633549973368645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07308576504389445,
      "backward_entropy": 0.005473921244794672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019672680646181107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029634816572070122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.073055366675059,
      "backward_entropy": 0.0054688609459183435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001315764500759542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029636073857545853,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07302550474802653,
      "backward_entropy": 0.00546385110779242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013282522559165955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029637249186635017,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07299647728602092,
      "backward_entropy": 0.004916305230422454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015841714339330792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02963836118578911,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07296821971734364,
      "backward_entropy": 0.005454626950350675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017469552112743258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029639462009072304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07294066747029622,
      "backward_entropy": 0.0054501505060629415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001415707403793931,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02964058145880699,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07291364669799805,
      "backward_entropy": 0.005445622585036538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012114649871364236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029641686007380486,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07288721700509389,
      "backward_entropy": 0.006028575653379614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014467036817222834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029642751440405846,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0728613833586375,
      "backward_entropy": 0.006026578220454129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010355997364968061,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029643815010786057,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07283586263656616,
      "backward_entropy": 0.004903382875702598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010423334315419197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02964482642710209,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07281095782915752,
      "backward_entropy": 0.005428612909533761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008945092558860779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029645800590515137,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07278661926587422,
      "backward_entropy": 0.0054246891628612175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008616624400019646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02964671514928341,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07276283701260884,
      "backward_entropy": 0.0054209713231433525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009216649923473597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029647594317793846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07273970047632854,
      "backward_entropy": 0.005417379465970126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008432729518972337,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02964845672249794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07271711031595866,
      "backward_entropy": 0.004894342950799249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009605850209482014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029649289324879646,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07269502679506938,
      "backward_entropy": 0.0048927444625984536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000775009160861373,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029650133103132248,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07267345984776814,
      "backward_entropy": 0.004891102286902341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007802210748195648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029650960117578506,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07265248397986095,
      "backward_entropy": 0.004889511587944898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007785467896610498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02965177781879902,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07263203461964925,
      "backward_entropy": 0.005400495773011988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005186453345231712,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029652591794729233,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07261208693186443,
      "backward_entropy": 0.004886304790323431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006019929423928261,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029653353616595268,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07259270548820496,
      "backward_entropy": 0.004884823818098415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047029994311742485,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029654089361429214,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07257379094759624,
      "backward_entropy": 0.004883412271738052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006870869547128677,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02965477854013443,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07255538801352183,
      "backward_entropy": 0.006005248562856154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005635570269078016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02965548448264599,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07253738244374593,
      "backward_entropy": 0.005385545844381506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006198807386681437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02965618297457695,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07251983880996704,
      "backward_entropy": 0.006002671339295127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005057160160504282,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029656890779733658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07250265280405681,
      "backward_entropy": 0.005379915237426758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005572049412876368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02965758554637432,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07248586416244507,
      "backward_entropy": 0.005377149378711527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004689666093327105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029658285900950432,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07246933877468109,
      "backward_entropy": 0.005998608740893277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048244575737044215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029658978804945946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07245321075121562,
      "backward_entropy": 0.005371671508659016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004464173980522901,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029659677296876907,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07243744532267253,
      "backward_entropy": 0.004872410473498431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003528669767547399,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029660368338227272,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07242195308208466,
      "backward_entropy": 0.004871027374809439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036712444853037596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029661035165190697,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0724069078763326,
      "backward_entropy": 0.005363689227537675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031533639412373304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029661692678928375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07239229480425517,
      "backward_entropy": 0.005361147224903107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002746973477769643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029662325978279114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07237807909647624,
      "backward_entropy": 0.0053586942905729466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002622945758048445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029662933200597763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07236433029174805,
      "backward_entropy": 0.005356329747221686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018916021508630365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029663514345884323,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07235096891721089,
      "backward_entropy": 0.005354061722755432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025942909996956587,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0296640507876873,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07233807444572449,
      "backward_entropy": 0.004863706840710206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020943731942679733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029664576053619385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07232551276683807,
      "backward_entropy": 0.005349876528436487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020482228137552738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02966507524251938,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07231328884760539,
      "backward_entropy": 0.0059848610650409355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023953223717398942,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02966555580496788,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07230142752329509,
      "backward_entropy": 0.004860833964564584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020464175031520426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029666036367416382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07228986422220866,
      "backward_entropy": 0.005344108424403451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018406675371807069,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029666505753993988,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227860887845357,
      "backward_entropy": 0.005342247811230746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001822557969717309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296669602394104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226765155792236,
      "backward_entropy": 0.005340457639910958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001973072940018028,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029667403548955917,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225695252418518,
      "backward_entropy": 0.005338710140098225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018831744091585279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029667848721146584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07224648197491963,
      "backward_entropy": 0.005336960608308966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013019249308854342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0296682920306921,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07223622004191081,
      "backward_entropy": 0.004855552180246873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001424383808625862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029668711125850677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722262312968572,
      "backward_entropy": 0.005333589897914367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011917996744159609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02966911904513836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07221653064092,
      "backward_entropy": 0.005331990393725308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012080872693331912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029669510200619698,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07220711310704549,
      "backward_entropy": 0.0053304515101692896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001140419626608491,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029669886454939842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07219792405764262,
      "backward_entropy": 0.005328965458002957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011828293645521626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029670247808098793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07218895852565765,
      "backward_entropy": 0.0053275312212380495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013153230247553438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029670603573322296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07218019167582194,
      "backward_entropy": 0.005326124754819003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010246994497720152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029670964926481247,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07217161854108174,
      "backward_entropy": 0.005324712531133132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839288057060912e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296713188290596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07216329872608185,
      "backward_entropy": 0.005323327739130367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.035578841576353e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02967165783047676,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07215517262617747,
      "backward_entropy": 0.005971681665290485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.351148476824164e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029671989381313324,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07214727501074474,
      "backward_entropy": 0.004848320375789295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.487411494366825e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029672300443053246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07213964064915974,
      "backward_entropy": 0.00531947985291481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.438732427544892e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967260219156742,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07213221987088521,
      "backward_entropy": 0.004847135733474384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.283725426532328e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02967289835214615,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07212501267592113,
      "backward_entropy": 0.005969261581247503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.54607504454907e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029673190787434578,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07211801409721375,
      "backward_entropy": 0.005968668244101785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.645840454031713e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029673468321561813,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07211122910181682,
      "backward_entropy": 0.005968105386603962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.688236706191674e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029673729091882706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07210466265678406,
      "backward_entropy": 0.005313841456716711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.087992030894384e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967398427426815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07209829489390056,
      "backward_entropy": 0.005312826484441757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0513506974093616e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029674232006072998,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07209209601084392,
      "backward_entropy": 0.005311839959838174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.938648999086581e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0296744666993618,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07208608587582906,
      "backward_entropy": 0.004843575033274564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.219683225732297e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029674699530005455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07208024462064107,
      "backward_entropy": 0.005309985442595048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.083508611074649e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029674936085939407,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07207455237706502,
      "backward_entropy": 0.005309061231938275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.63178041880019e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029675167053937912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07206901907920837,
      "backward_entropy": 0.005308153615756469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.322148404549807e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967539057135582,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07206365466117859,
      "backward_entropy": 0.005307279527187347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6324930988484994e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029675602912902832,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07205841441949208,
      "backward_entropy": 0.004841413687575947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.561771154636517e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029675815254449844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07205333312352498,
      "backward_entropy": 0.005305619402365251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1706742447568104e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029676025733351707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0720483809709549,
      "backward_entropy": 0.005304794419895519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2178857761900872e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967623434960842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07204357782999675,
      "backward_entropy": 0.005303985693237998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.329506605747156e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967642992734909,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07203892866770427,
      "backward_entropy": 0.0053032237020405855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.293432225997094e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029676616191864014,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07203440864880879,
      "backward_entropy": 0.005961693823337555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1396184820332564e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967679500579834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07203001777331035,
      "backward_entropy": 0.005301785739985379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7226298950845376e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02967696636915207,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07202574610710144,
      "backward_entropy": 0.005960986695506356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.005402529903222e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029677126556634903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07202160855134328,
      "backward_entropy": 0.005300477147102356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6462952771689743e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029677284881472588,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07201759020487468,
      "backward_entropy": 0.005299854684959759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5160550901782699e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029677435755729675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07201370596885681,
      "backward_entropy": 0.005299251865256916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.58699658641126e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029677579179406166,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0720099409421285,
      "backward_entropy": 0.005959797989238392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6531581422896124e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967771887779236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07200627525647481,
      "backward_entropy": 0.00483741746707396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3520581887860317e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02967785857617855,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07200271884600322,
      "backward_entropy": 0.005959260192784396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.483208486926742e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029677994549274445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719992717107137,
      "backward_entropy": 0.005297013304450295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.172457905340707e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029678119346499443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07199592391649882,
      "backward_entropy": 0.00529652021147988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0955428479064722e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029678240418434143,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07199269533157349,
      "backward_entropy": 0.005296031859788028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.003753459372092e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029678357765078545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07198955615361531,
      "backward_entropy": 0.005295556715943597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.83317955210805e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029678471386432648,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07198651631673177,
      "backward_entropy": 0.00529510493982922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.784249985183123e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029678577557206154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07198358575503032,
      "backward_entropy": 0.0052946690808643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.963078471424524e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967868186533451,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07198074460029602,
      "backward_entropy": 0.005294246429746801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.306873158086091e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967878431081772,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07197799781958263,
      "backward_entropy": 0.005293827165256847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.562426395044895e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029678883031010628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07197532057762146,
      "backward_entropy": 0.005293427543206649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.932707037776709e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967897430062294,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719727377096812,
      "backward_entropy": 0.005293056030165066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.347897058527451e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029679063707590103,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07197022934754689,
      "backward_entropy": 0.0048349357464096765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.957850251230411e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029679149389266968,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07196781039237976,
      "backward_entropy": 0.005956846881996502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.33706224814523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029679229483008385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07196547587712605,
      "backward_entropy": 0.005292016674171795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.961886133969529e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029679307714104652,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07196320096651714,
      "backward_entropy": 0.004834508015350862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.79109212392359e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967938408255577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719610055287679,
      "backward_entropy": 0.005291372537612915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.642341536964523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967946045100689,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07195888956387837,
      "backward_entropy": 0.00529106774113395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5947145988757256e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967953495681286,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07195683320363362,
      "backward_entropy": 0.004834106022661383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.351658961037174e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02967960573732853,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07195485631624858,
      "backward_entropy": 0.005956016480922699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2707428090361645e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02967967465519905,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07195294896761577,
      "backward_entropy": 0.005955883725122972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4546487768238876e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029679739847779274,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07195110122362773,
      "backward_entropy": 0.005289922045035796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8278655008762144e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029679805040359497,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07194931308428447,
      "backward_entropy": 0.0048336207189343195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8490130716818385e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967986650764942,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07194757461547852,
      "backward_entropy": 0.00483351471749219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.51394931183313e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029679927974939346,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07194589575131734,
      "backward_entropy": 0.005955404855988242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.045726660071523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967998757958412,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07194428145885468,
      "backward_entropy": 0.004833308133212003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6059204881457845e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296800434589386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07194270690282185,
      "backward_entropy": 0.0052886981178413735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.767106823535869e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029680095613002777,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07194121181964874,
      "backward_entropy": 0.005955094640905207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9546323528629728e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029680144041776657,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07193975647290547,
      "backward_entropy": 0.005955003879287026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7401890772816841e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680192470550537,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07193836073080699,
      "backward_entropy": 0.005288089202208953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6089238670247141e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680239036679268,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07193700472513835,
      "backward_entropy": 0.005287896164438941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3660990134667372e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968028374016285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07193570335706075,
      "backward_entropy": 0.00483280284838243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3289312619235716e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029680326581001282,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07193443179130554,
      "backward_entropy": 0.005954668603160165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2279556358407717e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680367559194565,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07193321983019511,
      "backward_entropy": 0.005287364463914524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31802219383826e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680408537387848,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07193203767140706,
      "backward_entropy": 0.004832582717592066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2470178489820682e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029680445790290833,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07193089524904887,
      "backward_entropy": 0.00595446608283303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.302342505179695e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680483043193817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192979753017426,
      "backward_entropy": 0.0052869001572782345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.022686526805046e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680518433451653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192873954772949,
      "backward_entropy": 0.0052867392924698916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.199010951808305e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968055196106434,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192772130171458,
      "backward_entropy": 0.00528659536079927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.956940754003881e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680583626031876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192674279212952,
      "backward_entropy": 0.00528646937825463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.173877184461162e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680613428354263,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192579905192058,
      "backward_entropy": 0.005286340347745202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.422307935987192e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680641368031502,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07192488511403401,
      "backward_entropy": 0.004832187836820429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.307680339683429e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968066744506359,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07192401587963104,
      "backward_entropy": 0.004832158034498041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.867730348858458e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968069165945053,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07192317644755046,
      "backward_entropy": 0.004832117394967513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.590398532400286e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968071587383747,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192237675189972,
      "backward_entropy": 0.005285909907384353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.754514921183727e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968074008822441,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192158699035645,
      "backward_entropy": 0.005285808647220785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3994805309921503e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680762439966202,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07192084689935048,
      "backward_entropy": 0.004832013764164664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.580617425948731e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029680782929062843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07192012667655945,
      "backward_entropy": 0.005953916771845384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.005590537621174e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680805280804634,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07191943128903706,
      "backward_entropy": 0.004831936887719415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.75242541647458e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680827632546425,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07191875576972961,
      "backward_entropy": 0.004831907085397027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.871971733180544e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680848121643066,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07191811005274455,
      "backward_entropy": 0.00483186813918027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.189053359164973e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968086674809456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191749413808186,
      "backward_entropy": 0.005285272205417807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.815780817400082e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968088537454605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191689809163411,
      "backward_entropy": 0.0052851902490312404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.757934112196381e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680904000997543,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07191632688045502,
      "backward_entropy": 0.004831779070875861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4254725872197014e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680922627449036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191578547159831,
      "backward_entropy": 0.005285042930733074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.259490798905972e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968093939125538,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191524902979533,
      "backward_entropy": 0.005284978246146982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0841774528435053e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680956155061722,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191474735736847,
      "backward_entropy": 0.005284902047027241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.284532172325271e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680972918868065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191425561904907,
      "backward_entropy": 0.005284838717092167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7965554377497028e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680989682674408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191378871599834,
      "backward_entropy": 0.0052847631952979346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5705784051078808e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968100644648075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191333174705505,
      "backward_entropy": 0.005284700881351124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9109036486497644e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681021347641945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719128946463267,
      "backward_entropy": 0.005284642292694612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3742501892011205e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968103624880314,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07191247741381328,
      "backward_entropy": 0.004831559617411007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.714088284643367e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681051149964333,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191208004951477,
      "backward_entropy": 0.005284514278173447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3777106744328194e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029681066051125526,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07191168765227,
      "backward_entropy": 0.005953404036435214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4611980247991596e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968108095228672,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07191130518913269,
      "backward_entropy": 0.004831477999687195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.020245362809874e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681095853447914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191094756126404,
      "backward_entropy": 0.00528434460813349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314127342146094e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02968110889196396,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07191060483455658,
      "backward_entropy": 0.00595331530679356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.91325823254374e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681121930480003,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07191027204195659,
      "backward_entropy": 0.004831397736614401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.892818842947236e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296811331063509,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190996408462524,
      "backward_entropy": 0.005284195935184305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.586806726247232e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681144282221794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719096561272939,
      "backward_entropy": 0.005284146829084916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.558543385106532e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968115545809269,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190936307112376,
      "backward_entropy": 0.005284100770950317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5598562198611035e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681166633963585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190908988316853,
      "backward_entropy": 0.005284056744792245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.579268957944805e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968117780983448,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190881172815959,
      "backward_entropy": 0.005284010686657645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.180393086197e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681188985705376,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0719085584084193,
      "backward_entropy": 0.004831279543313113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.655125872612189e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681198298931122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.071908305088679,
      "backward_entropy": 0.0052839324555613775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.874780129033752e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681207612156868,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190806170304616,
      "backward_entropy": 0.004831240597096356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.779465356818946e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681216925382614,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719078282515208,
      "backward_entropy": 0.0052838589657436714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.879954929037922e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968122623860836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190759976704915,
      "backward_entropy": 0.0052838196808641606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.677365612020367e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681235551834106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190738618373871,
      "backward_entropy": 0.005283780734647404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1142154572071377e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681244865059853,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190718253453572,
      "backward_entropy": 0.0048311769284985285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.169253304236008e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296812541782856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190697391827901,
      "backward_entropy": 0.005283718082037839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.080538490962681e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681263491511345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190678517023723,
      "backward_entropy": 0.0052836804904721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.991275493968715e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681270942091942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190659642219543,
      "backward_entropy": 0.005283643237569116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.472376969819834e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968127839267254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190642754236858,
      "backward_entropy": 0.005283620208501816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6294145527572255e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681285843253136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0719062586625417,
      "backward_entropy": 0.0048310963267629795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7624358861212386e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681293293833733,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190608481566112,
      "backward_entropy": 0.004831086166880347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5599380393259707e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968130074441433,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190593083699544,
      "backward_entropy": 0.004831073975021189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9627655944987055e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681308194994926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190577685832977,
      "backward_entropy": 0.005283502353863282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4448684854405656e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681313782930374,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190564274787903,
      "backward_entropy": 0.004831045866012573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7090762582938623e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02968132123351097,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07190550367037456,
      "backward_entropy": 0.0059528344056823035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1636643648671452e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02968132682144642,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07190535962581635,
      "backward_entropy": 0.005952813408591531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6817002901348133e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681332409381866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190523544947307,
      "backward_entropy": 0.005283404480327259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0408029993413948e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029681337997317314,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07190510630607605,
      "backward_entropy": 0.005952788347547705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2837253038355811e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029681343585252762,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0719049870967865,
      "backward_entropy": 0.00595277954231609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0361665303548762e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968134917318821,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190487782160442,
      "backward_entropy": 0.0048309835520657625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1015209189224606e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681354761123657,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190475861231486,
      "backward_entropy": 0.004830977456136184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0209681100548096e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681360349059105,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190465927124023,
      "backward_entropy": 0.0052833035588264465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.859274203132372e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681365936994553,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190454999605815,
      "backward_entropy": 0.004830963909626007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0261509864051277e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968136966228485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190445065498352,
      "backward_entropy": 0.004830945960500024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6933694142790046e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968137338757515,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190436124801636,
      "backward_entropy": 0.005283253436738794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.275637869952334e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681377112865448,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190426190694173,
      "backward_entropy": 0.005283240906216882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.86395287882624e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681380838155746,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190417249997456,
      "backward_entropy": 0.00483092801137404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.295671374165977e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681384563446045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190409302711487,
      "backward_entropy": 0.005283208055929704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.158575788755115e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681388288736343,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0719040036201477,
      "backward_entropy": 0.004830916158177636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.995222013803868e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029681392014026642,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07190392911434174,
      "backward_entropy": 0.00595265423709696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4148151800982305e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968139573931694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190384964148204,
      "backward_entropy": 0.004830896854400635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0468997869757e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968139946460724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190377513567607,
      "backward_entropy": 0.005283155224540017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6376093248691177e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681403189897537,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190370559692383,
      "backward_entropy": 0.004830890419808301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1136053735281166e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681406915187836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190364102522533,
      "backward_entropy": 0.005283135582100262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.747388177544053e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681408777832985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190356651941936,
      "backward_entropy": 0.004830881953239441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7139037683809875e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029681410640478134,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07190350691477458,
      "backward_entropy": 0.00595260817896236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.092427564548416e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681412503123283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719034473101298,
      "backward_entropy": 0.0052831017158248205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6856952217713115e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681414365768433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190338273843129,
      "backward_entropy": 0.005283091555942188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.669711480190017e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681416228413582,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190333306789398,
      "backward_entropy": 0.004830867052078247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7731096590978268e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968141809105873,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190327843030293,
      "backward_entropy": 0.004830865358764475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7331558410660364e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968141995370388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190322875976562,
      "backward_entropy": 0.005283063785596328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.650960257393308e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968142181634903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190317412217458,
      "backward_entropy": 0.005283057689666748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8277361846230633e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968142367899418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.071903129418691,
      "backward_entropy": 0.00528305091641166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4139800441625994e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681425541639328,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190307974815369,
      "backward_entropy": 0.005283044481819326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0591918453428661e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681427404284477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190304001172383,
      "backward_entropy": 0.005283039740540765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3787584407509712e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681429266929626,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190299530824025,
      "backward_entropy": 0.004830844700336456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0297611652276828e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681431129574776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190295060475667,
      "backward_entropy": 0.0052830211140892725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1854410786327207e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681432992219925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190291086832683,
      "backward_entropy": 0.005283017727461728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.761400411254726e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681434854865074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190288106600444,
      "backward_entropy": 0.004830837249755859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.960228115029167e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681436717510223,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190284132957458,
      "backward_entropy": 0.005283009599555622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.995897360364324e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681438580155373,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719028115272522,
      "backward_entropy": 0.0052830048582770605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.452953809661267e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681440442800522,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190277179082234,
      "backward_entropy": 0.005283000116998499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.416556175281585e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968144230544567,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190274198849995,
      "backward_entropy": 0.004830834540453824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.873612624578527e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968144416809082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190270721912384,
      "backward_entropy": 0.004830832508477298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5441339580065687e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968144603073597,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190268735090892,
      "backward_entropy": 0.004830832508477298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.674518550018547e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968144789338112,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190265258153279,
      "backward_entropy": 0.0052829886024648495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.949569643031282e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681449756026268,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190263271331787,
      "backward_entropy": 0.005282985893162814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.90757656734786e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681451618671417,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190261284510295,
      "backward_entropy": 0.005282973362640901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0120085031958297e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190259297688802,
      "backward_entropy": 0.005282970653338866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.128253294766182e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190256814161937,
      "backward_entropy": 0.005282968621362339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4710723184616654e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07190254330635071,
      "backward_entropy": 0.005952515385367654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5200997672291123e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190251847108205,
      "backward_entropy": 0.0052829638800837775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5930014519180986e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719025085369746,
      "backward_entropy": 0.005282962186770005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2575363800569903e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190248370170593,
      "backward_entropy": 0.005282960493456234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.716546987358015e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190246880054474,
      "backward_entropy": 0.005282959138805216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.859152914425067e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190244893232982,
      "backward_entropy": 0.005282957445491444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.503739437997865e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07190242906411488,
      "backward_entropy": 0.0059525119987401095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.120827957696747e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190241913000743,
      "backward_entropy": 0.005282954736189408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0941115508321673e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190240422884624,
      "backward_entropy": 0.005282952704212882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9872459233738482e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0719023843606313,
      "backward_entropy": 0.005282952704212882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0175150439172285e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190237442652385,
      "backward_entropy": 0.004830825057896701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.780762204361963e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190236449241638,
      "backward_entropy": 0.0052829493175853386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4006218407303095e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190234462420146,
      "backward_entropy": 0.0052829479629343205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5091927707544528e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.071902334690094,
      "backward_entropy": 0.005282945930957794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2857981346314773e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0719023197889328,
      "backward_entropy": 0.004830825057896701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.573567942614318e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190231482187907,
      "backward_entropy": 0.005282943221655759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0936673788819462e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190230985482533,
      "backward_entropy": 0.005282943221655759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3314149782672757e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190229495366414,
      "backward_entropy": 0.005282941189679233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.020907802740112e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190228501955669,
      "backward_entropy": 0.0052829398350282145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0102496617037104e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190227508544922,
      "backward_entropy": 0.0052829398350282145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.175238346870174e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190226515134175,
      "backward_entropy": 0.0052829398350282145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.645173465993139e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07190226018428802,
      "backward_entropy": 0.0048308223485946655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.966605153342243e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190225025018056,
      "backward_entropy": 0.005282926288518039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.737810392427491e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681453481316566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07190224528312683,
      "backward_entropy": 0.005282926288518039,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.3350350799589136e-08,
    "avg_log_Z": 0.02968134932219982,
    "success_rate": 1.0,
    "avg_reward": 49.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.1,
      "1": 0.29,
      "2": 0.61
    },
    "avg_forward_entropy": 0.07190487538774808,
    "avg_backward_entropy": 0.0052190979739481745,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}