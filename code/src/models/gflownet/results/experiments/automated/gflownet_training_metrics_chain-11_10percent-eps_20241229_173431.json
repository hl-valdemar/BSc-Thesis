{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06284745173020796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06284745173020796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06284745173020796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06284745173020796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06284745173020796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06287984414534135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06284745173020796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06284745173020796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45015811920166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138705333073933,
      "backward_entropy": 0.06286204403096979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.368907928466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139109651247661,
      "backward_entropy": 0.06285876577550714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098306655883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019998365314677358,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913950502872467,
      "backward_entropy": 0.06285551461306485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.937632083892822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00029990627081133425,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139901399612427,
      "backward_entropy": 0.06285224177620628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.171463012695312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0003997471940238029,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140289823214214,
      "backward_entropy": 0.06283197077837857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.089285850524902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004996253992430866,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140656391779582,
      "backward_entropy": 0.06284550103274258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.511239051818848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005994988605380058,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914101501305898,
      "backward_entropy": 0.06285686926408247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.658215045928955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006994967698119581,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141345818837483,
      "backward_entropy": 0.06283805587074974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.735700607299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007993080071173608,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141683578491211,
      "backward_entropy": 0.06283421949906783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.766733169555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008990142960101366,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142020344734192,
      "backward_entropy": 0.06283030726692894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.30419397354126,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009989694226533175,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142321348190308,
      "backward_entropy": 0.06280659545551646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.153525352478027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010986231500282884,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142635265986125,
      "backward_entropy": 0.06283613768490878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.806728839874268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011983509175479412,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142929315567017,
      "backward_entropy": 0.0628182129426436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.148598670959473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012980184983462095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143215417861938,
      "backward_entropy": 0.06282742456956343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.113738059997559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001397759304381907,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143484632174174,
      "backward_entropy": 0.06278812885284424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.621947765350342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001497178804129362,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143762787183125,
      "backward_entropy": 0.06278321959755638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.402077674865723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001596543355844915,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914402703444163,
      "backward_entropy": 0.06277810443531383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399377822875977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001696129096671939,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144274393717448,
      "backward_entropy": 0.06277295676144687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.533060073852539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001795900403521955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144506851832072,
      "backward_entropy": 0.0628041299906644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.737862586975098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018955140840262175,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144737323125203,
      "backward_entropy": 0.06276237964630127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.015939712524414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001995441736653447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144943952560425,
      "backward_entropy": 0.06275697187943892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.385168075561523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002094955649226904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145168463389079,
      "backward_entropy": 0.06278922341086647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72751522064209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021947042550891638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145356218020122,
      "backward_entropy": 0.06274592876434326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.92223596572876,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002294788369908929,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145502249399821,
      "backward_entropy": 0.06276706673882225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.12332534790039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002394413575530052,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145663181940715,
      "backward_entropy": 0.0627340620214289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.950012683868408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024941638112068176,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145796298980713,
      "backward_entropy": 0.06275645169344815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.46457290649414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025939319748431444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145920475323994,
      "backward_entropy": 0.06276190280914307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.860496997833252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002693949267268181,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146010875701904,
      "backward_entropy": 0.0627559640190818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.772160053253174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027938997372984886,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146106243133545,
      "backward_entropy": 0.06270792267539284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456866264343262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0028937440365552902,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146209557851155,
      "backward_entropy": 0.06270111690868031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.884997367858887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029937908984720707,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146301945050557,
      "backward_entropy": 0.06269425695592706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.138808250427246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003094206564128399,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146370490392049,
      "backward_entropy": 0.06273140690543434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.048824310302734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031950408592820168,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146416187286377,
      "backward_entropy": 0.0627250075340271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849946022033691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032961899414658546,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146446983019511,
      "backward_entropy": 0.06271029060537164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.357780456542969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033971064258366823,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146482745806377,
      "backward_entropy": 0.06266606937755238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61904525756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034980231430381536,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146519502003987,
      "backward_entropy": 0.06269833174618808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.197067260742188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003599085146561265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146535396575928,
      "backward_entropy": 0.06269815835085782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.703324317932129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003700114320963621,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146531422932942,
      "backward_entropy": 0.06264388561248779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.701436996459961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038013204466551542,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146507581075032,
      "backward_entropy": 0.06263599612496117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95258617401123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0039026786107569933,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146461884180705,
      "backward_entropy": 0.06262790073047984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.393280982971191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004004271235316992,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146398305892944,
      "backward_entropy": 0.06266715851697055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.088460922241211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004106317181140184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914628803730011,
      "backward_entropy": 0.06266061826185747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.693405151367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004208087921142578,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146210551261902,
      "backward_entropy": 0.06265377998352051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.513866424560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004309925250709057,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146109223365784,
      "backward_entropy": 0.06264695254239169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50543737411499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004411713685840368,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146006902058919,
      "backward_entropy": 0.06263589317148383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.006959915161133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004513023421168327,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145921468734741,
      "backward_entropy": 0.0625756870616566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.847512245178223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00461412500590086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145842989285786,
      "backward_entropy": 0.06261873245239258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.204019546508789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004715418443083763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145748615264893,
      "backward_entropy": 0.06260996515100653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.325510025024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004817512352019548,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145604570706685,
      "backward_entropy": 0.0626108863136985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.412004470825195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004919402301311493,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145478407541911,
      "backward_entropy": 0.06260360370982777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.765507698059082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005021161399781704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145361185073853,
      "backward_entropy": 0.06258312138644131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.244955062866211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005123015958815813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145224094390869,
      "backward_entropy": 0.06257386641068892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.832160949707031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005225116387009621,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145082036654155,
      "backward_entropy": 0.06256450306285512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167373657226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005327265709638596,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144930044809978,
      "backward_entropy": 0.06257357380606911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.342623710632324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005429616663604975,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914476712544759,
      "backward_entropy": 0.06256589564410123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.498364448547363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005532249342650175,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144582351048787,
      "backward_entropy": 0.06247973442077637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.751791954040527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005635180044919252,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914437969525655,
      "backward_entropy": 0.06255017627369273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.144972801208496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0057380408979952335,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914420485496521,
      "backward_entropy": 0.06251471151005138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.39876937866211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0058405036106705666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144043922424316,
      "backward_entropy": 0.06250421567396684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.812665939331055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005943216383457184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143872062365214,
      "backward_entropy": 0.062493573535572396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9816179275512695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006045870017260313,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143696228663127,
      "backward_entropy": 0.06242641535672275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.209537506103516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006148076616227627,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143535296122234,
      "backward_entropy": 0.0624152042649009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.049834251403809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006250439677387476,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143370389938354,
      "backward_entropy": 0.06240391731262207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.617751598358154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00635288143530488,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143197536468506,
      "backward_entropy": 0.06249085339632901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.288141250610352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006454658694565296,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143059452374776,
      "backward_entropy": 0.06248184767636386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.214144229888916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006556685548275709,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142908453941345,
      "backward_entropy": 0.06247280402617021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.396576881408691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006657914724200964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142794211705525,
      "backward_entropy": 0.062415128404443916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.302431106567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006759564857929945,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142654140790303,
      "backward_entropy": 0.06245390393517234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.120089530944824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006861021276563406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142519036928813,
      "backward_entropy": 0.062391107732599434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9374613761901855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006962188053876162,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142397840817769,
      "backward_entropy": 0.06231857971711592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.386167526245117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00706297904253006,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142302473386128,
      "backward_entropy": 0.06236656145616011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.688530921936035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007163723930716515,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142198165257771,
      "backward_entropy": 0.062291925603693184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.441449165344238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007264536339789629,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142086903254192,
      "backward_entropy": 0.06240390647541393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80263614654541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007365805096924305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141937891642253,
      "backward_entropy": 0.06226448579268022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.467893600463867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007467196322977543,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141769011815389,
      "backward_entropy": 0.06231500885703347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.86201810836792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007568522356450558,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141594171524048,
      "backward_entropy": 0.06237125938588923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010578155517578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007669439539313316,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914144515991211,
      "backward_entropy": 0.06228764490647749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098648071289062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007770045660436153,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141317009925842,
      "backward_entropy": 0.06220522251996127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8863396644592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007870432920753956,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141203761100769,
      "backward_entropy": 0.062336173924532806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.146745681762695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007970571517944336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141100446383159,
      "backward_entropy": 0.06224533644589511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.338795185089111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008071055635809898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140976270039876,
      "backward_entropy": 0.06215809692036022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569085121154785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008170918561518192,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140898784001668,
      "backward_entropy": 0.062299034812233665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.747446060180664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00827086716890335,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140816330909729,
      "backward_entropy": 0.062286420301957565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.612288475036621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00837100949138403,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140715996424358,
      "backward_entropy": 0.06227365407076749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262689590454102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008471718989312649,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140576918919881,
      "backward_entropy": 0.06209649822928689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.977140426635742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008572304621338844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140441815058391,
      "backward_entropy": 0.062080795114690605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.338072776794434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008673121221363544,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140288829803467,
      "backward_entropy": 0.0620648210698908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.254953384399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008774380199611187,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140096108118693,
      "backward_entropy": 0.062221711332147774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.684972763061523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008875447325408459,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139915307362874,
      "backward_entropy": 0.06220799142664129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.340775489807129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008976051583886147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139762322107951,
      "backward_entropy": 0.062088391997597435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30185317993164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009076591581106186,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139609336853027,
      "backward_entropy": 0.06217936494133689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.152668952941895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009177006781101227,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139464298884074,
      "backward_entropy": 0.062164615501057015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.638858318328857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009277253411710262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139331181844075,
      "backward_entropy": 0.0620327429337935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.727344989776611,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009377050213515759,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913923184076945,
      "backward_entropy": 0.061939255757765335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.456159591674805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00947650521993637,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139158328374226,
      "backward_entropy": 0.061993859030983665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.377342224121094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00957659725099802,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139031171798706,
      "backward_entropy": 0.061899846250360664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718791484832764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009676665998995304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138883153597514,
      "backward_entropy": 0.06195397810502486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.532877445220947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009776357561349869,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138768911361694,
      "backward_entropy": 0.06185896288264881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.624159812927246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009875588119029999,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138700366020203,
      "backward_entropy": 0.06205284053629095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.691189765930176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009975598193705082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138554334640503,
      "backward_entropy": 0.06181684407320889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.320950508117676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0100757647305727,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138389428456624,
      "backward_entropy": 0.06179514798251065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.652400016784668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010175821371376514,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138244390487671,
      "backward_entropy": 0.06177353317087347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.210816383361816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010275501757860184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913814902305603,
      "backward_entropy": 0.06183044476942583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.13569450378418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010375138372182846,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138046701749165,
      "backward_entropy": 0.061965579336339775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.346723556518555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010475275106728077,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913788874944051,
      "backward_entropy": 0.06194719943133267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.017285346984863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010575369000434875,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137725830078125,
      "backward_entropy": 0.061928543177517975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.22469425201416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01067524403333664,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137576818466187,
      "backward_entropy": 0.06165443767200817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9602532386779785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010775571689009666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09137376149495442,
      "backward_entropy": 0.061717618595470085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.16494083404541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010875659994781017,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09137198328971863,
      "backward_entropy": 0.06169382008639249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.303257942199707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010975121520459652,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09137087066968282,
      "backward_entropy": 0.06166994571685791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.832526206970215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011075137183070183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913691520690918,
      "backward_entropy": 0.06164571371945468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.595314025878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011175413616001606,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136712551116943,
      "backward_entropy": 0.06180954521352595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449694633483887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011275805532932281,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136496980985005,
      "backward_entropy": 0.06159559163180264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.080442428588867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011376244015991688,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136275450388591,
      "backward_entropy": 0.06146639043634588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.239433288574219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011476472951471806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136070807774861,
      "backward_entropy": 0.061543508009477096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.254735946655273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011577091179788113,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09135817488034566,
      "backward_entropy": 0.06172312931580977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.533158302307129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011677599512040615,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09135573108990987,
      "backward_entropy": 0.06170071255077015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.801050186157227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011778115294873714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135321776072185,
      "backward_entropy": 0.061462109739130195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.151509284973145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011878821067512035,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09135045607884724,
      "backward_entropy": 0.061654914509166374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.073263168334961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01197933778166771,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134785334269206,
      "backward_entropy": 0.06140524690801447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.414385795593262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012080146931111813,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09134489297866821,
      "backward_entropy": 0.06160744753750888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.636525630950928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012180936522781849,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134193261464436,
      "backward_entropy": 0.06134391914714466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.736223220825195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01228121668100357,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09133949875831604,
      "backward_entropy": 0.06155784563584761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.307811260223389,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012381628155708313,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09133683641751607,
      "backward_entropy": 0.06127957864241167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.86719799041748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012481385841965675,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09133488933245341,
      "backward_entropy": 0.06150632554834539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.480071544647217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012581981718540192,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913320283095042,
      "backward_entropy": 0.06108618866313587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.124391555786133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012682023458182812,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132976333300273,
      "backward_entropy": 0.06105050173672763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.110487937927246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012782450765371323,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09132702151934306,
      "backward_entropy": 0.061424753882668236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.152636528015137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01288269367069006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132446845372517,
      "backward_entropy": 0.06097703630273992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.144160270690918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01298336498439312,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132142861684163,
      "backward_entropy": 0.0610634522004561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642156600952148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01308328378945589,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131923317909241,
      "backward_entropy": 0.06089974533427845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.722371578216553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013183357194066048,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131682912508647,
      "backward_entropy": 0.061302683570168236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.908001899719238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013283101841807365,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131481250127156,
      "backward_entropy": 0.06081879138946533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67353343963623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01338312216103077,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131239851315816,
      "backward_entropy": 0.06090325658971613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.984267234802246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013483270071446896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130975604057312,
      "backward_entropy": 0.060861083594235504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.473454475402832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013583705760538578,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130671620368958,
      "backward_entropy": 0.06069445610046387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.06155014038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013684172183275223,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130360682805379,
      "backward_entropy": 0.06113212216984142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.825346946716309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013784421607851982,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130069613456726,
      "backward_entropy": 0.06060754169117321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919772148132324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013884884305298328,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09129746754964192,
      "backward_entropy": 0.061059095642783424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.317755699157715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013984990306198597,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129456679026286,
      "backward_entropy": 0.060517679561268196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.255517959594727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014085015282034874,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09129166603088379,
      "backward_entropy": 0.06098324602300471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.989171028137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014185496605932713,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912881890932719,
      "backward_entropy": 0.06094436212019487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528083801269531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014285670593380928,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09128501017888387,
      "backward_entropy": 0.06037847562269731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587035179138184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01438541617244482,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09128243724505107,
      "backward_entropy": 0.06086408008228649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502921104431152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014485884457826614,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09127896030743916,
      "backward_entropy": 0.06039019064469771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.873099327087402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01458640955388546,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127539396286011,
      "backward_entropy": 0.060229247266596016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.221543312072754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014686544425785542,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127214550971985,
      "backward_entropy": 0.06073676456104626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.100291728973389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014786576852202415,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126893679300944,
      "backward_entropy": 0.06069244037974964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.053606033325195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014885853976011276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09126664201418559,
      "backward_entropy": 0.06017564643513073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11072826385498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014985581859946251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126367171605428,
      "backward_entropy": 0.06002519889311357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.792056083679199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015085175633430481,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126079082489014,
      "backward_entropy": 0.059972156177867546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67226791381836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01518446858972311,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125819802284241,
      "backward_entropy": 0.06000309640711004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929798126220703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015284031629562378,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125526746114095,
      "backward_entropy": 0.05986287918957797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25682258605957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01538393646478653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125177065531413,
      "backward_entropy": 0.059883025559512054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4087653160095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015483798459172249,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09124833345413208,
      "backward_entropy": 0.060356048020449554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.37242317199707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015583147294819355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09124559164047241,
      "backward_entropy": 0.05976023999127475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.011678695678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015682555735111237,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912426511446635,
      "backward_entropy": 0.06025109507820823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.046828269958496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015781845897436142,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123985966046651,
      "backward_entropy": 0.05956954305822199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.126598358154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015881016850471497,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123711784680684,
      "backward_entropy": 0.06014227867126465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.162851333618164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015980137512087822,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123436609903972,
      "backward_entropy": 0.0594441294670105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.635420799255371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016079284250736237,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912316342194875,
      "backward_entropy": 0.060029436241496696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80129337310791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016178667545318604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122844537099202,
      "backward_entropy": 0.059372446753761986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.265936851501465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016278382390737534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122473001480103,
      "backward_entropy": 0.059302600947293366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.081123352050781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016378097236156464,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09122097492218018,
      "backward_entropy": 0.059172261844981804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.464136123657227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016477681696414948,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121728936831157,
      "backward_entropy": 0.0591588941487399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366495132446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016577383503317833,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121333559354146,
      "backward_entropy": 0.05972909927368164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.442792892456055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016677124425768852,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120922287305196,
      "backward_entropy": 0.058953637426549736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.216389179229736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016776954755187035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120488166809082,
      "backward_entropy": 0.0588781942020763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.030964851379395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016876153647899628,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120140473047893,
      "backward_entropy": 0.05953544920141047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.545027732849121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016975250095129013,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09119797746340434,
      "backward_entropy": 0.058770548213611946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.009875297546387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017073947936296463,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911949872970581,
      "backward_entropy": 0.059399984099648216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.652916431427002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017172586172819138,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119202693303426,
      "backward_entropy": 0.05856688456101851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.858148574829102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017270999029278755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09118946393330891,
      "backward_entropy": 0.058486591685901985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.192715644836426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01736931875348091,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118702014287312,
      "backward_entropy": 0.05843612280758945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.697240829467773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017467716708779335,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118428826332092,
      "backward_entropy": 0.05834839018908414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.039312362670898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017566468566656113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118075172106425,
      "backward_entropy": 0.05825834382664074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.371488571166992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017665188759565353,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09117717544237773,
      "backward_entropy": 0.058955842798406426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246427059173584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01776404120028019,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117317199707031,
      "backward_entropy": 0.05806235291741111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.872931957244873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017862362787127495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116990367571513,
      "backward_entropy": 0.057971867648037995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.287500381469727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017960626631975174,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09116675456364949,
      "backward_entropy": 0.058710488406094635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.976071357727051,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018059059977531433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116320808728536,
      "backward_entropy": 0.05777077241377397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.09135627746582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018157463520765305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115962187449138,
      "backward_entropy": 0.05766693570397117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5286970138549805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01825588569045067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115580717722575,
      "backward_entropy": 0.057561094110662285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527134895324707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018353957682847977,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115230043729146,
      "backward_entropy": 0.05745366486636075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2015509605407715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018452366814017296,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114811817804973,
      "backward_entropy": 0.058262120593677864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.078121185302734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018550315871834755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911447803179423,
      "backward_entropy": 0.05728777972134677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.346392631530762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018648294731974602,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911410649617513,
      "backward_entropy": 0.058065376498482445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.626068592071533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01874588616192341,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113784631093343,
      "backward_entropy": 0.05707521872086958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6943278312683105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01884330064058304,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911347468694051,
      "backward_entropy": 0.05696665156971325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.093212604522705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01894061081111431,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113165736198425,
      "backward_entropy": 0.056856144558299675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.912975788116455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019037466496229172,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112925330797832,
      "backward_entropy": 0.05664333430203525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8563385009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01913444511592388,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09112660090128581,
      "backward_entropy": 0.0575407093221491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.380064010620117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019231455400586128,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112362066904704,
      "backward_entropy": 0.05639283223585649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.404097557067871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01932884380221367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09111984570821126,
      "backward_entropy": 0.056262937459078705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.343506813049316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019426552578806877,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111518661181132,
      "backward_entropy": 0.05627045848152854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.324409484863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019524548202753067,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09110987186431885,
      "backward_entropy": 0.057083715092052116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098588943481445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019622791558504105,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09110396107037862,
      "backward_entropy": 0.056963541290976784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.050930976867676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01972113363444805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109776218732198,
      "backward_entropy": 0.05588674545288086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4441680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019818907603621483,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0910924772421519,
      "backward_entropy": 0.056715965270996094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.530730247497559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019916389137506485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09108743071556091,
      "backward_entropy": 0.0554226203398271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3661909103393555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020014222711324692,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09108121196428935,
      "backward_entropy": 0.055273484099995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.998781204223633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020111747086048126,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09107546011606853,
      "backward_entropy": 0.05512222376736728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.612118721008301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02020939253270626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106937050819397,
      "backward_entropy": 0.05496778271415017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.510440349578857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0203069020062685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106339017550151,
      "backward_entropy": 0.05481083284724842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.2567138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020404215902090073,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09105757872263591,
      "backward_entropy": 0.05591407689181241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.784939765930176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02050180360674858,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105088313420613,
      "backward_entropy": 0.05448840964924206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.928998947143555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020598767325282097,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09104542930920918,
      "backward_entropy": 0.05461421879855069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.505615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020695842802524567,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09103939930597942,
      "backward_entropy": 0.05547898465936834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360642433166504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020793341100215912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09103200833002727,
      "backward_entropy": 0.05398487502878362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.419453144073486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020891156047582626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09102357427279155,
      "backward_entropy": 0.053809052163904365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6051836013793945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02098866179585457,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09101545810699463,
      "backward_entropy": 0.05363102392716841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.047037124633789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021085431799292564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100926915804546,
      "backward_entropy": 0.053452085364948616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.759438514709473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021182453259825706,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09100231528282166,
      "backward_entropy": 0.05470350113782016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.249342918395996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021278874948620796,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09099640448888142,
      "backward_entropy": 0.0545411001552235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.889354228973389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021375102922320366,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099020560582478,
      "backward_entropy": 0.05331334742632779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.456014156341553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02147153578698635,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098298350969951,
      "backward_entropy": 0.05270249193364924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.716259479522705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02156720869243145,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09097757935523987,
      "backward_entropy": 0.05403823744166981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.766869068145752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021662984043359756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09097098310788472,
      "backward_entropy": 0.05231248248707165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.197667598724365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021758897230029106,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09096311529477437,
      "backward_entropy": 0.05259993943301114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.864611625671387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021854575723409653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095511833826701,
      "backward_entropy": 0.0519081787629561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.643557071685791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0219504926353693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09094586968421936,
      "backward_entropy": 0.05170027776197954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.500854969024658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022046497091650963,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09093582630157471,
      "backward_entropy": 0.05202519351785833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.826537132263184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02214251644909382,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09092543522516887,
      "backward_entropy": 0.05182556672529741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.398943901062012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022238142788410187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09091649452845256,
      "backward_entropy": 0.051055848598480225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.861199378967285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022333716973662376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09090681870778401,
      "backward_entropy": 0.05083502964539961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.336810111999512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022429578006267548,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09089591105779012,
      "backward_entropy": 0.05060953985561024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.96757173538208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022525329142808914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09088444709777832,
      "backward_entropy": 0.05038078264756636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.498593807220459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022620733827352524,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09087309241294861,
      "backward_entropy": 0.051974242383783516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.273110389709473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02271621860563755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09086108207702637,
      "backward_entropy": 0.04991453344171697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.87272310256958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022811565548181534,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09084830681482951,
      "backward_entropy": 0.05033981800079346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.228530406951904,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022906553000211716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09083568056424458,
      "backward_entropy": 0.050113927234302864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.615693092346191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02300090156495571,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09082581599553426,
      "backward_entropy": 0.051124735312028366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.610837459564209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02309553138911724,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09081456065177917,
      "backward_entropy": 0.05090377547524192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.066316604614258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02319038100540638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09080166618029277,
      "backward_entropy": 0.049407227472825485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.924674034118652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023285072296857834,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09078831473986308,
      "backward_entropy": 0.050451257012107155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.034169673919678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023379554972052574,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09077499310175578,
      "backward_entropy": 0.04891503399068659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.460892677307129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02347394824028015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09076158205668132,
      "backward_entropy": 0.04792469198053533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.02208137512207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023567168042063713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09075162808100383,
      "backward_entropy": 0.04766566103154963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.970404624938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023660359904170036,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09074050188064575,
      "backward_entropy": 0.049509893764149056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.822861194610596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023754166439175606,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09072620670000713,
      "backward_entropy": 0.049266782673922455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.140780448913574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023848453536629677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09070945779482524,
      "backward_entropy": 0.046857698397202927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246165752410889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023942051455378532,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0906943678855896,
      "backward_entropy": 0.04658171805468472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.237954139709473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024035772308707237,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09067790706952412,
      "backward_entropy": 0.04709772088310935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.058777332305908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024128921329975128,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09066253900527954,
      "backward_entropy": 0.04601983590559526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.805656909942627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02422141656279564,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0906482736269633,
      "backward_entropy": 0.04655461419712414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5139641761779785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024313850328326225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09063308437665303,
      "backward_entropy": 0.0454517196525227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.09377384185791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02440614439547062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0906190574169159,
      "backward_entropy": 0.04599846493114124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.605687141418457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024498628452420235,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09060335159301758,
      "backward_entropy": 0.045712964101271195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6043009757995605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02459091506898403,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09058687090873718,
      "backward_entropy": 0.044573962688446045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.696350574493408,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024682363495230675,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09057273467381795,
      "backward_entropy": 0.04513792558149858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.122549057006836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024773862212896347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0905579427878062,
      "backward_entropy": 0.04397901892662048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.351737022399902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02486499398946762,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905439058939616,
      "backward_entropy": 0.04454462094740434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.195644855499268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024955211207270622,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09053220351537068,
      "backward_entropy": 0.04583297534422441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.607213020324707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02504524029791355,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09052036205927531,
      "backward_entropy": 0.04555442116477273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.289546489715576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025134708732366562,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905103584130605,
      "backward_entropy": 0.043636235323819245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8615899085998535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025224098935723305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09049888451894124,
      "backward_entropy": 0.042463167147202927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.678850173950195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025313900783658028,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09048518538475037,
      "backward_entropy": 0.044705781069668854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.367453575134277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02540392428636551,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09046969811121623,
      "backward_entropy": 0.04183197292414578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.764386177062988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025493884459137917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09045258164405823,
      "backward_entropy": 0.04237753694707697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.431746959686279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025583406910300255,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09043636918067932,
      "backward_entropy": 0.04382268407128074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.579565048217773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025673042982816696,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09041885534922282,
      "backward_entropy": 0.04351705854589289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.807460308074951,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025762168690562248,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0904028316338857,
      "backward_entropy": 0.04139791835438122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.896858215332031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025851018726825714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09038744370142619,
      "backward_entropy": 0.040198277343403206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7490925788879395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02593960613012314,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09037089347839355,
      "backward_entropy": 0.04258609901775013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.556716442108154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602861076593399,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09035066763559978,
      "backward_entropy": 0.03952440077608282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1600117683410645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026117123663425446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09033090869585673,
      "backward_entropy": 0.03918379003351385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598883628845215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026205699890851974,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09031006693840027,
      "backward_entropy": 0.03969993916424838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0113725662231445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026293858885765076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09028905630111694,
      "backward_entropy": 0.03849458694458008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.404760360717773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026381975039839745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09026644627253215,
      "backward_entropy": 0.0381401235407049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3499979972839355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026469605043530464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09024434288342793,
      "backward_entropy": 0.0377833518114957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.53144645690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02655676007270813,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09022270639737447,
      "backward_entropy": 0.04031649773771113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.987311363220215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026642896234989166,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09020534157752991,
      "backward_entropy": 0.03707172924822027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.407619953155518,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026728423312306404,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09018893043200175,
      "backward_entropy": 0.03759795969182795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6043267250061035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026813719421625137,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09017115831375122,
      "backward_entropy": 0.03931349515914917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.303679943084717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02689821645617485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09015586972236633,
      "backward_entropy": 0.03599558635191484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.961552143096924,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02698332630097866,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09013543526331584,
      "backward_entropy": 0.03653421185233376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7168803215026855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02706792950630188,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09011538823445638,
      "backward_entropy": 0.036176410588351166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.03357458114624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027151882648468018,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09009653329849243,
      "backward_entropy": 0.037944235584952614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.083123207092285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027235517278313637,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09007714192072551,
      "backward_entropy": 0.03452768921852112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.601380348205566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027318857610225677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09005612134933472,
      "backward_entropy": 0.03510407968000932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.753169536590576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027401605620980263,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09003647168477376,
      "backward_entropy": 0.0337905152277513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.744575500488281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027483919635415077,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09001659353574117,
      "backward_entropy": 0.033422293988141144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5577392578125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756585367023945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08999663591384888,
      "backward_entropy": 0.03305369073694402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.750670433044434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02764730527997017,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08997733394304912,
      "backward_entropy": 0.033675987612117424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.240174293518066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027728471904993057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08995687961578369,
      "backward_entropy": 0.0323166467926719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.019189834594727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780900150537491,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08993837237358093,
      "backward_entropy": 0.03514183651317249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.709012985229492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027889598160982132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08991686503092448,
      "backward_entropy": 0.0326007062738592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.611783027648926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02797001414000988,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0898941159248352,
      "backward_entropy": 0.03443307226354426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.342525005340576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028049340471625328,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08987613519032796,
      "backward_entropy": 0.030843826857480137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.18897819519043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028128327801823616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08985814452171326,
      "backward_entropy": 0.030479022047736427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.525310039520264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028206856921315193,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0898402730623881,
      "backward_entropy": 0.0311580706726421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.871147632598877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828526496887207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08982003728548686,
      "backward_entropy": 0.029749783602627842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.755936145782471,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02836390770971775,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08979588747024536,
      "backward_entropy": 0.03266846320845864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.484501361846924,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028442658483982086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0897682507832845,
      "backward_entropy": 0.030070277777585117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8563272953033447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028521256521344185,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08973826964696248,
      "backward_entropy": 0.02970652146772905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.373105049133301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028599193319678307,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08971012632052104,
      "backward_entropy": 0.029343366622924805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.157110214233398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028676943853497505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08967912197113037,
      "backward_entropy": 0.02898254719647494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7633554935455322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028754450380802155,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08964816729227702,
      "backward_entropy": 0.027530298991636795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.05966329574585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028831282630562782,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08961769938468933,
      "backward_entropy": 0.027165057984265415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.388866901397705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028907783329486847,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08958517511685689,
      "backward_entropy": 0.027902619405226273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6528546810150146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02898336946964264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08955490589141846,
      "backward_entropy": 0.026441254399039528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.074148654937744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029058409854769707,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08952480554580688,
      "backward_entropy": 0.029494231397455387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3616626262664795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029133370146155357,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0894915262858073,
      "backward_entropy": 0.026847403157841076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.065101385116577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920760028064251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08946025371551514,
      "backward_entropy": 0.0264981822534041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.409698963165283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02928088791668415,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08943267663319905,
      "backward_entropy": 0.026151397011496803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.831449031829834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029353687539696693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08940565586090088,
      "backward_entropy": 0.024682529947974464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6939098834991455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029426446184515953,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08937498927116394,
      "backward_entropy": 0.025459766387939453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.957873821258545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029498009011149406,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08934911092122395,
      "backward_entropy": 0.02511938593604348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8679261207580566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029568759724497795,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08932488163312276,
      "backward_entropy": 0.024783058599992233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.868267297744751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02963867597281933,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08930227160453796,
      "backward_entropy": 0.02678310058333657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2774882316589355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029708920046687126,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08927302559216817,
      "backward_entropy": 0.0241194719618017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.75864315032959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02977885492146015,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08924196163813274,
      "backward_entropy": 0.023789273066954178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.794769287109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02984791062772274,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08921228845914204,
      "backward_entropy": 0.025796562433242798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.880540609359741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916293919086456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0891842246055603,
      "backward_entropy": 0.022029516371813686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5063440799713135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02998410537838936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0891553560892741,
      "backward_entropy": 0.022823312065818092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3390111923217773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03005106933414936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08912978569666545,
      "backward_entropy": 0.02139906856146726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.454741954803467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03011699579656124,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08910700678825378,
      "backward_entropy": 0.022196666760878128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6190614700317383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03018214739859104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08908557891845703,
      "backward_entropy": 0.020791492678902367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.915078639984131,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03024684637784958,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08906401197115581,
      "backward_entropy": 0.02158557420427149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.270275592803955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030311476439237595,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08903876940409343,
      "backward_entropy": 0.021281301975250244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3188633918762207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030375240370631218,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0890151063601176,
      "backward_entropy": 0.019899389960549095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8191184997558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03043833002448082,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08899252613385518,
      "backward_entropy": 0.0229986310005188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.212937831878662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0305002573877573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08897608518600464,
      "backward_entropy": 0.019327922300858932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7931681871414185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030561570078134537,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08896000186602275,
      "backward_entropy": 0.02010335163636641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.953925609588623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030621757730841637,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08894748489061992,
      "backward_entropy": 0.018778562545776367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0700676441192627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030681103467941284,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08893567323684692,
      "backward_entropy": 0.02184937217018821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9688369035720825,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030739877372980118,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08892319599787395,
      "backward_entropy": 0.01927047696980563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9007453918457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03079802542924881,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08891081809997559,
      "backward_entropy": 0.021293413909998806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.143035650253296,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030855508521199226,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08889863888422649,
      "backward_entropy": 0.01873571357943795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3137357234954834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030912693589925766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0888831615447998,
      "backward_entropy": 0.017475670034235172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.138430118560791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030969880521297455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0888639787832896,
      "backward_entropy": 0.017219348387284714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4363207817077637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03102686256170273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08884167671203613,
      "backward_entropy": 0.017954453825950623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7571349143981934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031084103509783745,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0888128678003947,
      "backward_entropy": 0.019942427223378963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7105571031570435,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031140586361289024,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08878470460573833,
      "backward_entropy": 0.019679060036485844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9127565622329712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031196322292089462,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08875708778699239,
      "backward_entropy": 0.016207271001555702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4574716091156006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312516987323761,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08872711658477783,
      "backward_entropy": 0.015961771661585026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4636740684509277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130606189370155,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08870015541712443,
      "backward_entropy": 0.016698804768649014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6878842115402222,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03135950118303299,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08867535988489787,
      "backward_entropy": 0.01548877087506381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3978595733642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03141248598694801,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08864881594975789,
      "backward_entropy": 0.0184178040786223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2684794664382935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0314645953476429,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08862364292144775,
      "backward_entropy": 0.015031597831032494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2459157705307007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0315156951546669,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08860074480374654,
      "backward_entropy": 0.014811484651132063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4534882307052612,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03156585618853569,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08857983350753784,
      "backward_entropy": 0.017709085887128658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.442635416984558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031615547835826874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08855764071146648,
      "backward_entropy": 0.014384681528264826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5108205080032349,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166477009654045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08853352069854736,
      "backward_entropy": 0.014175041155381636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4552503824234009,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031713731586933136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08850650986035664,
      "backward_entropy": 0.014912799000740051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.305406093597412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176236152648926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08847692608833313,
      "backward_entropy": 0.013760438019579107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.15336275100708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0318104512989521,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08844671646753947,
      "backward_entropy": 0.016593897884542293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.348629117012024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185773640871048,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08841703335444133,
      "backward_entropy": 0.01429496705532074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0267326831817627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03190464898943901,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0883843203385671,
      "backward_entropy": 0.016170058738101612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.242173671722412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031950704753398895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08835392196973164,
      "backward_entropy": 0.012969913807782259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1450680494308472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031996358186006546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08832121888796489,
      "backward_entropy": 0.012780307368798689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0787416696548462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03204146772623062,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08828729391098022,
      "backward_entropy": 0.012593673034147783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9809903502464294,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032085929065942764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08825237552324931,
      "backward_entropy": 0.015363939783789894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8937556743621826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032129667699337006,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08821815252304077,
      "backward_entropy": 0.015171210874210705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9531794190406799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217257186770439,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08818540970484416,
      "backward_entropy": 0.012056720527735624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9398678541183472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03221483901143074,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08815228939056396,
      "backward_entropy": 0.011885492639108137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0711231231689453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03225652873516083,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08811876177787781,
      "backward_entropy": 0.01263219795443795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9617050886154175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03229794278740883,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0880816380182902,
      "backward_entropy": 0.011550506407564337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7756448984146118,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032338906079530716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08804274598757426,
      "backward_entropy": 0.011386034163561735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.747390627861023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03237903118133545,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0880047877629598,
      "backward_entropy": 0.012137032367966392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.876113772392273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03241840749979019,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08796834945678711,
      "backward_entropy": 0.011978695338422602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6662234663963318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0324573777616024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08792997399965923,
      "backward_entropy": 0.010915790091861378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6120128035545349,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03249547258019447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0878931184609731,
      "backward_entropy": 0.011670746586539528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5270048379898071,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032532669603824615,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08785838882128398,
      "backward_entropy": 0.011522723869843916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7091235518455505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0325688011944294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08782644073168437,
      "backward_entropy": 0.011379667303778908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.759832501411438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032604437321424484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08779291311899821,
      "backward_entropy": 0.010344031859527935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44278690218925476,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0326397605240345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0877563754717509,
      "backward_entropy": 0.010207944295623085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5121180415153503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032674070447683334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08772411942481995,
      "backward_entropy": 0.010076988149772991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.53033447265625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03270759806036949,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08769327402114868,
      "backward_entropy": 0.01083535836501555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6210367679595947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03274047374725342,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08766292532285054,
      "backward_entropy": 0.0107066963206638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4561854600906372,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03277294710278511,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08762999375661214,
      "backward_entropy": 0.012407949024980719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5378000736236572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03280465304851532,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0875984529654185,
      "backward_entropy": 0.009584317830475893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5006662607192993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032835908234119415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08756580948829651,
      "backward_entropy": 0.009467448700558056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4708852767944336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032866597175598145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08753214279810588,
      "backward_entropy": 0.0093530226837505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5287801623344421,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032896749675273895,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08749828735987346,
      "backward_entropy": 0.011896696957674894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5790689587593079,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03292664512991905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0874628225962321,
      "backward_entropy": 0.009130240164019844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46817710995674133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03295641764998436,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08742372194925944,
      "backward_entropy": 0.009876167232340033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41801711916923523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032985713332891464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08738338947296143,
      "backward_entropy": 0.008911617777564308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3423865735530853,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03301439806818962,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08734260002772014,
      "backward_entropy": 0.00880599631504579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34096547961235046,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03304225206375122,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08730270465215047,
      "backward_entropy": 0.011306570334867998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4193427264690399,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03306940197944641,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08726364374160767,
      "backward_entropy": 0.008605008775537664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35766109824180603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033096157014369965,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08722254633903503,
      "backward_entropy": 0.008507627655159344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31171685457229614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03312234953045845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08718091249465942,
      "backward_entropy": 0.008412591435692528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3017384707927704,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033147942274808884,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08714023232460022,
      "backward_entropy": 0.010880089618942955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3770311176776886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0331728458404541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08709949254989624,
      "backward_entropy": 0.008230553431944414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2993234395980835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03319741040468216,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08705614010492961,
      "backward_entropy": 0.010682174427942797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38547852635383606,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033221371471881866,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08701225121815999,
      "backward_entropy": 0.008895396508953789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.280242383480072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033245235681533813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08696560064951579,
      "backward_entropy": 0.007970560680736195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2795829176902771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0332685187458992,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08691869179407756,
      "backward_entropy": 0.010400251908735796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1723736971616745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03329135477542877,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08687174320220947,
      "backward_entropy": 0.008645068515430798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23835912346839905,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033313311636447906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08682771523793538,
      "backward_entropy": 0.007728103886951099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17172449827194214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03333476930856705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08678390582402547,
      "backward_entropy": 0.007652380927042527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3386456072330475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033355433493852615,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08674193421999614,
      "backward_entropy": 0.010061142119494352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18611185252666473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03337618708610535,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0866960088411967,
      "backward_entropy": 0.008342858065258373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21219657361507416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033396221697330475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0866508682568868,
      "backward_entropy": 0.007436492903666062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19190071523189545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03341575339436531,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.086605171362559,
      "backward_entropy": 0.009829318658872084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19987565279006958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03343477472662926,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.086559663216273,
      "backward_entropy": 0.008137240328572014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1610155701637268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03345339000225067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0865137775739034,
      "backward_entropy": 0.00807231596925042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1699674278497696,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033471401780843735,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0864684780438741,
      "backward_entropy": 0.008009168912063946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21879814565181732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033488936722278595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08642322818438213,
      "backward_entropy": 0.007113173604011536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.182631254196167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03350634127855301,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08637607097625732,
      "backward_entropy": 0.007052704691886902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09825719892978668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033523399382829666,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08632802963256836,
      "backward_entropy": 0.00782664797522805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17089158296585083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03353961929678917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08628205458323161,
      "backward_entropy": 0.0077698061412031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10255526751279831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03355560079216957,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0862353245417277,
      "backward_entropy": 0.006882173093882474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14432010054588318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033570874482393265,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08618998527526855,
      "backward_entropy": 0.007660450583154505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17361457645893097,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033585768193006516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0861439307530721,
      "backward_entropy": 0.006778211756186051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09069284796714783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033600568771362305,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0860960880915324,
      "backward_entropy": 0.009138736535202373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07745817303657532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03361466899514198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08604951699574788,
      "backward_entropy": 0.00667858056046746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11415800452232361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03362807631492615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08600467443466187,
      "backward_entropy": 0.006632538004354997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11046422272920609,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03364108130335808,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08595941464106242,
      "backward_entropy": 0.007416861301118677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09708767384290695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03365372493863106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08591388662656148,
      "backward_entropy": 0.00654435699636286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12118767201900482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033665936440229416,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0858684778213501,
      "backward_entropy": 0.008903399109840393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10819906741380692,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03367798402905464,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08582211534182231,
      "backward_entropy": 0.00886061042547226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1210860162973404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03368980437517166,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08577535549799602,
      "backward_entropy": 0.008818772028792988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0759410411119461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03370145335793495,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08572704593340556,
      "backward_entropy": 0.00877774032679471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06531815230846405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033712614327669144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08567951122919719,
      "backward_entropy": 0.0063414424657821655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10893654823303223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03372327238321304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08563320835431416,
      "backward_entropy": 0.006304681978442452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13483358919620514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033733852207660675,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08558561404546101,
      "backward_entropy": 0.008664719760417938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11581364274024963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03374456986784935,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08553518851598103,
      "backward_entropy": 0.008627572520212694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09073852002620697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03375525027513504,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08548295497894287,
      "backward_entropy": 0.007028898054903204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1075047105550766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03376570716500282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08543037374814351,
      "backward_entropy": 0.006157600066878579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09697471559047699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03377610072493553,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08537624279658,
      "backward_entropy": 0.008519153026017275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11141509562730789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033786360174417496,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08532112836837769,
      "backward_entropy": 0.00692630491473458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06652743369340897,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03379667550325394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08526426553726196,
      "backward_entropy": 0.006892671639269049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06371019780635834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03380654379725456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08520783980687459,
      "backward_entropy": 0.006860598244450309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055729690939188004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03381600230932236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08515181144078572,
      "backward_entropy": 0.00682995468378067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07531296461820602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03382502496242523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08509668707847595,
      "backward_entropy": 0.006800833750854839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0519309900701046,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0338338278234005,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08504073818524678,
      "backward_entropy": 0.008324562148614363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07921349257230759,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033842213451862335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08498562375704448,
      "backward_entropy": 0.0067456466230479155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06661433726549149,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0338505357503891,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08492924769719441,
      "backward_entropy": 0.005861184136434035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07665559649467468,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033858682960271835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08487256368001302,
      "backward_entropy": 0.006693247367035259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058224257081747055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03386685624718666,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08481498559315999,
      "backward_entropy": 0.008216295729983936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04668928682804108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033874742686748505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08475724856058757,
      "backward_entropy": 0.005775854668833993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053814586251974106,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03388229012489319,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08470045526822408,
      "backward_entropy": 0.008166307752782648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04102029651403427,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03388958424329758,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08464354276657104,
      "backward_entropy": 0.008142935281450098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05358952283859253,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03389645367860794,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08458726604779561,
      "backward_entropy": 0.008121201937848871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054686710238456726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033903155475854874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08453059196472168,
      "backward_entropy": 0.005674796348268335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0396505668759346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03390975669026375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08447347084681193,
      "backward_entropy": 0.00565112212842161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05705038458108902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033916037529706955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08441698551177979,
      "backward_entropy": 0.0056285052136941386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04334648698568344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03392232954502106,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08435958623886108,
      "backward_entropy": 0.008040567690675909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038870278745889664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03392839431762695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0843022068341573,
      "backward_entropy": 0.005583868785337968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02657202072441578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03393418714404106,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08424512545267741,
      "backward_entropy": 0.006459161639213562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03262455016374588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03393951803445816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0841892659664154,
      "backward_entropy": 0.005543196404522116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034253619611263275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03394460678100586,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08413425087928772,
      "backward_entropy": 0.007973599840294231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03622494265437126,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033949512988328934,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08407971262931824,
      "backward_entropy": 0.006413080475547097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02994530275464058,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03395426645874977,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08402508497238159,
      "backward_entropy": 0.006398935209621082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028632938861846924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033958785235881805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08397104342778523,
      "backward_entropy": 0.005471577698534185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032804396003484726,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033963099122047424,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08391766746838887,
      "backward_entropy": 0.006372933360663327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027232378721237183,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0339672826230526,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08386415243148804,
      "backward_entropy": 0.00543942539529367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03547684848308563,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033971261233091354,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08381110429763794,
      "backward_entropy": 0.006349054927175695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027244478464126587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03397529944777489,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08375788728396098,
      "backward_entropy": 0.005408844148570841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022778265178203583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033979181200265884,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08370502789815266,
      "backward_entropy": 0.007874853909015656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023304514586925507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03398281708359718,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0836528738339742,
      "backward_entropy": 0.00537989153103395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023160569369792938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03398628905415535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08360145489374797,
      "backward_entropy": 0.00536637008190155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02521326020359993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03398958593606949,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08355040351549785,
      "backward_entropy": 0.005353391509164463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019998393952846527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03399281948804855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08349959055582683,
      "backward_entropy": 0.005340635776519775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01795770600438118,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0339958518743515,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08344940344492595,
      "backward_entropy": 0.0053285231644457035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020112015306949615,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033998653292655945,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0833999514579773,
      "backward_entropy": 0.006271694871512326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03172988444566727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03400133177638054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.083350936571757,
      "backward_entropy": 0.006264437328685413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023062385618686676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034004271030426025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08330100774765015,
      "backward_entropy": 0.00529438934542916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0154431676492095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034007176756858826,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08325097958246867,
      "backward_entropy": 0.005282722074877132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016280947253108025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03400986269116402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08320202430089314,
      "backward_entropy": 0.005271785638549111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020325379446148872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03401238098740578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08315383394559224,
      "backward_entropy": 0.005261382596059279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020081553608179092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03401491045951843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08310588200887044,
      "backward_entropy": 0.007780885154550726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015722863376140594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034017425030469894,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08305785059928894,
      "backward_entropy": 0.006220988251946189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016468288376927376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034019820392131805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08301055431365967,
      "backward_entropy": 0.006214735860174353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015917744487524033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402213379740715,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08296363552411397,
      "backward_entropy": 0.005221105434677817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010449914261698723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034024372696876526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08291709423065186,
      "backward_entropy": 0.006202929399230264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016733285039663315,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034026358276605606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08287170032660167,
      "backward_entropy": 0.006197972053831274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014189385809004307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402836620807648,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08282638589541118,
      "backward_entropy": 0.005194518037817695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01209990307688713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403032198548317,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08278162280718486,
      "backward_entropy": 0.0061881122263995085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012561536394059658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403215855360031,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08273756504058838,
      "backward_entropy": 0.006183691322803497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015402884222567081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034033916890621185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08269400397936504,
      "backward_entropy": 0.005170294506983323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014805164188146591,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03403573855757713,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08265044291814168,
      "backward_entropy": 0.00772987577048215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015062050893902779,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403761237859726,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08260703086853027,
      "backward_entropy": 0.006170574236999859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014565779827535152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034039564430713654,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08256363868713379,
      "backward_entropy": 0.006165789609605616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01195882074534893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03404157981276512,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08252029120922089,
      "backward_entropy": 0.007714858109300787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01088797114789486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03404355049133301,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08247736593087514,
      "backward_entropy": 0.0077096765691583805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012509381398558617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034045442938804626,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08243495225906372,
      "backward_entropy": 0.007704476063901728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009507603943347931,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404735401272774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08239259322484334,
      "backward_entropy": 0.0051133676686070184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009848710149526596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404915705323219,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08235089977582295,
      "backward_entropy": 0.005105704069137573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011764680035412312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405088558793068,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08230958878993988,
      "backward_entropy": 0.00509828193621202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010160278528928757,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034052662551403046,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08226825793584187,
      "backward_entropy": 0.0061333037235520105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007784252520650625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405442461371422,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08222729961077373,
      "backward_entropy": 0.005083258856426586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008420480415225029,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03405604884028435,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08218698700269063,
      "backward_entropy": 0.007674985311248086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007269849069416523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340576097369194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0821472704410553,
      "backward_entropy": 0.005069400099190799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006422117818146944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405905142426491,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08210809032122295,
      "backward_entropy": 0.005062959410927512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007123581599444151,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034060362726449966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08206981420516968,
      "backward_entropy": 0.005056965757500042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006923811510205269,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406160697340965,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08203213413556416,
      "backward_entropy": 0.00505120036276904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007847985252737999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034062787890434265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08199488123257954,
      "backward_entropy": 0.005045636811039664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006400651298463345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406399115920067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08195799589157104,
      "backward_entropy": 0.006106192415410822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006936157587915659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034065131098032,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08192167679468791,
      "backward_entropy": 0.006103856319730932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008158169686794281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406626731157303,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08188573519388835,
      "backward_entropy": 0.005029362033713947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005738239269703627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406749665737152,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08184987803300221,
      "backward_entropy": 0.005023786628788168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00553005700930953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406865894794464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08181460698445638,
      "backward_entropy": 0.0050184438851746645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007956785149872303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034069761633872986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08177989721298218,
      "backward_entropy": 0.0050133063711903314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005783409345895052,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407099470496178,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0817451278368632,
      "backward_entropy": 0.006091633303598924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043458822183310986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407220542430878,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08171067635218303,
      "backward_entropy": 0.005002411929043857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005916308145970106,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034073300659656525,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08167689541975658,
      "backward_entropy": 0.007630441676486622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00542623782530427,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03407442569732666,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08164345224698384,
      "backward_entropy": 0.0076274790547110815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0049383570440113544,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034075550734996796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08161028226216634,
      "backward_entropy": 0.004987205632708289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0057853213511407375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407665714621544,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08157762388388316,
      "backward_entropy": 0.0049822330474853516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004073831718415022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034077826887369156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08154512445131938,
      "backward_entropy": 0.004977087744257667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036800005473196507,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0340789258480072,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08151322603225708,
      "backward_entropy": 0.00607445700602098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004452254623174667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034079939126968384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08148196836312611,
      "backward_entropy": 0.0049675784327767114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003620363539084792,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034080952405929565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0814511626958847,
      "backward_entropy": 0.006070271134376526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00410812720656395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03408190608024597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0814208984375,
      "backward_entropy": 0.0049586018378084355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041547054424881935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034082863479852676,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0813909222682317,
      "backward_entropy": 0.004954405128955841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003220930229872465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03408384323120117,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08136129379272461,
      "backward_entropy": 0.004950143396854401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003097781678661704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03408476337790489,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08133225639661153,
      "backward_entropy": 0.004946080798452551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004059710539877415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034085631370544434,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08130377034346263,
      "backward_entropy": 0.004942170598290183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033874129876494408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03408655524253845,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08127555251121521,
      "backward_entropy": 0.007595199075612155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003258295124396682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03408747911453247,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08124777674674988,
      "backward_entropy": 0.007592604241587899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003116669598966837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03408839553594589,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08122044801712036,
      "backward_entropy": 0.004930054599588568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028604120016098022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034089308232069016,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08119350175062816,
      "backward_entropy": 0.004926071925596757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002719244686886668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409019485116005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08116706709067027,
      "backward_entropy": 0.004922195253047076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024731778539717197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409105911850929,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08114101986090343,
      "backward_entropy": 0.004918375475840135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025167646817862988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409188613295555,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0811154047648112,
      "backward_entropy": 0.0049146799878640604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002028335817158222,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409269452095032,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08109020193417867,
      "backward_entropy": 0.004911068149588325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002301473869010806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409343585371971,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08106552561124165,
      "backward_entropy": 0.004907666282220321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023447126150131226,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03409416601061821,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0810411771138509,
      "backward_entropy": 0.007573399354111065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021448894403874874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03409489616751671,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08101718624432881,
      "backward_entropy": 0.007571349089795893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019493662985041738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03409561142325401,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08099359770615895,
      "backward_entropy": 0.007569336078383706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021755823399871588,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03409629687666893,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0809704562028249,
      "backward_entropy": 0.006037717515772039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016905126394703984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409699723124504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08094757795333862,
      "backward_entropy": 0.0048912929540330715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00210056290961802,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03409765288233757,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08092518150806427,
      "backward_entropy": 0.006034744734113867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019306347239762545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03409833833575249,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08090302348136902,
      "backward_entropy": 0.0075615962797945194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017714110435917974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034099031239748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08088118334611256,
      "backward_entropy": 0.006031666967001828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016028234967961907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409971669316292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08085970083872478,
      "backward_entropy": 0.0048788965425708075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017055924981832504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03410038352012634,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08083859582742055,
      "backward_entropy": 0.007555559954859994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00131034676451236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034101054072380066,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08081780870755513,
      "backward_entropy": 0.0075535401701927185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015514013357460499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034101683646440506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079744378725688,
      "backward_entropy": 0.00487001815980131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015525624621659517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034102316945791245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077736695607503,
      "backward_entropy": 0.004867149008945985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001093828002922237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034102968871593475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08075753847757976,
      "backward_entropy": 0.004864241927862167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012302809627726674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410356491804123,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08073816696802776,
      "backward_entropy": 0.004861521449956027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008892261539585888,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03410414233803749,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08071913321812947,
      "backward_entropy": 0.007544380020011555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009838362457230687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03410464897751808,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08070059617360432,
      "backward_entropy": 0.006019221110777421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010400960454717278,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410511091351509,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.080682506163915,
      "backward_entropy": 0.004854198545217514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009828910697251558,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03410555422306061,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08066473404566447,
      "backward_entropy": 0.006017518991773779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012109093368053436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410598263144493,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08064729472001393,
      "backward_entropy": 0.004849868064576929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008514572982676327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410644829273224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0806300441424052,
      "backward_entropy": 0.004847643050280484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001063331845216453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03410688415169716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08061314125855763,
      "backward_entropy": 0.006014888259497556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010708634508773685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410734236240387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08059646189212799,
      "backward_entropy": 0.004843333566730673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006975293508730829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410783037543297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08057997624079387,
      "backward_entropy": 0.004841091957959262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006474889814853668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034108277410268784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08056387305259705,
      "backward_entropy": 0.004838964478536086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006251753657124937,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03410867601633072,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08054816722869873,
      "backward_entropy": 0.007531422783027996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007374396082013845,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03410903364419937,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08053285876909892,
      "backward_entropy": 0.007530449466271834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008618265856057405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034109387546777725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08051780859629314,
      "backward_entropy": 0.004833404990759763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007231123163364828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034109774976968765,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08050293723742168,
      "backward_entropy": 0.006008980626409704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005632375250570476,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034110162407159805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08048831423123677,
      "backward_entropy": 0.006008175963705236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006338708335533738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411051630973816,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0804740438858668,
      "backward_entropy": 0.006007510152730075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005903378478251398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034110866487026215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08046003182729085,
      "backward_entropy": 0.004826188764788888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007041729986667633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411121293902397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08044626315434773,
      "backward_entropy": 0.004824493419040333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004882985376752913,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03411158546805382,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08043269316355388,
      "backward_entropy": 0.007523083551363511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047538120998069644,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411193564534187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08041941126187642,
      "backward_entropy": 0.004821060733361678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005627407226711512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411226347088814,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08040643731753032,
      "backward_entropy": 0.006004124202511527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005120414425618947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034112598747015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08039366205533345,
      "backward_entropy": 0.004817839373241772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005479972460307181,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411293774843216,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0803811103105545,
      "backward_entropy": 0.00600280680439689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000391427573049441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411329910159111,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08036873737970988,
      "backward_entropy": 0.004814573309638284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004841327900066972,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411363810300827,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08035664757092793,
      "backward_entropy": 0.006001334298740734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004920149804092944,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034113992005586624,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08034474651018779,
      "backward_entropy": 0.0060005784034729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003878459974657744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411436080932617,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0803329994281133,
      "backward_entropy": 0.004809713160449808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038398883771151304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034114714711904526,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08032150069872539,
      "backward_entropy": 0.004808123138817874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032179526169784367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411506488919258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08031022548675537,
      "backward_entropy": 0.004806542599743063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033609895035624504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411538898944855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08029922842979431,
      "backward_entropy": 0.005997531793334268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034878775477409363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411569446325302,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08028844992319743,
      "backward_entropy": 0.005996938456188549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002885092981159687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034116003662347794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0802778700987498,
      "backward_entropy": 0.004802217537706549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002755569003056735,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03411629796028137,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08026753862698872,
      "backward_entropy": 0.0075086436488411646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003030738153029233,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034116581082344055,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0802574356396993,
      "backward_entropy": 0.007507759061726657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022178562358021736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411686047911644,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08024751643339793,
      "backward_entropy": 0.004798244007609107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021204023505561054,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03411710634827614,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08023785551389058,
      "backward_entropy": 0.007506140931086106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002647506189532578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034117333590984344,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08022845288117726,
      "backward_entropy": 0.0059937970204786825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023509940365329385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411756828427315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08021920919418335,
      "backward_entropy": 0.004794802178036083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021180092880968004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411779925227165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08021015922228496,
      "backward_entropy": 0.004793682897632772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002878126688301563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411803022027016,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08020130793253581,
      "backward_entropy": 0.0047925859689712524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002204436605097726,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411829099059105,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08019254108270009,
      "backward_entropy": 0.005991875448010184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023773220891598612,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411855176091194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08018394311269124,
      "backward_entropy": 0.005991257727146149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020982680143788457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034118831157684326,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08017546931902568,
      "backward_entropy": 0.007500777867707339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001410154509358108,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034119103103876114,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08016714950402577,
      "backward_entropy": 0.00598990646275607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016790807421784848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411933407187462,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08015906314055125,
      "backward_entropy": 0.004786753180352124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014261560863815248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034119557589292526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08015115062395732,
      "backward_entropy": 0.005988899957049976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019114903989247978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411975875496864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08014343678951263,
      "backward_entropy": 0.004784765568646518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015194699517451227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411996737122536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08013583223025005,
      "backward_entropy": 0.005988043817606839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016793755639810115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412017598748207,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08012838164965312,
      "backward_entropy": 0.007496423342011191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015067005006130785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412039205431938,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08012104034423828,
      "backward_entropy": 0.0074957148595289754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014422766980715096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412061184644699,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08011385798454285,
      "backward_entropy": 0.004780847917903553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011485196591820568,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341208316385746,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08010679980119069,
      "backward_entropy": 0.005986137146299536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012030950165353715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412103280425072,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08009991546471913,
      "backward_entropy": 0.0047789639370007944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.329678141511977e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412122279405594,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08009317020575206,
      "backward_entropy": 0.007492958822033622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.93544968473725e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412139415740967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0800866186618805,
      "backward_entropy": 0.004777267236601223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011372997687431052,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034121543169021606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08008026580015819,
      "backward_entropy": 0.0047765275971456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.498199506197125e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412169590592384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08007402221361797,
      "backward_entropy": 0.0047757862643762064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010573743929853663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412184491753578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08006792267163594,
      "backward_entropy": 0.0047750533981756734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.25860513234511e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412200137972832,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08006193240483601,
      "backward_entropy": 0.00598382137038491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.626477599842474e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412215784192085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08005606631437938,
      "backward_entropy": 0.004773583940484307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.990453013917431e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412230312824249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0800503393014272,
      "backward_entropy": 0.0047728920524770565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.348899816861376e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034122440963983536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08004474639892578,
      "backward_entropy": 0.004772212694991718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.065578443463892e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412257134914398,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08003928263982137,
      "backward_entropy": 0.0059827396815473385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.186964259948581e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412267938256264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08003399769465129,
      "backward_entropy": 0.004771007055586035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.217179518193007e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412279114127159,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08002878228823344,
      "backward_entropy": 0.005982393568212336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.776909867767245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034122906625270844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08002366622289021,
      "backward_entropy": 0.005982205271720886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.016963379806839e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034123022109270096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08001865943272908,
      "backward_entropy": 0.004769280214201321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.28506313660182e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412313759326935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08001377681891124,
      "backward_entropy": 0.004768719388680024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7620891311671585e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034123245626688004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08000896374384563,
      "backward_entropy": 0.004768170416355133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.738286588690244e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412335738539696,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08000427484512329,
      "backward_entropy": 0.004767620766704733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.280113353161141e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412346541881561,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07999969522158305,
      "backward_entropy": 0.004767083647576245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.763874312629923e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034123558551073074,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07999525467554729,
      "backward_entropy": 0.004766588861292059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.093549407320097e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412364795804024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07999091347058614,
      "backward_entropy": 0.00476613234389912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.996818122686818e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341237410902977,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07998664180437724,
      "backward_entropy": 0.004765648733485828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.116260970477015e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412383422255516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07998247941335042,
      "backward_entropy": 0.004765183410861276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.768482904182747e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034123923629522324,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07997842133045197,
      "backward_entropy": 0.005980562757362019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9382965294644237e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412402421236038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07997443278630574,
      "backward_entropy": 0.00476425208828666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.134028858970851e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412410989403725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07997055351734161,
      "backward_entropy": 0.004763814874670722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.210626164218411e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412420302629471,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07996675372123718,
      "backward_entropy": 0.004763366146521134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.416259278310463e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412429243326187,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07996304829915364,
      "backward_entropy": 0.005979953841729598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8950878913747147e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034124381840229034,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07995943228403728,
      "backward_entropy": 0.005979793992909518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.14221324515529e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341244600713253,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07995588580767314,
      "backward_entropy": 0.004762113094329834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.742951619438827e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412454202771187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07995242873827617,
      "backward_entropy": 0.004761713133616881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4652450520079583e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034124620258808136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07994905114173889,
      "backward_entropy": 0.004761319607496262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4897059120121412e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034124698489904404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07994576791922252,
      "backward_entropy": 0.004760951819744977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6408553821966052e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412477299571037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0799425741036733,
      "backward_entropy": 0.00476057150147178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3094162315828726e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412485122680664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07993943492571513,
      "backward_entropy": 0.00476020100441846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4227851099567488e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412492573261261,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07993637522061665,
      "backward_entropy": 0.004759831184690649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.165550904464908e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412500396370888,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07993338505427043,
      "backward_entropy": 0.00597877326336774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.016706275753677e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034125082194805145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0799304445584615,
      "backward_entropy": 0.004759091545235027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3190706997411326e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412516042590141,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07992758850256602,
      "backward_entropy": 0.004758729176087813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8069091311190277e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412524238228798,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07992477715015411,
      "backward_entropy": 0.0047583668069405985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0027753635076806e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412532061338425,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07992204030354817,
      "backward_entropy": 0.007479167120023208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7242955436813645e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034125398844480515,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07991933822631836,
      "backward_entropy": 0.004757663065736944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.336362402071245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412547707557678,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07991670568784077,
      "backward_entropy": 0.005977885966951197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3976342415844556e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412554785609245,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0799141526222229,
      "backward_entropy": 0.00597777014428919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.610065191925969e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034125614911317825,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0799116591612498,
      "backward_entropy": 0.0074781328439712524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.046850775310304e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034125685691833496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07990922530492146,
      "backward_entropy": 0.004756357859481464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5431314750458114e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412574902176857,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07990687092145284,
      "backward_entropy": 0.00475607304410501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4720427316206042e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034125812351703644,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0799045463403066,
      "backward_entropy": 0.004755780100822449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2483682439778931e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412587568163872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07990226149559021,
      "backward_entropy": 0.004755490544167432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.186468216474168e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412594273686409,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07990002632141113,
      "backward_entropy": 0.00597707520831715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3163570656615775e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412600979208946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07989785075187683,
      "backward_entropy": 0.004754892465743152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.807424819679e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412608057260513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07989570995171864,
      "backward_entropy": 0.005976788699626923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.650145900901407e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412614390254021,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07989361882209778,
      "backward_entropy": 0.004754298451271924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.615706974524073e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034126199781894684,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07989159226417542,
      "backward_entropy": 0.005976564504883506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.497299066017149e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412625566124916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07988962531089783,
      "backward_entropy": 0.00475379689173265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.141663784044795e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412631154060364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07988771796226501,
      "backward_entropy": 0.005976375531066547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.918015060364269e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034126367419958115,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07988586525122325,
      "backward_entropy": 0.007475416091355411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.252204341057222e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034126415848731995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0798840622107188,
      "backward_entropy": 0.004753064702857624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6399106799508445e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034126464277505875,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07988230387369792,
      "backward_entropy": 0.005976101891560988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.036838269414147e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412650525569916,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07988058527310689,
      "backward_entropy": 0.007474914193153381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.421559646696551e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412654623389244,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07987890640894572,
      "backward_entropy": 0.00475245781920173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0496627156680916e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034126587212085724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07987725734710693,
      "backward_entropy": 0.004752263426780701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.443554866564227e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412662446498871,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07987565298875172,
      "backward_entropy": 0.00747447054494511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.405978754424723e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412666544318199,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07987408339977264,
      "backward_entropy": 0.0059758201241493225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8073733271157835e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034126702696084976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07987254858016968,
      "backward_entropy": 0.0047517049718986855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.920286755805137e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412673994898796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07987104852994283,
      "backward_entropy": 0.004751524464650588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.338564733392559e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034126777201890945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07986957828203838,
      "backward_entropy": 0.00475135242397135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.406321750138886e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412681445479393,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0798681378364563,
      "backward_entropy": 0.007473750547929244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.222571988066193e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034126847982406616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07986673216025035,
      "backward_entropy": 0.004751009358601136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.410156750760507e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341268815100193,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07986536622047424,
      "backward_entropy": 0.004750848832455548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7852209970878903e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412691503763199,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07986404498418172,
      "backward_entropy": 0.005975448272444985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8249168028414715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034126948565244675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07986276348431905,
      "backward_entropy": 0.004750518974932757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.91038020097767e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412697836756706,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07986149191856384,
      "backward_entropy": 0.005975361574779858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1809270240046317e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412700816988945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07986026505629222,
      "backward_entropy": 0.004750220274383371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1589904665452195e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412703797221184,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07985905806223552,
      "backward_entropy": 0.0074728835712779655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.202274228897295e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127067774534225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07985789080460866,
      "backward_entropy": 0.004749936813657934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4729949927859707e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412709757685661,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07985673348108928,
      "backward_entropy": 0.00747265869920904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.754460638243472e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127127379179,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0798556258281072,
      "backward_entropy": 0.00474966588345441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4202568056352902e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412715718150139,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07985453804334004,
      "backward_entropy": 0.004749524661085822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6283266834070673e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034127186983823776,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07985349992911021,
      "backward_entropy": 0.007472307844595475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.404038013992249e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127216786146164,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07985247174898784,
      "backward_entropy": 0.00474925542419607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5388960693817353e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412724658846855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07985146840413411,
      "backward_entropy": 0.00474911860444329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.069955144179403e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412727639079094,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07985047499338786,
      "backward_entropy": 0.005974894897504287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.192986585214385e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412730619311333,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984950641791026,
      "backward_entropy": 0.004748860882087188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6361359485017601e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127332270145416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984855771064758,
      "backward_entropy": 0.0047487379475073385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6253450212388998e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127358347177505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984763383865356,
      "backward_entropy": 0.0047486244954846124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5025682387204142e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127384424209595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0798467497030894,
      "backward_entropy": 0.004748516123403202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.700952680039336e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127406775951385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984588543574016,
      "backward_entropy": 0.004748414185914126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3023775409237714e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412742540240288,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984504600365956,
      "backward_entropy": 0.004748316989703612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.411176640431222e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412744402885437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984422147274017,
      "backward_entropy": 0.004748221148144115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4494506785922567e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412746265530586,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0798434317111969,
      "backward_entropy": 0.0074712539261037655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1646957318589557e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034127477556467056,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07984264691670735,
      "backward_entropy": 0.005974651737646623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2066084309481084e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412749245762825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984188199043274,
      "backward_entropy": 0.004747977310960943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.055846837516583e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034127507358789444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07984114189942677,
      "backward_entropy": 0.005974632772532376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0847105613720487e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412752225995064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07984043161074321,
      "backward_entropy": 0.00474782254208218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.442698569728236e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412753716111183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983973622322083,
      "backward_entropy": 0.0047477534548802805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0930236840067664e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127552062273026,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983906070391338,
      "backward_entropy": 0.0047476735304702415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.218964578394662e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412756696343422,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0798384000857671,
      "backward_entropy": 0.005974600260907953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33890339890786e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412758186459541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983775436878204,
      "backward_entropy": 0.0047475282441486015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606947403677623e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412759304046631,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983711858590443,
      "backward_entropy": 0.004747467623515563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.46303066737164e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341276079416275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983651260534923,
      "backward_entropy": 0.004747396165674383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.766241540390183e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127622842788696,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983591159184773,
      "backward_entropy": 0.004747333174402063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.177132713171886e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412763774394989,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983532547950745,
      "backward_entropy": 0.004747271199118008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.044732572263456e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034127648919820786,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07983475923538208,
      "backward_entropy": 0.007470508190718564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.002141160228348e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412766009569168,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983420292536418,
      "backward_entropy": 0.004747144877910614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.855210929439636e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127671271562576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983366151650746,
      "backward_entropy": 0.0047470842572775755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.851724154126714e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412768617272377,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07983313004175822,
      "backward_entropy": 0.005974511531266299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.953456252427713e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127697348594666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983262836933136,
      "backward_entropy": 0.004746965047988025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.807866957889928e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412770852446556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0798321266969045,
      "backward_entropy": 0.005974483083594929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.79136758713139e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127719700336456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983163992563884,
      "backward_entropy": 0.0047468427907336845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.734445724352554e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412773087620735,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983116308848064,
      "backward_entropy": 0.004746792668646032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.097613270914735e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412774205207825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07983070611953735,
      "backward_entropy": 0.004746738821268082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.539418003128958e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412775322794914,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07983024915059407,
      "backward_entropy": 0.007470075379718433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.973133064188005e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412776440382004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982981701691945,
      "backward_entropy": 0.00474663959308104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0441395299239957e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412777557969093,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982941468556722,
      "backward_entropy": 0.004746588455005126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.426835064601619e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412778675556183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982900242010753,
      "backward_entropy": 0.0047465352849526835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.966020247185952e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034127797931432724,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07982861002286275,
      "backward_entropy": 0.00746988911520351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.753837122781988e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412780910730362,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07982822755972545,
      "backward_entropy": 0.0059743923219767485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.818603945797804e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034127820283174515,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07982786496480306,
      "backward_entropy": 0.007469801740212874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.659799633875082e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412783145904541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982750236988068,
      "backward_entropy": 0.004746338860555129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.343444265306971e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034127842634916306,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07982714970906575,
      "backward_entropy": 0.00746971842917529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0840289494117314e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0341278538107872,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07982682188351949,
      "backward_entropy": 0.007469677112319253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.485687673470238e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127864986658096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982649902502696,
      "backward_entropy": 0.004746217280626297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.089570898533566e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412787243723869,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982617616653442,
      "backward_entropy": 0.004746174947781997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6621523002413596e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412787988781929,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982586820920308,
      "backward_entropy": 0.004746132276274941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9231160308663675e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412788733839989,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982556521892548,
      "backward_entropy": 0.0047460923140699215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0745102347063948e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127894788980484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982528209686279,
      "backward_entropy": 0.004746063189073043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.069880338240182e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412790223956108,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07982499897480011,
      "backward_entropy": 0.0059742873365228825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9554916264041822e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412790969014168,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07982471585273743,
      "backward_entropy": 0.007469434629787098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3470624082856375e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127917140722275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982444266478221,
      "backward_entropy": 0.004745971072803844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4472450970970385e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412792459130287,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07982416947682698,
      "backward_entropy": 0.007469385185024955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3602196702322544e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412792831659317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07982391119003296,
      "backward_entropy": 0.004745915532112122,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.349339331672809e-06,
    "avg_log_Z": 0.03412694469094277,
    "success_rate": 1.0,
    "avg_reward": 49.7,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.18,
      "1": 0.19,
      "2": 0.63
    },
    "avg_forward_entropy": 0.07986203004916509,
    "avg_backward_entropy": 0.0054732657867399125,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}