{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377817749977112,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377817749977112,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377817749977112,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377817749977112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377817749977112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377817749977112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.13815362453460694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.225999355316162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308492501576742,
      "backward_entropy": 0.1377216100692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.223227500915527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308542172114053,
      "backward_entropy": 0.13774621486663818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.753443717956543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00019999928190372884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308587869008383,
      "backward_entropy": 0.13770885467529298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.848446369171143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003000955912284553,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308699131011963,
      "backward_entropy": 0.13759949207305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4810709953308105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00040026780334301293,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308826287587485,
      "backward_entropy": 0.13755733966827394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.212328910827637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000500385882332921,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830894947052002,
      "backward_entropy": 0.13800435066223143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.302416801452637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006003949092701077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309046824773154,
      "backward_entropy": 0.13755123615264891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.471988677978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007006468949839473,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309148152669272,
      "backward_entropy": 0.1374248743057251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.73379373550415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008008145377971232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309247493743896,
      "backward_entropy": 0.13746581077575684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.730301856994629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009009951027110219,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309352795283,
      "backward_entropy": 0.13733091354370117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.462536334991455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001001183409243822,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309460083643594,
      "backward_entropy": 0.13728203773498535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.723050594329834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001101293950341642,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309559424718222,
      "backward_entropy": 0.13723055124282837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.819460391998291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012014242820441723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309656778971353,
      "backward_entropy": 0.1372884750366211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.189452648162842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001301613636314869,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309746185938516,
      "backward_entropy": 0.13772740364074706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.449052333831787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014016281347721815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309815724690756,
      "backward_entropy": 0.1371936559677124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.344730854034424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015015866374596953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309879302978516,
      "backward_entropy": 0.13714479207992553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.430253982543945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016014479333534837,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309936920801798,
      "backward_entropy": 0.13760958909988402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.206727981567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017016400815919042,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309994538625082,
      "backward_entropy": 0.1369011878967285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3334431648254395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018020758870989084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18310036261876425,
      "backward_entropy": 0.13699073791503907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.329655647277832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001902320422232151,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1831007202466329,
      "backward_entropy": 0.13678193092346191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.571722030639648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002002399880439043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18310105800628662,
      "backward_entropy": 0.13688275814056397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770750045776367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021028153132647276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1831013560295105,
      "backward_entropy": 0.13682901859283447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.679832935333252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022036151494830847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18310161431630453,
      "backward_entropy": 0.13735003471374513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39907169342041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023042995017021894,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18310181299845377,
      "backward_entropy": 0.13652415275573732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.188788414001465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002405180362984538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18310193220774332,
      "backward_entropy": 0.13665655851364136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.594964981079102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002506118267774582,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18310195207595825,
      "backward_entropy": 0.13638570308685302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20915699005127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026073181070387363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18310193220774332,
      "backward_entropy": 0.13715810775756837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.996922492980957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002708982676267624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18310181299845377,
      "backward_entropy": 0.1364691972732544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.940629959106445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0028109345585107803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18310161431630453,
      "backward_entropy": 0.13705368041992189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.777215003967285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029131416231393814,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18310133616129556,
      "backward_entropy": 0.1360897183418274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.666633605957031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030154376290738583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18310091892878214,
      "backward_entropy": 0.1362660765647888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.997408390045166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003117746440693736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18310036261876425,
      "backward_entropy": 0.13619558811187743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.246769905090332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032198152039200068,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309970696767172,
      "backward_entropy": 0.13683807849884033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.807924270629883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0033217687159776688,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830989122390747,
      "backward_entropy": 0.13577309846878052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.578498840332031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0034238924272358418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.183098038037618,
      "backward_entropy": 0.13597557544708253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839853286743164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035256287083029747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309718370437622,
      "backward_entropy": 0.13589944839477539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.757104873657227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003627535654231906,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309617042541504,
      "backward_entropy": 0.13660855293273927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.098228454589844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037300235126167536,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830950379371643,
      "backward_entropy": 0.13654792308807373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.092090606689453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0038327686488628387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309390544891357,
      "backward_entropy": 0.13565974235534667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.01772689819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003935731016099453,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830927530924479,
      "backward_entropy": 0.13528562784194947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.948040962219238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004038382321596146,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309168020884195,
      "backward_entropy": 0.13519911766052245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.967869758605957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004140670411288738,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309054772059122,
      "backward_entropy": 0.13540453910827638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606553077697754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004243153613060713,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308939536412558,
      "backward_entropy": 0.13502078056335448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.934027671813965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0043456340208649635,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308822313944498,
      "backward_entropy": 0.13492895364761354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.278987884521484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004447313956916332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308726946512857,
      "backward_entropy": 0.13607733249664306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02422046661377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00454888679087162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308619658152261,
      "backward_entropy": 0.1350430965423584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6651835441589355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004650251939892769,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308508396148682,
      "backward_entropy": 0.13592529296875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.697478294372559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004751254338771105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308397134145102,
      "backward_entropy": 0.13584702014923095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.406307697296143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004851910285651684,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308266003926596,
      "backward_entropy": 0.13444116115570068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.302657127380371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004952166695147753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308148781458536,
      "backward_entropy": 0.1346587896347046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.628188133239746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0050529842264950275,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308003743489584,
      "backward_entropy": 0.13423184156417847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.12788200378418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00515392329543829,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307828903198242,
      "backward_entropy": 0.1355224847793579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9627103805542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005254744552075863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307640155156454,
      "backward_entropy": 0.13435132503509523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11319637298584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005355852656066418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307415644327799,
      "backward_entropy": 0.13424606323242189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260537147521973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005456812679767609,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307183186213175,
      "backward_entropy": 0.13413848876953124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.413983345031738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005558232311159372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306922912597656,
      "backward_entropy": 0.1340265989303589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.78758716583252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005659656599164009,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306662638982138,
      "backward_entropy": 0.1350945472717285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0045599937438965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005761232227087021,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306378523508707,
      "backward_entropy": 0.13341352939605713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527131080627441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005862061865627766,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306124210357666,
      "backward_entropy": 0.13328752517700196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.170943260192871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005962990690022707,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305852015813193,
      "backward_entropy": 0.13315873146057128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709696292877197,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006063822191208601,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830557386080424,
      "backward_entropy": 0.13471267223358155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.847465515136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006164311431348324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305287758509317,
      "backward_entropy": 0.13289287090301513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.425190448760986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006265104282647371,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304979801177979,
      "backward_entropy": 0.13451025485992432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39072847366333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006365462206304073,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304701646169028,
      "backward_entropy": 0.1326162338256836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.171698093414307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006465456914156675,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830448110898336,
      "backward_entropy": 0.13247461318969728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.191305637359619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006564983632415533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18304304281870523,
      "backward_entropy": 0.1327808141708374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.489962577819824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006664061453193426,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830414334932963,
      "backward_entropy": 0.132183837890625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.864467144012451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006763950455933809,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303926785786948,
      "backward_entropy": 0.1320338249206543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.537651538848877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006863710470497608,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303714195887247,
      "backward_entropy": 0.1318808078765869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.897370338439941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0069631366059184074,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303483724594116,
      "backward_entropy": 0.13172459602355957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.731830596923828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007062417920678854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830320954322815,
      "backward_entropy": 0.1320808172225952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.616343975067139,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007161553483456373,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302931388219199,
      "backward_entropy": 0.13346052169799805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.713220119476318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007260482758283615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830264925956726,
      "backward_entropy": 0.13333463668823242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.57793140411377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007359297014772892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302365144093832,
      "backward_entropy": 0.13320603370666503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.038019180297852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007458554580807686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830209493637085,
      "backward_entropy": 0.13307278156280516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.494222640991211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0075584277510643005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301804860432944,
      "backward_entropy": 0.13131120204925537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.44008207321167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007658479735255241,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301471074422201,
      "backward_entropy": 0.13054382801055908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3441290855407715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007758155465126038,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301155169804892,
      "backward_entropy": 0.130362606048584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.275020599365234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007857384160161018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830082138379415,
      "backward_entropy": 0.13081097602844238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.837245941162109,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007955703884363174,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300571044286093,
      "backward_entropy": 0.12997870445251464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.22052001953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00805412046611309,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300354480743408,
      "backward_entropy": 0.13047595024108888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941974639892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008153303526341915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300080299377441,
      "backward_entropy": 0.1295850992202759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.948921203613281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008252518251538277,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829981803894043,
      "backward_entropy": 0.13190898895263672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.061554908752441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008351720869541168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829953988393148,
      "backward_entropy": 0.12994306087493895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.695068836212158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008450947701931,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299221992492676,
      "backward_entropy": 0.12896711826324464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.480422019958496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008550034835934639,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829890807469686,
      "backward_entropy": 0.13143305778503417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.564939022064209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008649410679936409,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829854647318522,
      "backward_entropy": 0.12937872409820556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438615798950195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00874854251742363,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298184871673584,
      "backward_entropy": 0.1283138394355774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.540757656097412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008847982622683048,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297811349232992,
      "backward_entropy": 0.1309358596801758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.533203125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008947158232331276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297433853149414,
      "backward_entropy": 0.1287827730178833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62607479095459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009046663530170918,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297016620635986,
      "backward_entropy": 0.1285761833190918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.622657299041748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00914653018116951,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18296563625335693,
      "backward_entropy": 0.1273887872695923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.156464576721191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009246102534234524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18296090761820474,
      "backward_entropy": 0.12815064191818237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.57407283782959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009345748461782932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829559008280436,
      "backward_entropy": 0.12793232202529908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.570327281951904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009444608353078365,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18295194705327353,
      "backward_entropy": 0.1266523480415344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.883956909179688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009543298743665218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294793367385864,
      "backward_entropy": 0.12749102115631103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429407119750977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00964259635657072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829433043797811,
      "backward_entropy": 0.12726296186447145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.082834243774414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009742159396409988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293815851211548,
      "backward_entropy": 0.12929024696350097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.611936569213867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00984175968915224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293273448944092,
      "backward_entropy": 0.12908941507339478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50714111328125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009941729716956615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18292701244354248,
      "backward_entropy": 0.12655048370361327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.377413749694824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010041327215731144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292105197906494,
      "backward_entropy": 0.12867604494094848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.788473129272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010140547528862953,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829151709874471,
      "backward_entropy": 0.12478876113891602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.228846549987793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010240225121378899,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290837605794272,
      "backward_entropy": 0.12825045585632325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.438132286071777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010339505970478058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290263414382935,
      "backward_entropy": 0.1280311107635498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.658273220062256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010438494384288788,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289709091186523,
      "backward_entropy": 0.12391970157623292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.513426780700684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010536789894104004,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289254109064737,
      "backward_entropy": 0.1275763988494873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.496869087219238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010634961538016796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18288811047871908,
      "backward_entropy": 0.12331910133361816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.832738399505615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010733013041317463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18288367986679077,
      "backward_entropy": 0.1244208574295044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.649084091186523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010830515064299107,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287932872772217,
      "backward_entropy": 0.1268472671508789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.522622108459473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010928736068308353,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18287511666615805,
      "backward_entropy": 0.12238352298736573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.535207271575928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011027510277926922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182870884736379,
      "backward_entropy": 0.1220678448677063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.625198841094971,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011126142926514149,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286681175231934,
      "backward_entropy": 0.12324289083480836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.498717308044434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011224625632166862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828617254892985,
      "backward_entropy": 0.1229386568069458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907607555389404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0113229313865304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18285632133483887,
      "backward_entropy": 0.12263317108154297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.101235389709473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011421342380344868,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285051981608072,
      "backward_entropy": 0.12521941661834718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.866267681121826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011519997380673885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828444798787435,
      "backward_entropy": 0.12200388908386231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.524544715881348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01161869801580906,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18283804257710776,
      "backward_entropy": 0.12004963159561158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.032529830932617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011717185378074646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18283092975616455,
      "backward_entropy": 0.12428092956542969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.643621444702148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01181577704846859,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828226645787557,
      "backward_entropy": 0.11932675838470459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.148489475250244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01191483624279499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281296888987222,
      "backward_entropy": 0.12362918853759766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.861730098724365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012013510800898075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280412753423056,
      "backward_entropy": 0.12329394817352295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4167704582214355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012112248688936234,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279516696929932,
      "backward_entropy": 0.12295207977294922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8145341873168945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012210754677653313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278616666793823,
      "backward_entropy": 0.1196140170097351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.003180503845215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012309316545724869,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827770471572876,
      "backward_entropy": 0.11743074655532837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.97202205657959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012408077716827393,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827679475148519,
      "backward_entropy": 0.12189195156097413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.627762794494629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01250695250928402,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275833129882812,
      "backward_entropy": 0.1166356086730957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.09359884262085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012605668045580387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274782101313272,
      "backward_entropy": 0.11812467575073242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.716605186462402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01270397286862135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18273774782816568,
      "backward_entropy": 0.1207535743713379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.971126079559326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012802893295884132,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18272626399993896,
      "backward_entropy": 0.11540147066116332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.854808330535889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012901932001113892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18271438280741373,
      "backward_entropy": 0.11995881795883179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.185839653015137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013001085259020329,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18270325660705566,
      "backward_entropy": 0.1145514726638794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5791521072387695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01309977751225233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18269149462381998,
      "backward_entropy": 0.1191524624824524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.350897789001465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013198371976613998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826795736948649,
      "backward_entropy": 0.11874043941497803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.741903781890869,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01329675130546093,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266789118448892,
      "backward_entropy": 0.11323380470275879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098071098327637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01339525356888771,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18265676498413086,
      "backward_entropy": 0.11476045846939087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.974796295166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013494012877345085,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18264456590016684,
      "backward_entropy": 0.11233035326004029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.716818809509277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013592352159321308,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18263361851374307,
      "backward_entropy": 0.11187187433242798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.814907073974609,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013690020889043808,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18262219429016113,
      "backward_entropy": 0.11657758951187133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.189528465270996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013787267729640007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261182308197021,
      "backward_entropy": 0.11294162273406982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.742309093475342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013883731327950954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18260320027669272,
      "backward_entropy": 0.11248238086700439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.12427282333374,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013980473391711712,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18259376287460327,
      "backward_entropy": 0.10998153686523438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.96095609664917,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014076394960284233,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18258527914683023,
      "backward_entropy": 0.10949647426605225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4403228759765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014172036200761795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257516622543335,
      "backward_entropy": 0.1142828106880188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1136579513549805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014267824590206146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825640598932902,
      "backward_entropy": 0.11058292388916016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.991858005523682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01436353288590908,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18255237738291422,
      "backward_entropy": 0.11009080410003662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.655271053314209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014459124766290188,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254075447718301,
      "backward_entropy": 0.11283993721008301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.204338073730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014554343186318874,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18252885341644287,
      "backward_entropy": 0.1069677233695984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2571611404418945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014649596065282822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18251589934031168,
      "backward_entropy": 0.10857992172241211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28760814666748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014744885265827179,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825012962023417,
      "backward_entropy": 0.11134530305862426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.074790000915527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014840932562947273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18248438835144043,
      "backward_entropy": 0.11083197593688965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.431087970733643,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014937586151063442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18246648708979288,
      "backward_entropy": 0.1103089451789856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.555539131164551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015032901428639889,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824498176574707,
      "backward_entropy": 0.1042789340019226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.437143802642822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015127833932638168,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18243330717086792,
      "backward_entropy": 0.10372618436813355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.502617835998535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015222379006445408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18241759141286215,
      "backward_entropy": 0.10541445016860962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.952996253967285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015316640958189964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240274985631308,
      "backward_entropy": 0.10817594528198242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.755159854888916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01541014015674591,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238731225331625,
      "backward_entropy": 0.10763388872146606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.118415355682373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015502886846661568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18237268924713135,
      "backward_entropy": 0.1037945032119751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.966282367706299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015595282427966595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823593576749166,
      "backward_entropy": 0.10325007438659668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.842080116271973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015687191858887672,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18234618504842123,
      "backward_entropy": 0.10031799077987671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9404683113098145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015779249370098114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233096599578857,
      "backward_entropy": 0.10214418172836304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.781350135803223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01587163284420967,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18231570720672607,
      "backward_entropy": 0.09913934469223022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.745670795440674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015963442623615265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823015014330546,
      "backward_entropy": 0.10427392721176147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0801825523376465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01605471409857273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822882890701294,
      "backward_entropy": 0.10369383096694947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.564502239227295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01614576391875744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822755734125773,
      "backward_entropy": 0.10310736894607545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.657912731170654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016236914321780205,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18226128816604614,
      "backward_entropy": 0.09673340320587158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.213523864746094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016327593475580215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18224898974100748,
      "backward_entropy": 0.09870725870132446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.34478759765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01641816832125187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18223557869593301,
      "backward_entropy": 0.10131247043609619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.079880237579346,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016508733853697777,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18222043911616007,
      "backward_entropy": 0.09488424062728881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.984356880187988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016599206253886223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18220619360605875,
      "backward_entropy": 0.09692094326019288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.526918888092041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016690192744135857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821894645690918,
      "backward_entropy": 0.09630857110023498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.121795654296875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016781380400061607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18217265605926514,
      "backward_entropy": 0.09568971395492554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9863104820251465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016871606931090355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18215656280517578,
      "backward_entropy": 0.09507195949554444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.370323181152344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01696169003844261,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821403702100118,
      "backward_entropy": 0.0975569725036621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.546634674072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01705191843211651,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18212284644444784,
      "backward_entropy": 0.09106637835502625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598154544830322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017141664400696754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18210587898890176,
      "backward_entropy": 0.09626161456108093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.302926063537598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017231037840247154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18208956718444824,
      "backward_entropy": 0.09255456924438477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.348119258880615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01732056401669979,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18207093079884848,
      "backward_entropy": 0.0919119656085968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.030022144317627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017410287633538246,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820503075917562,
      "backward_entropy": 0.0884447693824768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5851569175720215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017499180510640144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820309559504191,
      "backward_entropy": 0.09361652135849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3573317527771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017587779089808464,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18201160430908203,
      "backward_entropy": 0.08711344599723816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.175832271575928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01767590455710888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18199191490809122,
      "backward_entropy": 0.08930470943450927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.968006610870361,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017764322459697723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18197005987167358,
      "backward_entropy": 0.0915934145450592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.581601142883301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017852867022156715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18194731076558432,
      "backward_entropy": 0.09090462923049927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6000752449035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01794120855629444,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18192549546559653,
      "backward_entropy": 0.084416264295578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596097469329834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01802935265004635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.181902805964152,
      "backward_entropy": 0.08663012385368347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.656012535095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018117433413863182,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18188170591990152,
      "backward_entropy": 0.08305492401123046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.145988464355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01820538192987442,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18185881773630777,
      "backward_entropy": 0.08237065076828003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.903340816497803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0182928629219532,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18183682362238565,
      "backward_entropy": 0.08168553113937378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.331668376922607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018379636108875275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818140745162964,
      "backward_entropy": 0.08391036987304687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2943243980407715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018466133624315262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1817886233329773,
      "backward_entropy": 0.0832245945930481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.123490810394287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018551621586084366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18176603317260742,
      "backward_entropy": 0.08526523113250732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.266564846038818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01863693632185459,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18174447615941366,
      "backward_entropy": 0.07894728779792785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.394590854644775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018722109496593475,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817201773325602,
      "backward_entropy": 0.0782659649848938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.642332553863525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018806500360369682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18169860045115152,
      "backward_entropy": 0.08049998283386231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9110159873962402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018890365958213806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18167726198832193,
      "backward_entropy": 0.07981948852539063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.384641647338867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01897313818335533,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816591421763102,
      "backward_entropy": 0.0817024827003479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.500758647918701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01905529946088791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816407044728597,
      "backward_entropy": 0.0809961199760437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.471102237701416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019137056544423103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18162224690119425,
      "backward_entropy": 0.07780008912086486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8195302486419678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019218487665057182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18160516023635864,
      "backward_entropy": 0.07712690830230713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.162341594696045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019299017265439034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18159099419911703,
      "backward_entropy": 0.07645997405052185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.265990257263184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01937989331781864,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1815723975499471,
      "backward_entropy": 0.07283506393432618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.257004261016846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019461221992969513,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1815501650174459,
      "backward_entropy": 0.07215241193771363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.074914932250977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019542861729860306,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18152201175689697,
      "backward_entropy": 0.07440856695175171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.379087448120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01962381973862648,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18149568637212118,
      "backward_entropy": 0.07078091502189636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.102880001068115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0197044275701046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1814687450726827,
      "backward_entropy": 0.0730313241481781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.277270317077637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019785374402999878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1814372738202413,
      "backward_entropy": 0.07233368754386901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.016923427581787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019865892827510834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18140562375386557,
      "backward_entropy": 0.07382911443710327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.22032356262207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019945787265896797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18137478828430176,
      "backward_entropy": 0.07094042897224426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.196601390838623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02002521976828575,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18134093284606934,
      "backward_entropy": 0.06735876798629761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.275754451751709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020104343071579933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813071370124817,
      "backward_entropy": 0.07167400121688842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.006766319274902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020183250308036804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18127218882242838,
      "backward_entropy": 0.07095593214035034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5688304901123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020261652767658234,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.181235671043396,
      "backward_entropy": 0.06531485319137573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9177074432373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02033924125134945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18120133876800537,
      "backward_entropy": 0.06463631987571716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.023937463760376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020416446030139923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18116788069407144,
      "backward_entropy": 0.06678542494773865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5521228313446045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020492464303970337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18114097913106283,
      "backward_entropy": 0.06612020134925842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.857102394104004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020567884668707848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18111417690912882,
      "backward_entropy": 0.06545823812484741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7026419639587402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020644091069698334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18107986450195312,
      "backward_entropy": 0.0647834599018097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7866504192352295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020719802007079124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810436248779297,
      "backward_entropy": 0.0660119891166687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6010470390319824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020795203745365143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18100589513778687,
      "backward_entropy": 0.06061837673187256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.120877742767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02087009884417057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18096641699473062,
      "backward_entropy": 0.06276730298995972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9986088275909424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02094515599310398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18092356125513712,
      "backward_entropy": 0.062092989683151245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1358230113983154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021020222455263138,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18087738752365112,
      "backward_entropy": 0.0632207751274109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6875052452087402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021094296127557755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808307965596517,
      "backward_entropy": 0.06253317594528199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.640390157699585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021167106926441193,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18078966935475668,
      "backward_entropy": 0.05732096433639526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.422589063644409,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021239735186100006,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18074429035186768,
      "backward_entropy": 0.056669038534164426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.408097267150879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021312035620212555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18069779872894287,
      "backward_entropy": 0.06050428152084351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4917690753936768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021385079249739647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18064218759536743,
      "backward_entropy": 0.0581131100654602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7666990756988525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021457849070429802,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18058504660924277,
      "backward_entropy": 0.054716312885284425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8899810314178467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021529626101255417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18053321043650308,
      "backward_entropy": 0.056796371936798096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3059449195861816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02160065621137619,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804849902788798,
      "backward_entropy": 0.05781238079071045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0667107105255127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021671297028660774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18043108781178793,
      "backward_entropy": 0.057153362035751346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.376443862915039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021741501986980438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18037815888722739,
      "backward_entropy": 0.05649455189704895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.953834056854248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021811576560139656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1803203026453654,
      "backward_entropy": 0.05423210263252258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.088881731033325,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021881084889173508,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18026177088419595,
      "backward_entropy": 0.05093582272529602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.684459924697876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02195039764046669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18020522594451904,
      "backward_entropy": 0.05296711921691895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.749295711517334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022018834948539734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18014721075693765,
      "backward_entropy": 0.05389578342437744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1188533306121826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022086618468165398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18008816242218018,
      "backward_entropy": 0.05172187089920044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4231224060058594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02215433679521084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18002601464589438,
      "backward_entropy": 0.0526276707649231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.513899564743042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022222422063350677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17995882034301758,
      "backward_entropy": 0.05199087858200073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.715559720993042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022290974855422974,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17988584438959757,
      "backward_entropy": 0.047315046191215515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.321958303451538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022358927875757217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1798135240872701,
      "backward_entropy": 0.04922571778297424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8743855953216553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022425808012485504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17974414428075156,
      "backward_entropy": 0.04861561954021454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.848278522491455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02249261736869812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17967655261357626,
      "backward_entropy": 0.04946401119232178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5165390968322754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022559218108654022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17960649728775024,
      "backward_entropy": 0.04740457534790039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.418354034423828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022625192999839783,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1795367399851481,
      "backward_entropy": 0.04823403358459473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5278210639953613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022690454497933388,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1794669230779012,
      "backward_entropy": 0.04387345910072327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.286508321762085,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022755390033125877,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1794001261393229,
      "backward_entropy": 0.04332229793071747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0720937252044678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022819599136710167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17933493852615356,
      "backward_entropy": 0.046434426307678224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.361351251602173,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02288290672004223,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17927459875742593,
      "backward_entropy": 0.04224381148815155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1869120597839355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02294573001563549,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17921183506647745,
      "backward_entropy": 0.045266848802566526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.846853256225586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023007871583104134,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17914817730585733,
      "backward_entropy": 0.044694569706916806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.070111036300659,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02306886948645115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1790862480799357,
      "backward_entropy": 0.042845115065574646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.299144983291626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02312934212386608,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1790276567141215,
      "backward_entropy": 0.04357843101024628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.294625759124756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023189576342701912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17896477381388345,
      "backward_entropy": 0.04178100824356079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5803518295288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023249629884958267,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17889827489852905,
      "backward_entropy": 0.03917074203491211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9688453674316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023308424279093742,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17883741855621338,
      "backward_entropy": 0.03868301212787628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3197271823883057,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023366689682006836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1787754694620768,
      "backward_entropy": 0.04141315221786499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8863544464111328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02342347800731659,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17872210343678793,
      "backward_entropy": 0.039734748005867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.405492901802063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023479823023080826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.178666889667511,
      "backward_entropy": 0.03924669027328491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8070436716079712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023535050451755524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17861835161844888,
      "backward_entropy": 0.038771864771842954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.164215564727783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023589877411723137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17856740951538086,
      "backward_entropy": 0.038300687074661256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9401013851165771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023645032197237015,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1785105268160502,
      "backward_entropy": 0.03591687679290771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.378374695777893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023699967190623283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17844653129577637,
      "backward_entropy": 0.03735226690769196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7208093404769897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023753885179758072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17838815848032633,
      "backward_entropy": 0.0368905246257782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8841934204101562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023807484656572342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1783286134401957,
      "backward_entropy": 0.03643256425857544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6102209091186523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023861026391386986,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1782626509666443,
      "backward_entropy": 0.0341822475194931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8010854721069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02391408011317253,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17819571495056152,
      "backward_entropy": 0.03376169502735138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.284604787826538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023967012763023376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17812289794286093,
      "backward_entropy": 0.03507002294063568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4381790161132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02401876263320446,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17804940541585287,
      "backward_entropy": 0.03293678760528564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1569057703018188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02406984753906727,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17797474066416422,
      "backward_entropy": 0.03253571689128876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3746259212493896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02411980926990509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17790367205937704,
      "backward_entropy": 0.033773300051689145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1320297718048096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024169081822037697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17782862981160483,
      "backward_entropy": 0.03335704803466797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.425559163093567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024217303842306137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17775489886601767,
      "backward_entropy": 0.03295123875141144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.156940221786499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024265171959996223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17767616113026938,
      "backward_entropy": 0.03254818916320801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.501286506652832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02431228570640087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17759990692138672,
      "backward_entropy": 0.03215349912643432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1189936399459839,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024359317496418953,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1775155464808146,
      "backward_entropy": 0.03260561227798462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5621001720428467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024405738338828087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17743690808614096,
      "backward_entropy": 0.03220722675323486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1771681308746338,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024452390149235725,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17734956741333008,
      "backward_entropy": 0.031809759140014646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2617548704147339,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024498458951711655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1772619088490804,
      "backward_entropy": 0.030594825744628906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2158210277557373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024544047191739082,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17716781298319498,
      "backward_entropy": 0.03021113872528076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.132088541984558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024589311331510544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17707276344299316,
      "backward_entropy": 0.029829859733581543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1603868007659912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024634134024381638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1769785483678182,
      "backward_entropy": 0.029453617334365845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7249190211296082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024678507819771767,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17688079675038657,
      "backward_entropy": 0.027888134121894836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0719422101974487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024721430614590645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17678868770599365,
      "backward_entropy": 0.02872338891029358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1113312244415283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02476397342979908,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1766948699951172,
      "backward_entropy": 0.02725956737995148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.818081796169281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024806292727589607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17659801244735718,
      "backward_entropy": 0.028017723560333253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0803484916687012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484789863228798,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17650965849558511,
      "backward_entropy": 0.028494220972061158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.942733883857727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02488926239311695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17641552289326987,
      "backward_entropy": 0.027335149049758912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.048386812210083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024930084124207497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17631928126017252,
      "backward_entropy": 0.027815613150596618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9247072339057922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024970879778265953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.176221231619517,
      "backward_entropy": 0.026666206121444703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8982852101325989,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025011247023940086,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17612202962239584,
      "backward_entropy": 0.025484320521354676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9089341759681702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025051169097423553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17602169513702393,
      "backward_entropy": 0.026012882590293884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0257755517959595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02509055659174919,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17591561873753866,
      "backward_entropy": 0.026505571603775025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5780386328697205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02512991800904274,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17580238978068033,
      "backward_entropy": 0.02618964612483978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8227819800376892,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02516806870698929,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17569684982299805,
      "backward_entropy": 0.02506643533706665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8236032128334045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025205766782164574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17558840910593668,
      "backward_entropy": 0.02476383000612259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6630759835243225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025243004783988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17547514041264853,
      "backward_entropy": 0.02446516752243042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7535334825515747,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025279507040977478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17536485195159912,
      "backward_entropy": 0.024998009204864502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6944957971572876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02531571313738823,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17525496085484824,
      "backward_entropy": 0.023887121677398683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7319725155830383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025351349264383316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.175144096215566,
      "backward_entropy": 0.0244313508272171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7545037865638733,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0253865048289299,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17502832412719727,
      "backward_entropy": 0.022911083698272706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7101364135742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025421498343348503,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17490981022516885,
      "backward_entropy": 0.022678810358047485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5357123613357544,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025456126779317856,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17478787899017334,
      "backward_entropy": 0.023616895079612732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5235885977745056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025490030646324158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17467188835144043,
      "backward_entropy": 0.02251683473587036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5572493076324463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025522911921143532,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17455502351125082,
      "backward_entropy": 0.02310154139995575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5970686078071594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025555066764354706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17443648974100748,
      "backward_entropy": 0.022855450212955476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5574601292610168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02558683417737484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17431612809499106,
      "backward_entropy": 0.021766906976699828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5525960326194763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02561819739639759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17419620354970297,
      "backward_entropy": 0.021525660157203676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.520235002040863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025649070739746094,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17407401402791342,
      "backward_entropy": 0.021203136444091795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6154204607009888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025679292157292366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17394874493281046,
      "backward_entropy": 0.02105708122253418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26144659519195557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025709431618452072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17381763458251953,
      "backward_entropy": 0.020826175808906555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4414067268371582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025738094002008438,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17369665702184042,
      "backward_entropy": 0.02064254432916641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43436864018440247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02576601877808571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17357351382573447,
      "backward_entropy": 0.02039674073457718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4576619267463684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02579330839216709,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17344888051350912,
      "backward_entropy": 0.02030019462108612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42501693964004517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025820212438702583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17332220077514648,
      "backward_entropy": 0.02086559236049652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4351423680782318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02584671974182129,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17319607734680176,
      "backward_entropy": 0.02066972553730011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4263591766357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02587290108203888,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.173068900903066,
      "backward_entropy": 0.01981300413608551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38975533843040466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02589881606400013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17294122775395712,
      "backward_entropy": 0.01939571350812912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2740023732185364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0259240735322237,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17281007766723633,
      "backward_entropy": 0.019206303358078002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3920122981071472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025948092341423035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17267998059590658,
      "backward_entropy": 0.019026340544223787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5020096898078918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025971705093979836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1725455125172933,
      "backward_entropy": 0.019756035506725313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29565054178237915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025995653122663498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17240206400553384,
      "backward_entropy": 0.019584174454212188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3282151520252228,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026018960401415825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1722626487414042,
      "backward_entropy": 0.01941675543785095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26769161224365234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026041872799396515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17212438583374023,
      "backward_entropy": 0.01925235688686371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32871896028518677,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0260639525949955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17198801040649414,
      "backward_entropy": 0.018682971596717834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33598312735557556,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02608581818640232,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17185145616531372,
      "backward_entropy": 0.018937687575817107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31558722257614136,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02610752359032631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17171327273050943,
      "backward_entropy": 0.017838703095912935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36290574073791504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02612876333296299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17157133420308432,
      "backward_entropy": 0.017681892216205596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30408868193626404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026149965822696686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17142373323440552,
      "backward_entropy": 0.017524924874305726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2233850657939911,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026170950382947922,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17127585411071777,
      "backward_entropy": 0.018335869908332823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21950331330299377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026191139593720436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17113093535105386,
      "backward_entropy": 0.018194128572940827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24081458151340485,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026210712268948555,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17098987102508545,
      "backward_entropy": 0.01785189062356949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23201248049736023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02622976526618004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17084880669911703,
      "backward_entropy": 0.01693853884935379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32988280057907104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026248246431350708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17070714632670084,
      "backward_entropy": 0.0168032631278038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2595836818218231,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026267055422067642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.170558492342631,
      "backward_entropy": 0.01666560173034668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21238422393798828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02628551609814167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17040632168451944,
      "backward_entropy": 0.016530312597751617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2047557681798935,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026303492486476898,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17025564114252725,
      "backward_entropy": 0.017347486317157747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22245267033576965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026320932433009148,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17010573546091715,
      "backward_entropy": 0.01627158373594284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27730217576026917,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026337923482060432,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16995364427566528,
      "backward_entropy": 0.017164844274520873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2207673341035843,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026355119422078133,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16979591051737467,
      "backward_entropy": 0.017073777318000794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1679397076368332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637207880616188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16963674624760947,
      "backward_entropy": 0.015897133946418764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2276974618434906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026388343423604965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16947988669077554,
      "backward_entropy": 0.015778258442878723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19858744740486145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026404643431305885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16931994756062826,
      "backward_entropy": 0.0167062908411026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20162086188793182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026420876383781433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1691588560740153,
      "backward_entropy": 0.015541496872901916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16589781641960144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02643701247870922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16899597644805908,
      "backward_entropy": 0.01542474925518036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1425374448299408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02645265869796276,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16883379220962524,
      "backward_entropy": 0.016564494371414183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19822092354297638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02646752819418907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16867331663767496,
      "backward_entropy": 0.01520405113697052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14993341267108917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026482507586479187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16851019859313965,
      "backward_entropy": 0.015095579624176025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13707491755485535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02649695985019207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16834741830825806,
      "backward_entropy": 0.014990960061550141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14456644654273987,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02651078812777996,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1681856314341227,
      "backward_entropy": 0.016270199418067934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10550849139690399,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02652449533343315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16802610953648886,
      "backward_entropy": 0.01588355451822281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13009653985500336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026537371799349785,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1678703228632609,
      "backward_entropy": 0.016138797998428343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07724828273057938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026549873873591423,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16771509250005087,
      "backward_entropy": 0.014607806503772736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11988085508346558,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026561453938484192,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16756689548492432,
      "backward_entropy": 0.016023734211921693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16086804866790771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026572851464152336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16742022832234701,
      "backward_entropy": 0.014441055059432984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12727360427379608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026584604755043983,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16726903120676676,
      "backward_entropy": 0.014355947077274323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11026657372713089,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026596104726195335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1671159267425537,
      "backward_entropy": 0.014272376894950867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12895061075687408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026607243344187737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1669633388519287,
      "backward_entropy": 0.014190702140331269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10183852165937424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02661835215985775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1668082078297933,
      "backward_entropy": 0.015237322449684143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09263022243976593,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026629144325852394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16665450731913248,
      "backward_entropy": 0.01516357958316803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09195935726165771,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026639578863978386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16650323073069254,
      "backward_entropy": 0.015092119574546814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1023855060338974,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026649562641978264,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16635300715764365,
      "backward_entropy": 0.015608878433704376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07462532818317413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026659373193979263,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.166201780239741,
      "backward_entropy": 0.014956334233283996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09917914867401123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02666870877146721,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16605448722839355,
      "backward_entropy": 0.014892029762268066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06858281046152115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026677990332245827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16590606172879538,
      "backward_entropy": 0.01366630345582962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06882172077894211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026686862111091614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16576196750005087,
      "backward_entropy": 0.014767253398895263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06654567271471024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026695692911744118,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16562304894129434,
      "backward_entropy": 0.013534238934516907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06660004705190659,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670382894575596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1654854714870453,
      "backward_entropy": 0.01347307562828064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07389961928129196,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026711856946349144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16535104314486185,
      "backward_entropy": 0.01459408551454544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07174103707075119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02671961858868599,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16521609822909036,
      "backward_entropy": 0.013354617357254028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060914572328329086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02672693505883217,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650798718134562,
      "backward_entropy": 0.014488981664180755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05242466554045677,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026733607053756714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16494409243265787,
      "backward_entropy": 0.013247029483318329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06517194956541061,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026739925146102905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16481180985768637,
      "backward_entropy": 0.013197648525238036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07220923900604248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02674608677625656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1646791696548462,
      "backward_entropy": 0.014352542161941529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061231810599565506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026752270758152008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16454430421193442,
      "backward_entropy": 0.013100729882717132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05553087592124939,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026758285239338875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16440969705581665,
      "backward_entropy": 0.013053235411643983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05880574509501457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02676396258175373,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16427587469418845,
      "backward_entropy": 0.015130746364593505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05914188548922539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026769451797008514,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1641417940457662,
      "backward_entropy": 0.01511169821023941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05140075832605362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026774974539875984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16400774319966635,
      "backward_entropy": 0.012918901443481446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05253732576966286,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02678043395280838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16387540102005005,
      "backward_entropy": 0.015072499215602875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04644790291786194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02678586170077324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1637438933054606,
      "backward_entropy": 0.012831324338912964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04902159422636032,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026791006326675415,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16361363728841147,
      "backward_entropy": 0.015034805238246917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042529862374067307,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0267960038036108,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16348359982172647,
      "backward_entropy": 0.01399659514427185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038697149604558945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02680090256035328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1633557677268982,
      "backward_entropy": 0.015000584721565246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0422399640083313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026805546134710312,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1632303794225057,
      "backward_entropy": 0.01392800360918045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03637932986021042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680978924036026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16310497124989828,
      "backward_entropy": 0.01263538897037506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05276690796017647,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026813825592398643,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1629818876584371,
      "backward_entropy": 0.013867023587226867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034186530858278275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02681807614862919,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1628556251525879,
      "backward_entropy": 0.012565548717975616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03994898870587349,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026822105050086975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16273203492164612,
      "backward_entropy": 0.013806670904159546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03803557902574539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02682633139193058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16260963678359985,
      "backward_entropy": 0.013776242733001709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03618789464235306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026830431073904037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16248762607574463,
      "backward_entropy": 0.012462294101715088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034856051206588745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683422714471817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16236579418182373,
      "backward_entropy": 0.01371885985136032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03401418775320053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026837851852178574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16224461793899536,
      "backward_entropy": 0.012398479133844375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030986705794930458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026841210201382637,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16212350130081177,
      "backward_entropy": 0.012368746101856232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03070731647312641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026844395324587822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16200372576713562,
      "backward_entropy": 0.012340144068002701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026253074407577515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026847489178180695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16188506285349527,
      "backward_entropy": 0.01231224536895752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03131839260458946,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02685053087770939,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617694099744161,
      "backward_entropy": 0.013596387207508087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024598747491836548,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02685374766588211,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16165451208750406,
      "backward_entropy": 0.013572500646114349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027261028066277504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026856889948248863,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1615422467390696,
      "backward_entropy": 0.014840805530548095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023692965507507324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026860082522034645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16143113374710083,
      "backward_entropy": 0.01220168024301529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032049257308244705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02686299942433834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1613216002782186,
      "backward_entropy": 0.012175875157117844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02076784335076809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026865966618061066,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16121002038319907,
      "backward_entropy": 0.014816784858703613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027034204453229904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02686889097094536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16110172867774963,
      "backward_entropy": 0.012123902887105941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024174541234970093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026871733367443085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16099258263905844,
      "backward_entropy": 0.013438776135444641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02262616530060768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026874497532844543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16088382403055826,
      "backward_entropy": 0.01207399070262909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025986412540078163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02687721699476242,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1607762078444163,
      "backward_entropy": 0.012049680948257447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018981782719492912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026879943907260895,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16066759824752808,
      "backward_entropy": 0.013377565145492553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017679214477539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026882564648985863,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1605613629023234,
      "backward_entropy": 0.014774736762046815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02314377762377262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02688497118651867,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16045733292897543,
      "backward_entropy": 0.014769594371318816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020129425451159477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02688734233379364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035223007202148,
      "backward_entropy": 0.011957530677318574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017807897180318832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02688957005739212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16024734576543173,
      "backward_entropy": 0.011936412751674652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019906798377633095,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026891805231571198,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16014432907104492,
      "backward_entropy": 0.014756233990192413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0159992016851902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026894116774201393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004159053166708,
      "backward_entropy": 0.011894096434116364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01817680336534977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026896445080637932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15994115670522055,
      "backward_entropy": 0.013252384960651398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017899040132761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026898594573140144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15984048446019491,
      "backward_entropy": 0.011852671205997468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014862453565001488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02690081112086773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15974008043607077,
      "backward_entropy": 0.011832170188426971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01361392904073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026902835816144943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15964106718699136,
      "backward_entropy": 0.011812907457351685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014736147597432137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02690466307103634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1595439910888672,
      "backward_entropy": 0.011794932186603546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01705661602318287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02690623514354229,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15944741169611612,
      "backward_entropy": 0.011778434365987777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012436185963451862,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02690783515572548,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15935004750887552,
      "backward_entropy": 0.01316300332546234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012223293073475361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026909325271844864,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15925473968187967,
      "backward_entropy": 0.01472814679145813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012833354994654655,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026910925284028053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15916182597478232,
      "backward_entropy": 0.013137529790401458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012706835754215717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02691245824098587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1590698560078939,
      "backward_entropy": 0.011713492125272751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012957179918885231,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026914017274975777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1589787801106771,
      "backward_entropy": 0.011697600781917571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013239869847893715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02691550739109516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15888777375221252,
      "backward_entropy": 0.011682119220495224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011111969128251076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026917148381471634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1587968866030375,
      "backward_entropy": 0.011665843427181244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009156739339232445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02691871114075184,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1587071418762207,
      "backward_entropy": 0.014718642830848694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01045779325067997,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026920143514871597,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15861980120340982,
      "backward_entropy": 0.014717452228069305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01106211543083191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026921555399894714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15853357315063477,
      "backward_entropy": 0.01162087470293045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008917635306715965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026923129335045815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15844805041948953,
      "backward_entropy": 0.01160547062754631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010138885118067265,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02692480757832527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15836486220359802,
      "backward_entropy": 0.01158965602517128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007828655652701855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0269264318048954,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.158281942208608,
      "backward_entropy": 0.01470687985420227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007555712014436722,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02692812867462635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15820151567459106,
      "backward_entropy": 0.013001206517219543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007193997967988253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02692975103855133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15812305609385172,
      "backward_entropy": 0.011543615907430648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008201112039387226,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026931267231702805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15804646412531534,
      "backward_entropy": 0.01152934730052948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008223789744079113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026932645589113235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15797017018000284,
      "backward_entropy": 0.011515870690345764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007624148856848478,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02693404071033001,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15789430340131125,
      "backward_entropy": 0.01469154804944992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007627927232533693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026935307309031487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1578188439210256,
      "backward_entropy": 0.012945108115673065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007020093500614166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026936596259474754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15774405002593994,
      "backward_entropy": 0.012934821844100951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006195276044309139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02693788707256317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15767026940981546,
      "backward_entropy": 0.01146416962146759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006146626081317663,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0269390270113945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1575977603594462,
      "backward_entropy": 0.014685326814651489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006150410044938326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026940131559967995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15752655267715454,
      "backward_entropy": 0.011440892517566682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00569802476093173,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02694147825241089,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15745709339777628,
      "backward_entropy": 0.01468166708946228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005337481386959553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026942765340209007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.157388836145401,
      "backward_entropy": 0.011415906250476837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005121448542922735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026943901553750038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15732168157895407,
      "backward_entropy": 0.011404573172330856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005486523266881704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026945043355226517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15725594758987427,
      "backward_entropy": 0.011393336951732636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004979119636118412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026946106925606728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571905811627706,
      "backward_entropy": 0.011382554471492768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00475138146430254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02694719284772873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712631742159525,
      "backward_entropy": 0.011371766775846481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004862342029809952,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026948265731334686,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1570631464322408,
      "backward_entropy": 0.014671708643436431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0039827353321015835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02694939635694027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15700074036916098,
      "backward_entropy": 0.011350293457508088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004191262181848288,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026950480416417122,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15694006284077963,
      "backward_entropy": 0.014667806029319764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038515932392328978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02695167250931263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15688082575798035,
      "backward_entropy": 0.011328878998756408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035511718597263098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026952793821692467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15682282050450644,
      "backward_entropy": 0.011318407952785492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00405068788677454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026953864842653275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15676628549893698,
      "backward_entropy": 0.012798221409320831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033550355583429337,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026954855769872665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15671002864837646,
      "backward_entropy": 0.012790247797966003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003102715825662017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02695588394999504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15665521224339804,
      "backward_entropy": 0.01128898411989212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035842580255120993,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026956982910633087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15660207470258078,
      "backward_entropy": 0.012773655354976654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037955541629344225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02695794589817524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15654900670051575,
      "backward_entropy": 0.012765946984291076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003365107113495469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026958882808685303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15649566054344177,
      "backward_entropy": 0.011260805279016494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003545233514159918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026959771290421486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15644269188245138,
      "backward_entropy": 0.012751144170761109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035007710102945566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02696070820093155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15638979276021323,
      "backward_entropy": 0.01124306619167328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003350393148139119,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02696162648499012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15633667508761087,
      "backward_entropy": 0.012736420333385467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003317193826660514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02696250192821026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15628347794214884,
      "backward_entropy": 0.011225469410419464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028446330688893795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026963302865624428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15622998277346292,
      "backward_entropy": 0.0112171471118927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002452742774039507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026964029297232628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1561769445737203,
      "backward_entropy": 0.011209306120872498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028155266772955656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026964833959937096,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15612532695134482,
      "backward_entropy": 0.012710055708885193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022255810908973217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026965560391545296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15607371926307678,
      "backward_entropy": 0.011193481087684632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022317441180348396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269662756472826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15602346261342367,
      "backward_entropy": 0.011185945570468902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023097246885299683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026967009529471397,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15597434838612875,
      "backward_entropy": 0.011178357154130935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018598419846966863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026967734098434448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15592586000760397,
      "backward_entropy": 0.014639979600906372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018714889883995056,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026968397200107574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1558788021405538,
      "backward_entropy": 0.012680217623710632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019571564625948668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026969050988554955,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15583289662996927,
      "backward_entropy": 0.012674635648727417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017214042600244284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026969749480485916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15578778584798178,
      "backward_entropy": 0.011149901896715164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020593826193362474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02697046846151352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1557439168294271,
      "backward_entropy": 0.01114281415939331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001576172886416316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026971053332090378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1556997001171112,
      "backward_entropy": 0.011136447638273239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017636504489928484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026971666142344475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15565675497055054,
      "backward_entropy": 0.011129999905824662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001316832727752626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026972247287631035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15561415751775107,
      "backward_entropy": 0.011123768985271454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015553348930552602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02697283960878849,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15557312965393066,
      "backward_entropy": 0.014635731279850007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001317218178883195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026973409578204155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15553257862726846,
      "backward_entropy": 0.011111553758382797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011563856387510896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02697395533323288,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15549304087956747,
      "backward_entropy": 0.014635050296783447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001207076944410801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026974577456712723,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15545503298441568,
      "backward_entropy": 0.014634063839912415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011056811781600118,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026975184679031372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15541801850001016,
      "backward_entropy": 0.011093695461750031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011532626813277602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026975784450769424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15538211663564047,
      "backward_entropy": 0.0126181960105896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001100083696655929,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02697637490928173,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.155346949895223,
      "backward_entropy": 0.012613414227962494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000795130617916584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026977013796567917,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15531260768572488,
      "backward_entropy": 0.014629863202571869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001015480374917388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026977645233273506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15527994434038797,
      "backward_entropy": 0.011070401221513749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009297403739765286,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026978231966495514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15524773796399435,
      "backward_entropy": 0.011064902693033219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009274616022594273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02697880007326603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.155216246843338,
      "backward_entropy": 0.011059547960758209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008879810920916498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269793551415205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15518526236216226,
      "backward_entropy": 0.011054304987192154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009471068042330444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026979897171258926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15515479445457458,
      "backward_entropy": 0.011049194633960724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007776948041282594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026980454102158546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15512446562449136,
      "backward_entropy": 0.012580773234367371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008264441858045757,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02698100358247757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15509489178657532,
      "backward_entropy": 0.012576405704021455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008015470230020583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02698158286511898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1550657351811727,
      "backward_entropy": 0.011033713072538375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006745648570358753,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026982150971889496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1550368865331014,
      "backward_entropy": 0.011028598994016647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007010823464952409,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026982717216014862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15500885248184204,
      "backward_entropy": 0.011023526638746261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006991822156123817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026983216404914856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15498122572898865,
      "backward_entropy": 0.011018837243318558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007021888741292059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026983706280589104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15495393673578897,
      "backward_entropy": 0.011014226078987121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005440050736069679,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026984170079231262,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1549267371495565,
      "backward_entropy": 0.01255144327878952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000504758907482028,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026984622702002525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15490041176478067,
      "backward_entropy": 0.011005453020334243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005758363986387849,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02698504738509655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15487496058146158,
      "backward_entropy": 0.011001338064670563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005487074959091842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026985477656126022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15484983722368875,
      "backward_entropy": 0.010997240245342255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047123085823841393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026985876262187958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15482505162556967,
      "backward_entropy": 0.01099332720041275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037081207847222686,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026986269280314445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15480093161265054,
      "backward_entropy": 0.012534101307392121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032642344012856483,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026986662298440933,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15477797389030457,
      "backward_entropy": 0.014610402286052704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004114992916584015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026987068355083466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1547562082608541,
      "backward_entropy": 0.010981981456279755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038534426130354404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026987465098500252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15473496913909912,
      "backward_entropy": 0.010978315770626069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003629555576480925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026987839490175247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15471422672271729,
      "backward_entropy": 0.01097482442855835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039238762110471725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026988202705979347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15469402074813843,
      "backward_entropy": 0.012518191337585449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003815360541921109,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026988554745912552,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15467401345570883,
      "backward_entropy": 0.01096806228160858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004416833689901978,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026988886296749115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15465417504310608,
      "backward_entropy": 0.012512460350990295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002416525239823386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02698918990790844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.154634028673172,
      "backward_entropy": 0.010961794853210449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003338731767144054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026989499107003212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1546149750550588,
      "backward_entropy": 0.01095876470208168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003334140928927809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02698979154229164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1545961300532023,
      "backward_entropy": 0.012504595518112182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002560072171036154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026990080252289772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15457739432652792,
      "backward_entropy": 0.010952949523925781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027162913465872407,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026990357786417007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1545593043168386,
      "backward_entropy": 0.010950148105621338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028201230452395976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026990633457899094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1545415719350179,
      "backward_entropy": 0.010947398096323013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023429907741956413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026990903541445732,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15452400843302408,
      "backward_entropy": 0.010944691300392152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021384646242950112,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699117362499237,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15450691183408102,
      "backward_entropy": 0.010942019522190094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022797084238845855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026991432532668114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15449042121569315,
      "backward_entropy": 0.01093944013118744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025040324544534087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026991697028279305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15447421868642172,
      "backward_entropy": 0.010936857759952545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024853236391209066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026991933584213257,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15445807576179504,
      "backward_entropy": 0.014603161811828613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021986024512443691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02699216455221176,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15444188316663107,
      "backward_entropy": 0.01460302472114563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001989645097637549,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026992391794919968,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15442585945129395,
      "backward_entropy": 0.010929681360721588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020326045341789722,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026992619037628174,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1544100840886434,
      "backward_entropy": 0.014602714776992798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018051695951726288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699282020330429,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15439451734224954,
      "backward_entropy": 0.0109251469373703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001339876325801015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026993023231625557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15437923868497214,
      "backward_entropy": 0.01247609406709671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018563079356681556,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026993228122591972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15436468521753946,
      "backward_entropy": 0.010920846462249756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016029200924094766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026993388310074806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1543502906958262,
      "backward_entropy": 0.010918977111577988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013248009781818837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699354663491249,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15433613459269205,
      "backward_entropy": 0.010917115211486816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001420927728759125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699369564652443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15432250499725342,
      "backward_entropy": 0.010915365070104599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001349344092886895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026993820443749428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15430923302968344,
      "backward_entropy": 0.010913721472024917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013559911167249084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026993950828909874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15429621934890747,
      "backward_entropy": 0.012466681003570557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010299160931026563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699408307671547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15428333481152853,
      "backward_entropy": 0.010910451412200928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010384408960817382,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026994211599230766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15427104632059732,
      "backward_entropy": 0.012463920563459397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011691025429172441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699435129761696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15425912539164224,
      "backward_entropy": 0.012462498247623443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012408787733875215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0269944965839386,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15424728393554688,
      "backward_entropy": 0.014604857563972473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.601289639249444e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026994621381163597,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15423548221588135,
      "backward_entropy": 0.010904140025377273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86200214154087e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026994740590453148,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15422403812408447,
      "backward_entropy": 0.010902659595012664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.857290569925681e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026994861662387848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15421297152837118,
      "backward_entropy": 0.010901232808828354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.949144103098661e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026994982734322548,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1542020042737325,
      "backward_entropy": 0.012455970048904419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.602373807458207e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269951019436121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.154191255569458,
      "backward_entropy": 0.010898387432098389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.78437388362363e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026995226740837097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1541808545589447,
      "backward_entropy": 0.010896974056959153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9387588407844305e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699534222483635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15417074163754782,
      "backward_entropy": 0.010895628482103348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.160653720144182e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269954614341259,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15416115522384644,
      "backward_entropy": 0.010894295573234559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.158583321142942e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026995588093996048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15415191650390625,
      "backward_entropy": 0.010892973840236663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.364845467032865e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026995711028575897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15414277712504068,
      "backward_entropy": 0.01089162677526474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.936894012847915e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026995819061994553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15413393576939902,
      "backward_entropy": 0.010890425741672516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.720428453059867e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026995932683348656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15412529309590658,
      "backward_entropy": 0.012446454167366028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8627487558405846e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699604630470276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15411684910456339,
      "backward_entropy": 0.012445323169231415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.770744271809235e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026996169239282608,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15410866340001425,
      "backward_entropy": 0.01244417279958725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.438249743543565e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026996292173862457,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15410077571868896,
      "backward_entropy": 0.012443017959594727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.609353709383868e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026996413245797157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15409318606058756,
      "backward_entropy": 0.010884311795234681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.671150989248417e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026996532455086708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15408583482106528,
      "backward_entropy": 0.01088312566280365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7585759855574e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699665166437626,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15407881140708923,
      "backward_entropy": 0.012439686805009842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.676194683066569e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026996763423085213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15407212575276694,
      "backward_entropy": 0.01243860125541687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.504095730022527e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699686959385872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1540657381216685,
      "backward_entropy": 0.010879838466644287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.273646143497899e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026996973901987076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15405954917271933,
      "backward_entropy": 0.010878822207450867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.841931538772769e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026997076347470284,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1540535887082418,
      "backward_entropy": 0.014606019854545594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.81873978767544e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026997175067663193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1540476381778717,
      "backward_entropy": 0.010876862704753876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2638225093251094e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026997266337275505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15404165784517923,
      "backward_entropy": 0.010875927656888962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.261283927713521e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699735015630722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1540358066558838,
      "backward_entropy": 0.010875048488378525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6326646548113786e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699742652475834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15403010447820029,
      "backward_entropy": 0.010874244570732116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2577656384091824e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699749916791916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15402464071909586,
      "backward_entropy": 0.01087343841791153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7611282348516397e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026997562497854233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1540191968282064,
      "backward_entropy": 0.010872716456651688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5488862118218094e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026997622102499008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15401387214660645,
      "backward_entropy": 0.010871980339288712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.63737983914325e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699769102036953,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15400895476341248,
      "backward_entropy": 0.01242898404598236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6340698241256177e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026997752487659454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15400408705075583,
      "backward_entropy": 0.010870567709207534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3666565539315343e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699780836701393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1539992094039917,
      "backward_entropy": 0.010869898647069932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.976044222828932e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699786238372326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15399440129597983,
      "backward_entropy": 0.010869246721267701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0493511328822933e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026997918263077736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15398969252904257,
      "backward_entropy": 0.010868579149246216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5802170310053043e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026997974142432213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1539850433667501,
      "backward_entropy": 0.01086796298623085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.657912798691541e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699803002178669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15398062268892923,
      "backward_entropy": 0.012425006181001664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.887976577563677e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026998085901141167,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15397639075915018,
      "backward_entropy": 0.014607562124729157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9175549823557958e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026998136192560196,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1539722184340159,
      "backward_entropy": 0.014607706665992736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0731018846854568e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998179033398628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1539680858453115,
      "backward_entropy": 0.010865569114685059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.708798299659975e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998231187462807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1539641817410787,
      "backward_entropy": 0.0108649842441082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.753974356688559e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998277753591537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15396026770273843,
      "backward_entropy": 0.010864441096782685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4783976439503022e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998315006494522,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15395638346672058,
      "backward_entropy": 0.010863958299160004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5235230421239976e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998350396752357,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15395253896713257,
      "backward_entropy": 0.010863463580608367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0984654181811493e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998380199074745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1539487342039744,
      "backward_entropy": 0.010863035172224044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0606303476379253e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699841372668743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1539450486501058,
      "backward_entropy": 0.010862582921981811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.126809547713492e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026998450979590416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15394147237141928,
      "backward_entropy": 0.012419662624597549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2621685527847148e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699848636984825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15393799543380737,
      "backward_entropy": 0.010861677676439285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.520515959593467e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699851617217064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15393455823262533,
      "backward_entropy": 0.0108612559735775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3895223673898727e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998547837138176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15393126010894775,
      "backward_entropy": 0.010860833525657653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.837633115239441e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998568326234818,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15392792224884033,
      "backward_entropy": 0.010860484093427658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.797209946147632e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699858695268631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15392465392748514,
      "backward_entropy": 0.010860156267881393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0093133217596915e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269986093044281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15392150481541952,
      "backward_entropy": 0.010859781503677368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.386552169919014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699863724410534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15391848484675089,
      "backward_entropy": 0.010859418660402298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.112575531209586e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026998665183782578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15391558408737183,
      "backward_entropy": 0.012416473031044007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.605965376773383e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026998693123459816,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15391280253728232,
      "backward_entropy": 0.012416081875562668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.522322109958623e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998717337846756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15391001105308533,
      "backward_entropy": 0.010858333110809327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.560031579283532e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026998743414878845,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15390732884407043,
      "backward_entropy": 0.01461101919412613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.364417342614615e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026998767629265785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1539047360420227,
      "backward_entropy": 0.012415015697479248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.634768513118615e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998788118362427,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15390220284461975,
      "backward_entropy": 0.010857363790273666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.844672275794437e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026998810470104218,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15389972925186157,
      "backward_entropy": 0.01241433471441269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.948055331828073e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026998834684491158,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15389742453893027,
      "backward_entropy": 0.012414003908634185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.325819190853508e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699885703623295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538950800895691,
      "backward_entropy": 0.010856473445892334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.644087766791927e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998883113265038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15389281511306763,
      "backward_entropy": 0.010856163501739503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756556336360518e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998909190297127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15389062960942587,
      "backward_entropy": 0.010855849087238311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.927735178876901e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026998933404684067,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15388846397399902,
      "backward_entropy": 0.01461205780506134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.403556315286551e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998959481716156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15388637781143188,
      "backward_entropy": 0.010855243355035783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.67850577479112e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026998979970812798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538843313852946,
      "backward_entropy": 0.010854983329772949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.596769374780706e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699899859726429,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15388228495915732,
      "backward_entropy": 0.012411804497241974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.007690000027651e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999017223715782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15388033787409464,
      "backward_entropy": 0.010854486376047134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5667483189172344e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999041438102722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15387850999832153,
      "backward_entropy": 0.010854220390319825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9203961275925394e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999065652489662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15387670199076334,
      "backward_entropy": 0.012410917133092881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9412051389954286e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999089866876602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15387498339017233,
      "backward_entropy": 0.010853681713342667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3254675599891925e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999114081263542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15387340386708578,
      "backward_entropy": 0.010853438824415206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9358525353018194e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999136433005333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15387181440989176,
      "backward_entropy": 0.010853179544210435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.842730737029342e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999156922101974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15387029449144998,
      "backward_entropy": 0.010852950811386108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6710509903059574e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999175548553467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15386876463890076,
      "backward_entropy": 0.01085273027420044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.370353058722685e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699919044971466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15386720498402914,
      "backward_entropy": 0.010852528363466262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7296669057031977e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999205350875854,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15386574467023215,
      "backward_entropy": 0.014613085985183715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.344879021620727e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999222114682198,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15386434396107992,
      "backward_entropy": 0.010852155834436416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7338905990982312e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699923701584339,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.153862992922465,
      "backward_entropy": 0.01240861862897873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.29385068450938e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999253779649734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15386171142260233,
      "backward_entropy": 0.010851768404245376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1934297365078237e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699926868081093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538604497909546,
      "backward_entropy": 0.010851605236530304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.39219866671192e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999281719326973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538592278957367,
      "backward_entropy": 0.01085142269730568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5773914583405713e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699929289519787,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538579761981964,
      "backward_entropy": 0.010851279646158219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9114706901746104e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999304071068764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15385684370994568,
      "backward_entropy": 0.010851110517978668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.946222027982003e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699931338429451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1538557012875875,
      "backward_entropy": 0.012407410144805908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1090258996991906e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999320834875107,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15385454893112183,
      "backward_entropy": 0.010850837826728821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5281568721547956e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999326422810555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15385335683822632,
      "backward_entropy": 0.010850727558135986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9064389107370516e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999332010746002,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15385217467943826,
      "backward_entropy": 0.014614123106002807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.609805622138083e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699933387339115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15385099252065024,
      "backward_entropy": 0.012406808137893677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2233900861247093e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269993357360363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15384982029596964,
      "backward_entropy": 0.01085040122270584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3584134421762428e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699933759868145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15384872754414877,
      "backward_entropy": 0.012406570464372635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.364389618174755e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0269993394613266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15384764472643533,
      "backward_entropy": 0.012406431138515472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.211523908750678e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269993394613266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15384657184282938,
      "backward_entropy": 0.010850109159946442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1679778708639788e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0269993394613266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15384548902511597,
      "backward_entropy": 0.012406205385923385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.050670317061304e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269993394613266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15384446581204733,
      "backward_entropy": 0.010849930346012115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.226975640151068e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699934132397175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15384350220362344,
      "backward_entropy": 0.010849860310554505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0666728940122994e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999346911907196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15384264787038168,
      "backward_entropy": 0.012405867129564286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.797554187367496e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999350637197495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15384181340535483,
      "backward_entropy": 0.012405757606029511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621006486464466e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999354362487793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15384097894032797,
      "backward_entropy": 0.010849577188491822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0884281209655455e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02699935808777809,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15384018421173096,
      "backward_entropy": 0.014615634083747863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.355495543175493e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02699935995042324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15383938948313394,
      "backward_entropy": 0.014615735411643982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.692839065181033e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699936181306839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15383861462275186,
      "backward_entropy": 0.010849349200725555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.997121424021316e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699936553835869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15383783976236978,
      "backward_entropy": 0.010849259048700332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.499782898572448e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699936553835869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15383708477020264,
      "backward_entropy": 0.010849212110042573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.23438722868741e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699936553835869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538363297780355,
      "backward_entropy": 0.010849135369062424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.166679895613925e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999367401003838,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538356045881907,
      "backward_entropy": 0.010849063843488693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.147262527316343e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999367401003838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15383487939834595,
      "backward_entropy": 0.012404847145080566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.001784302294254e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999369263648987,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15383418401082358,
      "backward_entropy": 0.014616438746452331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.807209847967897e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999371126294136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538335680961609,
      "backward_entropy": 0.01084890142083168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.217583580157225e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999374851584435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538329819838206,
      "backward_entropy": 0.010848824679851533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.008620066997537e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999378576874733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15383243560791016,
      "backward_entropy": 0.010848748683929443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.142069881003408e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699938416481018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15383190910021463,
      "backward_entropy": 0.010848690569400788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.852671000004193e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699938789010048,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1538313627243042,
      "backward_entropy": 0.012404283136129379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.948522705992218e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999391615390778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15383084615071616,
      "backward_entropy": 0.010848568379878997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4306777390847856e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999397203326225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15383036931355795,
      "backward_entropy": 0.01240408793091774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8078263742136187e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999404653906822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382994214693704,
      "backward_entropy": 0.010848409682512283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3402355370526493e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699941024184227,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538295050462087,
      "backward_entropy": 0.010848359763622284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.601925359613233e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999415829777718,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538290778795878,
      "backward_entropy": 0.010848283767700195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.39762357523432e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999421417713165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382870038350424,
      "backward_entropy": 0.01084820032119751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8288852149671584e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999428868293762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382832288742065,
      "backward_entropy": 0.010848143696784973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1358337676247174e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699943631887436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15382798512776694,
      "backward_entropy": 0.012403492629528046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1726474958304607e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999443769454956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538276473681132,
      "backward_entropy": 0.010847987234592437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.971639278508519e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999449357390404,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15382726987202963,
      "backward_entropy": 0.014617133140563964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.259953504335499e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699945494532585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538269023100535,
      "backward_entropy": 0.010847870260477066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7623847270442639e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0269994605332613,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382655461629233,
      "backward_entropy": 0.010847824066877365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2846894864869682e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999466121196747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382621685663858,
      "backward_entropy": 0.010847748070955277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.481685612565343e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999471709132195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538258989651998,
      "backward_entropy": 0.010847708582878113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1556957108259667e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999475434422493,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15382557113965353,
      "backward_entropy": 0.012402894347906113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6789181245258078e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699947915971279,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382526318232217,
      "backward_entropy": 0.010847604274749756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6951382519891922e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699948288500309,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538249353567759,
      "backward_entropy": 0.010847542434930801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9378080651222263e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02699948661029339,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15382464726765951,
      "backward_entropy": 0.014617343246936799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.203132396516594e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999490335583687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1538243293762207,
      "backward_entropy": 0.012402639538049699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5412260268021782e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999492198228836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1538240114847819,
      "backward_entropy": 0.012402570247650147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.683087447190701e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15382371346155801,
      "backward_entropy": 0.014617456495761872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.37732143912217e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999495923519135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382341543833414,
      "backward_entropy": 0.010847365111112594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0796957639058746e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999497786164284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538231372833252,
      "backward_entropy": 0.010847318917512894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8718820734357e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999499648809433,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15382285912831625,
      "backward_entropy": 0.014617584645748138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2956465411662066e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999501511454582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382261077562967,
      "backward_entropy": 0.010847266763448715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.757756203043755e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699950337409973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15382235248883566,
      "backward_entropy": 0.012402267754077911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3291992218000814e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699950523674488,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.153822124004364,
      "backward_entropy": 0.010847193002700806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.313812987291385e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699950709939003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15382190545399985,
      "backward_entropy": 0.012402161955833435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.992351041570146e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02699950896203518,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15382166703542074,
      "backward_entropy": 0.014617729187011718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.798264789471432e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699951082468033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382145841916403,
      "backward_entropy": 0.010847103595733643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6646231522991e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999512687325478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15382126967112222,
      "backward_entropy": 0.012402033805847168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.414541241563711e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999514549970627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15382108092308044,
      "backward_entropy": 0.012401995062828065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1512754127807057e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999516412615776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382089217503866,
      "backward_entropy": 0.010847039520740509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.559540987107539e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15382073322931925,
      "backward_entropy": 0.012401902675628662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0380976078749882e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15382055441538492,
      "backward_entropy": 0.010846982896327972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876003138562737e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1538203557332357,
      "backward_entropy": 0.014617939293384553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.687952484682683e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15382017691930136,
      "backward_entropy": 0.014617986977100372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.923234252553812e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15381999810536703,
      "backward_entropy": 0.01461801677942276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.64318334284053e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1538198192914327,
      "backward_entropy": 0.012401727586984634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.556934385391287e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538196603457133,
      "backward_entropy": 0.010846897959709167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.122731122104597e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15381949146588644,
      "backward_entropy": 0.014618125557899476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.479880016423522e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381935238838196,
      "backward_entropy": 0.010846877098083496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0380260912797894e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381918350855509,
      "backward_entropy": 0.010846863687038421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.602258402679581e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538190245628357,
      "backward_entropy": 0.010846857726573945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.425118297987865e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381890535354614,
      "backward_entropy": 0.010846839845180511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.935063368018746e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999518275260925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15381874640782675,
      "backward_entropy": 0.012401536852121354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5225366562817726e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999516412615776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381858746210733,
      "backward_entropy": 0.010846824944019317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3120252257722314e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999514549970627,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15381842851638794,
      "backward_entropy": 0.014618344604969025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.618431148628588e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999512687325478,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.153818279504776,
      "backward_entropy": 0.010846792161464692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7985318951095906e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699951082468033,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15381813049316406,
      "backward_entropy": 0.01240147352218628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.858889741081839e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699951082468033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381799141565958,
      "backward_entropy": 0.010846778005361556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.215132503622044e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699951082468033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381786227226257,
      "backward_entropy": 0.01084677129983902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.491169664471272e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699950896203518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381771326065063,
      "backward_entropy": 0.010846768319606782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4491016265292274e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699950709939003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15381758411725363,
      "backward_entropy": 0.012401401996612549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6209939935361035e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02699950523674488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15381744503974915,
      "backward_entropy": 0.014618599414825439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3322391129454445e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699950337409973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381731589635214,
      "backward_entropy": 0.010846757888793945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7252630374619002e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999501511454582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381717681884766,
      "backward_entropy": 0.010846754163503647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.06750891354568e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999499648809433,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15381706754366556,
      "backward_entropy": 0.014618697762489318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.037272477968145e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999497786164284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381693840026855,
      "backward_entropy": 0.010846748203039169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9447043086984195e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999495923519135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381683905919394,
      "backward_entropy": 0.010846748203039169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.066007276368964e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538167198499044,
      "backward_entropy": 0.010846741497516632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5622823923422402e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538166105747223,
      "backward_entropy": 0.010846734791994096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6284523002573223e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15381653110186258,
      "backward_entropy": 0.012401281297206879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5060180658110767e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1538164218266805,
      "backward_entropy": 0.0146188423037529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.081711159007682e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381633241971335,
      "backward_entropy": 0.010846717655658722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.402824073044485e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538162628809611,
      "backward_entropy": 0.010846713930368424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9539129425538704e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381616353988647,
      "backward_entropy": 0.010846710950136184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.901593371655963e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999494060873985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381606419881186,
      "backward_entropy": 0.010846707224845886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.627484587326762e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026999492198228836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381598472595215,
      "backward_entropy": 0.010846707224845886,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.949582429640941e-07,
    "avg_log_Z": 0.026999446302652358,
    "success_rate": 1.0,
    "avg_reward": 47.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.17,
      "1": 0.24,
      "2": 0.59
    },
    "avg_forward_entropy": 0.15382812559604644,
    "avg_backward_entropy": 0.011862152300775053,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}