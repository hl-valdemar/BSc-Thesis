{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23066401481628418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23078755537668863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.675724983215332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738960385322571,
      "backward_entropy": 0.23023998737335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671138763427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739132344722748,
      "backward_entropy": 0.23064088821411133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27813720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019999974756501615,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739296555519104,
      "backward_entropy": 0.23061700661977133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.107715606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00029991299379616976,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27394402027130127,
      "backward_entropy": 0.23059185345967612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.80154275894165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00039972877129912376,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27396348118782043,
      "backward_entropy": 0.23056534926096597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.184999465942383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004994107293896377,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739810347557068,
      "backward_entropy": 0.2305376927057902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098929405212402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005991248181089759,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27399876713752747,
      "backward_entropy": 0.23064176241556802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.712141513824463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000698830175679177,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740177512168884,
      "backward_entropy": 0.23047924041748047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.79293966293335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007984091644175351,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27403655648231506,
      "backward_entropy": 0.23058390617370605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.090205192565918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008979324484243989,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740536034107208,
      "backward_entropy": 0.23041596015294394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788662910461426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000997505383566022,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740713953971863,
      "backward_entropy": 0.22985645135243735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.465071678161621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001097027212381363,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274087518453598,
      "backward_entropy": 0.23034516970316568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6187639236450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011967298341915011,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27410462498664856,
      "backward_entropy": 0.23030813535054526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.884613037109375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012962782057002187,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274122029542923,
      "backward_entropy": 0.2304186224937439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.614199638366699,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001396116684190929,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27414029836654663,
      "backward_entropy": 0.22967990239461264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.611845970153809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014957725070416927,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741580605506897,
      "backward_entropy": 0.23018922408421835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.775608062744141,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015952772228047252,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27417534589767456,
      "backward_entropy": 0.23014821608861288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.736318588256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001694738632068038,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27419087290763855,
      "backward_entropy": 0.2302702267964681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.730644226074219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017945027211681008,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742070257663727,
      "backward_entropy": 0.2300641934076945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9773406982421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018941157031804323,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27422410249710083,
      "backward_entropy": 0.22944513956705728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.225268363952637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0019937276374548674,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742408514022827,
      "backward_entropy": 0.22997969388961792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.34519100189209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020930401515215635,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742564082145691,
      "backward_entropy": 0.22934802373250326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.594654083251953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021925470791757107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274272084236145,
      "backward_entropy": 0.22929781675338745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.471734046936035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002291920594871044,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742871046066284,
      "backward_entropy": 0.22924760977427164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.589560508728027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023911616299301386,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742992341518402,
      "backward_entropy": 0.2297975222269694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.128235816955566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024903076700866222,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743111550807953,
      "backward_entropy": 0.22974936167399088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.499786376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025896201841533184,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743220627307892,
      "backward_entropy": 0.2297006050745646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.324480056762695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002688781125470996,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27433332800865173,
      "backward_entropy": 0.22903645038604736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.861892700195312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00278817443177104,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27434495091438293,
      "backward_entropy": 0.2289807399113973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.291475772857666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0028880182653665543,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743558883666992,
      "backward_entropy": 0.22892363866170248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.175427436828613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002987569198012352,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743656635284424,
      "backward_entropy": 0.22965427239735922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3726301193237305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030868467874825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743721902370453,
      "backward_entropy": 0.22959748903910318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.825003623962402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031859525479376316,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27437758445739746,
      "backward_entropy": 0.2293828328450521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.020528793334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032851239666342735,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743816375732422,
      "backward_entropy": 0.2293257713317871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.734485626220703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033844197168946266,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27438589930534363,
      "backward_entropy": 0.2286104361216227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.449033260345459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034837082494050264,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27438950538635254,
      "backward_entropy": 0.22920731703440347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.625380039215088,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0035828729160130024,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27439165115356445,
      "backward_entropy": 0.22846702734629312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9823503494262695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003681532572954893,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743927240371704,
      "backward_entropy": 0.22839184602101645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.091104507446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003780420869588852,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743917405605316,
      "backward_entropy": 0.2290191650390625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720541954040527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0038795277941972017,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743908762931824,
      "backward_entropy": 0.22895284493764242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.16971492767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003978655207902193,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743898332118988,
      "backward_entropy": 0.2290162444114685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.10890007019043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004078025929629803,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27438831329345703,
      "backward_entropy": 0.2289423147837321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.935943603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004177524242550135,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27438944578170776,
      "backward_entropy": 0.2287365992863973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6233229637146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004277030471712351,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27439382672309875,
      "backward_entropy": 0.22865949074427286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.535285949707031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0043764542788267136,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743980884552002,
      "backward_entropy": 0.22780907154083252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.362232208251953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004475751891732216,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744027376174927,
      "backward_entropy": 0.22772045930226645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.882590293884277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004574829712510109,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744087874889374,
      "backward_entropy": 0.2276307741800944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.524749755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004673514049500227,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27441415190696716,
      "backward_entropy": 0.22833391030629477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.231057643890381,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0047721583396196365,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27441975474357605,
      "backward_entropy": 0.22744552294413248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7736382484436035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004870143719017506,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442383766174316,
      "backward_entropy": 0.2273502747217814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.77025842666626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004968337714672089,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442666888237,
      "backward_entropy": 0.2280769944190979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.950684547424316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005066716577857733,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442842721939087,
      "backward_entropy": 0.2271500825881958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.032567024230957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005164834670722485,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744293808937073,
      "backward_entropy": 0.2279784083366394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.855789184570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005262777674943209,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744290828704834,
      "backward_entropy": 0.22781171401341757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.315099716186523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0053614904172718525,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744286358356476,
      "backward_entropy": 0.22771898905436197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.277993202209473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0054605882614851,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744288444519043,
      "backward_entropy": 0.22766780853271484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.310690879821777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00555956456810236,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744264602661133,
      "backward_entropy": 0.22755901018778482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.862165451049805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005657840985804796,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744249701499939,
      "backward_entropy": 0.22650013367335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2890305519104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005756814498454332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744256854057312,
      "backward_entropy": 0.22733612855275473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.990932464599609,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005855637136846781,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744258940219879,
      "backward_entropy": 0.22626781463623047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010002136230469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005954742897301912,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744239866733551,
      "backward_entropy": 0.22710241874059042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.454745292663574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00605405867099762,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442219853401184,
      "backward_entropy": 0.2269841432571411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.721224784851074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006153804715722799,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442026138305664,
      "backward_entropy": 0.22588745752970377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.105331420898438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006253551691770554,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27441778779029846,
      "backward_entropy": 0.22574637333552042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.353536605834961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006353448610752821,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27441710233688354,
      "backward_entropy": 0.22560274600982666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.537689208984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006453647278249264,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744165062904358,
      "backward_entropy": 0.2265529235204061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0634126663208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006553673185408115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744161784648895,
      "backward_entropy": 0.22635777791341147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225320816040039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006653848569840193,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27441519498825073,
      "backward_entropy": 0.2251497507095337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1614203453063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006754267495125532,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744126319885254,
      "backward_entropy": 0.22618124882380167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.434164047241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006854287348687649,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27441030740737915,
      "backward_entropy": 0.2260523239771525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.678900241851807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0069546024315059185,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27440983057022095,
      "backward_entropy": 0.2259221871693929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50432014465332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007054830901324749,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744084596633911,
      "backward_entropy": 0.22565426429112753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.109516143798828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007155382074415684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27440810203552246,
      "backward_entropy": 0.22550288836161295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.826357364654541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0072560617700219154,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744063138961792,
      "backward_entropy": 0.2241455316543579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.931101322174072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00735671678557992,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744027078151703,
      "backward_entropy": 0.22396365801493326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.924480438232422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007457367144525051,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743989825248718,
      "backward_entropy": 0.22503002484639487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.367086887359619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007558009587228298,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743951678276062,
      "backward_entropy": 0.2235884666442871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.923122406005859,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007658369839191437,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27439019083976746,
      "backward_entropy": 0.22493120034535727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.985334873199463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0077582248486578465,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27438467741012573,
      "backward_entropy": 0.22319698333740234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.622641086578369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007858206517994404,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27437859773635864,
      "backward_entropy": 0.22462713718414307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279434204101562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007958104833960533,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27437204122543335,
      "backward_entropy": 0.22418506940205893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.785438537597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008058222010731697,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27436816692352295,
      "backward_entropy": 0.2243099013964335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.008484840393066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0081578204408288,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743620276451111,
      "backward_entropy": 0.22414608796437582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.771968841552734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00825700256973505,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743576169013977,
      "backward_entropy": 0.22364137570063272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.782683372497559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00835677981376648,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743541896343231,
      "backward_entropy": 0.2238072156906128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.716444969177246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008456558920443058,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743512690067291,
      "backward_entropy": 0.22363231579462686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.747663497924805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008555751293897629,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27434927225112915,
      "backward_entropy": 0.22148032983144125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.408722877502441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008655528537929058,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743479013442993,
      "backward_entropy": 0.22124874591827393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.637406826019287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008755102753639221,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27434760332107544,
      "backward_entropy": 0.22272058327992758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.745920658111572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008854661136865616,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27434563636779785,
      "backward_entropy": 0.22252933184305826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.543595790863037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008954227901995182,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27434423565864563,
      "backward_entropy": 0.22233551740646362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.263123989105225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009053715504705906,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274341881275177,
      "backward_entropy": 0.22027893861134848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.99489688873291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009152989834547043,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743377983570099,
      "backward_entropy": 0.2219387690226237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53110122680664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009252430871129036,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27433544397354126,
      "backward_entropy": 0.22173418601353964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.171777725219727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00935229379683733,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743355333805084,
      "backward_entropy": 0.2194968263308207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.557279586791992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0094523336738348,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27433714270591736,
      "backward_entropy": 0.22128740946451822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.764634609222412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00955329928547144,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743389308452606,
      "backward_entropy": 0.21896048386891684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.947750091552734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009654142893850803,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743396461009979,
      "backward_entropy": 0.22080334027608237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16889762878418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00975495483726263,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743406295776367,
      "backward_entropy": 0.22054815292358398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.386025428771973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009856395423412323,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27434155344963074,
      "backward_entropy": 0.2206817070643107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449897766113281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009957944974303246,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743435800075531,
      "backward_entropy": 0.2178005576133728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.647836208343506,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010059639811515808,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27434563636779785,
      "backward_entropy": 0.21749186515808105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.751646518707275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01016054768115282,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743450999259949,
      "backward_entropy": 0.21717039744059244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.188053131103516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01026077289134264,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27434441447257996,
      "backward_entropy": 0.2191706895828247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.757470607757568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010361216962337494,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27434101700782776,
      "backward_entropy": 0.2193434238433838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.273905754089355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010461599566042423,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27433639764785767,
      "backward_entropy": 0.21905740102132162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.676909446716309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01056219544261694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743310034275055,
      "backward_entropy": 0.21576058864593506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.814197540283203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010663222521543503,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743237018585205,
      "backward_entropy": 0.2179791529973348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.708437919616699,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010764735750854015,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743132710456848,
      "backward_entropy": 0.21766014893849692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.63096809387207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010866041295230389,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27430155873298645,
      "backward_entropy": 0.214620312054952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.346108436584473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010967674665153027,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742880582809448,
      "backward_entropy": 0.21754992008209229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.747476577758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011068877764046192,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742744982242584,
      "backward_entropy": 0.21381517251332602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.802433013916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011170510202646255,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742578685283661,
      "backward_entropy": 0.2168938716252645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.082764625549316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011271997354924679,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742394804954529,
      "backward_entropy": 0.21597369511922201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21506118774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011374025605618954,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742196321487427,
      "backward_entropy": 0.21619502703348795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.682518005371094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01147606410086155,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27419883012771606,
      "backward_entropy": 0.21206510066986084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.252965927124023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011577828787267208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27417799830436707,
      "backward_entropy": 0.2154665986696879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.550074577331543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011679664254188538,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741556763648987,
      "backward_entropy": 0.21111961205800375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.032217025756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011781098321080208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741367518901825,
      "backward_entropy": 0.21470844745635986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38421630859375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011882534250617027,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27411550283432007,
      "backward_entropy": 0.21371883153915405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715966701507568,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011984128504991531,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740933299064636,
      "backward_entropy": 0.20963563521703085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.838171482086182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012085476890206337,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27407214045524597,
      "backward_entropy": 0.21351444721221924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.968173027038574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012186698615550995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740500271320343,
      "backward_entropy": 0.21251332759857178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.171509742736816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012287264689803123,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27403193712234497,
      "backward_entropy": 0.20805736382802328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289114952087402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012387936934828758,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27401402592658997,
      "backward_entropy": 0.2122365633646647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4458746910095215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012488795444369316,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273994505405426,
      "backward_entropy": 0.2069640556971232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.679117679595947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012589349411427975,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739749848842621,
      "backward_entropy": 0.20640055338541666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.612858772277832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012689757160842419,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739551365375519,
      "backward_entropy": 0.2058261235555013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8244500160217285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01279058214277029,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27393168210983276,
      "backward_entropy": 0.2098787228266398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.618542671203613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012890749610960484,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27391016483306885,
      "backward_entropy": 0.20464189847310385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.658068656921387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012991320341825485,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27388784289360046,
      "backward_entropy": 0.20403722922007242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.084630012512207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013091136701405048,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27386942505836487,
      "backward_entropy": 0.20841248830159506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.548024654388428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013190554454922676,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738514244556427,
      "backward_entropy": 0.20279353857040405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.916332244873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01328981388360262,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27383655309677124,
      "backward_entropy": 0.20793628692626953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.700336456298828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013388611376285553,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27382388710975647,
      "backward_entropy": 0.2015165090560913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.31500244140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013487442396581173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738109827041626,
      "backward_entropy": 0.20633812745412192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.302779197692871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013586117886006832,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27379676699638367,
      "backward_entropy": 0.20634488264719644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25065803527832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013684033416211605,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27378684282302856,
      "backward_entropy": 0.19951210419336954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.918560981750488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013782410882413387,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27377355098724365,
      "backward_entropy": 0.1988147497177124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.225019931793213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013881002552807331,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737584412097931,
      "backward_entropy": 0.20466508467992148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8332109451293945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01397941168397665,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737419307231903,
      "backward_entropy": 0.1973653038342794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.871560096740723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01407740917056799,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737278342247009,
      "backward_entropy": 0.20278934637705484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.393136501312256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014175073243677616,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27371394634246826,
      "backward_entropy": 0.19585641225179037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092671394348145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014272746630012989,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736983597278595,
      "backward_entropy": 0.20145299037297568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.400026798248291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01437082327902317,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736799716949463,
      "backward_entropy": 0.2016177773475647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7103166580200195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014468882232904434,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27365902066230774,
      "backward_entropy": 0.19348220030466715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6841559410095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014566492289304733,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27364012598991394,
      "backward_entropy": 0.20031503836313883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.191514492034912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01466368418186903,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27362310886383057,
      "backward_entropy": 0.19183123111724854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.581912040710449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014760859310626984,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736018896102905,
      "backward_entropy": 0.19896743694941202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7745537757873535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014858229085803032,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27357685565948486,
      "backward_entropy": 0.19011310736338297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.221287250518799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014955295249819756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27355092763900757,
      "backward_entropy": 0.19627531369527182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.488901615142822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015051702037453651,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2735305428504944,
      "backward_entropy": 0.1968503793080648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7647199630737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015147686935961246,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27351343631744385,
      "backward_entropy": 0.19611895084381104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.329988956451416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015244062058627605,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27349433302879333,
      "backward_entropy": 0.18655155102411905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.991206169128418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015340495854616165,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27347755432128906,
      "backward_entropy": 0.18564548095067343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.134895324707031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015437419526278973,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27345702052116394,
      "backward_entropy": 0.1938071052233378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.577729225158691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015533654019236565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734403610229492,
      "backward_entropy": 0.19133702913920084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.180547714233398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01562953181564808,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734261453151703,
      "backward_entropy": 0.19046958287556967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.513504981994629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015724878758192062,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273412823677063,
      "backward_entropy": 0.19131559133529663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.158757209777832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01581992395222187,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27340167760849,
      "backward_entropy": 0.19045080741246542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.577572822570801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01591513119637966,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733863890171051,
      "backward_entropy": 0.18957175811131796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603304386138916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016010062769055367,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27337518334388733,
      "backward_entropy": 0.18688432375590006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.581557273864746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016105448827147484,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27335718274116516,
      "backward_entropy": 0.18777136007944742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.211125373840332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01620061695575714,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2733365595340729,
      "backward_entropy": 0.17684811353683472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.793543815612793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016295339912176132,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27331671118736267,
      "backward_entropy": 0.18591956297556558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.940146446228027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01638937182724476,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2733021080493927,
      "backward_entropy": 0.1747074325879415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.051568508148193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01648285984992981,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732929587364197,
      "backward_entropy": 0.18208314975102743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.425434112548828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01657596416771412,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27328476309776306,
      "backward_entropy": 0.1810974677403768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.024535655975342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01666894182562828,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732774019241333,
      "backward_entropy": 0.17143150170644125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.385115146636963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01676158234477043,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27326980233192444,
      "backward_entropy": 0.17908747990926108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5373334884643555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016853485256433487,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27326714992523193,
      "backward_entropy": 0.18007556597391763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.590512275695801,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016945457085967064,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27326419949531555,
      "backward_entropy": 0.16805249452590942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.047391891479492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01703754812479019,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732582688331604,
      "backward_entropy": 0.16690297921498617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.641687393188477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01712939329445362,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2732524275779724,
      "backward_entropy": 0.17698427041371664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.73471212387085,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017220724374055862,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732512354850769,
      "backward_entropy": 0.16457587480545044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.14835786819458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017312346026301384,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27324479818344116,
      "backward_entropy": 0.17486206690470377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.015013694763184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01740383356809616,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732376456260681,
      "backward_entropy": 0.17168104648590088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.194288730621338,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01749514974653721,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27322667837142944,
      "backward_entropy": 0.16099035739898682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.346309661865234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01758642867207527,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732114791870117,
      "backward_entropy": 0.1597361167271932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.768259525299072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01767708919942379,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273198664188385,
      "backward_entropy": 0.17047500610351562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.896916389465332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017768152058124542,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2731795310974121,
      "backward_entropy": 0.16934667030970255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.434334754943848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017859648913145065,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27315548062324524,
      "backward_entropy": 0.16820315519968668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.864880561828613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01795055717229843,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27313393354415894,
      "backward_entropy": 0.16704978545506796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.081328868865967,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018040534108877182,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2731189429759979,
      "backward_entropy": 0.15317376454671225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.553831577301025,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018129827454686165,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27310776710510254,
      "backward_entropy": 0.1518334150314331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.334572792053223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01821884512901306,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2730957865715027,
      "backward_entropy": 0.1611952781677246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.108931064605713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01830676943063736,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27308979630470276,
      "backward_entropy": 0.16000322500864664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.328875541687012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01839493028819561,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27308008074760437,
      "backward_entropy": 0.16115187605222067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.00510835647583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0184827521443367,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730720639228821,
      "backward_entropy": 0.1599294145901998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.834967136383057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018570754677057266,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2730603814125061,
      "backward_entropy": 0.15632746616999307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.430706977844238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018658103421330452,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27305078506469727,
      "backward_entropy": 0.15741215149561563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.021722316741943,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01874527335166931,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2730405926704407,
      "backward_entropy": 0.1420835256576538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.645360946655273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018832694739103317,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27302733063697815,
      "backward_entropy": 0.1548511783281962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.801342487335205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018920112401247025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2730087637901306,
      "backward_entropy": 0.15124329924583435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.319524765014648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019007638096809387,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2729846239089966,
      "backward_entropy": 0.14993170897165933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.461743354797363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0190949197858572,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.272956907749176,
      "backward_entropy": 0.13631872336069742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.190243721008301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01918131485581398,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27293574810028076,
      "backward_entropy": 0.13486367464065552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.809329032897949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019266780465841293,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729141414165497,
      "backward_entropy": 0.13339763879776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.674036979675293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01935180090367794,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27289509773254395,
      "backward_entropy": 0.14696345726648966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2088398933410645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019436363130807877,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27287396788597107,
      "backward_entropy": 0.1304621398448944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.409458160400391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019520891830325127,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27284952998161316,
      "backward_entropy": 0.12898631890614828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.591400623321533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0196047592908144,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27283018827438354,
      "backward_entropy": 0.14294928312301636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5650739669799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01968817412853241,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728132903575897,
      "backward_entropy": 0.13936916987101236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.558108806610107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019771169871091843,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727971374988556,
      "backward_entropy": 0.14024031162261963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.39699649810791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019854549318552017,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27277570962905884,
      "backward_entropy": 0.12312263250350952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1392598152160645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019937360659241676,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727580964565277,
      "backward_entropy": 0.1375041405359904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.19584321975708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02001946046948433,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27274495363235474,
      "backward_entropy": 0.13399277130762735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.959054470062256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020101776346564293,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27272552251815796,
      "backward_entropy": 0.13263348738352457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4808685779571533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020184114575386047,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27269989252090454,
      "backward_entropy": 0.11730153361956279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9187347888946533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020265299826860428,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726770043373108,
      "backward_entropy": 0.12990824381510416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.598950386047363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020345749333500862,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27265894412994385,
      "backward_entropy": 0.1306237280368805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6841347217559814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02042613923549652,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27263420820236206,
      "backward_entropy": 0.12719659010569254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.900188446044922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02050570584833622,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27261149883270264,
      "backward_entropy": 0.12584418058395386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.276110649108887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020584654062986374,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27259522676467896,
      "backward_entropy": 0.11006015539169312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.327834129333496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020663371309638023,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27257952094078064,
      "backward_entropy": 0.12314808368682861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.841214418411255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02074197120964527,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2725580036640167,
      "backward_entropy": 0.10721572240193684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0142412185668945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02082004025578499,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27253594994544983,
      "backward_entropy": 0.10579713185628255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0566651821136475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020897794514894485,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725096642971039,
      "backward_entropy": 0.1190735399723053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.171640157699585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020974380895495415,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27249324321746826,
      "backward_entropy": 0.11964136362075806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.608018398284912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021049996837973595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27248576283454895,
      "backward_entropy": 0.1164069374402364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.123719215393066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021125169470906258,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724764049053192,
      "backward_entropy": 0.10022694865862529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9152369499206543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021200399845838547,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2724605202674866,
      "backward_entropy": 0.11374927560488383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7069091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021275516599416733,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27243733406066895,
      "backward_entropy": 0.11422632137934367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7199759483337402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02135036326944828,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724064588546753,
      "backward_entropy": 0.09610381722450256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.351414442062378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021424923092126846,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723747491836548,
      "backward_entropy": 0.09473849336306255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0484440326690674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021498914808034897,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2723408043384552,
      "backward_entropy": 0.11020068327585857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0090572834014893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02157207578420639,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27231067419052124,
      "backward_entropy": 0.10707217454910278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.968975782394409,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021644456312060356,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27228283882141113,
      "backward_entropy": 0.10755519072214763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8986635208129883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021716099232435226,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27225592732429504,
      "backward_entropy": 0.08938881754875183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9095253944396973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021786997094750404,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722310423851013,
      "backward_entropy": 0.08808500568072002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9744293689727783,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021858204156160355,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27219802141189575,
      "backward_entropy": 0.08678791920344035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.624234676361084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021928777918219566,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27216649055480957,
      "backward_entropy": 0.10235542058944702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6115195751190186,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021999429911375046,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27212804555892944,
      "backward_entropy": 0.08422512809435527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1506190299987793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022070175036787987,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2720784544944763,
      "backward_entropy": 0.09800978501637776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4554603099823,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0221405029296875,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27202633023262024,
      "backward_entropy": 0.08168192704518636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0299270153045654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02221078798174858,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2719666063785553,
      "backward_entropy": 0.09724116325378418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.787079334259033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022280577570199966,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27190542221069336,
      "backward_entropy": 0.09413877129554749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.411203145980835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022349653765559196,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27184587717056274,
      "backward_entropy": 0.09473402301470439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5460569858551025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022417686879634857,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27179065346717834,
      "backward_entropy": 0.09162084261576335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7756006717681885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02248494140803814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2717348635196686,
      "backward_entropy": 0.09038796027501424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.763439416885376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02255171537399292,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2716786563396454,
      "backward_entropy": 0.08916451533635457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8828072547912598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02261807583272457,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2716168463230133,
      "backward_entropy": 0.07321308056513469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7892842292785645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022684214636683464,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27154552936553955,
      "backward_entropy": 0.08673296372095744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2679734230041504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022750023752450943,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2714692950248718,
      "backward_entropy": 0.07089859743913014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.684976100921631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022814931347966194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713949382305145,
      "backward_entropy": 0.0843350887298584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.731950044631958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022879524156451225,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2713119685649872,
      "backward_entropy": 0.0851957102616628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9568378925323486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022943856194615364,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27122682332992554,
      "backward_entropy": 0.08197429776191711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.061915874481201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023007037118077278,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27114760875701904,
      "backward_entropy": 0.08292510112126668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5815625190734863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023069310933351517,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2710701525211334,
      "backward_entropy": 0.07969141999880473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.362077236175537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02313140593469143,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2709856629371643,
      "backward_entropy": 0.08071372906366985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7653993368148804,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02319304645061493,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27090123295783997,
      "backward_entropy": 0.0633145272731781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8757009506225586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023253528401255608,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27082353830337524,
      "backward_entropy": 0.07635505000750224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8245570659637451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023313121870160103,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27074530720710754,
      "backward_entropy": 0.061315457026163735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5178983211517334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02337183803319931,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27066752314567566,
      "backward_entropy": 0.060339982310930886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7335354089736938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023429352790117264,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27059388160705566,
      "backward_entropy": 0.07541416088740031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.078737497329712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0234860610216856,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27052032947540283,
      "backward_entropy": 0.07440629104773204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0261776447296143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023542510345578194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27043837308883667,
      "backward_entropy": 0.0711786945660909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7188749313354492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023598650470376015,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27034956216812134,
      "backward_entropy": 0.07242194811503093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.806884527206421,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023654067888855934,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2702626585960388,
      "backward_entropy": 0.05569326877593994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8738412857055664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023708967491984367,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2701708674430847,
      "backward_entropy": 0.06821542978286743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4666855335235596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023763485252857208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2700761556625366,
      "backward_entropy": 0.053935701648394264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1958911418914795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02381705306470394,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26998913288116455,
      "backward_entropy": 0.06630516052246094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3990113735198975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023869354277849197,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2699131965637207,
      "backward_entropy": 0.05226731797059377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4734560251235962,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023920821025967598,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26983585953712463,
      "backward_entropy": 0.05146054923534393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6544103622436523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023971641436219215,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26975512504577637,
      "backward_entropy": 0.06589730083942413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2837803363800049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02402215264737606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26966866850852966,
      "backward_entropy": 0.06272519131501515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2499449253082275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024071794003248215,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26958560943603516,
      "backward_entropy": 0.049123600125312805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.531685709953308,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024120589718222618,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2695029377937317,
      "backward_entropy": 0.048377921183904014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2847206592559814,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0241690780967474,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2694140672683716,
      "backward_entropy": 0.06248977283636729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2491989135742188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024216875433921814,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26932358741760254,
      "backward_entropy": 0.046924625833829246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.215061068534851,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024263983592391014,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2692337930202484,
      "backward_entropy": 0.06086862583955129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7881542444229126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024310406297445297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26914361119270325,
      "backward_entropy": 0.057761967182159424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4390618801116943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024355454370379448,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26906436681747437,
      "backward_entropy": 0.05699808398882548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.117453932762146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024400407448410988,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2689734101295471,
      "backward_entropy": 0.05623533328374227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0865118503570557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024444693699479103,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26888081431388855,
      "backward_entropy": 0.0554861972729365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2392828464508057,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024488316848874092,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2687872350215912,
      "backward_entropy": 0.05707456171512604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1143337488174438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024531623348593712,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2686879336833954,
      "backward_entropy": 0.05402209858099619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2604117393493652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02457440085709095,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2685820162296295,
      "backward_entropy": 0.04172287384668986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5710662603378296,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024616986513137817,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26846736669540405,
      "backward_entropy": 0.054941932360331215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1912579536437988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0246600192040205,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26833534240722656,
      "backward_entropy": 0.05186764399210612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4966139793395996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024702703580260277,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2681961953639984,
      "backward_entropy": 0.03994692862033844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.800972580909729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024743642657995224,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26807039976119995,
      "backward_entropy": 0.0504753440618515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8578805923461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024783626198768616,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2679460048675537,
      "backward_entropy": 0.05224753419558207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7534129023551941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024822868406772614,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2678225636482239,
      "backward_entropy": 0.05161762237548828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1098723411560059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024861203506588936,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26770031452178955,
      "backward_entropy": 0.05100430051485697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7069455981254578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024899505078792572,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26756682991981506,
      "backward_entropy": 0.050396169225374855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1213817596435547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024936864152550697,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2674339711666107,
      "backward_entropy": 0.0367964506149292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6625078916549683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02497432939708233,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2672874927520752,
      "backward_entropy": 0.04670079549153646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5046340823173523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02501080557703972,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26714131236076355,
      "backward_entropy": 0.048649738232294716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8972526788711548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025046009570360184,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26700183749198914,
      "backward_entropy": 0.045543054739634194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0032967329025269,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025081027299165726,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.266854852437973,
      "backward_entropy": 0.03492481509844462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.648968517780304,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025116143748164177,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2666955292224884,
      "backward_entropy": 0.03448061148325602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5047880411148071,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025150442495942116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26653507351875305,
      "backward_entropy": 0.043867905934651695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7345963716506958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025183632969856262,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2663799822330475,
      "backward_entropy": 0.04333996772766113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5930198431015015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025216422975063324,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2662190794944763,
      "backward_entropy": 0.04281954964001974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6916600465774536,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025248469784855843,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26605796813964844,
      "backward_entropy": 0.03282705942789713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4990367889404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02528011053800583,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26589077711105347,
      "backward_entropy": 0.04453474779923757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4271215498447418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025310836732387543,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26572519540786743,
      "backward_entropy": 0.032063628236452736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.415422260761261,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025340517982840538,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2655629515647888,
      "backward_entropy": 0.040865754087766014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5640333890914917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025369223207235336,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2654045820236206,
      "backward_entropy": 0.04041832437117895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.806667149066925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02539750002324581,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2652427852153778,
      "backward_entropy": 0.03997855633497238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4808580279350281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025426121428608894,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26506444811820984,
      "backward_entropy": 0.039532783130804695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41470423340797424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02545406110584736,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26488614082336426,
      "backward_entropy": 0.03909926861524582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7399888634681702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025481142103672028,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2647087275981903,
      "backward_entropy": 0.038680421809355416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.437701553106308,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025508509948849678,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2645149230957031,
      "backward_entropy": 0.029708767930666607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.426424503326416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025535153225064278,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26432090997695923,
      "backward_entropy": 0.04079024742046992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2798519730567932,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025561129674315453,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26412785053253174,
      "backward_entropy": 0.0404183492064476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5309523940086365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02558598667383194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26394277811050415,
      "backward_entropy": 0.03706591327985128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5135594606399536,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02561071142554283,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26374951004981995,
      "backward_entropy": 0.02854474385579427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49988430738449097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025635216385126114,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26354697346687317,
      "backward_entropy": 0.028271747132142384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2460165023803711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025659505277872086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2633365988731384,
      "backward_entropy": 0.03594279040892919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3547437787055969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025682657957077026,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26313406229019165,
      "backward_entropy": 0.03870134303967158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19394029676914215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025705184787511826,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26293066143989563,
      "backward_entropy": 0.035249521334966026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22558966279029846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02572653256356716,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26273682713508606,
      "backward_entropy": 0.03492741038401922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2541278898715973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02574695087969303,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2625495195388794,
      "backward_entropy": 0.0346205805738767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35278499126434326,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025766590610146523,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2623642385005951,
      "backward_entropy": 0.026837232212225597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2756275236606598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02578594535589218,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2621734142303467,
      "backward_entropy": 0.03403549393018087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3348599374294281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025804739445447922,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2619827389717102,
      "backward_entropy": 0.026431212822596233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39106225967407227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025823267176747322,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2617868483066559,
      "backward_entropy": 0.02623618145783742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25430458784103394,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02584180049598217,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26158082485198975,
      "backward_entropy": 0.03650756428639094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3091809153556824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02585974521934986,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26137539744377136,
      "backward_entropy": 0.025856822729110718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30108392238616943,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025877395644783974,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26116517186164856,
      "backward_entropy": 0.025675445795059204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2639407217502594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02589474618434906,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26095035672187805,
      "backward_entropy": 0.025498588879903156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14323849976062775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025911657139658928,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26073360443115234,
      "backward_entropy": 0.03557084004084269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30612877011299133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025927554816007614,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2605237662792206,
      "backward_entropy": 0.02516855299472809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43337950110435486,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025943366810679436,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2603064477443695,
      "backward_entropy": 0.02501160403092702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36913836002349854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025959772989153862,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2600712478160858,
      "backward_entropy": 0.03493664165337881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30723801255226135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025976385921239853,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25982382893562317,
      "backward_entropy": 0.02468709150950114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.299058735370636,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025992929935455322,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2595701813697815,
      "backward_entropy": 0.03450572987397512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24239611625671387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026009317487478256,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25930994749069214,
      "backward_entropy": 0.030685290694236755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16514718532562256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026025261729955673,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2590491771697998,
      "backward_entropy": 0.02421567589044571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27417486906051636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02604041062295437,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2587960362434387,
      "backward_entropy": 0.030219438175360363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24424973130226135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02605545148253441,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25853651762008667,
      "backward_entropy": 0.033705530067284904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21610529720783234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0260702483355999,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25827333331108093,
      "backward_entropy": 0.03351854284604391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29224321246147156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026084663346409798,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2580087184906006,
      "backward_entropy": 0.029558824996153515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28417378664016724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026099245995283127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25773555040359497,
      "backward_entropy": 0.029341389735539753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17870250344276428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026113921776413918,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2574542760848999,
      "backward_entropy": 0.02338971197605133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13577139377593994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026128014549613,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2571752071380615,
      "backward_entropy": 0.028910522659619648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20378272235393524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026141315698623657,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25690197944641113,
      "backward_entropy": 0.03263286749521891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21680036187171936,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026154419407248497,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2566262483596802,
      "backward_entropy": 0.03247209390004476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14164701104164124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02616739459335804,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2563457489013672,
      "backward_entropy": 0.028321926792462666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25459763407707214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026179760694503784,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25606876611709595,
      "backward_entropy": 0.028137490153312683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21516454219818115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02619236707687378,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2557815611362457,
      "backward_entropy": 0.02268197387456894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19251979887485504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026204913854599,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25548863410949707,
      "backward_entropy": 0.027762820323308308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14098581671714783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02621728554368019,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2551925480365753,
      "backward_entropy": 0.027578418453534443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10867762565612793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026229145005345345,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25489920377731323,
      "backward_entropy": 0.02740384389956792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17513012886047363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026240264996886253,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2546123266220093,
      "backward_entropy": 0.022269052763779957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06212626025080681,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026251306757330894,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25432315468788147,
      "backward_entropy": 0.022174994150797527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19230946898460388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026261312887072563,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25404495000839233,
      "backward_entropy": 0.026926522453625996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1228431686758995,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0262715145945549,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2537602186203003,
      "backward_entropy": 0.031069872279961903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1320393979549408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026281310245394707,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25347763299942017,
      "backward_entropy": 0.03095603734254837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11560014635324478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026290830224752426,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2531946003437042,
      "backward_entropy": 0.026484020054340363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14732787013053894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629999816417694,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25291314721107483,
      "backward_entropy": 0.02634608248869578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06458945572376251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026309162378311157,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2526281774044037,
      "backward_entropy": 0.026208043098449707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0837879404425621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026317540556192398,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25235116481781006,
      "backward_entropy": 0.02608107527097066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13635310530662537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026325445622205734,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2520785927772522,
      "backward_entropy": 0.025960673888524372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12326689064502716,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633339911699295,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2518017888069153,
      "backward_entropy": 0.03036300589640935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05717483162879944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634124830365181,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2515224516391754,
      "backward_entropy": 0.025719985365867615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0861046314239502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026348447427153587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.251251220703125,
      "backward_entropy": 0.02560986081759135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1120847836136818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026355329900979996,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2509825825691223,
      "backward_entropy": 0.025503769516944885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12899194657802582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026362231001257896,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25071215629577637,
      "backward_entropy": 0.02539682885011037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1147172823548317,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02636929415166378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25043681263923645,
      "backward_entropy": 0.025287233293056488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09477324783802032,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026376444846391678,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2501591444015503,
      "backward_entropy": 0.021258172889550526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08376767486333847,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026383446529507637,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24988147616386414,
      "backward_entropy": 0.025068295498689015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11490900814533234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026390204206109047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24960538744926453,
      "backward_entropy": 0.02496368686358134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09413556754589081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263970959931612,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24932482838630676,
      "backward_entropy": 0.024857242902119953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06970497220754623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02640395425260067,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24904394149780273,
      "backward_entropy": 0.021083809435367584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08255847543478012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02641044743359089,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2487659454345703,
      "backward_entropy": 0.029516359170277912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07210002839565277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026416795328259468,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24848797917366028,
      "backward_entropy": 0.021008585890134174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06285423040390015,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02642294019460678,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24821248650550842,
      "backward_entropy": 0.0293813223640124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10289441049098969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026428811252117157,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2479408085346222,
      "backward_entropy": 0.020941118399302166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07312176376581192,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026434939354658127,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24766455590724945,
      "backward_entropy": 0.020905402799447376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07758261263370514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026440942659974098,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24738958477973938,
      "backward_entropy": 0.02918806920448939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06329724937677383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026446908712387085,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24711397290229797,
      "backward_entropy": 0.029123902320861816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07308084517717361,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026452643796801567,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24684031307697296,
      "backward_entropy": 0.020806034406026203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0528486967086792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02645835094153881,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24656632542610168,
      "backward_entropy": 0.023913922409216564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07413991540670395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026463789865374565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24629724025726318,
      "backward_entropy": 0.023829845090707142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08896928280591965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026469312608242035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24603290855884552,
      "backward_entropy": 0.02374518911043803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0532512366771698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02647513337433338,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2457650601863861,
      "backward_entropy": 0.023656557003657024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04096158593893051,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02648075483739376,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2455008178949356,
      "backward_entropy": 0.020652932425340016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04070630297064781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026486044749617577,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2452429234981537,
      "backward_entropy": 0.02348954975605011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07416586577892303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026490995660424232,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24499036371707916,
      "backward_entropy": 0.02059902747472127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05164775997400284,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02649616450071335,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24473430216312408,
      "backward_entropy": 0.02057196944952011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06043614074587822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02650126814842224,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.244480699300766,
      "backward_entropy": 0.0232552836338679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06314285099506378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026506410911679268,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24422705173492432,
      "backward_entropy": 0.0231764813264211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04738989472389221,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026511650532484055,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2439725399017334,
      "backward_entropy": 0.020488714178403217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06751076877117157,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026516782119870186,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24372050166130066,
      "backward_entropy": 0.023018832008043926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04077904298901558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026522140949964523,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24346481263637543,
      "backward_entropy": 0.02293817202250163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03514603152871132,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02652727998793125,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24321287870407104,
      "backward_entropy": 0.02839827040831248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04541899636387825,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026532163843512535,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2429659068584442,
      "backward_entropy": 0.02037958676616351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033163804560899734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02653701975941658,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24272048473358154,
      "backward_entropy": 0.022713889678319294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03235708922147751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026541631668806076,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24248024821281433,
      "backward_entropy": 0.02264450987180074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0381668321788311,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02654600888490677,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.242244690656662,
      "backward_entropy": 0.028250381350517273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04642544314265251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026550306007266045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24201184511184692,
      "backward_entropy": 0.02251271406809489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028636300936341286,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02655475214123726,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2417793571949005,
      "backward_entropy": 0.028182854255040485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05015338212251663,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0265590138733387,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24155256152153015,
      "backward_entropy": 0.020252473652362823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054518043994903564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026563525199890137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24132469296455383,
      "backward_entropy": 0.022322803735733032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032474033534526825,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02656838484108448,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24109405279159546,
      "backward_entropy": 0.02805885672569275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03677920624613762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026573097333312035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24086670577526093,
      "backward_entropy": 0.022181029121081035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049230895936489105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02657780423760414,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24064122140407562,
      "backward_entropy": 0.02210891495148341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04216594249010086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026582788676023483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24041299521923065,
      "backward_entropy": 0.02203116814295451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025648048147559166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026587888598442078,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2401847243309021,
      "backward_entropy": 0.02783664067586263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03172709792852402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02659272588789463,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23996064066886902,
      "backward_entropy": 0.027783458431561787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02587112784385681,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026597505435347557,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2397388517856598,
      "backward_entropy": 0.019966074575980503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015894057229161263,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026602113619446754,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23952102661132812,
      "backward_entropy": 0.019931146254142124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030678316950798035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026606349274516106,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23931005597114563,
      "backward_entropy": 0.019900844742854435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023433668538928032,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026610611006617546,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2390994131565094,
      "backward_entropy": 0.02162626137336095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024386141449213028,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0266147218644619,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2388916015625,
      "backward_entropy": 0.021566323935985565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02181636169552803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026618758216500282,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23868602514266968,
      "backward_entropy": 0.02150761087735494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03406205773353577,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026622656732797623,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23848310112953186,
      "backward_entropy": 0.027489629884560902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033071406185626984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02662677876651287,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2382776141166687,
      "backward_entropy": 0.02139110614856084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017526792362332344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026631072163581848,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23806896805763245,
      "backward_entropy": 0.02132958173751831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015607339330017567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026635153219103813,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23786483705043793,
      "backward_entropy": 0.02127094070116679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01493922807276249,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02663896605372429,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2376653254032135,
      "backward_entropy": 0.019687638928492863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016067277640104294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026642540469765663,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2374705970287323,
      "backward_entropy": 0.021164233485857647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02102016843855381,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026645932346582413,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2372795194387436,
      "backward_entropy": 0.01965085913737615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016300784423947334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026649365201592445,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23709003627300262,
      "backward_entropy": 0.019632667303085327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016803381964564323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02665267325937748,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23690350353717804,
      "backward_entropy": 0.021016128361225128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02304028905928135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026655929163098335,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23671965301036835,
      "backward_entropy": 0.02096870293219884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018587717786431313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026659328490495682,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23653502762317657,
      "backward_entropy": 0.020921056469281513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017587842419743538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026662705466151237,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23635117709636688,
      "backward_entropy": 0.02087246874968211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015534487552940845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026666078716516495,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23616936802864075,
      "backward_entropy": 0.020822783311208088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013820541091263294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026669418439269066,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23599064350128174,
      "backward_entropy": 0.020774311075607937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013283824548125267,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02667267993092537,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2358149290084839,
      "backward_entropy": 0.019496243447065353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013975772075355053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026675865054130554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23564252257347107,
      "backward_entropy": 0.020682158569494884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011164178140461445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02667899988591671,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23547203838825226,
      "backward_entropy": 0.02063717693090439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008154700510203838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026682034134864807,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23530542850494385,
      "backward_entropy": 0.020593468099832535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01584690622985363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02668483555316925,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2351434826850891,
      "backward_entropy": 0.026942595839500427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010943809524178505,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026687780395150185,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23498156666755676,
      "backward_entropy": 0.02691667030255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009571009315550327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026690654456615448,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23482221364974976,
      "backward_entropy": 0.02046976238489151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01334837544709444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02669343538582325,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23466601967811584,
      "backward_entropy": 0.02043000857035319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009592043235898018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02669629268348217,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23451004922389984,
      "backward_entropy": 0.02684369683265686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0098482770845294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026699088513851166,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23435744643211365,
      "backward_entropy": 0.020351092020670574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008933271281421185,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670186758041382,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23420852422714233,
      "backward_entropy": 0.02679247409105301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007222010288387537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670457400381565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2340628206729889,
      "backward_entropy": 0.020272408922513325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006244380958378315,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670714259147644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23392048478126526,
      "backward_entropy": 0.01929072042306264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009915939532220364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026709556579589844,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23378172516822815,
      "backward_entropy": 0.01927672078212102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008839099667966366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026712004095315933,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23364324867725372,
      "backward_entropy": 0.0201665461063385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006679321173578501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02671445533633232,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23350587487220764,
      "backward_entropy": 0.020132011423508327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00601776409894228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026716820895671844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23337149620056152,
      "backward_entropy": 0.020098544657230377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005022784229367971,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02671905793249607,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23323984444141388,
      "backward_entropy": 0.020067226141691208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006502228789031506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026721175760030746,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23311257362365723,
      "backward_entropy": 0.02003733068704605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006144239567220211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026723254472017288,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23298782110214233,
      "backward_entropy": 0.02000734955072403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043874094262719154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02672531083226204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23286579549312592,
      "backward_entropy": 0.01997713992993037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006744650658220053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02672727219760418,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23274771869182587,
      "backward_entropy": 0.019949063658714294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006482651922851801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026729248464107513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23263008892536163,
      "backward_entropy": 0.019920865694681805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0044593350030481815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026731235906481743,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23251287639141083,
      "backward_entropy": 0.019892702500025432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038788386154919863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02673313580453396,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23239818215370178,
      "backward_entropy": 0.01914849504828453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005283515900373459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026734929531812668,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2322864532470703,
      "backward_entropy": 0.026497239867846172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003928917460143566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026736730709671974,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23217672109603882,
      "backward_entropy": 0.019131044546763103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004545946139842272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02673846296966076,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2320701777935028,
      "backward_entropy": 0.019789893180131912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004393137060105801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026740174740552902,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23196543753147125,
      "backward_entropy": 0.019765451550483704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0052687074057757854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026741860434412956,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23186209797859192,
      "backward_entropy": 0.02643526593844096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004289913922548294,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026743585243821144,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23175892233848572,
      "backward_entropy": 0.0190958467622598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037886579521000385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026745319366455078,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23165765404701233,
      "backward_entropy": 0.019086841493844986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0054731895215809345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026747040450572968,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23155906796455383,
      "backward_entropy": 0.019668489694595337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002705236431211233,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026748869568109512,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2314605414867401,
      "backward_entropy": 0.01964319373170535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003445931477472186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026750588789582253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23136454820632935,
      "backward_entropy": 0.01961926867564519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038102802354842424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02675226517021656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23126976191997528,
      "backward_entropy": 0.019596333305040996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025994298048317432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026753947138786316,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2311761975288391,
      "backward_entropy": 0.019572788228591282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027479170821607113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0267555583268404,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2310856133699417,
      "backward_entropy": 0.01902789870897929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038169356994330883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026757121086120605,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23099727928638458,
      "backward_entropy": 0.019528750330209732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028015095740556717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02675873041152954,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23090951144695282,
      "backward_entropy": 0.019506465643644333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028259684331715107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026760293170809746,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23082292079925537,
      "backward_entropy": 0.019000281890233357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002718264702707529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026761848479509354,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23073799908161163,
      "backward_entropy": 0.018991313874721527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034133344888687134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026763390749692917,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23065456748008728,
      "backward_entropy": 0.01944228634238243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015008539194241166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02676498144865036,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23057100176811218,
      "backward_entropy": 0.018973104655742645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020476661156862974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026766477152705193,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23049095273017883,
      "backward_entropy": 0.019400373101234436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002851560479030013,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0267679151147604,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23041272163391113,
      "backward_entropy": 0.018956514696280163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003016970120370388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026769373565912247,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2303348183631897,
      "backward_entropy": 0.01936074843009313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020765054505318403,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02677088975906372,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23025712370872498,
      "backward_entropy": 0.02616024762392044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016580901574343443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026772379875183105,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2301812320947647,
      "backward_entropy": 0.019319839775562286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019108259584754705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02677381969988346,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2301076054573059,
      "backward_entropy": 0.019300368924935658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018054073443636298,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02677522972226143,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23003515601158142,
      "backward_entropy": 0.018910168359676998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021128999069333076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026776615530252457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2299639880657196,
      "backward_entropy": 0.019262590756018955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001391231082379818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026778019964694977,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22989341616630554,
      "backward_entropy": 0.01924374947945277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016729483613744378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02677936851978302,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22982478141784668,
      "backward_entropy": 0.019225845734278362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013748325873166323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026780707761645317,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22975775599479675,
      "backward_entropy": 0.019207745790481567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015268655261024833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02678200788795948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22969262301921844,
      "backward_entropy": 0.019190164903799694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011730564292520285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0267832949757576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22962845861911774,
      "backward_entropy": 0.01917293667793274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013076533796265721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026784522458910942,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22956575453281403,
      "backward_entropy": 0.01885145530104637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012185184750705957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026785720139741898,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22950410842895508,
      "backward_entropy": 0.019140479465325672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011951883789151907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02678689919412136,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22944407165050507,
      "backward_entropy": 0.019124619662761688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010994634358212352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026788044720888138,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22938498854637146,
      "backward_entropy": 0.0191090926527977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009955610148608685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02678917534649372,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22932742536067963,
      "backward_entropy": 0.019093941897153854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008820402435958385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02679026685655117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22927100956439972,
      "backward_entropy": 0.019079537441333134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001121179899200797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02679130621254444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22921589016914368,
      "backward_entropy": 0.019065652042627335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000989456893876195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026792345568537712,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22916141152381897,
      "backward_entropy": 0.01905140032370885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010161246173083782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026793373748660088,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2291080504655838,
      "backward_entropy": 0.01903750126560529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009017637930810452,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026794398203492165,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22905540466308594,
      "backward_entropy": 0.019023795922597248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001038562972098589,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0267954058945179,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22900375723838806,
      "backward_entropy": 0.025915016730626423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007659794064238667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026796426624059677,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22895237803459167,
      "backward_entropy": 0.018996596336364746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010334763210266829,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02679741382598877,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22890187799930573,
      "backward_entropy": 0.01877112314105034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005752575234510005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02679843083024025,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22885151207447052,
      "backward_entropy": 0.02588426073392232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000709567335434258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026799401268363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22880277037620544,
      "backward_entropy": 0.018956953038771946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005135315586812794,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02680034376680851,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2287546992301941,
      "backward_entropy": 0.01875273510813713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000585593399591744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02680124342441559,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22870823740959167,
      "backward_entropy": 0.018747371931870777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005982338334433734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680211514234543,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22866272926330566,
      "backward_entropy": 0.018920723348855972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005596025730483234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026802966371178627,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22861799597740173,
      "backward_entropy": 0.018737530956665676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000565298949368298,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680380269885063,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22857430577278137,
      "backward_entropy": 0.018898288408915203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043808016926050186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680463157594204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22853171825408936,
      "backward_entropy": 0.018887332330147426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004909533308818936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026805425062775612,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22849030792713165,
      "backward_entropy": 0.018876555065313976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032906729029491544,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026806196197867393,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22844955325126648,
      "backward_entropy": 0.025808376570542652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035606484743766487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026806922629475594,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22841006517410278,
      "backward_entropy": 0.018856321771939594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039784383261576295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680760808289051,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22837138175964355,
      "backward_entropy": 0.01884706566731135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004752035310957581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680828794836998,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22833383083343506,
      "backward_entropy": 0.01883792132139206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036326763802208006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026808971539139748,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22829653322696686,
      "backward_entropy": 0.018828692535559338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034140891511924565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680964395403862,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2282601296901703,
      "backward_entropy": 0.018819631387790043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000390977889765054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026810307055711746,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22822469472885132,
      "backward_entropy": 0.01881076271335284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002910873736254871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02681097760796547,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22818976640701294,
      "backward_entropy": 0.018690496683120728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031746967579238117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268116258084774,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22815576195716858,
      "backward_entropy": 0.018793287376562755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003334686625748873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02681226097047329,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22812259197235107,
      "backward_entropy": 0.01878514016668002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002728963445406407,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026812899857759476,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2280900627374649,
      "backward_entropy": 0.01877684270342191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017885080887936056,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026813514530658722,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22805801033973694,
      "backward_entropy": 0.018673910448948543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027357618091627955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026814093813300133,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22802728414535522,
      "backward_entropy": 0.02572873483101527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001779651502147317,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026814665645360947,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22799691557884216,
      "backward_entropy": 0.01866635928551356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027662195498123765,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026815207675099373,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22796761989593506,
      "backward_entropy": 0.018662831435600918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020680758461821824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026815762743353844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2279386818408966,
      "backward_entropy": 0.01873796929915746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017874603508971632,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026816295459866524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22791028022766113,
      "backward_entropy": 0.01873084530234337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015485349285881966,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026816805824637413,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22788259387016296,
      "backward_entropy": 0.0187239907681942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001833019487094134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026817291975021362,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22785574197769165,
      "backward_entropy": 0.018648657947778702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018479544087313116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026817766949534416,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.227829247713089,
      "backward_entropy": 0.018710965911547344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012222926307003945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02681824378669262,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22780326008796692,
      "backward_entropy": 0.025682481626669567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013511978613678366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026818692684173584,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22777800261974335,
      "backward_entropy": 0.01869853337605794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013534472964238375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02681913413107395,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22775357961654663,
      "backward_entropy": 0.025673024356365204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001391234836773947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026819560676813126,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2277296781539917,
      "backward_entropy": 0.01868681237101555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115714055951685e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02681998535990715,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22770637273788452,
      "backward_entropy": 0.02566388001044591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011417861969675869,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026820378378033638,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22768375277519226,
      "backward_entropy": 0.01862936094403267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.437963697360829e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682075835764408,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22766155004501343,
      "backward_entropy": 0.018670658270517986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.441851241514087e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026821108534932137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22763992846012115,
      "backward_entropy": 0.018665848920742672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.600485307397321e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026821445673704147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22761905193328857,
      "backward_entropy": 0.018661193549633026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.255995635408908e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026821766048669815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.227598637342453,
      "backward_entropy": 0.018656787772973377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.293784776469693e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682206779718399,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22757866978645325,
      "backward_entropy": 0.018652851382891338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.748893403913826e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02682235836982727,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2275591343641281,
      "backward_entropy": 0.018619546045859654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15567109384574e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026822637766599655,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22754020988941193,
      "backward_entropy": 0.01861821860074997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.13430781615898e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026822907850146294,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22752147912979126,
      "backward_entropy": 0.018641258279482525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.674793985439464e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026823164895176888,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22750316560268402,
      "backward_entropy": 0.018637569000323612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.833321822341532e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026823420077562332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22748544812202454,
      "backward_entropy": 0.018633846193552017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.628983439644799e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026823675259947777,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22746819257736206,
      "backward_entropy": 0.018630117177963257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5351370974676684e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026823943480849266,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2274514138698578,
      "backward_entropy": 0.018626220524311066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.849046621937305e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682420052587986,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22743500769138336,
      "backward_entropy": 0.01862264672915141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.139666609466076e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026824455708265305,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22741857171058655,
      "backward_entropy": 0.018619123846292496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.045999932917766e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026824703440070152,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22740253806114197,
      "backward_entropy": 0.025615523258845013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.413504888769239e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026824941858649254,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22738680243492126,
      "backward_entropy": 0.01860640694697698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7667512262705714e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026825185865163803,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2273712158203125,
      "backward_entropy": 0.018609080463647842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.226906483178027e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026825422421097755,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22735600173473358,
      "backward_entropy": 0.01860388120015462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.004969014204107e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026825645938515663,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.227341428399086,
      "backward_entropy": 0.025605671107769012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4047076042043045e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682586759328842,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22732725739479065,
      "backward_entropy": 0.01859960953394572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.671771628432907e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026826074346899986,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2273133397102356,
      "backward_entropy": 0.018596737335125606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.710128294187598e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682628110051155,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22729986906051636,
      "backward_entropy": 0.01859389990568161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.660135578480549e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026826487854123116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22728675603866577,
      "backward_entropy": 0.018590965618689854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.767078305827454e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026826685294508934,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22727414965629578,
      "backward_entropy": 0.018597758064667385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8168655262561515e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026826882734894753,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22726160287857056,
      "backward_entropy": 0.01859673112630844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.864020279957913e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026827070862054825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22724926471710205,
      "backward_entropy": 0.01858297735452652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9623493901453912e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268272552639246,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22723720967769623,
      "backward_entropy": 0.018595059712727863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1972304239170626e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026827439665794373,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22722533345222473,
      "backward_entropy": 0.018577969322601955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.462465999997221e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682761661708355,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22721385955810547,
      "backward_entropy": 0.018575566510359447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6638818124192767e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026827791705727577,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22720269858837128,
      "backward_entropy": 0.01857307304938634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9542536392691545e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02682795375585556,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22719186544418335,
      "backward_entropy": 0.018591692050298054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.713870369712822e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026828113943338394,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22718146443367004,
      "backward_entropy": 0.018568526953458786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.737812090141233e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02682826854288578,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.227171391248703,
      "backward_entropy": 0.018590038021405537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5266577975125983e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026828421279788017,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22716158628463745,
      "backward_entropy": 0.025576968987782795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.15989123514737e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026828566566109657,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2271520495414734,
      "backward_entropy": 0.01856226722399394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.399865413986845e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02682870253920555,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22714287042617798,
      "backward_entropy": 0.018587951858838398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.726583286654204e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026828831061720848,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2271338403224945,
      "backward_entropy": 0.01855854069193204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0607165677356534e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026828963309526443,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22712492942810059,
      "backward_entropy": 0.018556715299685795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0259065675199963e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682908996939659,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22711634635925293,
      "backward_entropy": 0.018554996699094772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.024035009322688e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02682921104133129,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22710804641246796,
      "backward_entropy": 0.025569116075833637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0029826626123395e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026829326525330544,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22710004448890686,
      "backward_entropy": 0.018551766872406006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.252038242062554e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026829438284039497,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22709229588508606,
      "backward_entropy": 0.018585070967674255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1514095604070462e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026829546317458153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22708484530448914,
      "backward_entropy": 0.018548574298620224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.563112831121543e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026829656213521957,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22707757353782654,
      "backward_entropy": 0.018547024577856064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.63843308959622e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026829762384295464,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22707054018974304,
      "backward_entropy": 0.01854550962646802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.078457540250383e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682986855506897,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22706374526023865,
      "backward_entropy": 0.01854405676325162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.757621238444699e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026829976588487625,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22705718874931335,
      "backward_entropy": 0.018542592724164326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.918645340192597e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026830079033970833,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22705085575580597,
      "backward_entropy": 0.018541183322668076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.258003056951566e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683018147945404,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2270447015762329,
      "backward_entropy": 0.01853979378938675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.521224127529422e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683028019964695,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22703877091407776,
      "backward_entropy": 0.018580748389164608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.383845746109728e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683037333190441,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2270330786705017,
      "backward_entropy": 0.018537191053231556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.018403953727102e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026830462738871574,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22702747583389282,
      "backward_entropy": 0.018579949935277302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9377905522997025e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683054842054844,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2270219922065735,
      "backward_entropy": 0.01857958237330119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.859500222664792e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026830634102225304,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22701682150363922,
      "backward_entropy": 0.018579181283712387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0898972909199074e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683071792125702,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2270117700099945,
      "backward_entropy": 0.01853253444035848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7946974771330133e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026830799877643585,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2270069718360901,
      "backward_entropy": 0.018531424303849537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1383974601340014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026830879971385002,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2270023077726364,
      "backward_entropy": 0.025550775229930878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.812774710037047e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683095447719097,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269977480173111,
      "backward_entropy": 0.01852932075659434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.102375103480881e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683102712035179,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269933521747589,
      "backward_entropy": 0.018528377016385395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9396342142717913e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831097900867462,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22698906064033508,
      "backward_entropy": 0.01852742334206899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6374102617410244e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026831166818737984,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2269849330186844,
      "backward_entropy": 0.025547762711842854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6095619887200883e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026831235736608505,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22698090970516205,
      "backward_entropy": 0.01857617621620496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.608315753604984e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831302791833878,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22697702050209045,
      "backward_entropy": 0.01852465296785037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9876088117598556e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268313679844141,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22697317600250244,
      "backward_entropy": 0.01857547089457512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2025710677553434e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831429451704025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22696943581104279,
      "backward_entropy": 0.018522908290227253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6982072565951967e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683149091899395,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269657999277115,
      "backward_entropy": 0.018522121012210846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.71727810993616e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831548660993576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22696226835250854,
      "backward_entropy": 0.018521322558323543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4792185538681224e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026831604540348053,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22695887088775635,
      "backward_entropy": 0.025542822976907093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2706466350209666e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683165669441223,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22695553302764893,
      "backward_entropy": 0.018519823749860127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3258297713036882e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683170512318611,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22695229947566986,
      "backward_entropy": 0.01857384170095126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.477174671701505e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831751689314842,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22694915533065796,
      "backward_entropy": 0.01851852983236313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.22245703804947e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026831796392798424,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22694620490074158,
      "backward_entropy": 0.01857348034779231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.172954378300346e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831839233636856,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22694337368011475,
      "backward_entropy": 0.018517302970091503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9972508021674e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683188021183014,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22694069147109985,
      "backward_entropy": 0.018573203434546787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.293645805679262e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026831919327378273,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22693805396556854,
      "backward_entropy": 0.025539507468541462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634809549017518e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831956580281258,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22693553566932678,
      "backward_entropy": 0.018515693644682567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.942840519106539e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026831991970539093,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22693310678005219,
      "backward_entropy": 0.018515204389890034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.71312114061584e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683202549815178,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22693081200122833,
      "backward_entropy": 0.018514777223269146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.643674967359402e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832055300474167,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22692859172821045,
      "backward_entropy": 0.0185143214960893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.19133970758412e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832085102796555,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269265204668045,
      "backward_entropy": 0.018513915439446766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.088603529657121e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832114905118942,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22692450881004333,
      "backward_entropy": 0.01851351062456767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.434304230471753e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683214284479618,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22692254185676575,
      "backward_entropy": 0.025537048776944477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.334768502507359e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683216892182827,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22692067921161652,
      "backward_entropy": 0.025536743303140003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.115221088341059e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683219499886036,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22691887617111206,
      "backward_entropy": 0.018512340883413952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7999785718056955e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683222107589245,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22691713273525238,
      "backward_entropy": 0.025536110003789265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7688010934289196e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683224529027939,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22691543400287628,
      "backward_entropy": 0.018571995198726654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0209363899302843e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683226764202118,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22691377997398376,
      "backward_entropy": 0.018511351197957993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.148292648802453e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683228999376297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269122302532196,
      "backward_entropy": 0.018511029581228893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.966291390293918e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683231048285961,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22691071033477783,
      "backward_entropy": 0.018571805208921432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.905449036916252e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832330971956253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22690925002098083,
      "backward_entropy": 0.018510440985361736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3012481165096688e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832351461052895,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22690783441066742,
      "backward_entropy": 0.018510134269793827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4272233645206143e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832371950149536,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269064337015152,
      "backward_entropy": 0.018509843697150547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7657900741596677e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683239057660103,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22690510749816895,
      "backward_entropy": 0.02553415795167287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.609100763744209e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683240920305252,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22690385580062866,
      "backward_entropy": 0.025533969203631084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5182766333055042e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832425966858864,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22690263390541077,
      "backward_entropy": 0.018509088704983395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8462661444118567e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832442730665207,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22690151631832123,
      "backward_entropy": 0.018508878846963246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.634796547023143e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268324576318264,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269003987312317,
      "backward_entropy": 0.0185086727142334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1507334818361414e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832472532987595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22689929604530334,
      "backward_entropy": 0.018508462856213253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1233191798964981e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683248743414879,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22689828276634216,
      "backward_entropy": 0.018508216987053554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.016304409517943e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832502335309982,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22689732909202576,
      "backward_entropy": 0.018508050590753555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1262123678079661e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832515373826027,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22689640522003174,
      "backward_entropy": 0.018507864326238632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.363457564859345e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683252841234207,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268955111503601,
      "backward_entropy": 0.018507690479358036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0025517127587591e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832541450858116,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22689467668533325,
      "backward_entropy": 0.018571255107720692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907707555432353e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683255448937416,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22689388692378998,
      "backward_entropy": 0.01850731795032819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.45321813155897e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832567527890205,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268931269645691,
      "backward_entropy": 0.01850714534521103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.782000466249883e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268325787037611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.226892352104187,
      "backward_entropy": 0.018506986399491627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.202319807220192e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832589879631996,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268916666507721,
      "backward_entropy": 0.018506867190202076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.683230597242073e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683260105550289,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22689098119735718,
      "backward_entropy": 0.01850669210155805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6742067044979194e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832612231373787,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22689032554626465,
      "backward_entropy": 0.018506541848182678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1478622253853246e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832623407244682,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22688966989517212,
      "backward_entropy": 0.01857093224922816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0224641395525396e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683263272047043,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22688907384872437,
      "backward_entropy": 0.025531309346357983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.098171046962307e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832642033696175,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268884778022766,
      "backward_entropy": 0.01850614696741104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6549391069229387e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683265134692192,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22688791155815125,
      "backward_entropy": 0.018506011615196865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.108032231580182e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832660660147667,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22688736021518707,
      "backward_entropy": 0.018570820490519207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.369224188531916e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832668110728264,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22688686847686768,
      "backward_entropy": 0.018505809207757313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7234165145273437e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683267556130886,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22688637673854828,
      "backward_entropy": 0.01857079565525055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6635524008611355e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026832683011889458,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22688591480255127,
      "backward_entropy": 0.025530755519866943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.518104302851043e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832690462470055,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22688546776771545,
      "backward_entropy": 0.018570775787035625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.439938384668494e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683269791305065,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22688508033752441,
      "backward_entropy": 0.018570785721143086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.052045289246962e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268327035009861,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.226884663105011,
      "backward_entropy": 0.018505337337652843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1394185978351743e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832709088921547,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22688430547714233,
      "backward_entropy": 0.0185052752494812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8940724544336263e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832714676856995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268839180469513,
      "backward_entropy": 0.018505179633696873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7547151287544693e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832720264792442,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22688357532024384,
      "backward_entropy": 0.018505117545525234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3945403054549388e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683272585272789,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22688323259353638,
      "backward_entropy": 0.01857073853413264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4397350867056957e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832731440663338,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268829047679901,
      "backward_entropy": 0.018504958599805832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3639400719966943e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832737028598785,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22688257694244385,
      "backward_entropy": 0.018504916379849117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1279922773610451e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026832740753889084,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22688230872154236,
      "backward_entropy": 0.02553001542886098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0900265579039115e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832744479179382,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22688201069831848,
      "backward_entropy": 0.01850477357705434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0381683068771963e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683274820446968,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.226881742477417,
      "backward_entropy": 0.01857071618239085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.815607882046606e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683275192975998,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268814742565155,
      "backward_entropy": 0.01850464567542076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.061523087439127e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832755655050278,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2268812358379364,
      "backward_entropy": 0.01857069383064906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527472061814478e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832759380340576,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2268809825181961,
      "backward_entropy": 0.01857069383064906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3279124990222044e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832763105630875,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268807291984558,
      "backward_entropy": 0.01850452522436778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.476795988419326e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832766830921173,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22688047587871552,
      "backward_entropy": 0.018570701281229656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.664141156103142e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683277055621147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22688028216362,
      "backward_entropy": 0.018504414707422256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.358970156521536e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683277428150177,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2268800586462021,
      "backward_entropy": 0.018570701281229656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8428887566842604e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683277800679207,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687985002994537,
      "backward_entropy": 0.025529585778713226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.582339840908389e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832779869437218,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687967121601105,
      "backward_entropy": 0.018570701281229656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0285570435116824e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026832781732082367,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687949240207672,
      "backward_entropy": 0.02552948147058487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.740126430784585e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832783594727516,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2268793284893036,
      "backward_entropy": 0.01857069383064906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.435644657656667e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832785457372665,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687917947769165,
      "backward_entropy": 0.018504194915294647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1656952614866896e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832787320017815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687901556491852,
      "backward_entropy": 0.018504172563552856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8537101570691448e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832789182662964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687888145446777,
      "backward_entropy": 0.018504150211811066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7507311983754335e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026832791045308113,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687873244285583,
      "backward_entropy": 0.02552931010723114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.458612868849741e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832792907953262,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687864303588867,
      "backward_entropy": 0.01857064664363861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1935306904197205e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683279477059841,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687846422195435,
      "backward_entropy": 0.018504044661919277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.043414326635684e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683279663324356,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687837481498718,
      "backward_entropy": 0.025529203315575916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8660415435078903e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683279849588871,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687825560569763,
      "backward_entropy": 0.025529180963834126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7328147805528715e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683280035853386,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687813639640808,
      "backward_entropy": 0.0185039925078551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6094077182060573e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683280222117901,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687804698944092,
      "backward_entropy": 0.01857064664363861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4088072930462658e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832804083824158,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687798738479614,
      "backward_entropy": 0.01850391924381256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3561134437622968e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832805946469307,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268778681755066,
      "backward_entropy": 0.0185039018591245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2453540421120124e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026832807809114456,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687780857086182,
      "backward_entropy": 0.025529106458028156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0768914648906502e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832809671759605,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687773406505585,
      "backward_entropy": 0.01850387454032898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0682157380870194e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026832811534404755,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687765955924988,
      "backward_entropy": 0.01857069383064906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.64384128110396e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832813397049904,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268775999546051,
      "backward_entropy": 0.018503855913877487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15312262147927e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832815259695053,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687754034996033,
      "backward_entropy": 0.018503844738006592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.605578389302536e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026832817122340202,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687751054763794,
      "backward_entropy": 0.018503833562135696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.629097353856196e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683281898498535,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687740623950958,
      "backward_entropy": 0.01857069383064906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.055618311824219e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268328208476305,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2268773764371872,
      "backward_entropy": 0.01857069383064906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.020233283583366e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683282271027565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268773317337036,
      "backward_entropy": 0.018503811210393906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.715037332265638e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687727212905884,
      "backward_entropy": 0.025528947512308758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.190514684727532e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687724232673645,
      "backward_entropy": 0.01850380003452301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.537046376957733e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687718272209167,
      "backward_entropy": 0.018503788858652115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.699387545770151e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2268771529197693,
      "backward_entropy": 0.018570706248283386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.35498748174723e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268770933151245,
      "backward_entropy": 0.018503739188114803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.348095217210357e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687707841396332,
      "backward_entropy": 0.018570706248283386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.843680929094262e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687706351280212,
      "backward_entropy": 0.02552885313828786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.185434138686105e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687703371047974,
      "backward_entropy": 0.018503726770480473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.751221472863108e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687700390815735,
      "backward_entropy": 0.018503715594609577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0036062526050955e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687697410583496,
      "backward_entropy": 0.018503715594609577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.60925503425824e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687694430351257,
      "backward_entropy": 0.018503710627555847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.539763954700902e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687691450119019,
      "backward_entropy": 0.018503704418738682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4294166678373585e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687691450119019,
      "backward_entropy": 0.018503699451684952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.163744738936657e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2268768697977066,
      "backward_entropy": 0.025528813401858013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0302337588873343e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268768548965454,
      "backward_entropy": 0.018503693242867787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7293189102929318e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2268768548965454,
      "backward_entropy": 0.01857071618239085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.660467319197778e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687683999538422,
      "backward_entropy": 0.01850368206699689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.482902689531329e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687682509422302,
      "backward_entropy": 0.01850368206699689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6681411807439872e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687682509422302,
      "backward_entropy": 0.018503674616416294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.553388528918731e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687682509422302,
      "backward_entropy": 0.018503674616416294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4275514104156173e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687682509422302,
      "backward_entropy": 0.018570723632971447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3250911479190108e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687679529190063,
      "backward_entropy": 0.018503674616416294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0629719326971099e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687679529190063,
      "backward_entropy": 0.018570723632971447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0268763617204968e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687679529190063,
      "backward_entropy": 0.018503670891125996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29558643999917e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687678039073944,
      "backward_entropy": 0.018503670891125996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.636380582378479e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687679529190063,
      "backward_entropy": 0.018503670891125996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.913048077374697e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687678039073944,
      "backward_entropy": 0.018503670891125996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.009237717487849e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22687675058841705,
      "backward_entropy": 0.02552870164314906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.073452934491797e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22687678039073944,
      "backward_entropy": 0.01850365847349167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71978045324795e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268328245729208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687676548957825,
      "backward_entropy": 0.018570728600025177,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.7347648199338436e-08,
    "avg_log_Z": 0.026832730378955602,
    "success_rate": 1.0,
    "avg_reward": 48.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.25,
      "2": 0.6
    },
    "avg_forward_entropy": 0.22688287988305092,
    "avg_backward_entropy": 0.01957527127116919,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}