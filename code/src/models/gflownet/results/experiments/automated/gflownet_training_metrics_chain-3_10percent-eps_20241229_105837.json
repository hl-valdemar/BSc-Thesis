{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2300866444905599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2300866444905599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2300866444905599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2300866444905599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2300866444905599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2300866444905599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2307637333869934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.2300866444905599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39466667175293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738338112831116,
      "backward_entropy": 0.22978941599527994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.390114784240723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27384766936302185,
      "backward_entropy": 0.23073871930440268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776355743408203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00019999966025352478,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738609313964844,
      "backward_entropy": 0.23071253299713135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.771045684814453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0003000770811922848,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738743722438812,
      "backward_entropy": 0.2299679716428121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.15489387512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00040019224979914725,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738886773586273,
      "backward_entropy": 0.22953681151072183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.888252258300781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005004220292903483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739032208919525,
      "backward_entropy": 0.23062896728515625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.979339599609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006006380426697433,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27391648292541504,
      "backward_entropy": 0.2294038931528727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.492707252502441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007005857769399881,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739275097846985,
      "backward_entropy": 0.22980773448944092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.488139152526855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008005183190107346,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27393895387649536,
      "backward_entropy": 0.22926185528437296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869027137756348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009004392195492983,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739505469799042,
      "backward_entropy": 0.2297192613283793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73339557647705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010004742071032524,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27396273612976074,
      "backward_entropy": 0.22967259089152017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.604382514953613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001100543886423111,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27397435903549194,
      "backward_entropy": 0.2296247680981954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.476701736450195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012006207834929228,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739865183830261,
      "backward_entropy": 0.22957555452982584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.489789962768555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013006830122321844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739998400211334,
      "backward_entropy": 0.23035955429077148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.581938743591309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014010657323524356,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27401384711265564,
      "backward_entropy": 0.22879215081532797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.334095001220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015013506636023521,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740258276462555,
      "backward_entropy": 0.22870721419652304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46137809753418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016015119617804885,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740382254123688,
      "backward_entropy": 0.23023855686187744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704971313476562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017019429942592978,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27405017614364624,
      "backward_entropy": 0.23019532362620035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447301864624023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018023602897301316,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740623950958252,
      "backward_entropy": 0.22925448417663574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.072461128234863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0019030036637559533,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27407392859458923,
      "backward_entropy": 0.22834626833597818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.431026458740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0020037346985191107,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27408576011657715,
      "backward_entropy": 0.2282509207725525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30790901184082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002104267245158553,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27409628033638,
      "backward_entropy": 0.2300074895222982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.799137115478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0022046060767024755,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27410656213760376,
      "backward_entropy": 0.22805879513422647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6624174118042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002304557478055358,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741156220436096,
      "backward_entropy": 0.22894748051961264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.656968116760254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024045039899647236,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741231918334961,
      "backward_entropy": 0.22984925905863443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788486480712891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002504445146769285,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27412939071655273,
      "backward_entropy": 0.22979082663853964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.40160083770752,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026040447410196066,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27413445711135864,
      "backward_entropy": 0.22873997688293457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.781692504882812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027035970706492662,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741384506225586,
      "backward_entropy": 0.22966718673706055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.276829719543457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002803311450406909,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741433084011078,
      "backward_entropy": 0.22960209846496582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.64268970489502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002902938751503825,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741483449935913,
      "backward_entropy": 0.22734737396240234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12077522277832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003002650337293744,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741538882255554,
      "backward_entropy": 0.2272366682688395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.872834205627441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031026159413158894,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741585969924927,
      "backward_entropy": 0.2271231214205424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25771713256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003202710533514619,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741628587245941,
      "backward_entropy": 0.22700679302215576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.125131607055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0033026610035449266,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27416709065437317,
      "backward_entropy": 0.22688760360081991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35960865020752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0034024124033749104,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27417057752609253,
      "backward_entropy": 0.2291612227757772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.168563842773438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035020827781409025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741728127002716,
      "backward_entropy": 0.22907882928848267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840757369995117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036024488508701324,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741730213165283,
      "backward_entropy": 0.22791834672292074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469429969787598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003702887799590826,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741730213165283,
      "backward_entropy": 0.22890440622965494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.682552337646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003803221508860588,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741726040840149,
      "backward_entropy": 0.22624319791793823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.291935920715332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0039035051595419645,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741692066192627,
      "backward_entropy": 0.22871865828831991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.048184394836426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004004053771495819,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27416422963142395,
      "backward_entropy": 0.2286207675933838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.040182113647461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0041047376580536366,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27415865659713745,
      "backward_entropy": 0.2258146603902181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.51949691772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004205536562949419,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27415239810943604,
      "backward_entropy": 0.2256651520729065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.769834518432617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004306673537939787,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274146169424057,
      "backward_entropy": 0.22551302115122476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.275716781616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004407713655382395,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741379737854004,
      "backward_entropy": 0.2253564198811849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.909974575042725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004508418031036854,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274127334356308,
      "backward_entropy": 0.22519318262736002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.514055252075195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004608647897839546,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27411454916000366,
      "backward_entropy": 0.22501987218856812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09177303314209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004708781372755766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741008996963501,
      "backward_entropy": 0.2278417150179545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827216148376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004809095524251461,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27408555150032043,
      "backward_entropy": 0.22465888659159342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.716882705688477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004909413401037455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27406787872314453,
      "backward_entropy": 0.22758611043294272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.77307653427124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005009709857404232,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27404871582984924,
      "backward_entropy": 0.22745231787363687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.238641738891602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005109534598886967,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27402904629707336,
      "backward_entropy": 0.227315624554952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.52090072631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005210156086832285,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27400854229927063,
      "backward_entropy": 0.223879873752594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.846792697906494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005311131943017244,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739872336387634,
      "backward_entropy": 0.22702685991923013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35175895690918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005411558318883181,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739642262458801,
      "backward_entropy": 0.22582491238911948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30788803100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005511811468750238,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739420235157013,
      "backward_entropy": 0.22325124343236288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.34289026260376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005611845292150974,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739187180995941,
      "backward_entropy": 0.2255252202351888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456912994384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005711161065846682,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738935649394989,
      "backward_entropy": 0.22281217575073242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7138237953186035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005810502450913191,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273870050907135,
      "backward_entropy": 0.22521271308263144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.528569221496582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005909441038966179,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738463878631592,
      "backward_entropy": 0.22605534394582114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606790542602539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006008927244693041,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27382057905197144,
      "backward_entropy": 0.22587905327479044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115527153015137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006108442787081003,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737935781478882,
      "backward_entropy": 0.2218697468439738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.195167541503906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006208307109773159,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737678587436676,
      "backward_entropy": 0.22551204760869345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261846542358398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006307901348918676,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737393379211426,
      "backward_entropy": 0.22436372439066568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.200445175170898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006407856475561857,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737092971801758,
      "backward_entropy": 0.22512425978978476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.812389373779297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006508057005703449,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736758589744568,
      "backward_entropy": 0.22399723529815674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32878303527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006608348339796066,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27364373207092285,
      "backward_entropy": 0.22055168946584067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92060661315918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006708452478051186,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736111283302307,
      "backward_entropy": 0.2245012124379476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.306943893432617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00680873217061162,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27357855439186096,
      "backward_entropy": 0.22428526480992636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.220035552978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006908814888447523,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2735452353954315,
      "backward_entropy": 0.21969387928644815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.007986545562744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007008707150816917,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2735130488872528,
      "backward_entropy": 0.21939754486083984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.815960884094238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0071077183820307255,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27348044514656067,
      "backward_entropy": 0.22361469268798828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.466471672058105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007206936366856098,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734455466270447,
      "backward_entropy": 0.22338197628657022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.992635726928711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007306152489036322,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734096944332123,
      "backward_entropy": 0.22314369678497314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.767695426940918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007405636832118034,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27337175607681274,
      "backward_entropy": 0.21814433733622232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.559069633483887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007504166103899479,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733350694179535,
      "backward_entropy": 0.21781373023986816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.81415843963623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007602295838296413,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27329927682876587,
      "backward_entropy": 0.217476487159729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.537930965423584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007700787857174873,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27326399087905884,
      "backward_entropy": 0.2214144468307495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.056034088134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00779887568205595,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2732293903827667,
      "backward_entropy": 0.2167835235595703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776496887207031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007897499017417431,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27319639921188354,
      "backward_entropy": 0.22091156244277954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.505148410797119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00799641851335764,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27316340804100037,
      "backward_entropy": 0.22132188081741333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420561790466309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00809487234801054,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2731308043003082,
      "backward_entropy": 0.21569999059041342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.067672729492188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00819345097988844,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27309921383857727,
      "backward_entropy": 0.22011677424112955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.127058029174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008291871286928654,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730640172958374,
      "backward_entropy": 0.21494150161743164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.458845615386963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008390231989324093,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730278968811035,
      "backward_entropy": 0.21455017725626627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426780700683594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008488166145980358,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27299249172210693,
      "backward_entropy": 0.21927688519159952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.277756690979004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00858626700937748,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729553282260895,
      "backward_entropy": 0.2189856767654419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1192626953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008684420958161354,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2729157507419586,
      "backward_entropy": 0.219196617603302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.543879508972168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008782058954238892,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2728840708732605,
      "backward_entropy": 0.21291124820709229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.096575736999512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008879420347511768,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27285364270210266,
      "backward_entropy": 0.21248501539230347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.330016136169434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008977447636425495,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27282223105430603,
      "backward_entropy": 0.2182100017865499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.035748481750488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009075052104890347,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727937698364258,
      "backward_entropy": 0.21161333719889322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27047061920166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009173193015158176,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727600038051605,
      "backward_entropy": 0.21116379896799722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.613140106201172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009271441027522087,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727266550064087,
      "backward_entropy": 0.21677056948343912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.873648643493652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009369409643113613,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2726956307888031,
      "backward_entropy": 0.21641470988591513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.643085479736328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009466657415032387,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27266404032707214,
      "backward_entropy": 0.21642200152079263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256962776184082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009564271196722984,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726254463195801,
      "backward_entropy": 0.21604013442993164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.873876094818115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009662022814154625,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.272584468126297,
      "backward_entropy": 0.20878642797470093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.316561698913574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009759709239006042,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2725451588630676,
      "backward_entropy": 0.20828711986541748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.158795356750488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009856953285634518,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27250391244888306,
      "backward_entropy": 0.2077782154083252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.006142616271973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009954358451068401,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27246323227882385,
      "backward_entropy": 0.21414756774902344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.391267776489258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010051805526018143,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27242207527160645,
      "backward_entropy": 0.20673503478368124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870772361755371,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010149458423256874,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723737955093384,
      "backward_entropy": 0.2133335073788961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.265605926513672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010247668251395226,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723250389099121,
      "backward_entropy": 0.21313440799713135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.381807327270508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01034599356353283,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27227532863616943,
      "backward_entropy": 0.21248241265614828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.778487205505371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01044450793415308,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2722252607345581,
      "backward_entropy": 0.20453409353892008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.759005069732666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010542807169258595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27217423915863037,
      "backward_entropy": 0.21174395084381104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603173732757568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010640905238687992,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.272122323513031,
      "backward_entropy": 0.21125845114390054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.510118007659912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010738717392086983,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27206873893737793,
      "backward_entropy": 0.21067400773366293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.799412727355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0108362827450037,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27202004194259644,
      "backward_entropy": 0.2021821935971578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.848929405212402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010933802463114262,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27197471261024475,
      "backward_entropy": 0.201572855313619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.487508296966553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011031254194676876,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2719256579875946,
      "backward_entropy": 0.20095189412434897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.227967739105225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011128460057079792,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2718779146671295,
      "backward_entropy": 0.2087279955546061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.574710845947266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011225231923162937,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271825909614563,
      "backward_entropy": 0.20816675821940103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.773168563842773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011323093436658382,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2717636525630951,
      "backward_entropy": 0.20770692825317383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.403524875640869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011421465314924717,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2716984748840332,
      "backward_entropy": 0.20703842242558798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.343433380126953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011519450694322586,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2716354727745056,
      "backward_entropy": 0.20663986603418985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.958844184875488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011616427451372147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2715790867805481,
      "backward_entropy": 0.20588195323944092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.688660621643066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011713511310517788,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27152082324028015,
      "backward_entropy": 0.19631834824879965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827360153198242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011810468509793282,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27145564556121826,
      "backward_entropy": 0.20467841625213623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.081794738769531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011908045038580894,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27138131856918335,
      "backward_entropy": 0.20441106955210367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.539429664611816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012005208060145378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713225483894348,
      "backward_entropy": 0.20342115561167398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.378507137298584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01210157573223114,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27126944065093994,
      "backward_entropy": 0.19340387980143228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.554327487945557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012197787873446941,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271218866109848,
      "backward_entropy": 0.20215052366256714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.329270362854004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012293899431824684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2711598873138428,
      "backward_entropy": 0.20149536927541098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.323449611663818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01238985825330019,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27110394835472107,
      "backward_entropy": 0.19108972946802774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.896681308746338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01248565036803484,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27104681730270386,
      "backward_entropy": 0.2001572847366333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.150738716125488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012581627815961838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2709808647632599,
      "backward_entropy": 0.19946527481079102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.680628299713135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012677288614213467,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27091050148010254,
      "backward_entropy": 0.19950870672861734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.652535438537598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012772384099662304,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2708422839641571,
      "backward_entropy": 0.18782140811284384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.475287437438965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012867612764239311,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2707687020301819,
      "backward_entropy": 0.19819863637288412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.447396278381348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01296220999211073,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27069878578186035,
      "backward_entropy": 0.19656709829966226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.135961532592773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013057511299848557,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2706177234649658,
      "backward_entropy": 0.18522443373998007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.370389461517334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013151957653462887,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2705439329147339,
      "backward_entropy": 0.19616073369979858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.646134853363037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013246486894786358,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2704734206199646,
      "backward_entropy": 0.1942683458328247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.016708374023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01334057841449976,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27040430903434753,
      "backward_entropy": 0.18248164653778076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.712974548339844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013435205444693565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27032962441444397,
      "backward_entropy": 0.19268129269282022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.250250816345215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013530058786273003,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27024364471435547,
      "backward_entropy": 0.19185837109883627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2384934425354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01362486183643341,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27015674114227295,
      "backward_entropy": 0.17962414026260376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.492287635803223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013718999922275543,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2700845003128052,
      "backward_entropy": 0.19172358512878418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.147403717041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013812622986733913,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2700093388557434,
      "backward_entropy": 0.17765796184539795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.112885475158691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013906270265579224,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26993224024772644,
      "backward_entropy": 0.19015955924987793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.942390441894531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013999952003359795,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2698579430580139,
      "backward_entropy": 0.18935638666152954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2281599044799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014093569479882717,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26978978514671326,
      "backward_entropy": 0.17461560169855753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.822024345397949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01418666634708643,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2697344422340393,
      "backward_entropy": 0.18770907322565714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5026373863220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014280349016189575,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2696712613105774,
      "backward_entropy": 0.17253947257995605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4607343673706055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01437428593635559,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2695940434932709,
      "backward_entropy": 0.18384035428365073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.61428689956665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014468427747488022,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26950129866600037,
      "backward_entropy": 0.18286128838857016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1870832443237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014562179334461689,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2694035470485687,
      "backward_entropy": 0.16929725805918375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.42508602142334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014655336737632751,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.269314706325531,
      "backward_entropy": 0.1681880553563436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8952460289001465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014748160727322102,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2692362666130066,
      "backward_entropy": 0.1798723340034485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.613207817077637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014840957708656788,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2691495418548584,
      "backward_entropy": 0.16594022512435913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.437291622161865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014933599159121513,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26906952261924744,
      "backward_entropy": 0.18062694867451987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.87824821472168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015025967732071877,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2689945697784424,
      "backward_entropy": 0.1796907385190328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2216997146606445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015117701143026352,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26893168687820435,
      "backward_entropy": 0.17576074600219727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.560021877288818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015209098346531391,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2688714563846588,
      "backward_entropy": 0.1777933438618978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.485720634460449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01530042476952076,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26880478858947754,
      "backward_entropy": 0.16013131539026895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9785261154174805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015391578897833824,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2687213122844696,
      "backward_entropy": 0.1724851131439209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.02053165435791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015482311137020588,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2686464786529541,
      "backward_entropy": 0.17135880390803018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.635298252105713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0155726233497262,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26856350898742676,
      "backward_entropy": 0.17021536827087402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.836912631988525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01566162332892418,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2685084640979767,
      "backward_entropy": 0.17283896605173746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5384202003479,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015751037746667862,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2684400975704193,
      "backward_entropy": 0.1679327686627706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.362396717071533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01584061048924923,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2683609426021576,
      "backward_entropy": 0.17076178391774496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.081660270690918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015929443761706352,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26828432083129883,
      "backward_entropy": 0.16971063613891602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.631863594055176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016018185764551163,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2682071328163147,
      "backward_entropy": 0.1643864115079244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8773393630981445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016106467694044113,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2681257426738739,
      "backward_entropy": 0.1631831725438436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.182205677032471,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01619458943605423,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26804935932159424,
      "backward_entropy": 0.1475870410601298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.532628059387207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016282791271805763,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26796847581863403,
      "backward_entropy": 0.1653741200764974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.586750030517578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016371386125683784,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2678874731063843,
      "backward_entropy": 0.1595145066579183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.110054969787598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016460366547107697,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2678016424179077,
      "backward_entropy": 0.16307246685028076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0026679039001465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016549397259950638,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2677312195301056,
      "backward_entropy": 0.1421555777390798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.422642707824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016638336703181267,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2676621079444885,
      "backward_entropy": 0.14078330993652344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.335074424743652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01672668196260929,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26758915185928345,
      "backward_entropy": 0.15951232115427652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.45008659362793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016815252602100372,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2675037980079651,
      "backward_entropy": 0.15315871437390646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.520115852355957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016903316602110863,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26741719245910645,
      "backward_entropy": 0.1518555482228597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.899893283843994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016991756856441498,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26730477809906006,
      "backward_entropy": 0.13520320256551108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.191633224487305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017080063000321388,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26718077063560486,
      "backward_entropy": 0.154637078444163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.427289962768555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017168620601296425,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2670678198337555,
      "backward_entropy": 0.1478317379951477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.306568622589111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01725664921104908,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2669462561607361,
      "backward_entropy": 0.1521372894446055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1354079246521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01734416000545025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.266828715801239,
      "backward_entropy": 0.1451171338558197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.915644645690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017431899905204773,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26669904589653015,
      "backward_entropy": 0.1281011402606964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.320481300354004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01751888543367386,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26658928394317627,
      "backward_entropy": 0.12668039401372275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.192887306213379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017605463042855263,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26647117733955383,
      "backward_entropy": 0.1252544621626536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.987227916717529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017692485824227333,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.266343355178833,
      "backward_entropy": 0.12382085124651591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.912810325622559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017778830602765083,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26621320843696594,
      "backward_entropy": 0.13823644320170084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.449240684509277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017864588648080826,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2660996913909912,
      "backward_entropy": 0.12094312906265259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.982486248016357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017950262874364853,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26598164439201355,
      "backward_entropy": 0.11949832240740459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.424459934234619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018035385757684708,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26584872603416443,
      "backward_entropy": 0.1405948797861735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.723670959472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01811954379081726,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26571568846702576,
      "backward_entropy": 0.11659876505533855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.835577964782715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018203234300017357,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26560574769973755,
      "backward_entropy": 0.13129866123199463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.810218334197998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018286503851413727,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26548683643341064,
      "backward_entropy": 0.1299094557762146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.267845630645752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018369492143392563,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2653852701187134,
      "backward_entropy": 0.11228940884272258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.672910690307617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01845259591937065,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26527339220046997,
      "backward_entropy": 0.12711101770401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6273932456970215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018536176532506943,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2651393413543701,
      "backward_entropy": 0.12567725777626038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.448178291320801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018619228154420853,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2650046944618225,
      "backward_entropy": 0.10799516240755717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8899078369140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01870162971317768,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2648681104183197,
      "backward_entropy": 0.12281588713328044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.43914270401001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018782906234264374,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2647373080253601,
      "backward_entropy": 0.12139963110287984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.703650951385498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0188637413084507,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26460567116737366,
      "backward_entropy": 0.1037387748559316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.243342399597168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018943456932902336,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26448550820350647,
      "backward_entropy": 0.12620208660761514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.32275915145874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019022734835743904,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2643694281578064,
      "backward_entropy": 0.11719319224357605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9247066974639893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01910167746245861,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2642454504966736,
      "backward_entropy": 0.1236076553662618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.263633728027344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01917988248169422,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2641097903251648,
      "backward_entropy": 0.11440177758534749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.395907402038574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019257811829447746,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26396188139915466,
      "backward_entropy": 0.12103543678919475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.373034954071045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01933572068810463,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26381877064704895,
      "backward_entropy": 0.11160534620285034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4420104026794434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019413508474826813,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2636537551879883,
      "backward_entropy": 0.11844360828399658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6895928382873535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01949022337794304,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26349076628685,
      "backward_entropy": 0.10880696773529053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4783530235290527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019566340371966362,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2633478343486786,
      "backward_entropy": 0.09124045570691426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.919152021408081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019641654565930367,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26321423053741455,
      "backward_entropy": 0.10607320070266724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.782930374145508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019716735929250717,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.263075053691864,
      "backward_entropy": 0.08855636914571126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.791177272796631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019791537895798683,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.262950599193573,
      "backward_entropy": 0.10336724917093913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5099315643310547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01986604742705822,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26281964778900146,
      "backward_entropy": 0.11065646012624104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.699517011642456,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019940007477998734,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2626936137676239,
      "backward_entropy": 0.08461699883143108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.489647388458252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02001376822590828,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26258230209350586,
      "backward_entropy": 0.08333079020182292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6911780834198,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020087072625756264,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2624753713607788,
      "backward_entropy": 0.09805107116699219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.419990062713623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020160185173153877,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2623554468154907,
      "backward_entropy": 0.10546642541885376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1996138095855713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02023283764719963,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2622343599796295,
      "backward_entropy": 0.0795429249604543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8956093788146973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020304875448346138,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26213058829307556,
      "backward_entropy": 0.07830959061781566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0374114513397217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020375985652208328,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2620457708835602,
      "backward_entropy": 0.10161763429641724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.607922315597534,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020446429029107094,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2619672119617462,
      "backward_entropy": 0.07589754958947499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3063933849334717,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020516986027359962,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.261869341135025,
      "backward_entropy": 0.07470678786436717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7650060653686523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020587267354130745,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2617569863796234,
      "backward_entropy": 0.09783247113227844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4882311820983887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020656690001487732,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.261665016412735,
      "backward_entropy": 0.09658646583557129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0308756828308105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020724916830658913,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2615814208984375,
      "backward_entropy": 0.09536152084668477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.479860544204712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020792780444025993,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2614801526069641,
      "backward_entropy": 0.08547899127006531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.599942684173584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020859573036432266,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.261375367641449,
      "backward_entropy": 0.06898337602615356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6838974952697754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0209256112575531,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2612702250480652,
      "backward_entropy": 0.08311765392621358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.492795467376709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020991044119000435,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26114577054977417,
      "backward_entropy": 0.06680212418238322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9027881622314453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021055733785033226,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2610223591327667,
      "backward_entropy": 0.08079627652963002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8016986846923828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021120375022292137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26088738441467285,
      "backward_entropy": 0.07964466015497844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4165170192718506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021183405071496964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26078560948371887,
      "backward_entropy": 0.07853373388449351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.04416561126709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02124588005244732,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2606840133666992,
      "backward_entropy": 0.08606725931167603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.153383493423462,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021307287737727165,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2605903148651123,
      "backward_entropy": 0.08496463298797607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2694523334503174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02136794850230217,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26050642132759094,
      "backward_entropy": 0.06066406269868215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2197976112365723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021428052335977554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26040661334991455,
      "backward_entropy": 0.07424934208393097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2785842418670654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021487589925527573,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.260292112827301,
      "backward_entropy": 0.05875079333782196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1553587913513184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02154678665101528,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2601734399795532,
      "backward_entropy": 0.08066403369108836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5016956329345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0216054730117321,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2600492537021637,
      "backward_entropy": 0.05689152081807455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.418261766433716,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021664375439286232,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2599219083786011,
      "backward_entropy": 0.07856138547261556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.114457607269287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02172325737774372,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25977015495300293,
      "backward_entropy": 0.06909153362115224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4021599292755127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021781647577881813,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2596108913421631,
      "backward_entropy": 0.05417997141679128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5368316173553467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021840224042534828,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.259453147649765,
      "backward_entropy": 0.06706373393535614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1647019386291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021897394210100174,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2593180537223816,
      "backward_entropy": 0.052440837025642395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.010315179824829,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021954404190182686,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25916510820388794,
      "backward_entropy": 0.051594083507855736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9358575344085693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022011078894138336,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2590138018131256,
      "backward_entropy": 0.050761173168818154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5691564083099365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022067230194807053,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258842408657074,
      "backward_entropy": 0.06319079796473186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6200793981552124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02212231419980526,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2586851119995117,
      "backward_entropy": 0.062260578076044716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6723039150238037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022176552563905716,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2585361897945404,
      "backward_entropy": 0.061351001262664795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8273918628692627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022230084985494614,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25837674736976624,
      "backward_entropy": 0.047597289085388184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3456968069076538,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022283433005213737,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2582206428050995,
      "backward_entropy": 0.04684346914291382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.461115837097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022335706278681755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25810128450393677,
      "backward_entropy": 0.05869633952776591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8004051446914673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02238708920776844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2579724192619324,
      "backward_entropy": 0.05784831941127777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.350282907485962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022438518702983856,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2578338086605072,
      "backward_entropy": 0.05700161059697469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3186761140823364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022489028051495552,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2577117085456848,
      "backward_entropy": 0.06407650808493297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5848718881607056,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022538581863045692,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2575877010822296,
      "backward_entropy": 0.04332915941874186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2744545936584473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022587982937693596,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2574574947357178,
      "backward_entropy": 0.062371671199798584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.386333703994751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022636448964476585,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25731781125068665,
      "backward_entropy": 0.05378027757008871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2175856828689575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022684361785650253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25716179609298706,
      "backward_entropy": 0.05300285418828329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3556039333343506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022731510922312737,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25701940059661865,
      "backward_entropy": 0.05224494139353434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2495896816253662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02277824468910694,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2568625211715698,
      "backward_entropy": 0.05149423082669576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7239568829536438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0228243600577116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25669607520103455,
      "backward_entropy": 0.05075502395629883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9620305299758911,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022868577390909195,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25655266642570496,
      "backward_entropy": 0.05005394419034322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0142197608947754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02291172742843628,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2564147710800171,
      "backward_entropy": 0.049373775720596313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3176714181900024,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022954130545258522,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2562854588031769,
      "backward_entropy": 0.03791676958401998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1085283756256104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02299671433866024,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2561403512954712,
      "backward_entropy": 0.048044443130493164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0994961261749268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023038813844323158,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25597822666168213,
      "backward_entropy": 0.047385637958844505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7611333727836609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023080453276634216,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2557952404022217,
      "backward_entropy": 0.0467328280210495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1403778791427612,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023120705038309097,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2556154429912567,
      "backward_entropy": 0.04610491792360941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.642826497554779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023160960525274277,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2554224729537964,
      "backward_entropy": 0.03537539392709732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9151445627212524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023199638351798058,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.255241721868515,
      "backward_entropy": 0.0448803702990214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.971185564994812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0232376791536808,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25503745675086975,
      "backward_entropy": 0.04429036875565847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8247916102409363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02327539213001728,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25481098890304565,
      "backward_entropy": 0.043703898787498474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6490106582641602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023312371224164963,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25457561016082764,
      "backward_entropy": 0.043129692475001015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8242422342300415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023348182439804077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25435298681259155,
      "backward_entropy": 0.04257854322592417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5468352437019348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023383503779768944,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.254116952419281,
      "backward_entropy": 0.04203501840432485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7774152755737305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02341734804213047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25388163328170776,
      "backward_entropy": 0.041515866915384926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6015464067459106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023450786247849464,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2536344826221466,
      "backward_entropy": 0.041003008683522545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5687341690063477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023483170196413994,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2533828020095825,
      "backward_entropy": 0.04763898253440857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6972660422325134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02351451851427555,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2531319260597229,
      "backward_entropy": 0.0471472442150116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.710222601890564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023545516654849052,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2528756260871887,
      "backward_entropy": 0.030944255491097767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6897284984588623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02357637882232666,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2526240348815918,
      "backward_entropy": 0.04617902636528015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6973098516464233,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02360706962645054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25237664580345154,
      "backward_entropy": 0.038628920912742615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6496521234512329,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023637617006897926,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2521231770515442,
      "backward_entropy": 0.03817132363716761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6092225909233093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023667922243475914,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2518741488456726,
      "backward_entropy": 0.03772045920292536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5783387422561646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023697827011346817,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2516273856163025,
      "backward_entropy": 0.03727797915538152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5899820923805237,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023727290332317352,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25138723850250244,
      "backward_entropy": 0.043824280301729836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5461068153381348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023756293579936028,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25113099813461304,
      "backward_entropy": 0.028699425359567005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4253878593444824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02378460392355919,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25085097551345825,
      "backward_entropy": 0.042943631609280906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5008761882781982,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023811813443899155,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25057265162467957,
      "backward_entropy": 0.042528962095578514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46253734827041626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023838628083467484,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25030818581581116,
      "backward_entropy": 0.02786286175251007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4778214991092682,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023864813148975372,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2500464916229248,
      "backward_entropy": 0.041719516118367515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48285287618637085,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023890715092420578,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24980443716049194,
      "backward_entropy": 0.04132238030433655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44725602865219116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023916369304060936,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24957060813903809,
      "backward_entropy": 0.03408838560183843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43920889496803284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023941529914736748,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2493344247341156,
      "backward_entropy": 0.033731011052926384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5118067860603333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02396630123257637,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24910323321819305,
      "backward_entropy": 0.026615363856156666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5087236166000366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02399117685854435,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24886149168014526,
      "backward_entropy": 0.03303025166193644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44875606894493103,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02401622198522091,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2486129105091095,
      "backward_entropy": 0.02613787353038788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39536619186401367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02404090389609337,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2483437955379486,
      "backward_entropy": 0.03903999676307043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35130611062049866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02406526356935501,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24809661507606506,
      "backward_entropy": 0.03867401679356893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2840580642223358,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024089019745588303,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24786831438541412,
      "backward_entropy": 0.038315740724404655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34368160367012024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024111587554216385,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24764373898506165,
      "backward_entropy": 0.03135153899590174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3023035526275635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02413352206349373,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2474088817834854,
      "backward_entropy": 0.025051650901635487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3560500741004944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0241546593606472,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2471746951341629,
      "backward_entropy": 0.030760188897450764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2567181885242462,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024175507947802544,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24692806601524353,
      "backward_entropy": 0.03702053427696228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2826138138771057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024195244535803795,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24667520821094513,
      "backward_entropy": 0.03020155429840088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30346381664276123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02421431802213192,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2464205026626587,
      "backward_entropy": 0.03644609451293945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2696742117404938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02423303760588169,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24616122245788574,
      "backward_entropy": 0.02419263869524002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31690895557403564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02425106056034565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24589018523693085,
      "backward_entropy": 0.029431370397408802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34307727217674255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02426922507584095,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24562685191631317,
      "backward_entropy": 0.02918173372745514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27726858854293823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024287786334753036,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24536016583442688,
      "backward_entropy": 0.028927383323510487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25256988406181335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024306118488311768,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2450997233390808,
      "backward_entropy": 0.02867770940065384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28018781542778015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02432389371097088,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24483315646648407,
      "backward_entropy": 0.028435205419858296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2903430163860321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024341614916920662,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24456411600112915,
      "backward_entropy": 0.02819397548834483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22255472838878632,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024359414353966713,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2442844808101654,
      "backward_entropy": 0.034331860641638436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2268376648426056,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02437666989862919,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24401473999023438,
      "backward_entropy": 0.02300332486629486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19638794660568237,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02439361996948719,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2437593638896942,
      "backward_entropy": 0.03383863468964895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2423730343580246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024409743025898933,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24350009858608246,
      "backward_entropy": 0.02727358043193817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24445560574531555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024425994604825974,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24324774742126465,
      "backward_entropy": 0.022609777748584747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20398874580860138,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02444237470626831,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24299107491970062,
      "backward_entropy": 0.026838595668474834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18531093001365662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024458352476358414,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24273428320884705,
      "backward_entropy": 0.0223519429564476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20972740650177002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02447371371090412,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.242475688457489,
      "backward_entropy": 0.02642173320055008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16395048797130585,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024488886818289757,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2422029823064804,
      "backward_entropy": 0.03247508406639099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2044689953327179,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02450333721935749,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2419344186782837,
      "backward_entropy": 0.026025469104448955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1846514493227005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024518005549907684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24167069792747498,
      "backward_entropy": 0.025830773015817005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1750185787677765,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024532359093427658,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24139191210269928,
      "backward_entropy": 0.02563874175151189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1576288342475891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02454654686152935,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24111808836460114,
      "backward_entropy": 0.025449884434541065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15227219462394714,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02456049621105194,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24086534976959229,
      "backward_entropy": 0.03146673242251078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15429627895355225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024574201554059982,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24063174426555634,
      "backward_entropy": 0.025089288751284283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14003057777881622,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024587620049715042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24039682745933533,
      "backward_entropy": 0.024915506442387898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14729204773902893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02460053563117981,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2401619553565979,
      "backward_entropy": 0.024748260776201885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11640237271785736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024613207206130028,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23992016911506653,
      "backward_entropy": 0.021182018021742504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12498106062412262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024624910205602646,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23967236280441284,
      "backward_entropy": 0.02443011353413264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11400860548019409,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024636201560497284,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2394292652606964,
      "backward_entropy": 0.02428244799375534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13521136343479156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024646898731589317,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2391912043094635,
      "backward_entropy": 0.030243198076883953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11278587579727173,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0246578399091959,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2389582395553589,
      "backward_entropy": 0.030088141560554504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11200541257858276,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02466830424964428,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2387235164642334,
      "backward_entropy": 0.029939666390419006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11757590621709824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024678420275449753,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2384871542453766,
      "backward_entropy": 0.02979627251625061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10536843538284302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024688737466931343,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2382650077342987,
      "backward_entropy": 0.02359919746716817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10116715729236603,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02469884417951107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23805104196071625,
      "backward_entropy": 0.029505896071592968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09681697189807892,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02470858208835125,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2378341555595398,
      "backward_entropy": 0.02936730533838272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09776493161916733,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024717962369322777,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23761741816997528,
      "backward_entropy": 0.029233646889527638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09631586819887161,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024727188050746918,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23740079998970032,
      "backward_entropy": 0.029102471967538197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08926306664943695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024736346676945686,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23718437552452087,
      "backward_entropy": 0.02298658589522044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0951351672410965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024745244532823563,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23696856200695038,
      "backward_entropy": 0.022871769964694977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07806193083524704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02475426159799099,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23674559593200684,
      "backward_entropy": 0.022754989564418793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07599703222513199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02476280927658081,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23653192818164825,
      "backward_entropy": 0.028599634766578674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0802333652973175,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02477085031569004,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2363194227218628,
      "backward_entropy": 0.028485159079233806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07630123198032379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02477884478867054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23610803484916687,
      "backward_entropy": 0.022437013685703278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07540786266326904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024786772206425667,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23590274155139923,
      "backward_entropy": 0.022334953149159748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07035543024539948,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02479477971792221,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23570558428764343,
      "backward_entropy": 0.02223282555739085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06816717982292175,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02480260841548443,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2355111986398697,
      "backward_entropy": 0.019975580275058746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06283817440271378,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02481040172278881,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2353287935256958,
      "backward_entropy": 0.019928055504957836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06088259816169739,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02481777034699917,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2351478785276413,
      "backward_entropy": 0.02781812349955241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06008489057421684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024824606254696846,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23495706915855408,
      "backward_entropy": 0.021854035556316376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06095827743411064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024831172078847885,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23476457595825195,
      "backward_entropy": 0.021769148608048756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05620906502008438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024837784469127655,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23456910252571106,
      "backward_entropy": 0.027531373004118603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05355997011065483,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844128638505936,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23437079787254333,
      "backward_entropy": 0.01974376415212949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0532304123044014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024850215762853622,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23417648673057556,
      "backward_entropy": 0.0273538480202357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049934107810258865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02485627308487892,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.233986496925354,
      "backward_entropy": 0.027267140646775562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04761814698576927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02486201748251915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23379391431808472,
      "backward_entropy": 0.021366576353708904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04709850624203682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024867400527000427,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23360109329223633,
      "backward_entropy": 0.021295073131720226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04454808682203293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024872656911611557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23340892791748047,
      "backward_entropy": 0.0212250550587972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04337458312511444,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024877654388546944,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.233221173286438,
      "backward_entropy": 0.019583817571401596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0418056920170784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0248824805021286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23303595185279846,
      "backward_entropy": 0.02109380563100179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04171539098024368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024887144565582275,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2328552007675171,
      "backward_entropy": 0.021031399567921955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03935591131448746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024891972541809082,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23267975449562073,
      "backward_entropy": 0.026747281352678936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03756510093808174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02489675022661686,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2324993908405304,
      "backward_entropy": 0.02090393751859665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03470974415540695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02490135468542576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23232561349868774,
      "backward_entropy": 0.02084273099899292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034906622022390366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024905376136302948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23215296864509583,
      "backward_entropy": 0.020788138111432392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03356008976697922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02490934357047081,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23197966814041138,
      "backward_entropy": 0.020734049379825592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03260143846273422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02491314709186554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23181280493736267,
      "backward_entropy": 0.02068232372403145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03139946237206459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02491701766848564,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23164409399032593,
      "backward_entropy": 0.020629594723383587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030040491372346878,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024920783936977386,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23148207366466522,
      "backward_entropy": 0.019420893241961796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028792893514037132,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024924449622631073,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23132294416427612,
      "backward_entropy": 0.019409115115801494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02858986333012581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02492796629667282,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23116645216941833,
      "backward_entropy": 0.020481100926796596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026515528559684753,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02493150904774666,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2310183048248291,
      "backward_entropy": 0.02043360968430837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02512129209935665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024935055524110794,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23086635768413544,
      "backward_entropy": 0.020385312537352245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02576342225074768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024938398972153664,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2307121455669403,
      "backward_entropy": 0.020338254670302074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02366200089454651,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02494182251393795,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23056679964065552,
      "backward_entropy": 0.02599886308113734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023678498342633247,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024945104494690895,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23042255640029907,
      "backward_entropy": 0.02594883491595586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022262437269091606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024948591366410255,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23028260469436646,
      "backward_entropy": 0.020196400582790375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021004678681492805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024952111765742302,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23014453053474426,
      "backward_entropy": 0.020147810379664104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019657712429761887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02495555765926838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23000657558441162,
      "backward_entropy": 0.020099971443414688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020234767347574234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02495875023305416,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22986674308776855,
      "backward_entropy": 0.02574564019838969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01771746203303337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02496190555393696,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2297336906194687,
      "backward_entropy": 0.020010311156511307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01881263591349125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024964867159724236,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22959622740745544,
      "backward_entropy": 0.019967667758464813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01762722060084343,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024967849254608154,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22946593165397644,
      "backward_entropy": 0.019925347218910854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01668921485543251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02497083507478237,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22933951020240784,
      "backward_entropy": 0.01988326758146286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015739673748612404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02497357875108719,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22921565175056458,
      "backward_entropy": 0.019844089945157368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01602822355926037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02497629076242447,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22909262776374817,
      "backward_entropy": 0.0198052575190862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01490542758256197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024979177862405777,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22897562384605408,
      "backward_entropy": 0.019764994581540424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014378312043845654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0249819066375494,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22886142134666443,
      "backward_entropy": 0.019726718465487163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013898844830691814,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024984566494822502,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2287503480911255,
      "backward_entropy": 0.025353121260801952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014119556173682213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024987302720546722,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22864308953285217,
      "backward_entropy": 0.01965157315135002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012512614019215107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02499012090265751,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22854334115982056,
      "backward_entropy": 0.019613475849231083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012783313170075417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024992911145091057,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22844508290290833,
      "backward_entropy": 0.01916357750693957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012534672394394875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024995723739266396,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22835226356983185,
      "backward_entropy": 0.019538318117459614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010772719979286194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024998653680086136,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22826632857322693,
      "backward_entropy": 0.019500109056631725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010765643790364265,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02500152215361595,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2281799018383026,
      "backward_entropy": 0.0191220020254453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010836789384484291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025004466995596886,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22809642553329468,
      "backward_entropy": 0.025054847200711567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009046843275427818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025007421150803566,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2280176728963852,
      "backward_entropy": 0.02501145750284195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010454120114445686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025010187178850174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22793543338775635,
      "backward_entropy": 0.019350430617729824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009230832569301128,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025012977421283722,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2278602123260498,
      "backward_entropy": 0.024929501116275787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009248724207282066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025015641003847122,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22778615355491638,
      "backward_entropy": 0.01928039640188217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007555735297501087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025018254294991493,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2277158498764038,
      "backward_entropy": 0.01924699420730273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007590872701257467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025020869448781013,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22764451801776886,
      "backward_entropy": 0.024812082449595135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007101752795279026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025023285299539566,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2275707721710205,
      "backward_entropy": 0.019182006518046062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007781829684972763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025025712326169014,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22749775648117065,
      "backward_entropy": 0.02474023401737213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007487186696380377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025028228759765625,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22743096947669983,
      "backward_entropy": 0.019118348757425945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0062422361224889755,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025030706077814102,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22736793756484985,
      "backward_entropy": 0.019087036450703938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00639685895293951,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025033140555024147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2273048460483551,
      "backward_entropy": 0.019056200981140137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006478997878730297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025035463273525238,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22724202275276184,
      "backward_entropy": 0.019026632110277813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006551239639520645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025037717074155807,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22718164324760437,
      "backward_entropy": 0.018997992078463238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005563387181609869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02503994107246399,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2271255999803543,
      "backward_entropy": 0.018970039983590443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005268271081149578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025042081251740456,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22706982493400574,
      "backward_entropy": 0.02449825406074524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005910580046474934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025044037029147148,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22701159119606018,
      "backward_entropy": 0.02446859081586202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005464049521833658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025046005845069885,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22695881128311157,
      "backward_entropy": 0.01889289418856303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00467620138078928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025047922506928444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22690874338150024,
      "backward_entropy": 0.018868762999773026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004676678217947483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025049718096852303,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2268575131893158,
      "backward_entropy": 0.018845828870932262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041410839185118675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025051455944776535,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22680741548538208,
      "backward_entropy": 0.01882364849249522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0040412787348032,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025053173303604126,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22675827145576477,
      "backward_entropy": 0.018858227878808975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032844722736626863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025054799392819405,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2267085313796997,
      "backward_entropy": 0.01878076915939649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004536053631454706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02505633793771267,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22665643692016602,
      "backward_entropy": 0.01876051475604375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035641759168356657,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02505774237215519,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2266053855419159,
      "backward_entropy": 0.018741842359304428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00301157939247787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025059210136532784,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22655807435512543,
      "backward_entropy": 0.0188351571559906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00342712108977139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025060560554265976,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22650820016860962,
      "backward_entropy": 0.018704663962125778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035916895139962435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02506193518638611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22646158933639526,
      "backward_entropy": 0.018686602512995403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003304593963548541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025063257664442062,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22641697525978088,
      "backward_entropy": 0.01866926997900009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033914174418896437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025064606219530106,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2263759970664978,
      "backward_entropy": 0.01865192875266075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002687233267351985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02506592497229576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2263374626636505,
      "backward_entropy": 0.018635100374619167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002923614578321576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025067264214158058,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22630107402801514,
      "backward_entropy": 0.02410498509804408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026065767742693424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025068577378988266,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.226266548037529,
      "backward_entropy": 0.018601812422275543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002752145519480109,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025069832801818848,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22623223066329956,
      "backward_entropy": 0.01858600601553917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00270708161406219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025071123614907265,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2262016385793686,
      "backward_entropy": 0.01857014497121175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001674022525548935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025072427466511726,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22617417573928833,
      "backward_entropy": 0.01855432242155075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002199099399149418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025073666125535965,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2261447161436081,
      "backward_entropy": 0.024003406365712483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021098472643643618,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025074878707528114,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.226116344332695,
      "backward_entropy": 0.018524204691251118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024932713713496923,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025076063349843025,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22608911991119385,
      "backward_entropy": 0.02396553506453832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020688867662101984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02507721446454525,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22606399655342102,
      "backward_entropy": 0.018495719879865646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018993181874975562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025078311562538147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22603926062583923,
      "backward_entropy": 0.01848234236240387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001909684156998992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02507931739091873,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22601337730884552,
      "backward_entropy": 0.018755286931991577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019125055987387896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025080278515815735,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22598803043365479,
      "backward_entropy": 0.02389676868915558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001957199303433299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025081152096390724,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22596201300621033,
      "backward_entropy": 0.018446798125902813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017866268754005432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025082003325223923,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22593767940998077,
      "backward_entropy": 0.023867112894852955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014617880806326866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025082826614379883,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22591443359851837,
      "backward_entropy": 0.02385273575782776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009568280656822026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025083651766180992,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22589249908924103,
      "backward_entropy": 0.018415475885073345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010357261635363102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025084439665079117,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22586946189403534,
      "backward_entropy": 0.023824922740459442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014732552226632833,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025085218250751495,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2258467674255371,
      "backward_entropy": 0.023811740179856617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001011822372674942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02508590556681156,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22582289576530457,
      "backward_entropy": 0.018386658281087875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001437333645299077,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025086548179388046,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22579842805862427,
      "backward_entropy": 0.023788223663965862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011958529939875007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02508721873164177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22577691078186035,
      "backward_entropy": 0.018369466066360474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014104244764894247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025087883695960045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22575661540031433,
      "backward_entropy": 0.018361012140909832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011687937658280134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02508857659995556,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22573933005332947,
      "backward_entropy": 0.018352457632621128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001339730340987444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025089288130402565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22572419047355652,
      "backward_entropy": 0.018343905607859295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011197099229320884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025089943781495094,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22570905089378357,
      "backward_entropy": 0.023728827635447185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00103080365806818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02509060874581337,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2256956547498703,
      "backward_entropy": 0.018328023453553517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000888860144186765,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025091223418712616,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2256818413734436,
      "backward_entropy": 0.023706013957659405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010777115821838379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02509179525077343,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2256675660610199,
      "backward_entropy": 0.023695555826028187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008803922683000565,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025092339143157005,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22565381228923798,
      "backward_entropy": 0.0187269722421964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008285304647870362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025092851370573044,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22564004361629486,
      "backward_entropy": 0.018300560613473255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007236225064843893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025093378499150276,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2256278395652771,
      "backward_entropy": 0.01872606948018074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000797135871835053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02509387582540512,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2256154716014862,
      "backward_entropy": 0.018288031220436096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009584990330040455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025094300508499146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22560159862041473,
      "backward_entropy": 0.018282615890105564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008649587398394942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02509474940598011,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22558999061584473,
      "backward_entropy": 0.018277095009883244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008317978936247528,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02509523183107376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22558075189590454,
      "backward_entropy": 0.018271415183941524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007778040017001331,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0250957440584898,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22557371854782104,
      "backward_entropy": 0.01826556275288264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005409996956586838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025096267461776733,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556811571121216,
      "backward_entropy": 0.018259740124146145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006088112131692469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02509676106274128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556215524673462,
      "backward_entropy": 0.018254180749257404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005484718130901456,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025097239762544632,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22555643320083618,
      "backward_entropy": 0.023592797418435413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005622963653877378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02509767934679985,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555001080036163,
      "backward_entropy": 0.018243737518787384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005111073842272162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025098107755184174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554391622543335,
      "backward_entropy": 0.018238861113786697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005584511673077941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025098547339439392,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22553902864456177,
      "backward_entropy": 0.0235680490732193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004323374596424401,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025098979473114014,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255346179008484,
      "backward_entropy": 0.01822913686434428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041778796003200114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025099366903305054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255292385816574,
      "backward_entropy": 0.018224749714136124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005936608067713678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02509976178407669,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255246937274933,
      "backward_entropy": 0.018220315376917522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036560531589202583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025100136175751686,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22552040219306946,
      "backward_entropy": 0.01821612815062205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004864486982114613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025100477039813995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22551539540290833,
      "backward_entropy": 0.018212230255206425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040095666190609336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025100791826844215,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22551017999649048,
      "backward_entropy": 0.018208590646584828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004513189196586609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025101128965616226,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255064845085144,
      "backward_entropy": 0.018204830586910248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003591060230974108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510148100554943,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550402581691742,
      "backward_entropy": 0.018201008439064026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003572470450308174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025101840496063232,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255024015903473,
      "backward_entropy": 0.01819718877474467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034821711597032845,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025102173909544945,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255004346370697,
      "backward_entropy": 0.023497581481933594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003280401579104364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025102509185671806,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22549903392791748,
      "backward_entropy": 0.023491092026233673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023919742670841515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025102796033024788,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549641132354736,
      "backward_entropy": 0.018186885863542557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003732465556822717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025103062391281128,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22549346089363098,
      "backward_entropy": 0.023479739824930828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003077775763813406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025103338062763214,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549143433570862,
      "backward_entropy": 0.018180937816699345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003160368651151657,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025103624910116196,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549042105674744,
      "backward_entropy": 0.018177899221579235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003451415104791522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510390430688858,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22548963129520416,
      "backward_entropy": 0.01817498231927554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034697091905400157,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025104161351919174,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2254885584115982,
      "backward_entropy": 0.023457393050193787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030728656565770507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510441653430462,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22548791766166687,
      "backward_entropy": 0.018169583131869633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027840747497975826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510465495288372,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254871428012848,
      "backward_entropy": 0.018167056143283844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029699545120820403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025104917585849762,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22548773884773254,
      "backward_entropy": 0.01816440001130104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021576620929408818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025105198845267296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22548948228359222,
      "backward_entropy": 0.01816163460413615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002517852117307484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025105459615588188,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549083828926086,
      "backward_entropy": 0.018159036835034687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001886298123281449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025105705484747887,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549200057983398,
      "backward_entropy": 0.01815663402279218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002569807693362236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02510593645274639,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22549299895763397,
      "backward_entropy": 0.023420507709185284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021570462558884174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025106173008680344,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254945933818817,
      "backward_entropy": 0.01815200348695119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020770628179889172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510642632842064,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549714148044586,
      "backward_entropy": 0.018149609367052715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002234416751889512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025106647983193398,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549879550933838,
      "backward_entropy": 0.0187142180899779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012023735325783491,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025106865912675858,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255006730556488,
      "backward_entropy": 0.018145402272542317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019112086738459766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025107039138674736,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255011647939682,
      "backward_entropy": 0.018143648902575176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018374811043031514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510720118880272,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550150752067566,
      "backward_entropy": 0.01814203957716624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014592659135814756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025107353925704956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550180554389954,
      "backward_entropy": 0.018140524625778198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015419301053043455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510749362409115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255018651485443,
      "backward_entropy": 0.018139109015464783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018130286480300128,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02510760724544525,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22550120949745178,
      "backward_entropy": 0.018717333674430847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001614350767340511,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025107715278863907,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22550050914287567,
      "backward_entropy": 0.02337966114282608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001243518927367404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510783076286316,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255004197359085,
      "backward_entropy": 0.018135588616132736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001263584417756647,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025107936933636665,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550013661384583,
      "backward_entropy": 0.018134544293085735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014982395805418491,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025108030065894127,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549960017204285,
      "backward_entropy": 0.018721091250578564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013340145233087242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025108128786087036,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2254994809627533,
      "backward_entropy": 0.018722017606099445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011992431245744228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025108221918344498,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549930214881897,
      "backward_entropy": 0.018131621181964874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010348916839575395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025108307600021362,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254990041255951,
      "backward_entropy": 0.01813078795870145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001274097739951685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510841004550457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549964487552643,
      "backward_entropy": 0.018129773437976837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011869172158185393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025108516216278076,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22550050914287567,
      "backward_entropy": 0.023356591661771137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011217720748391002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025108613073825836,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255011796951294,
      "backward_entropy": 0.018127888441085815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.446167001035064e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510869689285755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550146281719208,
      "backward_entropy": 0.018127056459585827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.672340820543468e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02510875277221203,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22550083696842194,
      "backward_entropy": 0.02334908644358317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.295813702512532e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510879747569561,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254999279975891,
      "backward_entropy": 0.018125973641872406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706496737431735e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025108834728598595,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22549885511398315,
      "backward_entropy": 0.0233452245593071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.85482770879753e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025108857080340385,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549736499786377,
      "backward_entropy": 0.018732210000356037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.480512118083425e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025108881294727325,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22549602389335632,
      "backward_entropy": 0.023341899116834004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.786009518895298e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025108899921178818,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254946529865265,
      "backward_entropy": 0.01812465861439705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.471158460248262e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025108924135565758,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549353539943695,
      "backward_entropy": 0.018124349415302277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.253046012716368e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0251089408993721,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254922091960907,
      "backward_entropy": 0.018124109754959743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.569475615629926e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025108980014920235,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549185156822205,
      "backward_entropy": 0.0181237297753493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.925418761558831e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025109007954597473,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22549116611480713,
      "backward_entropy": 0.023334013919035595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.501594180008397e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025109034031629562,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2254904806613922,
      "backward_entropy": 0.023332553605238598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.055314199533314e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109058246016502,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254898101091385,
      "backward_entropy": 0.01812283570567767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.982859900337644e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510909177362919,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254895567893982,
      "backward_entropy": 0.018122481803099316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5535249228123575e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109130889177322,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22548949718475342,
      "backward_entropy": 0.0181221142411232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.094310861546546e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025109175592660904,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2254897654056549,
      "backward_entropy": 0.018744412809610367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.83793043915648e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510921098291874,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254897505044937,
      "backward_entropy": 0.018121315787235897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.123798812041059e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02510925568640232,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22549015283584595,
      "backward_entropy": 0.02332320064306259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6068423873512074e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025109294801950455,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549033164978027,
      "backward_entropy": 0.018746722489595413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.898447564803064e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109341368079185,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549083828926086,
      "backward_entropy": 0.018120136111974716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.850881694233976e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025109384208917618,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2254912555217743,
      "backward_entropy": 0.023318531612555187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.655935168149881e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025109419599175453,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2254914492368698,
      "backward_entropy": 0.02331712345282237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.889547249651514e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109458714723587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549183666706085,
      "backward_entropy": 0.01811906447013219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.311469820095226e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510949783027172,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549223899841309,
      "backward_entropy": 0.01811871553460757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9910548619227484e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0251095462590456,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549305856227875,
      "backward_entropy": 0.01811831071972847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8749453122145496e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025109585374593735,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549355030059814,
      "backward_entropy": 0.018751125782728195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8978840418858454e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025109615176916122,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549378871917725,
      "backward_entropy": 0.018751731763283413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0546278139809147e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510964684188366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549405694007874,
      "backward_entropy": 0.018117400507132213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.439043419144582e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0251096710562706,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254941165447235,
      "backward_entropy": 0.018117152154445648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9656566514167935e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109698995947838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.225494384765625,
      "backward_entropy": 0.01811690131823222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.164269921602681e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109736248850822,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549496591091156,
      "backward_entropy": 0.018116569767395656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9610620913445018e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109777227044106,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549572587013245,
      "backward_entropy": 0.018116208414236706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2900796466274187e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02510981634259224,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549641132354736,
      "backward_entropy": 0.01875503609577815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1155483409529552e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025109851732850075,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549694776535034,
      "backward_entropy": 0.018755514174699783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3216041881823912e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02510988898575306,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22549760341644287,
      "backward_entropy": 0.01875597859422366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1711869774444494e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025109922513365746,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549819946289062,
      "backward_entropy": 0.018114956716696422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3428250642609783e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510995604097843,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.225498765707016,
      "backward_entropy": 0.018114694704612095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3362317986320704e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510998770594597,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549936175346375,
      "backward_entropy": 0.01811441530783971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.490926842961926e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110015645623207,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22549983859062195,
      "backward_entropy": 0.018114186823368073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7954540453501977e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025110045447945595,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22550037503242493,
      "backward_entropy": 0.023295198877652485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.042497908405494e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110067799687386,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255006581544876,
      "backward_entropy": 0.01811372737089793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8910777725977823e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511008270084858,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550061345100403,
      "backward_entropy": 0.018113616853952408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6524118109373376e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110092014074326,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255004346370697,
      "backward_entropy": 0.018113506337006886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2885415091877803e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110095739364624,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550001740455627,
      "backward_entropy": 0.018113460391759872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1980009478284046e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110114365816116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550013661384583,
      "backward_entropy": 0.018113293995459873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.673434962867759e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110138580203056,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550055384635925,
      "backward_entropy": 0.01811309407154719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4518502212013118e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110164657235146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550097107887268,
      "backward_entropy": 0.018112844477097195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9474135115160607e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025110192596912384,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22550159692764282,
      "backward_entropy": 0.023288418849309284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.173122745967703e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02511022984981537,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22550250589847565,
      "backward_entropy": 0.018762414654095966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.542020052322187e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025110265240073204,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255033552646637,
      "backward_entropy": 0.02328636993964513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4946158444217872e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511029690504074,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550414502620697,
      "backward_entropy": 0.01811174675822258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7917085642693564e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110330432653427,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550499439239502,
      "backward_entropy": 0.018111492196718853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3389910236583091e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511036954820156,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255060374736786,
      "backward_entropy": 0.018111163129409153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.024163096502889e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025110410526394844,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22550714015960693,
      "backward_entropy": 0.018763504922389984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.885467079584487e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511044591665268,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22550809383392334,
      "backward_entropy": 0.023281392951806385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3919579032517504e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110481306910515,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22550907731056213,
      "backward_entropy": 0.01811026657621066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.416099601367023e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511051669716835,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22551007568836212,
      "backward_entropy": 0.018110000838836033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3106046935718041e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110553950071335,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22551116347312927,
      "backward_entropy": 0.018109702815612156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.593572940502781e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110594928264618,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255123257637024,
      "backward_entropy": 0.01810936505595843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.199412266345462e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025110634043812752,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255135178565979,
      "backward_entropy": 0.023276517788569134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0983610081893858e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110671296715736,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22551462054252625,
      "backward_entropy": 0.01810877025127411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0069575182569679e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511071227490902,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22551590204238892,
      "backward_entropy": 0.01810843249162038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.838861165510025e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025110751390457153,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22551710903644562,
      "backward_entropy": 0.023273661732673645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312146863114322e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025110790506005287,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22551828622817993,
      "backward_entropy": 0.02327270805835724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.234380740963388e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025110825896263123,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22551941871643066,
      "backward_entropy": 0.018764714399973553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.772252840572037e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110865011811256,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22552065551280975,
      "backward_entropy": 0.01810722549756368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.815078566229204e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110909715294838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22552210092544556,
      "backward_entropy": 0.018106880287329357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.984619863535045e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110948830842972,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255234271287918,
      "backward_entropy": 0.018106597165266674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.478183538798476e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025110984221100807,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22552455961704254,
      "backward_entropy": 0.018106310317913692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.382784936751705e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111017748713493,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255256623029709,
      "backward_entropy": 0.018106070657571156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3814881135185715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02511104755103588,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22552666068077087,
      "backward_entropy": 0.018764918049176533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1429287901119096e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511107176542282,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22552745044231415,
      "backward_entropy": 0.023265935480594635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.902964858250925e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111088529229164,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22552800178527832,
      "backward_entropy": 0.018105556567509968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.485848083073506e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111107155680656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22552868723869324,
      "backward_entropy": 0.018105395138263702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.192993739910889e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111127644777298,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22552940249443054,
      "backward_entropy": 0.018105264753103256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3610438094910933e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511114813387394,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553017735481262,
      "backward_entropy": 0.018105152994394302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.398532382765552e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111164897680283,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22553080320358276,
      "backward_entropy": 0.018765833228826523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.688592980528483e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111181661486626,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553148865699768,
      "backward_entropy": 0.018104876081148785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.12370434080367e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511119842529297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553208470344543,
      "backward_entropy": 0.01810478667418162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0623316383280326e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511121705174446,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553278505802155,
      "backward_entropy": 0.01810464883844058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.321979758969974e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111235678195953,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553345561027527,
      "backward_entropy": 0.01810450355211894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8512451990536647e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111256167292595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553426027297974,
      "backward_entropy": 0.018104349573453266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8143479084974388e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111274793744087,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553491592407227,
      "backward_entropy": 0.018104237814744312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4372723146370845e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511129155755043,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553560137748718,
      "backward_entropy": 0.0181041123966376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.791080644077738e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111304596066475,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22553609311580658,
      "backward_entropy": 0.01876692349712054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4252356070064707e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511131949722767,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553670406341553,
      "backward_entropy": 0.018103916198015213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.194458258803934e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111332535743713,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255372405052185,
      "backward_entropy": 0.018103813131650288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.493326287047239e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111349299550056,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553786635398865,
      "backward_entropy": 0.018103723724683125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.654137006175006e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111371651291847,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255387306213379,
      "backward_entropy": 0.018103556086619694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.338146487090853e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511139214038849,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22553953528404236,
      "backward_entropy": 0.01810341328382492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.176674115617061e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111408904194832,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255401909351349,
      "backward_entropy": 0.018103323876857758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2564031496585812e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111425668001175,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22554084658622742,
      "backward_entropy": 0.023255514601866405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.561097517173039e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511144056916237,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22554148733615875,
      "backward_entropy": 0.02325509985287984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9529675228113774e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111457332968712,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554218769073486,
      "backward_entropy": 0.018102979908386867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.266745923407143e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111472234129906,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255428433418274,
      "backward_entropy": 0.02325422316789627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7671803789198748e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0251114871352911,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554343938827515,
      "backward_entropy": 0.018102776259183884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.695388505140727e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111502036452293,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22554408013820648,
      "backward_entropy": 0.01876801997423172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.935390628204914e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111516937613487,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22554470598697662,
      "backward_entropy": 0.023252954085667927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7214970284840092e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511153183877468,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554530203342438,
      "backward_entropy": 0.018102464576562245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7819195363699691e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111543014645576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554582357406616,
      "backward_entropy": 0.018102371444304783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.589794919709675e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111554190516472,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22554634511470795,
      "backward_entropy": 0.018768372635046642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5819375676073832e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111567229032516,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22554689645767212,
      "backward_entropy": 0.02325147142012914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6025118156903773e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511158026754856,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554746270179749,
      "backward_entropy": 0.018102142959833145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.804931912374741e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111593306064606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554805874824524,
      "backward_entropy": 0.018102070937554043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.371535063299234e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511160634458065,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554858028888702,
      "backward_entropy": 0.01810196042060852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.556616780362674e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111617520451546,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2255491018295288,
      "backward_entropy": 0.018768730262915295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5412464335895493e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511163055896759,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22554966807365417,
      "backward_entropy": 0.01810178781549136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4034652622285648e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111643597483635,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22555023431777954,
      "backward_entropy": 0.01876884202162425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.5793859600235e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511165849864483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555086016654968,
      "backward_entropy": 0.01810159410039584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0035779496320174e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111671537160873,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555142641067505,
      "backward_entropy": 0.018101538221041363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79067101777764e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511168271303177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555193305015564,
      "backward_entropy": 0.018101433912913006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2665766462305328e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111693888902664,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22555240988731384,
      "backward_entropy": 0.02324796716372172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.191229312615178e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511170506477356,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555294632911682,
      "backward_entropy": 0.018101279934247334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.211334829866246e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111716240644455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255534827709198,
      "backward_entropy": 0.018101217846075695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1903458698725444e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511172741651535,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555401921272278,
      "backward_entropy": 0.018101161966721218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.017788448138162e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111740455031395,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22555458545684814,
      "backward_entropy": 0.02324672043323517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2725411124847597e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511175163090229,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22555507719516754,
      "backward_entropy": 0.023246407508850098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.960887498687953e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111764669418335,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255556881427765,
      "backward_entropy": 0.023246084650357563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.916925710560463e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511177770793438,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555628418922424,
      "backward_entropy": 0.01810080682237943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.956688937658328e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111792609095573,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555692493915558,
      "backward_entropy": 0.018100691338380177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.603791007364634e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111805647611618,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555747628211975,
      "backward_entropy": 0.018100624283154804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.145906124605972e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111816823482513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555798292160034,
      "backward_entropy": 0.018100531150897343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.889160542617901e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511182799935341,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555845975875854,
      "backward_entropy": 0.018100474029779434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.969670612808841e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111839175224304,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555899620056152,
      "backward_entropy": 0.01810041939218839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.810810534967459e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0251118503510952,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22555950284004211,
      "backward_entropy": 0.018100343644618988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.735145916536567e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111859664320946,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22555994987487793,
      "backward_entropy": 0.018769383430480957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.212857618313137e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111868977546692,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556036710739136,
      "backward_entropy": 0.018100204567114513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3754411649388203e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511187642812729,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255607545375824,
      "backward_entropy": 0.01810017228126526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.670486871167668e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111883878707886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556111216545105,
      "backward_entropy": 0.01810013751188914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.349276648303203e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111889466643333,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22556142508983612,
      "backward_entropy": 0.018769562244415283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9657393813286035e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02511189691722393,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22556176781654358,
      "backward_entropy": 0.01876960943142573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5350884647632483e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111904367804527,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556211054325104,
      "backward_entropy": 0.018100013335545857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4190656467435474e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111911818385124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255624383687973,
      "backward_entropy": 0.01809997856616974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.947168008584413e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111917406320572,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556275129318237,
      "backward_entropy": 0.018099945038557053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.236934844608186e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511192299425602,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556307911872864,
      "backward_entropy": 0.02324190487464269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8665607487710076e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111926719546318,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556333243846893,
      "backward_entropy": 0.02324173351128896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7187329010303074e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025111930444836617,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22556355595588684,
      "backward_entropy": 0.018769932289918263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2004444960875844e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111934170126915,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556376457214355,
      "backward_entropy": 0.023241430521011353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6117714330430317e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111937895417213,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556400299072266,
      "backward_entropy": 0.018099805961052578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4422544697699777e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111941620707512,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556418180465698,
      "backward_entropy": 0.02324116478363673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.043426488602563e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511194348335266,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556434571743011,
      "backward_entropy": 0.018099805961052578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.004003872320027e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511194720864296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556450963020325,
      "backward_entropy": 0.018099788576364517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8897840448062198e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511194907128811,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556467354297638,
      "backward_entropy": 0.018099788576364517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3216452404994925e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111950933933258,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556480765342712,
      "backward_entropy": 0.018099783609310787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7982320343890024e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111952796578407,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556498646736145,
      "backward_entropy": 0.018099773675203323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.358632056915667e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111954659223557,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556515038013458,
      "backward_entropy": 0.023240407307942707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.302862978671328e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111958384513855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255653440952301,
      "backward_entropy": 0.018099756290515263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.791234609527237e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111963972449303,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255655825138092,
      "backward_entropy": 0.023240168889363606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9445410259777418e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511196956038475,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255658358335495,
      "backward_entropy": 0.018099668125311535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8115176203536976e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111975148320198,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.225566104054451,
      "backward_entropy": 0.01809963583946228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8257833289681002e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111980736255646,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255663424730301,
      "backward_entropy": 0.02323971688747406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4315490659555508e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111984461545944,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.225566565990448,
      "backward_entropy": 0.023239587744077046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7066375335161865e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025111988186836243,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255667746067047,
      "backward_entropy": 0.0232394536336263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4737599940417567e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511199191212654,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556692361831665,
      "backward_entropy": 0.018099551399548847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7364882864967512e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511199563741684,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556711733341217,
      "backward_entropy": 0.023239242533842724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0096806590809138e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025111999362707138,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556725144386292,
      "backward_entropy": 0.01809948558608691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0097294023125869e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112003087997437,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556743025779724,
      "backward_entropy": 0.018099479377269745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3620891081700393e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112004950642586,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255675494670868,
      "backward_entropy": 0.01809947316845258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.138523657573387e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112006813287735,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556766867637634,
      "backward_entropy": 0.018099461992581684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0616598444812553e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025112008675932884,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2255677580833435,
      "backward_entropy": 0.01877114673455556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.239512954498423e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112010538578033,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556786239147186,
      "backward_entropy": 0.01809945081671079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.941900458443342e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025112012401223183,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22556796669960022,
      "backward_entropy": 0.01877121503154437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.622071590025371e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112014263868332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255680412054062,
      "backward_entropy": 0.01809945081671079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0416596296636271e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511201612651348,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556814551353455,
      "backward_entropy": 0.018099439640839893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.537704422271418e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511201798915863,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255682647228241,
      "backward_entropy": 0.018099428464968998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.039533210852824e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511201985180378,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556833922863007,
      "backward_entropy": 0.023238326112429302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.275168283944367e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511202171444893,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556844353675842,
      "backward_entropy": 0.023238234221935272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.511256055498961e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511202171444893,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.225568488240242,
      "backward_entropy": 0.018099417289098103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.702524129626909e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112023577094078,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556856274604797,
      "backward_entropy": 0.018099417289098103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.774330867960089e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025112025439739227,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556862235069275,
      "backward_entropy": 0.02323804299036662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.192135053126549e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112027302384377,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255687415599823,
      "backward_entropy": 0.01809940238793691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.878162477936712e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025112029165029526,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22556880116462708,
      "backward_entropy": 0.018771653374036152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.777745488127039e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025112031027674675,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556892037391663,
      "backward_entropy": 0.023237839341163635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.017676857870356e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112032890319824,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255689650774002,
      "backward_entropy": 0.018099383761485417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.569449340076972e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112034752964973,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255690097808838,
      "backward_entropy": 0.01809937258561452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.371944666876516e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112036615610123,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556906938552856,
      "backward_entropy": 0.01809937258561452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.591147100858507e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025112038478255272,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556912899017334,
      "backward_entropy": 0.023237583537896473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.936854480774855e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556915879249573,
      "backward_entropy": 0.01809936265150706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.712594048328356e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2255692481994629,
      "backward_entropy": 0.01809936265150706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3709981412121124e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2255692481994629,
      "backward_entropy": 0.018771909177303314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3733998583993525e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2255692481994629,
      "backward_entropy": 0.01877193773786227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8476842096079054e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556927800178528,
      "backward_entropy": 0.018099357684453327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.854356123156322e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22556927800178528,
      "backward_entropy": 0.018772051980098087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1655976446008935e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556930780410767,
      "backward_entropy": 0.018099351475636166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3842318341849023e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556929290294647,
      "backward_entropy": 0.018099357684453327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1480319623588e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204034090042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556932270526886,
      "backward_entropy": 0.018099351475636166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.656428049225724e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204220354557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556936740875244,
      "backward_entropy": 0.01809930180509885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.007295390489162e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204406619072,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556939721107483,
      "backward_entropy": 0.01809930180509885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.486676902753061e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511204592883587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556942701339722,
      "backward_entropy": 0.01809929683804512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0057688721617524e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511204592883587,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255694568157196,
      "backward_entropy": 0.023237039645512898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.667134862439525e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025112047791481018,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.225569486618042,
      "backward_entropy": 0.023236992458502453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2451168863190105e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112049654126167,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556950151920319,
      "backward_entropy": 0.018099280695120495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7503403998707654e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112051516771317,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556954622268677,
      "backward_entropy": 0.01809927448630333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9707631910014243e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025112053379416466,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556960582733154,
      "backward_entropy": 0.02323685089747111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.595834835972255e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025112055242061615,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22556963562965393,
      "backward_entropy": 0.018772368629773457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.675842480925894e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112057104706764,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556966543197632,
      "backward_entropy": 0.018099234749873478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5840448952531005e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025112058967351913,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2255697399377823,
      "backward_entropy": 0.023236689468224842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4351741128848516e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112060829997063,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556981444358826,
      "backward_entropy": 0.018099223574002583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.23156249035128e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112062692642212,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556984424591064,
      "backward_entropy": 0.018099212398131687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7193983126162493e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511206455528736,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556987404823303,
      "backward_entropy": 0.02323654294013977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6547801351407543e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02511206641793251,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22556990385055542,
      "backward_entropy": 0.023236528038978577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.939957883223542e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02511206828057766,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2255699336528778,
      "backward_entropy": 0.01877244934439659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9389787553336646e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02511207014322281,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22556999325752258,
      "backward_entropy": 0.018099190046389897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.503214974718503e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025112072005867958,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22557002305984497,
      "backward_entropy": 0.018772471696138382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5634476824288868e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025112073868513107,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22557006776332855,
      "backward_entropy": 0.01809916893641154,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.1160069907443244e-07,
    "avg_log_Z": 0.025111947134137155,
    "success_rate": 1.0,
    "avg_reward": 48.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.25,
      "2": 0.6
    },
    "avg_forward_entropy": 0.22556457415223122,
    "avg_backward_entropy": 0.019485583019753297,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}