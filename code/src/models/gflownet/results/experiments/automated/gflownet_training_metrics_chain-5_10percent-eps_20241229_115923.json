{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831095695495604,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831095695495604,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831095695495604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831095695495604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831095695495604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831095695495604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.1384824275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831790685653686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.850811958312988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289581934611002,
      "backward_entropy": 0.13831095695495604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.227950096130371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829052766164144,
      "backward_entropy": 0.13829957246780394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225427627563477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00020005421538371593,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18291463454564413,
      "backward_entropy": 0.13829119205474855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.104028701782227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0003001275472342968,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292391300201416,
      "backward_entropy": 0.13846137523651122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8423686027526855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004001728375442326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829326550165812,
      "backward_entropy": 0.13845425844192505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.722252368927002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005001377430744469,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18294076124827066,
      "backward_entropy": 0.13825358152389527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.461096286773682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006000062567181885,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829481522242228,
      "backward_entropy": 0.1382399320602417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.096030235290527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006997358868829906,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829545497894287,
      "backward_entropy": 0.13822543621063232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.340670585632324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000799562141764909,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829610268274943,
      "backward_entropy": 0.138210928440094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.455989837646484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008992095245048404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182966411113739,
      "backward_entropy": 0.13841431140899657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.946963787078857,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009987736120820045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829712986946106,
      "backward_entropy": 0.1384054183959961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.596521854400635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001098455861210823,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829761266708374,
      "backward_entropy": 0.1381641149520874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7109856605529785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001198077341541648,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18298033873240152,
      "backward_entropy": 0.13838698863983154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824855327606201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012977041769772768,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298433224360147,
      "backward_entropy": 0.13814432621002198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.968451976776123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013973896857351065,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298840522766113,
      "backward_entropy": 0.13811330795288085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.318358421325684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014971551718190312,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829924782117208,
      "backward_entropy": 0.13809556961059571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.558213710784912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001596361747942865,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829948623975118,
      "backward_entropy": 0.13807718753814696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.180369853973389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001695614424534142,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829973061879476,
      "backward_entropy": 0.1380584716796875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.030600547790527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00179475755430758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299941221872965,
      "backward_entropy": 0.13832485675811768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.799824237823486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018937739077955484,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300131956736246,
      "backward_entropy": 0.13801987171173097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.698115348815918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001992562785744667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300263086954752,
      "backward_entropy": 0.13803138732910156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.696490287780762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020915106870234013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300394217173258,
      "backward_entropy": 0.13829002380371094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.770904541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021905964240431786,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300525347391763,
      "backward_entropy": 0.13795852661132812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.467560768127441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022898842580616474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300692240397134,
      "backward_entropy": 0.1382652997970581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.674710750579834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002389142056927085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300811449686685,
      "backward_entropy": 0.13825246095657348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.53794527053833,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024880676064640284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300855159759521,
      "backward_entropy": 0.13823926448822021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.535654544830322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002587102120742202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830090880393982,
      "backward_entropy": 0.13822572231292723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1564412117004395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026862318627536297,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300970395406088,
      "backward_entropy": 0.13821183443069457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907986164093018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002785277320072055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301006158192953,
      "backward_entropy": 0.13788460493087767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6399245262146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002884587273001671,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301087617874146,
      "backward_entropy": 0.1377988338470459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.549481391906738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029840224888175726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830118497212728,
      "backward_entropy": 0.13816815614700317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.191123008728027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003083024173974991,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301182985305786,
      "backward_entropy": 0.138152813911438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.098140716552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031819341238588095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830113927523295,
      "backward_entropy": 0.13772284984588623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7633585929870605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003280807053670287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830108960469564,
      "backward_entropy": 0.13812084197998048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.980757713317871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0033794476184993982,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830098827679952,
      "backward_entropy": 0.13766918182373047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.623672962188721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003478019265457988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300867080688477,
      "backward_entropy": 0.13772778511047362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.803670406341553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035768249072134495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300771713256836,
      "backward_entropy": 0.13770312070846558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.425597190856934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036753849126398563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300606807072958,
      "backward_entropy": 0.1376777172088623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.205449104309082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037745251320302486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300537268320718,
      "backward_entropy": 0.13765125274658202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.934157371520996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00387404253706336,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300525347391763,
      "backward_entropy": 0.13752453327178954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.392319202423096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00397377647459507,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300549189249674,
      "backward_entropy": 0.13799638748168946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.877604007720947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004073466639965773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300559123357138,
      "backward_entropy": 0.13797686100006104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.225853443145752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004173371475189924,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300602833429971,
      "backward_entropy": 0.13742947578430176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.978193759918213,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004273158963769674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830061674118042,
      "backward_entropy": 0.13793642520904542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.870023250579834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0043721976689994335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300501505533853,
      "backward_entropy": 0.13791545629501342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.001426696777344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0044715311378240585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830042600631714,
      "backward_entropy": 0.13744430541992186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.080126762390137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0045706732198596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830030878384908,
      "backward_entropy": 0.13787174224853516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.482810020446777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004670236725360155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300251166025797,
      "backward_entropy": 0.13737964630126953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.859253406524658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0047698416747152805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830019156138102,
      "backward_entropy": 0.13782637119293212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.070215225219727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0048696743324398994,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300163745880127,
      "backward_entropy": 0.13717248439788818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.367411136627197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004969845525920391,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300183614095053,
      "backward_entropy": 0.13713185787200927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.48500394821167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005069911479949951,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300171693166098,
      "backward_entropy": 0.13724064826965332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.953703880310059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005169851239770651,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300149838129678,
      "backward_entropy": 0.13704608678817748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.526562690734863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005270044784992933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300175666809082,
      "backward_entropy": 0.1377051591873169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7056245803833,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005370180122554302,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300199508666992,
      "backward_entropy": 0.137679386138916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.670615196228027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005470931995660067,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300328652064005,
      "backward_entropy": 0.136908221244812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8034086227417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0055717104114592075,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830044984817505,
      "backward_entropy": 0.13686025142669678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.663241863250732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005673095118254423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300650517145792,
      "backward_entropy": 0.13759913444519042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.973453044891357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0057744248770177364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.183008074760437,
      "backward_entropy": 0.1369670271873474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372199058532715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00587591202929616,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300950527191162,
      "backward_entropy": 0.13671228885650635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.348003387451172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005977636203169823,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301131327946982,
      "backward_entropy": 0.13751345872879028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.610145568847656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0060785929672420025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301173051198324,
      "backward_entropy": 0.13748376369476317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.265548229217529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006179444957524538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301206827163696,
      "backward_entropy": 0.13745477199554443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.084599494934082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006280082277953625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301188945770264,
      "backward_entropy": 0.13675224781036377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.190380573272705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006380916573107243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830120086669922,
      "backward_entropy": 0.13739473819732667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.18010425567627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006481368560343981,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301198879877725,
      "backward_entropy": 0.13638079166412354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.218086242675781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006582104600965977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.183012326558431,
      "backward_entropy": 0.13661065101623535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.387839317321777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006682544481009245,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301212787628174,
      "backward_entropy": 0.13625745773315429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.211972236633301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00678278086706996,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301214774449667,
      "backward_entropy": 0.1372710347175598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.992042064666748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0068827723152935505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301190932591757,
      "backward_entropy": 0.13645811080932618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.104123115539551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006983031518757343,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301165103912354,
      "backward_entropy": 0.1360593318939209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.808711051940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00708296662196517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830111543337504,
      "backward_entropy": 0.13634908199310303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.126427173614502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007183569483458996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301157156626383,
      "backward_entropy": 0.13629225492477418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.571562767028809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007283883169293404,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301133314768472,
      "backward_entropy": 0.1358487844467163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869402885437012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007384135387837887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830111344655355,
      "backward_entropy": 0.13617533445358276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5913825035095215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007485006470233202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301212787628174,
      "backward_entropy": 0.13611390590667724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485322952270508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007585825864225626,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301264444986978,
      "backward_entropy": 0.13562554121017456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.657008171081543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007686991710215807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301397562026978,
      "backward_entropy": 0.13598672151565552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.378500938415527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007788058370351791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301514784495035,
      "backward_entropy": 0.13592085838317872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.448867321014404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007888898253440857,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301586310068765,
      "backward_entropy": 0.13539259433746337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31843090057373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00798952579498291,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301655848821005,
      "backward_entropy": 0.13531107902526857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.562532424926758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00809052400290966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301721413930258,
      "backward_entropy": 0.13678863048553466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606778144836426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008191904984414577,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301856517791748,
      "backward_entropy": 0.1351445198059082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.302557945251465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008293774910271168,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301973740259805,
      "backward_entropy": 0.13506026268005372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.825083255767822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008395862765610218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302075068155924,
      "backward_entropy": 0.1355052709579468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.389168739318848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008497863076627254,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302138646443686,
      "backward_entropy": 0.1348876714706421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53683090209961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008598383516073227,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302043279012045,
      "backward_entropy": 0.13479727506637573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.689980983734131,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008699319325387478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830202341079712,
      "backward_entropy": 0.13650877475738527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.040673732757568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008800136856734753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302035331726074,
      "backward_entropy": 0.13520255088806152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8767266273498535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00890049897134304,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302029371261597,
      "backward_entropy": 0.1364067792892456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.082328796386719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009000941179692745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302045265833536,
      "backward_entropy": 0.1350398302078247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.320651054382324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009102142415940762,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302124738693237,
      "backward_entropy": 0.13430877923965454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.95855712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00920304749161005,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302162488301596,
      "backward_entropy": 0.13420454263687134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.062654495239258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009304031729698181,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830220421155294,
      "backward_entropy": 0.13477988243103028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31653118133545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009405703283846378,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302297592163086,
      "backward_entropy": 0.13399006128311158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.940977573394775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009507567621767521,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302404880523682,
      "backward_entropy": 0.1338799238204956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.818648815155029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00960939098149538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302500247955322,
      "backward_entropy": 0.13449251651763916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.385994911193848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009711028076708317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302651246388754,
      "backward_entropy": 0.1359250068664551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.264355182647705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009812363423407078,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830273469289144,
      "backward_entropy": 0.13585795164108277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45697021484375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009913280606269836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302826086680093,
      "backward_entropy": 0.1341776132583618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449644088745117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010014517232775688,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302959203720093,
      "backward_entropy": 0.1357194185256958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.248960494995117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010116033256053925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830312410990397,
      "backward_entropy": 0.13564484119415282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.163773536682129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010217651724815369,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830333669980367,
      "backward_entropy": 0.1355677604675293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715821743011475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010318804532289505,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303481737772623,
      "backward_entropy": 0.13548798561096193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.418158531188965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01041988842189312,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830357313156128,
      "backward_entropy": 0.1335995078086853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.509280204772949,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01052124798297882,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830369234085083,
      "backward_entropy": 0.13261160850524903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.699006080627441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010622364468872547,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830377777417501,
      "backward_entropy": 0.1352349877357483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.4841947555542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010722842998802662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303765853246054,
      "backward_entropy": 0.13514604568481445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.220829963684082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010824269615113735,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303817510604858,
      "backward_entropy": 0.13505513668060304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.3757905960083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010927017778158188,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830387512842814,
      "backward_entropy": 0.13496205806732178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.461992263793945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011029830202460289,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830394665400187,
      "backward_entropy": 0.13486695289611816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.560039520263672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011132762767374516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304020166397095,
      "backward_entropy": 0.1347687602043152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.347247123718262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01123531349003315,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830404003461202,
      "backward_entropy": 0.13154826164245606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.506925582885742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011337928473949432,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304075797398886,
      "backward_entropy": 0.13138482570648194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.651028156280518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011440659873187542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18304147322972616,
      "backward_entropy": 0.1322554588317871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.865191459655762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011543155647814274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830409566561381,
      "backward_entropy": 0.13210536241531373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.496907711029053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011646045371890068,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18304034074147543,
      "backward_entropy": 0.13195130825042725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4350266456604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011748448014259338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303990364074707,
      "backward_entropy": 0.13412866592407227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5937604904174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011850487440824509,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.183038592338562,
      "backward_entropy": 0.13050398826599122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.107763290405273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011952262371778488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303682406743368,
      "backward_entropy": 0.1338963747024536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.762200832366943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01205406803637743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830349564552307,
      "backward_entropy": 0.13131701946258545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.347939491271973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012155760079622269,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830323338508606,
      "backward_entropy": 0.12992699146270753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.815304756164551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012257613241672516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830298105875651,
      "backward_entropy": 0.13352677822113038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.492875099182129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01235933043062687,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302702903747559,
      "backward_entropy": 0.12952380180358886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.79388952255249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012461258098483086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302472432454428,
      "backward_entropy": 0.13065277338027953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.949752330780029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012563025578856468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302210172017416,
      "backward_entropy": 0.1304759979248047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.512415885925293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01266471017152071,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830195188522339,
      "backward_entropy": 0.13029528856277467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6497602462768555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01276610791683197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301651875178018,
      "backward_entropy": 0.13011178970336915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.914851665496826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012867237441241741,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301421403884888,
      "backward_entropy": 0.12842094898223877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.044766426086426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012968329712748528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301192919413248,
      "backward_entropy": 0.12973227500915527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.798440456390381,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013070065528154373,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300926685333252,
      "backward_entropy": 0.12794339656829834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.015129089355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013171612285077572,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300684293111166,
      "backward_entropy": 0.12769734859466553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.51678991317749,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013272571377456188,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830042004585266,
      "backward_entropy": 0.13210946321487427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.363870620727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013373270630836487,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300169706344604,
      "backward_entropy": 0.12718863487243653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.419069766998291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013474209234118462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299945195515951,
      "backward_entropy": 0.12870264053344727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93627643585205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013574877753853798,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829966902732849,
      "backward_entropy": 0.1266589045524597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902438163757324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013676111586391926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299448490142822,
      "backward_entropy": 0.12825932502746581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.345590114593506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013777297921478748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299208084742227,
      "backward_entropy": 0.12803032398223876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7316975593566895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013877540826797485,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829894781112671,
      "backward_entropy": 0.13111324310302735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.112431526184082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013977831229567528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829853653907776,
      "backward_entropy": 0.12756766080856324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.955020904541016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014078283682465553,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18298073609670004,
      "backward_entropy": 0.13075262308120728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9820075035095215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01417887955904007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297475576400757,
      "backward_entropy": 0.1305661678314209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.931170463562012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014278970658779144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18296857674916586,
      "backward_entropy": 0.12684335708618164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.20485782623291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014379765838384628,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296170234680176,
      "backward_entropy": 0.1301814556121826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.027966499328613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01448015309870243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829547882080078,
      "backward_entropy": 0.1299830675125122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.995445251464844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01458009798079729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829474171002706,
      "backward_entropy": 0.12607665061950685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.267704010009766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014679565094411373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294072151184082,
      "backward_entropy": 0.12581171989440917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.573211669921875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014779421500861645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829331914583842,
      "backward_entropy": 0.12936389446258545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.199001312255859,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014879749156534672,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292595942815146,
      "backward_entropy": 0.12914901971817017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28535270690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014979664236307144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829195817311605,
      "backward_entropy": 0.12227530479431152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.518221378326416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015079885721206665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291316429773966,
      "backward_entropy": 0.12468549013137817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.085576057434082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015179960988461971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829057534535726,
      "backward_entropy": 0.1243896484375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.641776084899902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015280235558748245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828975280125936,
      "backward_entropy": 0.12824645042419433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.797650337219238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015380402095615864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18288914362589517,
      "backward_entropy": 0.12800917625427247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260345458984375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01548059843480587,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287980556488037,
      "backward_entropy": 0.127767014503479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495941162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01558162271976471,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18287076552708945,
      "backward_entropy": 0.11999101638793945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.477255821228027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015682965517044067,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828616460164388,
      "backward_entropy": 0.11958920955657959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.051200866699219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01578335277736187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18285375833511353,
      "backward_entropy": 0.12248058319091797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.038959503173828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01588328368961811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18284531434377035,
      "backward_entropy": 0.1221441388130188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.585086345672607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01598217710852623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18283730745315552,
      "backward_entropy": 0.12180482149124146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5044403076171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016081087291240692,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18282870451609293,
      "backward_entropy": 0.11788973808288575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52754020690918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016179384663701057,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281936645507812,
      "backward_entropy": 0.12592654228210448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.620129585266113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016278348863124847,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828087568283081,
      "backward_entropy": 0.11699752807617188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.238616466522217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016376735642552376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279820680618286,
      "backward_entropy": 0.1253516435623169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.059996604919434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016474930569529533,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827886700630188,
      "backward_entropy": 0.116074538230896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.363104343414307,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016572874039411545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277976910273233,
      "backward_entropy": 0.12475640773773193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.253918170928955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01667078211903572,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827709674835205,
      "backward_entropy": 0.11511439085006714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.665456295013428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016768576577305794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827626427014669,
      "backward_entropy": 0.1241388201713562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.418982028961182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016865910962224007,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275511264801025,
      "backward_entropy": 0.11411097049713134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.179621696472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016962755471467972,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827462911605835,
      "backward_entropy": 0.11359856128692628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.307251930236816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017059551551938057,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827379266421,
      "backward_entropy": 0.12317130565643311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941011905670166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01715635508298874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18273075421651205,
      "backward_entropy": 0.11718780994415283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.814285755157471,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017253635451197624,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18272207180658975,
      "backward_entropy": 0.12249698638916015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.602126598358154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017350714653730392,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18271068731943765,
      "backward_entropy": 0.11146527528762817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.727128505706787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01744738407433033,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826996405919393,
      "backward_entropy": 0.11091586351394653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.784104347229004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01754373498260975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18268962701161703,
      "backward_entropy": 0.12143868207931519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.84036922454834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017639854922890663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18268001079559326,
      "backward_entropy": 0.11496126651763916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0753912925720215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01773582026362419,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826700965563456,
      "backward_entropy": 0.12070422172546387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.249659538269043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017831068485975266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266276518503824,
      "backward_entropy": 0.12032989263534546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.000090599060059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017926489934325218,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18265533447265625,
      "backward_entropy": 0.11994991302490235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7047438621521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018022526055574417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826479434967041,
      "backward_entropy": 0.11304373741149902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.78432035446167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01811826601624489,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826421022415161,
      "backward_entropy": 0.11253570318222046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.433847904205322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018214484676718712,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18263574441274008,
      "backward_entropy": 0.11876699924468995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7764811515808105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018310289829969406,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826284925142924,
      "backward_entropy": 0.10554330348968506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.372345924377441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01840590499341488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826216181119283,
      "backward_entropy": 0.11794091463088989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.936886310577393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018501130864024162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261414766311646,
      "backward_entropy": 0.11751738786697388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.986186504364014,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018596317619085312,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18260741233825684,
      "backward_entropy": 0.10359439849853516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9785847663879395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018691523000597954,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18260039885838827,
      "backward_entropy": 0.10293135643005372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.383275508880615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018786806613206863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182590921719869,
      "backward_entropy": 0.10875859260559081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8193039894104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01888171024620533,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825814445813497,
      "backward_entropy": 0.10158768892288209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.954640865325928,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018975907936692238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257280190785727,
      "backward_entropy": 0.1152998685836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.973904609680176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019069597125053406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825634241104126,
      "backward_entropy": 0.1070467472076416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.191160678863525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019162794575095177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182554562886556,
      "backward_entropy": 0.11435556411743164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.47296667098999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019255751743912697,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254419167836508,
      "backward_entropy": 0.09881585836410522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.901519775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019349273294210434,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18253364165623984,
      "backward_entropy": 0.09810558557510377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.38423490524292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019443634897470474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18252110481262207,
      "backward_entropy": 0.11288435459136963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.411183834075928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019537771120667458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825068791707357,
      "backward_entropy": 0.10405049324035645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.625594139099121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019630957394838333,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249507745107016,
      "backward_entropy": 0.0959405243396759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.363799095153809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019723493605852127,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18248327573140463,
      "backward_entropy": 0.09520435929298401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.765011310577393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019815878942608833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18247278531392416,
      "backward_entropy": 0.10215879678726196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.476320743560791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01990777812898159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18246223529179892,
      "backward_entropy": 0.1015161395072937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.963295936584473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019998980686068535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18245402971903482,
      "backward_entropy": 0.10977349281311036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7303361892700195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02009137161076069,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18244179089864096,
      "backward_entropy": 0.09217034578323365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.815870761871338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020183268934488297,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242891629536948,
      "backward_entropy": 0.09953373670578003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.398301601409912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020274750888347626,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824162801106771,
      "backward_entropy": 0.09060517549514771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.104104042053223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020366227254271507,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824042797088623,
      "backward_entropy": 0.09817377924919128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3988261222839355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020457563921809196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239104747772217,
      "backward_entropy": 0.09748157262802123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.257347583770752,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02054823935031891,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18237866957982382,
      "backward_entropy": 0.10640444755554199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3874969482421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020638898015022278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823669672012329,
      "backward_entropy": 0.10581893920898437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.637879848480225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02072884328663349,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235981464385986,
      "backward_entropy": 0.09537043571472167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8927459716796875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020818468183279037,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823514699935913,
      "backward_entropy": 0.10463442802429199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0661940574646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020907150581479073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18234666188557944,
      "backward_entropy": 0.09393295049667358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.207210540771484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020995233207941055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18234101931254068,
      "backward_entropy": 0.0932042121887207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6013617515563965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02108352817595005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182335098584493,
      "backward_entropy": 0.09246158599853516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1309075355529785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021172357723116875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18232675393422446,
      "backward_entropy": 0.08232682943344116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.213139533996582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021261412650346756,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18231433629989624,
      "backward_entropy": 0.10155792236328125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9896039962768555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021350638940930367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18230050802230835,
      "backward_entropy": 0.0901635766029358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.19779109954834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0214398093521595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18228662014007568,
      "backward_entropy": 0.10027107000350952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.230130195617676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02152833342552185,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822739044825236,
      "backward_entropy": 0.07890469431877137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9866251945495605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02161632478237152,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822615067164103,
      "backward_entropy": 0.07803846001625062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.773448944091797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02170444093644619,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822471817334493,
      "backward_entropy": 0.08699084520339966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2407379150390625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02179168164730072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18223454554875693,
      "backward_entropy": 0.08617516756057739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.422496318817139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021878579631447792,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18222049872080484,
      "backward_entropy": 0.07542364597320557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.197873115539551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021966110914945602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822022795677185,
      "backward_entropy": 0.08452094197273255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9474921226501465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022053930908441544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18218261003494263,
      "backward_entropy": 0.08366837501525878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1942057609558105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022141898050904274,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18216025829315186,
      "backward_entropy": 0.07278253436088562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.21989107131958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022229403257369995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18213687340418497,
      "backward_entropy": 0.08194352388381958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.919858455657959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022316541522741318,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18211189905802408,
      "backward_entropy": 0.07101700305938721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.599914073944092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022403882816433907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18208428223927817,
      "backward_entropy": 0.08020460605621338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7912983894348145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02249114215373993,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18205475807189941,
      "backward_entropy": 0.09199498295783996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.296851634979248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022577710449695587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18202467759450278,
      "backward_entropy": 0.07844597101211548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.564705848693848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022663988173007965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18199390172958374,
      "backward_entropy": 0.07756292819976807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.289760589599609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022750338539481163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18195990721384683,
      "backward_entropy": 0.0766744613647461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.32882022857666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022835638374090195,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.181927224000295,
      "backward_entropy": 0.06571456789970398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3435187339782715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022920122370123863,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18189426263173422,
      "backward_entropy": 0.08825265169143677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.843557834625244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023003844544291496,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818615198135376,
      "backward_entropy": 0.0874941110610962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.444510459899902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023088224232196808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18182384967803955,
      "backward_entropy": 0.07318670749664306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.547616004943848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023171883076429367,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18178786834081015,
      "backward_entropy": 0.06224326491355896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.649082660675049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023255042731761932,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817509333292643,
      "backward_entropy": 0.061383414268493655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.116175174713135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02333790250122547,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18171191215515137,
      "backward_entropy": 0.060529005527496335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6841583251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023419925943017006,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18167376518249512,
      "backward_entropy": 0.05967879891395569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.577171802520752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023501865565776825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18163381020228067,
      "backward_entropy": 0.06885360479354859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.292673587799072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023583490401506424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18159276247024536,
      "backward_entropy": 0.08195934295654297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6609175205230713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02366456761956215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815509796142578,
      "backward_entropy": 0.06712979078292847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.200096607208252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02374456077814102,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18151195844014487,
      "backward_entropy": 0.08035877943038941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.336881160736084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023823196068406105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18147714932759604,
      "backward_entropy": 0.0795629620552063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8213582038879395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02390173077583313,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814392407735189,
      "backward_entropy": 0.07876350283622742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.225999593734741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023980651050806046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813958485921224,
      "backward_entropy": 0.06376715302467346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9125542640686035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02405826933681965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813560128211975,
      "backward_entropy": 0.07715885639190674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.026444911956787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02413540706038475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18131514390309653,
      "backward_entropy": 0.07636064887046815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0884547233581543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02421216294169426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18127276500066122,
      "backward_entropy": 0.07556517720222473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4558756351470947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024287769570946693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812329888343811,
      "backward_entropy": 0.07476955652236938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.226115703582764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024362819269299507,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18119259675343832,
      "backward_entropy": 0.0739678680896759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.324249267578125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0244381595402956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18114701906840006,
      "backward_entropy": 0.07315930128097534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.918954610824585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02451380528509617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18109601736068726,
      "backward_entropy": 0.058034902811050414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9477763175964355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024588176980614662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18104819456736246,
      "backward_entropy": 0.07154074311256409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.712374210357666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024662623181939125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18099615971247354,
      "backward_entropy": 0.05642260313034057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6453490257263184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024736745283007622,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18094178040822348,
      "backward_entropy": 0.046140560507774354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9244000911712646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024810513481497765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808851957321167,
      "backward_entropy": 0.06912139058113098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6478159427642822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024883156642317772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18083061774571738,
      "backward_entropy": 0.04467354416847229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1201977729797363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024955684319138527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18077258268992105,
      "backward_entropy": 0.0675313115119934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0193097591400146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02502751722931862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18071428934733072,
      "backward_entropy": 0.05242672562599182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.208519458770752,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025098668411374092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1806559960047404,
      "backward_entropy": 0.06595191359519958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.538275957107544,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025169337168335915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18059595425923666,
      "backward_entropy": 0.041839486360549925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.109010696411133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025238770991563797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18053869406382242,
      "backward_entropy": 0.06439419984817504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.605185031890869,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02530788443982601,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18047916889190674,
      "backward_entropy": 0.040479636192321776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7891502380371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025375865399837494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18042117357254028,
      "backward_entropy": 0.03981234431266785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8014819622039795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025443343445658684,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1803621451059977,
      "backward_entropy": 0.062103503942489625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2767093181610107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025510277599096298,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18030174573262533,
      "backward_entropy": 0.04716164767742157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.252549409866333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025576023384928703,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1802437702814738,
      "backward_entropy": 0.04644947648048401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7198398113250732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025640763342380524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18018782138824463,
      "backward_entropy": 0.045752871036529544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.842022180557251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025705130770802498,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1801291505495707,
      "backward_entropy": 0.04505897760391235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6548099517822266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02576928772032261,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18006632725397745,
      "backward_entropy": 0.044364449381828305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8571364879608154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025833260267972946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1800008217493693,
      "backward_entropy": 0.04367662668228149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6534640789031982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025897284969687462,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17993062734603882,
      "backward_entropy": 0.03482241630554199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1794562339782715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025961078703403473,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17985721429189047,
      "backward_entropy": 0.042306792736053464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2340874671936035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026023967191576958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17978445688883463,
      "backward_entropy": 0.04163766503334045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.758592963218689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02608620375394821,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17971163988113403,
      "backward_entropy": 0.04098018109798431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.422523260116577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02614702098071575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17964237928390503,
      "backward_entropy": 0.05411035418510437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.054856777191162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026207489892840385,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17956912517547607,
      "backward_entropy": 0.032004323601722715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0583622455596924,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02626720443367958,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17949543396631876,
      "backward_entropy": 0.05274006724357605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.932930827140808,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026326121762394905,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17942025264104208,
      "backward_entropy": 0.030946820974349976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9358091354370117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026384158059954643,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17934441566467285,
      "backward_entropy": 0.05141119956970215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7651393413543701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02644127979874611,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17926692962646484,
      "backward_entropy": 0.029926422238349914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8567025661468506,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02649747021496296,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17918958266576132,
      "backward_entropy": 0.05013056993484497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7199956178665161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02655310370028019,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17911136150360107,
      "backward_entropy": 0.03604855537414551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8318949937820435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026607932522892952,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17903278271357217,
      "backward_entropy": 0.03547334671020508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7188889980316162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026662111282348633,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1789512832959493,
      "backward_entropy": 0.04826830625534058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6301946640014648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02671554684638977,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17886785666147867,
      "backward_entropy": 0.027545523643493653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2062201499938965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026768308132886887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17878387371699014,
      "backward_entropy": 0.0337922602891922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5835269689559937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026821613311767578,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17869253953297934,
      "backward_entropy": 0.03323713839054108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7364461421966553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02687423676252365,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17860098679860434,
      "backward_entropy": 0.026215076446533203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3433666229248047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02692658267915249,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17850693066914877,
      "backward_entropy": 0.04529492855072022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6041983366012573,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026977917179465294,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17841506004333496,
      "backward_entropy": 0.025369304418563842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3769018650054932,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0270286425948143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17831925551096597,
      "backward_entropy": 0.024960379302501678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2842519283294678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027078542858362198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17822355031967163,
      "backward_entropy": 0.04359082579612732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.558619499206543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027127550914883614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17812895774841309,
      "backward_entropy": 0.04303945600986481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2440826892852783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02717636525630951,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1780309279759725,
      "backward_entropy": 0.029638725519180297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.420664668083191,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027224378660321236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17793414990107217,
      "backward_entropy": 0.041949570178985596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4114450216293335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027272075414657593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17783522605895996,
      "backward_entropy": 0.028696292638778688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0121805667877197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027319330722093582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17773214975992838,
      "backward_entropy": 0.028232526779174805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9500314593315125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027365252375602722,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17763044436772665,
      "backward_entropy": 0.022347185015678405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1700319051742554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02740999311208725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1775321364402771,
      "backward_entropy": 0.027353394031524658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9791592359542847,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02745431289076805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17743372917175293,
      "backward_entropy": 0.039370876550674436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9070826768875122,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027497628703713417,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.177336057027181,
      "backward_entropy": 0.03888516426086426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9098078012466431,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027539901435375214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17724013328552246,
      "backward_entropy": 0.03841087222099304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7718754410743713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027581078931689262,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17714329560597739,
      "backward_entropy": 0.020764169096946717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9938945174217224,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027621151879429817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17705019315083823,
      "backward_entropy": 0.03750105500221253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8636182546615601,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02766076847910881,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17695502440134683,
      "backward_entropy": 0.037057805061340335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.010730504989624,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027699649333953857,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17685997486114502,
      "backward_entropy": 0.036623090505599976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7246890068054199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027738209813833237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.176760733127594,
      "backward_entropy": 0.03619417250156402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6881705522537231,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775539085268974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17666069666544595,
      "backward_entropy": 0.02393922209739685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7779379487037659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027811748906970024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1765612562497457,
      "backward_entropy": 0.03537908494472504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0610347986221313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02784726768732071,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17646048466364542,
      "backward_entropy": 0.023285505175590516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9019256830215454,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02788327820599079,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17635464668273926,
      "backward_entropy": 0.018679147958755492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6937075853347778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027919011190533638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17624417940775552,
      "backward_entropy": 0.02263219505548477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6182677149772644,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027953971177339554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1761344075202942,
      "backward_entropy": 0.03381689786911011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.712007462978363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027987660840153694,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1760228474934896,
      "backward_entropy": 0.01799481511116028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8573808670043945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028020799160003662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1759097377459208,
      "backward_entropy": 0.021713286638259888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7257524728775024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028054160997271538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17579360802968344,
      "backward_entropy": 0.032729816436767575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6885350346565247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02808701992034912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17567414045333862,
      "backward_entropy": 0.02111890763044357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6112937927246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028119578957557678,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17555461327234903,
      "backward_entropy": 0.01715722680091858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5640946626663208,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02815135195851326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17543367544809976,
      "backward_entropy": 0.03168543577194214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47059258818626404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028182458132505417,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17531422773996988,
      "backward_entropy": 0.03135039508342743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6158861517906189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02821238897740841,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1751958131790161,
      "backward_entropy": 0.020011623203754426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5449617505073547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02824186533689499,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17507398128509521,
      "backward_entropy": 0.016412222385406496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2648393511772156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028270915150642395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17495296398798624,
      "backward_entropy": 0.03039505481719971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5128109455108643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02829824388027191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17483840386072794,
      "backward_entropy": 0.019268028438091278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3884860873222351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028325090184807777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17472209533055624,
      "backward_entropy": 0.019038894772529603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4375261664390564,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028350986540317535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17460747559865317,
      "backward_entropy": 0.029526081681251527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43189364671707153,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028376322239637375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1744931141535441,
      "backward_entropy": 0.018605932593345642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4879280924797058,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028401216492056847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1743794878323873,
      "backward_entropy": 0.018397194147109986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.391242116689682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028425952419638634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17426379521687826,
      "backward_entropy": 0.018189768493175506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4635791778564453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028450259938836098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1741503675778707,
      "backward_entropy": 0.01798769533634186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4542977809906006,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0284744780510664,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17403539021809897,
      "backward_entropy": 0.028187075257301332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3478381335735321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849867194890976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1739195187886556,
      "backward_entropy": 0.017586095631122588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30275049805641174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028521984815597534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17380265394846597,
      "backward_entropy": 0.017393383383750915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4023313522338867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028544090688228607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17368421951929727,
      "backward_entropy": 0.01721082776784897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.408001184463501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028565773740410805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17356157302856445,
      "backward_entropy": 0.017030754685401918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3649524748325348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028587445616722107,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17343737681706747,
      "backward_entropy": 0.014501272141933442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3568466305732727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028608698397874832,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1733109951019287,
      "backward_entropy": 0.014392377436161041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3936249613761902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02862963266670704,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17318312327067056,
      "backward_entropy": 0.014285841584205627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1955382525920868,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02865084819495678,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17305495341618857,
      "backward_entropy": 0.014176666736602783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38107210397720337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028670718893408775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17293012142181396,
      "backward_entropy": 0.01616157740354538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25801604986190796,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02869049832224846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1727999448776245,
      "backward_entropy": 0.015998128056526183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2843642830848694,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028709379956126213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17266897360483804,
      "backward_entropy": 0.01584226042032242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26534685492515564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028727814555168152,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1725372870763143,
      "backward_entropy": 0.013801102340221406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2136770635843277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028745949268341064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17240720987319946,
      "backward_entropy": 0.015541431307792664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30906715989112854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02876342460513115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17228007316589355,
      "backward_entropy": 0.01539922207593918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20194025337696075,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02878078818321228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1721489429473877,
      "backward_entropy": 0.02493327409029007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25117412209510803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028797687962651253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17202216386795044,
      "backward_entropy": 0.015120060741901397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20703627169132233,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02881411835551262,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17189284165700278,
      "backward_entropy": 0.013400468230247497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22237150371074677,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028829755261540413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1717625061670939,
      "backward_entropy": 0.024418240785598753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21649420261383057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02884465828537941,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17162891228993735,
      "backward_entropy": 0.014736396074295045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18931354582309723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028859054669737816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1714936892191569,
      "backward_entropy": 0.014617685973644257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20361188054084778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02887304499745369,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17136025428771973,
      "backward_entropy": 0.014502720534801483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20645034313201904,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028886914253234863,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17122801144917807,
      "backward_entropy": 0.02382092922925949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19023719429969788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02890060842037201,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1710953712463379,
      "backward_entropy": 0.023677949607372285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2021249383687973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028913894668221474,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17096145947774252,
      "backward_entropy": 0.012988758087158204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19563567638397217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028926968574523926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17082500457763672,
      "backward_entropy": 0.014059454202651978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18004179000854492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028939738869667053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17068596680959067,
      "backward_entropy": 0.01395341008901596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14799726009368896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02895224653184414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17054625352223715,
      "backward_entropy": 0.01384936273097992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14332039654254913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028964517638087273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17041003704071045,
      "backward_entropy": 0.013748103380203247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15579421818256378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02897646836936474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17027636369069418,
      "backward_entropy": 0.01364995539188385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15657971799373627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028987957164645195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17014112075169882,
      "backward_entropy": 0.013555166125297547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1479429304599762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0289992094039917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17000540097554526,
      "backward_entropy": 0.0226579949259758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11212187260389328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029010534286499023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16987228393554688,
      "backward_entropy": 0.013369935750961303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11784303933382034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02902130037546158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16974182923634848,
      "backward_entropy": 0.013281527161598205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13160310685634613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029031360521912575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16961081822713217,
      "backward_entropy": 0.022324568033218382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13775910437107086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029041044414043427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1694784959157308,
      "backward_entropy": 0.02222396433353424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08957107365131378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02905060350894928,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16934510072072348,
      "backward_entropy": 0.013037055730819702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0981154814362526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029059812426567078,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16921685139338175,
      "backward_entropy": 0.022028982639312744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11736305803060532,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02906877174973488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16909192005793253,
      "backward_entropy": 0.012435156106948852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10997984558343887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029077649116516113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1689669688542684,
      "backward_entropy": 0.02184196412563324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1283041536808014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02908625639975071,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1688414216041565,
      "backward_entropy": 0.021751999855041504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0849260687828064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02909507229924202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16871492067972818,
      "backward_entropy": 0.012665648758411408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10009326040744781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029103608801960945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16859225432078043,
      "backward_entropy": 0.021571996808052062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10026030987501144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029111793264746666,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16846805810928345,
      "backward_entropy": 0.012525047361850738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09786452353000641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02911974862217903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1683426300684611,
      "backward_entropy": 0.012457389384508133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0942239761352539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029127711430191994,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16821769873301187,
      "backward_entropy": 0.02132277488708496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08020888268947601,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02913566306233406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16809332370758057,
      "backward_entropy": 0.02124113142490387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.074332594871521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029143352061510086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16797016064325967,
      "backward_entropy": 0.012256639450788498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08398748189210892,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029150690883398056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16784814993540445,
      "backward_entropy": 0.012194083631038665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07585567981004715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02915802411735058,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16772673527399698,
      "backward_entropy": 0.012162891775369644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07749585807323456,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0291653610765934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16760746637980142,
      "backward_entropy": 0.020935766398906708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07006557285785675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029172446578741074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16748785972595215,
      "backward_entropy": 0.012008765339851379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06848699599504471,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029179522767663002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16737043857574463,
      "backward_entropy": 0.020790858566761015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0681946724653244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02918631210923195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16725287834803262,
      "backward_entropy": 0.02072145938873291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06809840351343155,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029192719608545303,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1671339472134908,
      "backward_entropy": 0.012061088532209396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06480202823877335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029199395328760147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16701765855153403,
      "backward_entropy": 0.011777694523334502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05608883500099182,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029205957427620888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16690162817637125,
      "backward_entropy": 0.02052173912525177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05811498686671257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029212530702352524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16678863763809204,
      "backward_entropy": 0.020455102622509002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05213674530386925,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0292188860476017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16667572657267252,
      "backward_entropy": 0.020390786230564117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03791029006242752,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029225053265690804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16656424601872763,
      "backward_entropy": 0.02032829523086548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04359791800379753,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02923102118074894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16645787159601846,
      "backward_entropy": 0.020267236232757568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050663936883211136,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02923688292503357,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16635476549466452,
      "backward_entropy": 0.011458390951156616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035601384937763214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029242495074868202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16625136137008667,
      "backward_entropy": 0.01141013130545616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04271510988473892,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02924782782793045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16615108648935953,
      "backward_entropy": 0.020094466209411622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.043121159076690674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02925300970673561,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16605152686436972,
      "backward_entropy": 0.011884746700525283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04718947038054466,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029258310794830322,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1659539739290873,
      "backward_entropy": 0.011869557946920396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029493678361177444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02926366589963436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16585570573806763,
      "backward_entropy": 0.011226897686719894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0418519601225853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029268654063344002,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16576023896535239,
      "backward_entropy": 0.011839842796325684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0322047658264637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029273439198732376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16566340128580728,
      "backward_entropy": 0.01983064115047455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035338059067726135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029278086498379707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1655686100323995,
      "backward_entropy": 0.019782572984695435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03801568225026131,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02928289584815502,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16547580560048422,
      "backward_entropy": 0.019733162224292757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02747783623635769,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029287446290254593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1653809348742167,
      "backward_entropy": 0.011017714440822602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029522687196731567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029291890561580658,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16528891523679098,
      "backward_entropy": 0.01097824051976204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030279334634542465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02929617092013359,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16519776980082193,
      "backward_entropy": 0.010940044373273849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031923871487379074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029300546273589134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16510810454686484,
      "backward_entropy": 0.010901206731796264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030145900323987007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02930493652820587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16501825054486594,
      "backward_entropy": 0.010862108319997787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026523208245635033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293091032654047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16492734352747598,
      "backward_entropy": 0.010824417322874069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02268199250102043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029313016682863235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.164836585521698,
      "backward_entropy": 0.010788541287183762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027829885482788086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029316747561097145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16474745670954385,
      "backward_entropy": 0.010754212737083435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026599669829010963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029320374131202698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16465705633163452,
      "backward_entropy": 0.010720445960760116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024653421714901924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029323896393179893,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16456472873687744,
      "backward_entropy": 0.010687237977981568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02311558648943901,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029327351599931717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16447226206461588,
      "backward_entropy": 0.01927955597639084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018590649589896202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029330629855394363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16437939802805582,
      "backward_entropy": 0.010622940957546234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01836269721388817,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933391183614731,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1642891267935435,
      "backward_entropy": 0.01921345591545105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01865646243095398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933715656399727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16420076290766397,
      "backward_entropy": 0.0105609230697155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019046349450945854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029340239241719246,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1641130248705546,
      "backward_entropy": 0.019149595499038698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01444887463003397,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029343103989958763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1640251874923706,
      "backward_entropy": 0.019120556116104127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018793150782585144,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029345912858843803,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16394040981928507,
      "backward_entropy": 0.011669549345970153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015703517943620682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029348652809858322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16385499636332193,
      "backward_entropy": 0.010449337214231491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013669975101947784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02935149148106575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16377127170562744,
      "backward_entropy": 0.01042199283838272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012881860136985779,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029354332014918327,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16368969281514487,
      "backward_entropy": 0.019007503986358643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013288331218063831,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029357032850384712,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16360961397488913,
      "backward_entropy": 0.018980391323566437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011677929200232029,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029359586536884308,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1635302205880483,
      "backward_entropy": 0.018954738974571228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011101690120995045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029362058266997337,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16345253586769104,
      "backward_entropy": 0.018929833173751832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009223316796123981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02936449460685253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1633769373099009,
      "backward_entropy": 0.010297194868326188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010931414552032948,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029366889968514442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16330432891845703,
      "backward_entropy": 0.01888105124235153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009995848871767521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029369110241532326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1632321079572042,
      "backward_entropy": 0.0102528914809227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010679426603019238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029371194541454315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16316082080205283,
      "backward_entropy": 0.01023244857788086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006759714800864458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029373114928603172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16308932503064474,
      "backward_entropy": 0.01021309792995453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008317657746374607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375074431300163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1630216638247172,
      "backward_entropy": 0.010193906724452972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007456008344888687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376868158578873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16295499602953592,
      "backward_entropy": 0.01877877116203308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0073832301422953606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937864139676094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16289039452870688,
      "backward_entropy": 0.010158397257328033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006665095686912537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029380401596426964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16282769044240317,
      "backward_entropy": 0.01014103889465332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006634394638240337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029381955042481422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16276619831720987,
      "backward_entropy": 0.010125294327735901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006556162144988775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029383543878793716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16270634531974792,
      "backward_entropy": 0.010109420120716094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005835091229528189,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029385168105363846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16264783342679343,
      "backward_entropy": 0.018691925704479216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005955674219876528,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0293867364525795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1625907818476359,
      "backward_entropy": 0.01867547333240509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005573677364736795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02938830293715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16253483295440674,
      "backward_entropy": 0.010062532871961594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005045006982982159,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02938976138830185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1624798079331716,
      "backward_entropy": 0.010047990083694457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004768405109643936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029391298070549965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16242667039235434,
      "backward_entropy": 0.010033039748668671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004621852654963732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029392775148153305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16237483421961466,
      "backward_entropy": 0.010018625855445861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0044023036025464535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029394259676337242,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1623243490854899,
      "backward_entropy": 0.011633896827697754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004256416577845812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029395628720521927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16227487723032633,
      "backward_entropy": 0.018582943081855773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004681228660047054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02939695492386818,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1622264285882314,
      "backward_entropy": 0.009977765381336212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034665914718061686,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029398156329989433,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1621779998143514,
      "backward_entropy": 0.018556565046310425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004051194526255131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029399361461400986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16213144858678183,
      "backward_entropy": 0.009953420609235764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00367868528701365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029400553554296494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16208529472351074,
      "backward_entropy": 0.00994146168231964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032534629572182894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029401667416095734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16203967730204263,
      "backward_entropy": 0.009930076450109482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003212404204532504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02940269559621811,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16199499368667603,
      "backward_entropy": 0.0185078889131546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003379469970241189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029403574764728546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16195080677668253,
      "backward_entropy": 0.009909855574369431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028783935122191906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029404543340206146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16190731525421143,
      "backward_entropy": 0.00989968478679657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025972388684749603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029405446723103523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16186468799908957,
      "backward_entropy": 0.009890037029981614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026759577449411154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02940630353987217,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16182321310043335,
      "backward_entropy": 0.011644482612609863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021797579247504473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029407110065221786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178250312805176,
      "backward_entropy": 0.00987202525138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020719505846500397,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029407981783151627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174346208572388,
      "backward_entropy": 0.009862935543060303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002145580481737852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02940884232521057,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16170579195022583,
      "backward_entropy": 0.018440233170986177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017900719540193677,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029409684240818024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16166903575261435,
      "backward_entropy": 0.01843109875917435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002534969011321664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029410509392619133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16163372000058493,
      "backward_entropy": 0.018422065675258635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018259510397911072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029411260038614273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1615977088610331,
      "backward_entropy": 0.009828788042068482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019501777132973075,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02941199764609337,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16156272093454996,
      "backward_entropy": 0.01840573698282242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016864539356902242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029412759467959404,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16152815024058023,
      "backward_entropy": 0.009812919050455093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014730182010680437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029413415119051933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1614941656589508,
      "backward_entropy": 0.01839023530483246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001291557913646102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02941407449543476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1614613632361094,
      "backward_entropy": 0.009798562526702881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011570804053917527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02941472828388214,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16142996152242026,
      "backward_entropy": 0.011660369485616684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001436822465620935,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02941538579761982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16140010952949524,
      "backward_entropy": 0.018368476629257204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015176086453720927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029416009783744812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16137057542800903,
      "backward_entropy": 0.009778212755918503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011074867798015475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029416635632514954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.161341001590093,
      "backward_entropy": 0.018354828655719756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010858129244297743,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02941722981631756,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16131240129470825,
      "backward_entropy": 0.018348237872123717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001245219842530787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029417797923088074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16128464539845785,
      "backward_entropy": 0.018341821432113648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011530077317729592,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02941836416721344,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16125700871149698,
      "backward_entropy": 0.018335455656051637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008626696071587503,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029418911784887314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16122968991597494,
      "backward_entropy": 0.018329328298568724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007943024975247681,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02941950038075447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16120357314745584,
      "backward_entropy": 0.00974118784070015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009406128665432334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02942010946571827,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16117865840593973,
      "backward_entropy": 0.01831636130809784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008256782894022763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029420729726552963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16115407148996988,
      "backward_entropy": 0.018309757113456726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007451377459801733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029421323910355568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1611300508181254,
      "backward_entropy": 0.009722935408353806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006618002662435174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02942190133035183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1611067255338033,
      "backward_entropy": 0.009717141836881637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006637959158979356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02942248247563839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16108431418736777,
      "backward_entropy": 0.00971142053604126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005217358120717108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029423046857118607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16106253862380981,
      "backward_entropy": 0.009705847501754761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005916613154113293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029423639178276062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16104193528493246,
      "backward_entropy": 0.01827853173017502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047928193816915154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029424211010336876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16102190812428793,
      "backward_entropy": 0.01827242374420166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005206677014939487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02942478470504284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16100290417671204,
      "backward_entropy": 0.009689376503229142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005314285517670214,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029425300657749176,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16098434726397196,
      "backward_entropy": 0.011670129746198655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004628086171578616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029425783082842827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16096599896748862,
      "backward_entropy": 0.009679765999317169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004118061042390764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02942625805735588,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1609481374422709,
      "backward_entropy": 0.018250079452991487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003687167481984943,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029426701366901398,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1609308918317159,
      "backward_entropy": 0.018245147168636323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039425649447366595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029427122324705124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16091438134511313,
      "backward_entropy": 0.00966678112745285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003937060828320682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029427550733089447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16089830795923868,
      "backward_entropy": 0.00966266393661499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039969608769752085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02942795865237713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16088245312372842,
      "backward_entropy": 0.009658713638782502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003242448146920651,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02942831441760063,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16086666782697043,
      "backward_entropy": 0.018227049708366395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028088022372685373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02942865900695324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16085137923558554,
      "backward_entropy": 0.009651651978492737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002916616213042289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294289980083704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16083678603172302,
      "backward_entropy": 0.00964827612042427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029754405841231346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02942931093275547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16082256038983664,
      "backward_entropy": 0.009645094722509384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024221408239100128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029429595917463303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16080854336420694,
      "backward_entropy": 0.00964215248823166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025604289839975536,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02942989580333233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1607950528462728,
      "backward_entropy": 0.018208655714988708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026645552134141326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943020686507225,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16078190008799234,
      "backward_entropy": 0.01167568638920784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018171530973631889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943050116300583,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16076882680257162,
      "backward_entropy": 0.011676213145256043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001953097671503201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029430817812681198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16075646877288818,
      "backward_entropy": 0.01819816529750824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018225042731501162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029431113973259926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1607445478439331,
      "backward_entropy": 0.009627147763967513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023326781229116023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029431382194161415,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16073302427927652,
      "backward_entropy": 0.011677202582359315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016054106527008116,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029431642964482307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1607213815053304,
      "backward_entropy": 0.01818862557411194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002066723391180858,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029431894421577454,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16071020563443503,
      "backward_entropy": 0.01167820543050766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015534333942923695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943211793899536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16069887081782022,
      "backward_entropy": 0.009616967290639877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001550659944768995,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029432350769639015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16068792343139648,
      "backward_entropy": 0.009614570438861847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012943953333888203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029432594776153564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16067721446355185,
      "backward_entropy": 0.018177710473537445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013429285900201648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029432842507958412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1606669227282206,
      "backward_entropy": 0.01817488670349121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001367985678371042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029433084651827812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1606568694114685,
      "backward_entropy": 0.00960727483034134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012090791278751567,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943330630660057,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16064695517222086,
      "backward_entropy": 0.01168074756860733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012509882799349725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029433520510792732,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1606372892856598,
      "backward_entropy": 0.018167154490947725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.980016329791397e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029433725401759148,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1606277028719584,
      "backward_entropy": 0.009600720554590225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.669944509165362e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943391352891922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1606184442838033,
      "backward_entropy": 0.009598763287067413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010417440353194252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943410538136959,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16060960292816162,
      "backward_entropy": 0.018160431087017058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.592481026425958e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943428047001362,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16060084104537964,
      "backward_entropy": 0.011683014035224915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.201005402952433e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943444810807705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1605923374493917,
      "backward_entropy": 0.009593182802200317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.562844984931871e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029434606432914734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16058403253555298,
      "backward_entropy": 0.009591484814882279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.830319373169914e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943475916981697,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16057602564493814,
      "backward_entropy": 0.018152740597724915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835120439063758e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029434898868203163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16056809822718301,
      "backward_entropy": 0.009588326513767242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.670734728686512e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029435034841299057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16056042909622192,
      "backward_entropy": 0.009586803615093231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.47133492748253e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029435159638524055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16055288910865784,
      "backward_entropy": 0.01814793348312378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.859586599399336e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943526953458786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1605454683303833,
      "backward_entropy": 0.00958414226770401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.145759860170074e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029435385018587112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16053825616836548,
      "backward_entropy": 0.009582830965518952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.324497033143416e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029435506090521812,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16053134202957153,
      "backward_entropy": 0.011688478291034698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5976255933055654e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943562902510166,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1605245272318522,
      "backward_entropy": 0.011688969284296035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.332336175139062e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943575009703636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1605179707209269,
      "backward_entropy": 0.018140797317028046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.496539284242317e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029435867443680763,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16051161289215088,
      "backward_entropy": 0.011689894646406174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.658638524939306e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029435988515615463,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16050562262535095,
      "backward_entropy": 0.011690241098403931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5743374610319734e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029436107724905014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1604998509089152,
      "backward_entropy": 0.01813657283782959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.256554919062182e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943621762096882,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16049420833587646,
      "backward_entropy": 0.009573884308338165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.419225322431885e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029436316341161728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16048874457677206,
      "backward_entropy": 0.009572836756706237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8723135983454995e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029436418786644936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1604833503564199,
      "backward_entropy": 0.018132814764976503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.45400624407921e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029436523094773293,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16047816475232443,
      "backward_entropy": 0.009570644050836564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4445707822451368e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029436636716127396,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16047330697377524,
      "backward_entropy": 0.01813024878501892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2252832422964275e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943674847483635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604686180750529,
      "backward_entropy": 0.00956844985485077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5583174647181295e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0294368676841259,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1604641874631246,
      "backward_entropy": 0.01812759041786194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2218791855266318e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943698689341545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16045977671941122,
      "backward_entropy": 0.00956619456410408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8633672880241647e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0294371098279953,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1604554851849874,
      "backward_entropy": 0.011692473292350769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.884418998088222e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943722903728485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604513426621755,
      "backward_entropy": 0.00956394299864769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.624789547349792e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943735010921955,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160447359085083,
      "backward_entropy": 0.018122252821922303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3555981240642723e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294374730437994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16044354438781738,
      "backward_entropy": 0.009561719000339508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5184973563009407e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0294375941157341,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1604399879773458,
      "backward_entropy": 0.018119567632675172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2822345524909906e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294377189129591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16043653090794882,
      "backward_entropy": 0.009559521079063415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1910579814866651e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029437841847538948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16043325265248617,
      "backward_entropy": 0.009558477997779846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0251409548800439e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029437962919473648,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16043011347452799,
      "backward_entropy": 0.009557439386844635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1448741133790463e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0294380821287632,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1604271630446116,
      "backward_entropy": 0.011691061407327652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.073036310117459e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943819761276245,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16042428215344748,
      "backward_entropy": 0.011690812557935715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870129022398032e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029438307508826256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16042145093282065,
      "backward_entropy": 0.009554510563611984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513916666037403e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029438413679599762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16041875878969827,
      "backward_entropy": 0.009553609788417817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.988753168319818e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943851426243782,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16041610638300577,
      "backward_entropy": 0.018109484016895293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08413460617885e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943861111998558,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16041352351506552,
      "backward_entropy": 0.011689995974302292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.725921932433266e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029438696801662445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16041102011998495,
      "backward_entropy": 0.009551159292459487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246268523886101e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029438776895403862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604085365931193,
      "backward_entropy": 0.009550460427999497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.44596730126068e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943885326385498,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16040613253911337,
      "backward_entropy": 0.018105721473693846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.945943601342151e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943892776966095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16040374835332236,
      "backward_entropy": 0.011689771711826325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.359019723982783e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943900041282177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16040154298146567,
      "backward_entropy": 0.01810404658317566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3636722441297024e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943906933069229,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16039941708246866,
      "backward_entropy": 0.009547845274209977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.667541361413896e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439136385917664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16039733091990152,
      "backward_entropy": 0.009547252953052521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.882241344399517e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029439203441143036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16039531429608664,
      "backward_entropy": 0.01810174286365509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.304816800664412e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943926677107811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16039341688156128,
      "backward_entropy": 0.009546104818582535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.420422899580444e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439333826303482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16039166847864786,
      "backward_entropy": 0.009545548260211945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5410434975347016e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439399018883705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16038997968037924,
      "backward_entropy": 0.009544998407363892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1580389077134896e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943946234881878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16038834055264792,
      "backward_entropy": 0.018098776042461396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.409676764931646e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029439521953463554,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16038678089777628,
      "backward_entropy": 0.01168907731771469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.257973730796948e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439575970172882,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603852113087972,
      "backward_entropy": 0.009543466567993163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5539181933709187e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943962626159191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16038364171981812,
      "backward_entropy": 0.00954304039478302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.279067985000438e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02943967469036579,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603821317354838,
      "backward_entropy": 0.009542610496282578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0206334738759324e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029439721256494522,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603807012240092,
      "backward_entropy": 0.018095801770687103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.02950695893378e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029439769685268402,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16037934025128683,
      "backward_entropy": 0.018095259368419648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.92483139471733e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439816251397133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16037802894910178,
      "backward_entropy": 0.009541389346122742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4138416872810922e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439860954880714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603767474492391,
      "backward_entropy": 0.009541022777557372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7722757092997199e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439905658364296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603755752245585,
      "backward_entropy": 0.009540620446205138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5038593801364186e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943994663655758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16037444273630777,
      "backward_entropy": 0.01809321641921997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4906943306414178e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029439987614750862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16037334005037943,
      "backward_entropy": 0.009539934247732163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2215319884489872e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440024867653847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16037225723266602,
      "backward_entropy": 0.00953960046172142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3347042795430752e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944006212055683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603712538878123,
      "backward_entropy": 0.009539284557104111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0451919933984755e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440095648169518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16037029027938843,
      "backward_entropy": 0.009539011120796203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0307815045962343e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440129175782204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16036935647328696,
      "backward_entropy": 0.00953872799873352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1199626896996051e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944016084074974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603684425354004,
      "backward_entropy": 0.009538463503122329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0817113889061147e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944019064307213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16036757826805115,
      "backward_entropy": 0.018090330064296722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.028262772706512e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440218582749367,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16036668419837952,
      "backward_entropy": 0.01809000372886658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.749087558295287e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440242797136307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16036581993103027,
      "backward_entropy": 0.009537722915410995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73212570695614e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440267011523247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16036500533421835,
      "backward_entropy": 0.009537509828805923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.411229946934327e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440289363265038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603641907374064,
      "backward_entropy": 0.009537331759929657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.271355689728807e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944031171500683,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16036340594291687,
      "backward_entropy": 0.011688626557588577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.182671086207847e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944033406674862,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1603626807530721,
      "backward_entropy": 0.011688637733459472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.858085501131427e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944035455584526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16036197543144226,
      "backward_entropy": 0.009536763280630111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.670266887136677e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440373182296753,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16036130984624228,
      "backward_entropy": 0.018088097870349883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.819593755200913e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440391808748245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16036065419514975,
      "backward_entropy": 0.009536427259445191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.162567049410427e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944040857255459,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16036001841227213,
      "backward_entropy": 0.011688734591007232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.021112829377671e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944042533636093,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16035940249760947,
      "backward_entropy": 0.011688759922981263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.276088532151334e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440440237522125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16035878658294678,
      "backward_entropy": 0.01808726489543915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8835881355225865e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944045513868332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035820047060648,
      "backward_entropy": 0.009535850584506988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1107384163296956e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440468177199364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603576441605886,
      "backward_entropy": 0.009535697102546693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3337735178283765e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944048121571541,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603570580482483,
      "backward_entropy": 0.00953558161854744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6207646897091763e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440492391586304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035649180412292,
      "backward_entropy": 0.009535476565361023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.324757926748134e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0294405035674572,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603559652964274,
      "backward_entropy": 0.018086446821689604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.918035875154601e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440512880682945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035540898640951,
      "backward_entropy": 0.009535262733697892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.707706698856782e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944052219390869,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16035487254460654,
      "backward_entropy": 0.018086186051368712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0897786612295022e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440531507134438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035435597101846,
      "backward_entropy": 0.009535090625286102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0799286915007542e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440540820360184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603538691997528,
      "backward_entropy": 0.009534989297389985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2748106687231484e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944055013358593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16035338242848715,
      "backward_entropy": 0.018085864186286927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2233689378481358e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440557584166527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16035290559132895,
      "backward_entropy": 0.018085765838623046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4216583110737702e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440565034747124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035244862238565,
      "backward_entropy": 0.009534750878810883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5103572081898164e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944057248532772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16035200158754984,
      "backward_entropy": 0.011689439415931702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4872500742058037e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440579935908318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603515942891439,
      "backward_entropy": 0.0180854856967926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3788721275886928e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029440587386488914,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16035117705663046,
      "backward_entropy": 0.011689510941505433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0527053717623858e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440592974424362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035080949465433,
      "backward_entropy": 0.009534447640180587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.462111367180114e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944060042500496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035044193267822,
      "backward_entropy": 0.00953439250588417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2297252283133275e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440607875585556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603501041730245,
      "backward_entropy": 0.009534310549497604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0881078793545385e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440613463521004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034976641337076,
      "backward_entropy": 0.009534233808517456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0607494971281994e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944061905145645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034944852193198,
      "backward_entropy": 0.009534185379743576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.759040698829267e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294406246393919,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603491504987081,
      "backward_entropy": 0.009534122049808502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.624468167932719e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440630227327347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034887234369913,
      "backward_entropy": 0.00953407883644104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.525228795657313e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440635815262794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034859418869019,
      "backward_entropy": 0.01808471530675888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.891434705697975e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440641403198242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034831603368124,
      "backward_entropy": 0.01808466613292694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.751424308504284e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944064699113369,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603480577468872,
      "backward_entropy": 0.009533911943435669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.635331135067645e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944065071642399,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034779946009317,
      "backward_entropy": 0.01168988049030304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.497586030855928e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440654441714287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034756104151407,
      "backward_entropy": 0.009533843398094178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.491235117143333e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440658167004585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034733255704245,
      "backward_entropy": 0.018084405362606047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.329029934524442e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029440661892294884,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034708420435587,
      "backward_entropy": 0.011689966917037964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.797796921389818e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440665617585182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603468954563141,
      "backward_entropy": 0.009533718228340149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.200314762670132e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944066934287548,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603467067082723,
      "backward_entropy": 0.009533660113811493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7658537621609867e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944067306816578,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034650802612305,
      "backward_entropy": 0.011690010875463485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.583551588803857e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440676793456078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034632921218872,
      "backward_entropy": 0.009533572196960449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5706108292288263e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440680518746376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034614046414694,
      "backward_entropy": 0.01808406263589859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9098353948597833e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029440684244036674,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034598151842752,
      "backward_entropy": 0.01169007271528244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.378169483563397e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440687969326973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603458027044932,
      "backward_entropy": 0.00953349769115448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5299353723085005e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944069169461727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034565369288126,
      "backward_entropy": 0.00953344777226448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1914697612146483e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944069541990757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034550468126932,
      "backward_entropy": 0.00953342393040657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9451492860866892e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944069914519787,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034535566965738,
      "backward_entropy": 0.0095333993434906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.984435904489601e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440702870488167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034522652626038,
      "backward_entropy": 0.0095333531498909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0075219708814984e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440706595778465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034511725107828,
      "backward_entropy": 0.01808375269174576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5547001908089442e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440710321068764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034497817357382,
      "backward_entropy": 0.018083693087100984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6233066446602606e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440714046359062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034487883249918,
      "backward_entropy": 0.018083658814430238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9779264448516187e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944071777164936,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034475962320963,
      "backward_entropy": 0.011690184473991394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2600033016951784e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944071963429451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160344660282135,
      "backward_entropy": 0.018083573877811433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0934201100099017e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944072149693966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034454107284546,
      "backward_entropy": 0.018083524703979493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4311410723166773e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944072335958481,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603444516658783,
      "backward_entropy": 0.009533187747001648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.258834458894853e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440725222229958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034435232480368,
      "backward_entropy": 0.009533172845840454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0195130073498149e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029440727084875107,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034426291783652,
      "backward_entropy": 0.01169021874666214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.072078958941347e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440728947520256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034417351086935,
      "backward_entropy": 0.01808340400457382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.999727020229329e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440730810165405,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603441039721171,
      "backward_entropy": 0.01808338314294815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.101771532485145e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440732672810555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034402449925741,
      "backward_entropy": 0.00953308641910553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.105178667643486e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440734535455704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034393509229025,
      "backward_entropy": 0.009533074498176575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.639616690838011e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440736398100853,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160343865553538,
      "backward_entropy": 0.018083293735980988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519417977164267e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440738260746002,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603437860806783,
      "backward_entropy": 0.009533048421144486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.41742650739252e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944074012339115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160343736410141,
      "backward_entropy": 0.018083226680755616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.046047135692788e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294407419860363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034366687138876,
      "backward_entropy": 0.009533001482486725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.550720854647807e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944074384868145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160343607266744,
      "backward_entropy": 0.018083184957504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.060030616732547e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0294407457113266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034356753031412,
      "backward_entropy": 0.018083147704601288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.250182428222615e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944074757397175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034350792566934,
      "backward_entropy": 0.018083128333091735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.929635283839161e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029440749436616898,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034344832102457,
      "backward_entropy": 0.011690302193164826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5448124435788486e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029440751299262047,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034340858459473,
      "backward_entropy": 0.011690309643745423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8514506311694277e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440753161907196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603433589140574,
      "backward_entropy": 0.00953294187784195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.054633961914078e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440755024552345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603433092435201,
      "backward_entropy": 0.009532935917377472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7067628138865985e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440756887197495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034326950709024,
      "backward_entropy": 0.018083035945892334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.687109201815474e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440758749842644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034320990244547,
      "backward_entropy": 0.0180830255150795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9554704522306565e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440760612487793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034317016601562,
      "backward_entropy": 0.018083009123802184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1245938341962756e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029440762475132942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034313042958578,
      "backward_entropy": 0.009532885998487473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.216602013049851e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944076433777809,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034309069315592,
      "backward_entropy": 0.011690342426300048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6278499376530817e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034306089083353,
      "backward_entropy": 0.009532873332500458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2239419195102528e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034301122029623,
      "backward_entropy": 0.00953286737203598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5827694710424112e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034298141797385,
      "backward_entropy": 0.009532857686281204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4352963262354024e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034297148386636,
      "backward_entropy": 0.009532855451107025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5883543369454856e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034293174743652,
      "backward_entropy": 0.018082927167415618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4704824025102425e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034289201100668,
      "backward_entropy": 0.009532846510410309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3542447163672477e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034287214279175,
      "backward_entropy": 0.00953284427523613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.158689144631353e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603428324063619,
      "backward_entropy": 0.018082877993583678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.043702013703296e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034281253814697,
      "backward_entropy": 0.011690401285886765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.79198944150994e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034279266993204,
      "backward_entropy": 0.009532834589481353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251319627561315e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603427529335022,
      "backward_entropy": 0.01808285862207413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.332694617114612e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034273306528726,
      "backward_entropy": 0.009532829374074936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.232774462157977e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034271319707236,
      "backward_entropy": 0.018082842230796814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.988329914747737e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034271319707236,
      "backward_entropy": 0.018082836270332338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.218616815407586e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034269332885742,
      "backward_entropy": 0.00953281968832016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.809468461848155e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603426734606425,
      "backward_entropy": 0.009532814472913742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.148184183984995e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034265359242758,
      "backward_entropy": 0.009532788395881652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.157989673738484e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034263372421265,
      "backward_entropy": 0.009532788395881652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4227022044651676e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603426138559977,
      "backward_entropy": 0.009532785415649414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8136960256451857e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034260392189026,
      "backward_entropy": 0.01808277815580368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.278266712593904e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603425939877828,
      "backward_entropy": 0.018082772195339204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1579539811209543e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034257411956787,
      "backward_entropy": 0.009532776474952698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.531415243036463e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034255425135294,
      "backward_entropy": 0.009532773494720459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.752678250952158e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034255425135294,
      "backward_entropy": 0.009532773494720459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.638191969912441e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034253438313803,
      "backward_entropy": 0.01808275282382965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.409752480365569e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034254431724548,
      "backward_entropy": 0.011690437048673629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.183568881264364e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603425145149231,
      "backward_entropy": 0.009532764554023743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9976376936247107e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603425145149231,
      "backward_entropy": 0.018082737922668457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.701767698454205e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603425145149231,
      "backward_entropy": 0.018082737922668457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.962821099572466e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034250458081564,
      "backward_entropy": 0.018082727491855622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.643858465489757e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034249464670816,
      "backward_entropy": 0.01808270961046219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8404477941658115e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034249464670816,
      "backward_entropy": 0.009532755613327027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3577229057991644e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034249464670816,
      "backward_entropy": 0.009532755613327027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1302781760823564e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034247477849325,
      "backward_entropy": 0.009532755613327027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9804247131105512e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034247477849325,
      "backward_entropy": 0.009532755613327027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9768719994317507e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034247477849325,
      "backward_entropy": 0.018082693219184875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5208456716209184e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034245491027832,
      "backward_entropy": 0.018082688748836517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5782575246703345e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034245491027832,
      "backward_entropy": 0.011690443754196167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5018031263025478e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034245491027832,
      "backward_entropy": 0.018082684278488158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.438991148461355e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034244497617087,
      "backward_entropy": 0.00953274667263031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4008350035510375e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034243504206339,
      "backward_entropy": 0.009532743692398071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2571632623803453e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034243504206339,
      "backward_entropy": 0.01808267831802368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.020907802740112e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034243504206339,
      "backward_entropy": 0.009532743692398071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.839595804805867e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034243504206339,
      "backward_entropy": 0.011690443754196167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0333423006159137e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034243504206339,
      "backward_entropy": 0.018082667887210847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.191847200578195e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034243504206339,
      "backward_entropy": 0.009532737731933593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.080291991063859e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034242510795593,
      "backward_entropy": 0.009532737731933593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279954499812447e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034242510795593,
      "backward_entropy": 0.018082666397094726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.974421123435604e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034241517384848,
      "backward_entropy": 0.009532737731933593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.558043080280186e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160342405239741,
      "backward_entropy": 0.018082661926746367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.463807267209631e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034241517384848,
      "backward_entropy": 0.011690448224544524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.999556489972747e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160342405239741,
      "backward_entropy": 0.01808265745639801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.554756737386924e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034239530563354,
      "backward_entropy": 0.009532734751701355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.292122295941226e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034239530563354,
      "backward_entropy": 0.009532734751701355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.993694346921984e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034239530563354,
      "backward_entropy": 0.018082650005817415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.354650056688115e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16034239530563354,
      "backward_entropy": 0.011690448224544524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9896974612929625e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02944076620042324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034239530563354,
      "backward_entropy": 0.018082647025585173,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.28522804749332e-09,
    "avg_log_Z": 0.02944074572995305,
    "success_rate": 1.0,
    "avg_reward": 42.1,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.14,
      "1": 0.39,
      "2": 0.47
    },
    "avg_forward_entropy": 0.16034348597129186,
    "avg_backward_entropy": 0.013169528774917125,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}