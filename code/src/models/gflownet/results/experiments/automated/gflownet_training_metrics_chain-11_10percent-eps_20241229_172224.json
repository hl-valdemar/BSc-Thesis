{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06298329071565108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06298329071565108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06298329071565108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06298329071565108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06298329071565108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06298329071565108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.06289290839975531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.976273536682129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143956502278645,
      "backward_entropy": 0.0629193511876193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.60227108001709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143882989883423,
      "backward_entropy": 0.06291540102525191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.968926429748535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019993555906694382,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143771727879842,
      "backward_entropy": 0.06291135874661533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.210836410522461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00029993202770128846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143664439519246,
      "backward_entropy": 0.06287782842462714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.223742485046387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004000060143880546,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143546223640442,
      "backward_entropy": 0.06297352097251198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.221007347106934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000499862595461309,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143394231796265,
      "backward_entropy": 0.06289865753867409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.586319923400879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000599582155700773,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143220384915669,
      "backward_entropy": 0.06296804276379672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.729050636291504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006993234856054187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143039584159851,
      "backward_entropy": 0.06285574761303989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.461953163146973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007988220313563943,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142854809761047,
      "backward_entropy": 0.06296209313652733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.80229377746582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008983882144093513,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142692883809407,
      "backward_entropy": 0.06284356117248535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.189970016479492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009984050411731005,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142550826072693,
      "backward_entropy": 0.06295555830001831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329895973205566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010985976550728083,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142424662907918,
      "backward_entropy": 0.06295198743993585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.202444076538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001198633573949337,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142285585403442,
      "backward_entropy": 0.06286632472818549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929874420166016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001298487652093172,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142118692398071,
      "backward_entropy": 0.06294445558027788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.843264102935791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013984511606395245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141942858695984,
      "backward_entropy": 0.06281025301326405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.423696517944336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001498144119977951,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141775965690613,
      "backward_entropy": 0.06293639269742099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.044635772705078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015981951728463173,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141648809115092,
      "backward_entropy": 0.06293213367462158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.964053630828857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016983785899356008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141512711842854,
      "backward_entropy": 0.06278816136446866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.275279998779297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017983019351959229,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141399463017781,
      "backward_entropy": 0.06278044527227228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.996034622192383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001898456714116037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141264359156291,
      "backward_entropy": 0.06277250159870494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.406982421875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001999070169404149,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141117334365845,
      "backward_entropy": 0.06276439536701549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.22161865234375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020998986437916756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140994151433308,
      "backward_entropy": 0.06275612657720392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.105711936950684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022011552937328815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140843152999878,
      "backward_entropy": 0.06274760311300104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.63051986694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023027535062283278,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140685200691223,
      "backward_entropy": 0.06280024485154585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.969045639038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024044837336987257,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140533208847046,
      "backward_entropy": 0.06279333071275191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.465137481689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025064197834581137,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914035936196645,
      "backward_entropy": 0.0627862431786277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.473493576049805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026087623555213213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140198429425557,
      "backward_entropy": 0.06271133639595726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.737448692321777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027110085356980562,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140002727508545,
      "backward_entropy": 0.06287283247167413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.40941333770752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028133299201726913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139827887217204,
      "backward_entropy": 0.0626918456771157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.582735061645508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029159081168472767,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913961132367452,
      "backward_entropy": 0.06275627287951382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.258272171020508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0030183964408934116,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139372905095418,
      "backward_entropy": 0.06274827501990578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.237028121948242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031202230602502823,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139090776443481,
      "backward_entropy": 0.06284534389322455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.523148536682129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032219444401562214,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138818581899007,
      "backward_entropy": 0.06283792582425204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.269353866577148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003323266515508294,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138558308283488,
      "backward_entropy": 0.06272285634821112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.099334716796875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0034241003450006247,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138286113739014,
      "backward_entropy": 0.06262732635844838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.927138328552246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003524879924952984,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138011932373047,
      "backward_entropy": 0.06281466375697743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.863992691040039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036259805783629417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137743711471558,
      "backward_entropy": 0.06280632452531294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.633783340454102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037268984597176313,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137480457623799,
      "backward_entropy": 0.06268570639870384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.107661247253418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0038275648839771748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09137239058812459,
      "backward_entropy": 0.06257856975902211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.329652786254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003928233869373798,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137021501859029,
      "backward_entropy": 0.06266595016826283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.376724243164062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0040289913304150105,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136813879013062,
      "backward_entropy": 0.06276993318037553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.371087074279785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004130289424210787,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136604269345601,
      "backward_entropy": 0.0627600984139876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.669478416442871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0042311339639127254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136383732159932,
      "backward_entropy": 0.06252483888105913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.786392211914062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004331250209361315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136160214742024,
      "backward_entropy": 0.0625106692314148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.459589958190918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004431739915162325,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135949611663818,
      "backward_entropy": 0.06272888725454157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.956317901611328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004532448016107082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135788679122925,
      "backward_entropy": 0.06248136000199751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6882243156433105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0046330648474395275,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913563072681427,
      "backward_entropy": 0.06258873506025835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.171090126037598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004733014851808548,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913550357023875,
      "backward_entropy": 0.06257662989876488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.944990158081055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004833051934838295,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135359525680542,
      "backward_entropy": 0.06268103556199507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260375022888184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004933072719722986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135214487711589,
      "backward_entropy": 0.06241897019472989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034599304199219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0050331903621554375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.091350257396698,
      "backward_entropy": 0.06240225380117243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.719888687133789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005133299622684717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.091348131497701,
      "backward_entropy": 0.06238507140766491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.83818244934082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00523372832685709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134564797083537,
      "backward_entropy": 0.06236732547933405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.334250450134277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005334508139640093,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134297569592793,
      "backward_entropy": 0.06261205673217773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.676070213317871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005434862803667784,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134020407994588,
      "backward_entropy": 0.06259705803611061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.793334007263184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0055354502983391285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133676687876384,
      "backward_entropy": 0.06258173422379927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.964652061462402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005635869689285755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133332967758179,
      "backward_entropy": 0.062565955248746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.904061317443848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005737195257097483,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09132963418960571,
      "backward_entropy": 0.06243561614643444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99799919128418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0058387755416333675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132549166679382,
      "backward_entropy": 0.06225021318955855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.972421646118164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005940153729170561,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132098158200581,
      "backward_entropy": 0.06222884763370861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.375596046447754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00604084599763155,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131652116775513,
      "backward_entropy": 0.06238720633766868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.859880447387695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006142147351056337,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131198128064473,
      "backward_entropy": 0.06237044117667458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.130573272705078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00624319352209568,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091307133436203,
      "backward_entropy": 0.06246197765523737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.432816505432129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006344212684780359,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130264321962993,
      "backward_entropy": 0.06233552369204434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.426807403564453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006445317529141903,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129794438680013,
      "backward_entropy": 0.06242330507798628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.360404014587402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006546494551002979,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129303693771362,
      "backward_entropy": 0.0624031587080522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.529586791992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006647767964750528,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09128870566685994,
      "backward_entropy": 0.06227993965148926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860380172729492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006748658139258623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912845532099406,
      "backward_entropy": 0.06204055114225908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642836570739746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0068493736907839775,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09128043055534363,
      "backward_entropy": 0.062240779399871826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.701425552368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006949837785214186,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127660592397054,
      "backward_entropy": 0.06222050840204412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.845335006713867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007050187326967716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912739634513855,
      "backward_entropy": 0.06229367581280795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75014591217041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007150415796786547,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127121170361836,
      "backward_entropy": 0.06226995858279141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502808570861816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007250515278428793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09126869837443034,
      "backward_entropy": 0.061907394365830856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.126585006713867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007350347936153412,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126618504524231,
      "backward_entropy": 0.06222069263458252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.620302200317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007450730539858341,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126260876655579,
      "backward_entropy": 0.062112981622869316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.36823844909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007550372742116451,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125963846842448,
      "backward_entropy": 0.06208996339277788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9935941696167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007649716921150684,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125653902689616,
      "backward_entropy": 0.06206635995344682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719305992126465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007749080192297697,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125263492266338,
      "backward_entropy": 0.06211553378538652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71402359008789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007848399691283703,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124904870986938,
      "backward_entropy": 0.06208791516043923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.215707778930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007947678677737713,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09124574065208435,
      "backward_entropy": 0.06199193000793457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.911723136901855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008047130890190601,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124181667963664,
      "backward_entropy": 0.062030575492165306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.489335060119629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008146620355546474,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123792250951131,
      "backward_entropy": 0.06193931536241011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.572710990905762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008245949633419514,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123461445172627,
      "backward_entropy": 0.061912227760661735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.893680572509766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008345155976712704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09123143553733826,
      "backward_entropy": 0.061551099473779854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.68016242980957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008444421924650669,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122821688652039,
      "backward_entropy": 0.061514182524247604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.118041038513184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008543644100427628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912252167860667,
      "backward_entropy": 0.061476523225957695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.077168464660645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008643070235848427,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09122231602668762,
      "backward_entropy": 0.0617978572845459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.543844223022461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008742053993046284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121910730997722,
      "backward_entropy": 0.06139868497848511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.007635116577148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008840944617986679,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09121599793434143,
      "backward_entropy": 0.0617691386829723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.678638458251953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008939482271671295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121347467104594,
      "backward_entropy": 0.061317736452276055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.819711685180664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00903908722102642,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120965003967285,
      "backward_entropy": 0.06167286092584783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9073872566223145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009138640947639942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120531876881917,
      "backward_entropy": 0.06123161315917969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.210268020629883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009237168356776237,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120222926139832,
      "backward_entropy": 0.0616176886992021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.702925682067871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009336513467133045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09119791785875957,
      "backward_entropy": 0.06114195151762529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.354887008666992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00943637266755104,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119339783986409,
      "backward_entropy": 0.061536095359108665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.248546600341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009535896591842175,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09118852019309998,
      "backward_entropy": 0.061498858711936256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.601056098937988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009635664522647858,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118356307347615,
      "backward_entropy": 0.06099752946333452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.390226364135742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009735305793583393,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117911259333293,
      "backward_entropy": 0.061405398628928444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.425591468811035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009834734722971916,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09117536743481953,
      "backward_entropy": 0.06138157844543457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753543853759766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009934503585100174,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09117101629575093,
      "backward_entropy": 0.060843993316997184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.570056915283203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010034178383648396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116607904434204,
      "backward_entropy": 0.06079028953205456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902152061462402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010133723728358746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116147955258687,
      "backward_entropy": 0.06073558330535889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69471263885498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010232754983007908,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115721782048543,
      "backward_entropy": 0.061213200742548164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.116326332092285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010331847704946995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115386009216309,
      "backward_entropy": 0.060623699968511406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.884475708007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01043061912059784,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115083018938701,
      "backward_entropy": 0.06112503463571722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879582405090332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010530048049986362,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114652872085571,
      "backward_entropy": 0.06050718914378773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.717282772064209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010629446245729923,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911407470703125,
      "backward_entropy": 0.06103006276217374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.659255027770996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010728339664638042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113673369089763,
      "backward_entropy": 0.060384967110373756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.414917945861816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010826674290001392,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113332629203796,
      "backward_entropy": 0.06032232804731889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.092211723327637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010925456881523132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112877647082011,
      "backward_entropy": 0.060763012279163704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.682878494262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011024465784430504,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09112346172332764,
      "backward_entropy": 0.060826659202575684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.337812423706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011123480275273323,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09111809730529785,
      "backward_entropy": 0.06077257069674405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.750089645385742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011222274973988533,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111246466636658,
      "backward_entropy": 0.06057314439253374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.739638328552246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01132111344486475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911063551902771,
      "backward_entropy": 0.0599820613861084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.493524551391602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011419987305998802,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09109981854756673,
      "backward_entropy": 0.05990901860323819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.212606430053711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011518207378685474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910940170288086,
      "backward_entropy": 0.059835076332092285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289121627807617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011616256088018417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108840425809224,
      "backward_entropy": 0.06030113046819514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.303243637084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011714170686900616,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09108249346415202,
      "backward_entropy": 0.0604208761995489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.660764694213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011812012642621994,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09107683102289836,
      "backward_entropy": 0.06035759232260964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.061967849731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011909928172826767,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09107014536857605,
      "backward_entropy": 0.060292617841200394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.856289863586426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012007617391645908,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106362859408061,
      "backward_entropy": 0.059440027583729134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56521987915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0121050039306283,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0910576581954956,
      "backward_entropy": 0.06015854532068426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.895352363586426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012202530167996883,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105163812637329,
      "backward_entropy": 0.05927045778794722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715591907501221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01229973416775465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09104510148366292,
      "backward_entropy": 0.059182936495000664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.285113334655762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01239660196006298,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103906154632568,
      "backward_entropy": 0.05968743020837957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.793664932250977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012493454851210117,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103224674860637,
      "backward_entropy": 0.059604102914983574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.272094249725342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01259060762822628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09102455774943034,
      "backward_entropy": 0.05890940536152233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547965049743652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012687173672020435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910177230834961,
      "backward_entropy": 0.0588148832321167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.670370101928711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012783913873136044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09100984533627827,
      "backward_entropy": 0.05934392322193493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.664636611938477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012880931608378887,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100164969762166,
      "backward_entropy": 0.05861819332296198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262099266052246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012978771701455116,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099224209785461,
      "backward_entropy": 0.059159831567244095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.515038013458252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013076571747660637,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09098342061042786,
      "backward_entropy": 0.05939404530958696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.693380355834961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013173863291740417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09097521503766377,
      "backward_entropy": 0.05896526033228094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89333724975586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01327195018529892,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09096509218215942,
      "backward_entropy": 0.058864257552407005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955595970153809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013370310887694359,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09095439314842224,
      "backward_entropy": 0.05876061591235074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.750954627990723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013468929566442966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09094261129697163,
      "backward_entropy": 0.05796694755554199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.36141300201416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013567676767706871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09093026320139568,
      "backward_entropy": 0.05784859440543435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314897537231445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013666343875229359,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0909183422724406,
      "backward_entropy": 0.05772825804623691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251272201538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013764877803623676,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09090610345204671,
      "backward_entropy": 0.058754314075816765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.970162391662598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013863319531083107,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09089489777882893,
      "backward_entropy": 0.05865521864457564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.194907188415527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01396204438060522,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09088262915611267,
      "backward_entropy": 0.05855379863218828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7477445602417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014061213470995426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09087026119232178,
      "backward_entropy": 0.05722589926286177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.863767147064209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014160477556288242,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09085732698440552,
      "backward_entropy": 0.05834485184062611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919926643371582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014259319752454758,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09084511796633403,
      "backward_entropy": 0.05771987004713579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.357234954833984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014358418993651867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09083271026611328,
      "backward_entropy": 0.05683063377033581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.057378768920898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014457461424171925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09082149465878804,
      "backward_entropy": 0.05669469183141535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.257457733154297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01455681212246418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09080926577250163,
      "backward_entropy": 0.056555341590534554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.775879859924316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014655953273177147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09079667925834656,
      "backward_entropy": 0.056413704698736016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.728056907653809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01475464180111885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09078474839528401,
      "backward_entropy": 0.05627061020244251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.552492141723633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014852863736450672,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.090772678454717,
      "backward_entropy": 0.056125521659851074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.793632507324219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014951150864362717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09075915813446045,
      "backward_entropy": 0.055975946513089264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.275060653686523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015049068257212639,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09074601531028748,
      "backward_entropy": 0.05664208802309903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.217308044433594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015146421268582344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073543548583984,
      "backward_entropy": 0.05567213622006503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.040292739868164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0152443191036582,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09072201450665791,
      "backward_entropy": 0.055514866655523125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.018623352050781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015342074446380138,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09070894122123718,
      "backward_entropy": 0.056202238256281074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.140649795532227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015439692884683609,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0906961460908254,
      "backward_entropy": 0.05678681351921775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.170635223388672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015537216328084469,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09068230787913005,
      "backward_entropy": 0.05589531768452038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.60711669921875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015635322779417038,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090667059024175,
      "backward_entropy": 0.05573660677129572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.027993202209473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015733040869235992,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09065345923105876,
      "backward_entropy": 0.05557486685839566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.515761375427246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01583065278828144,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09064027667045593,
      "backward_entropy": 0.056229320439425384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.921214580535889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01592842862010002,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09062570333480835,
      "backward_entropy": 0.05524223501032049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.021207809448242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0160259660333395,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09061012665430705,
      "backward_entropy": 0.05592819235541604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.998504161834717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01612277515232563,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09059587121009827,
      "backward_entropy": 0.05397410826249556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.041912078857422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016219545155763626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09058136741320293,
      "backward_entropy": 0.053789295933463356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.249222755432129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016316285356879234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09056593974431355,
      "backward_entropy": 0.05360089106993242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.834861755371094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016412559896707535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09055207173029582,
      "backward_entropy": 0.05341113697398792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6981987953186035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01650812104344368,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905394156773885,
      "backward_entropy": 0.05419527942484075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.109808921813965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016603583469986916,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09052625298500061,
      "backward_entropy": 0.054961865598505195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.182218551635742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01669865846633911,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09051617980003357,
      "backward_entropy": 0.05383110046386719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.004135131835938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016793444752693176,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09050826231638591,
      "backward_entropy": 0.052634613080458206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.886734962463379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016888456419110298,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09049939115842183,
      "backward_entropy": 0.05345233462073586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.467625617980957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01698416844010353,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09048662583033244,
      "backward_entropy": 0.0542696009982716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.469103813171387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017079630866646767,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09047321478525798,
      "backward_entropy": 0.052021010355515915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7902703285217285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01717432402074337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09046347935994466,
      "backward_entropy": 0.0528600811958313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.344370365142822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01726912520825863,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0904530684153239,
      "backward_entropy": 0.053721064871007744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.04875373840332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017363760620355606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09044337272644043,
      "backward_entropy": 0.05138213526118885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.938803672790527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017458656802773476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09043159087498982,
      "backward_entropy": 0.05116071484305642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.982444763183594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017553122714161873,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09042123953501384,
      "backward_entropy": 0.05202280391346325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.038561820983887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01764783449470997,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09040886163711548,
      "backward_entropy": 0.05070918256586248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.255167007446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01774219237267971,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0903972585995992,
      "backward_entropy": 0.05275063081221147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.786818981170654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017837001010775566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09038390715916951,
      "backward_entropy": 0.05024193633686413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.710293292999268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017931900918483734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09036876757939656,
      "backward_entropy": 0.051128067753531715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.353813648223877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0180255938321352,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09035873413085938,
      "backward_entropy": 0.04976178299296986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.306028366088867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01811918616294861,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0903460184733073,
      "backward_entropy": 0.04951834678649902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6046600341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018212750554084778,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09033374985059102,
      "backward_entropy": 0.05170393531972712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.631869316101074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01830582320690155,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09032309055328369,
      "backward_entropy": 0.04902330311861905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.594086647033691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018399128690361977,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09031106034914653,
      "backward_entropy": 0.04877012426202947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.16357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018492622300982475,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09029775857925415,
      "backward_entropy": 0.05104222080924294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8427348136901855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01858602464199066,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09028482437133789,
      "backward_entropy": 0.0494528358632868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.364720344543457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0186797883361578,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0902700424194336,
      "backward_entropy": 0.049196806820956146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.73394775390625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01877351850271225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09025336305300395,
      "backward_entropy": 0.047713870351964775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.096002578735352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018867485225200653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09023440877596538,
      "backward_entropy": 0.047437781637365166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08936882019043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01896129548549652,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09021637837092082,
      "backward_entropy": 0.04840314930135554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295309066772461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019055547192692757,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09019376834233601,
      "backward_entropy": 0.046873916279185905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.054699420928955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019150367006659508,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09016719460487366,
      "backward_entropy": 0.0465819618918679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9430012702941895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01924493908882141,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09014234940210979,
      "backward_entropy": 0.04628791050477461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.324567794799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019339125603437424,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09011622269948323,
      "backward_entropy": 0.04887989976189353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.652106285095215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01943260245025158,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09009223182996114,
      "backward_entropy": 0.04697865789586848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.266237735748291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01952565461397171,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09006855885187785,
      "backward_entropy": 0.04539071971719915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312617301940918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019618114456534386,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09004778663317363,
      "backward_entropy": 0.04639105363325639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.462682247161865,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0197107195854187,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09002466003100078,
      "backward_entropy": 0.047835496338931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.213310718536377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019802898168563843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09000260631243388,
      "backward_entropy": 0.04756750843741677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.951163291931152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019895199686288834,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0899778703848521,
      "backward_entropy": 0.045482402498071846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6217732429504395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019988110288977623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08994786938031514,
      "backward_entropy": 0.04384001276709817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.515686511993408,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020080696791410446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08991879224777222,
      "backward_entropy": 0.04485164989124645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.579706192016602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02017294615507126,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08989159266153972,
      "backward_entropy": 0.04452974687923084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.689483165740967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020264901220798492,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08986409505208333,
      "backward_entropy": 0.04617462374947288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.06227970123291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020355980843305588,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08983993530273438,
      "backward_entropy": 0.04588958350094882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1790337562561035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0204465389251709,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08981701731681824,
      "backward_entropy": 0.04355296221646396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.146923542022705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02053740806877613,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08978988726933797,
      "backward_entropy": 0.045310697772286156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.84386682510376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020627139136195183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08976799249649048,
      "backward_entropy": 0.04289171912453391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.346619129180908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020716339349746704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08974707126617432,
      "backward_entropy": 0.04119936986403032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.366630554199219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020805446431040764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08972529570261638,
      "backward_entropy": 0.04086179083043879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.194011211395264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020894499495625496,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08970283468564351,
      "backward_entropy": 0.04412538896907459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.53958797454834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020984040573239326,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08967322111129761,
      "backward_entropy": 0.04382079839706421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.10895299911499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021073555573821068,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08963978290557861,
      "backward_entropy": 0.039810988036069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0912065505981445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021162772551178932,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08960558970769246,
      "backward_entropy": 0.04085924408652566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.185513973236084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021251775324344635,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0895730455716451,
      "backward_entropy": 0.04288896376436407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.648187637329102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02134060487151146,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0895388921101888,
      "backward_entropy": 0.04257370667024092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1543121337890625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021428927779197693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08950708309809367,
      "backward_entropy": 0.03836152228442105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.332705497741699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021517179906368256,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08947460850079854,
      "backward_entropy": 0.04193852977319197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.031525611877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021604731678962708,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08944416046142578,
      "backward_entropy": 0.04161789200522683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.474193096160889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021692218258976936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08941269914309184,
      "backward_entropy": 0.03872684457085349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5942277908325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02177993394434452,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08937537670135498,
      "backward_entropy": 0.03836411779577082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.225478172302246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021867232397198677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0893384615580241,
      "backward_entropy": 0.03651000694795088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.077953815460205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02195386216044426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08930283784866333,
      "backward_entropy": 0.036136220801960335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.304566383361816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02203981950879097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08927069107691447,
      "backward_entropy": 0.035764553330161354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.676548957824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022125348448753357,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0892396370569865,
      "backward_entropy": 0.03964804248376326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9962310791015625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022210756316781044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08920527497927348,
      "backward_entropy": 0.03653566945682873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.32987117767334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02229553461074829,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08917224407196045,
      "backward_entropy": 0.036167851903221825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.335883617401123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022379230707883835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08914493521054585,
      "backward_entropy": 0.03427637707103382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.74564266204834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02246277779340744,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0891162355740865,
      "backward_entropy": 0.03543515097011219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.49206018447876,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02254650555551052,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08908207217852275,
      "backward_entropy": 0.03506552902134982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.863698482513428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022630246356129646,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08904615044593811,
      "backward_entropy": 0.03469230370088057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.58375358581543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02271345816552639,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08901052673657735,
      "backward_entropy": 0.03432001308961348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.48611307144165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022796034812927246,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0889799992243449,
      "backward_entropy": 0.03693934462287209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.582223892211914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02287791110575199,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08895151813824971,
      "backward_entropy": 0.03203099424188787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.941869258880615,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02295924536883831,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08892380197842915,
      "backward_entropy": 0.03320280259305781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.479584693908691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023040425032377243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08889471491177876,
      "backward_entropy": 0.03128981048410589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.015042304992676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02312108874320984,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08886773387591045,
      "backward_entropy": 0.03556179187514565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.356551647186279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02320175990462303,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08883827924728394,
      "backward_entropy": 0.03054860234260559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2045183181762695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023281875997781754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0888109803199768,
      "backward_entropy": 0.030179096893830734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.076560974121094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02336222678422928,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08877795934677124,
      "backward_entropy": 0.029805305329236118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7446370124816895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02344268374145031,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08873965342839558,
      "backward_entropy": 0.02942832491614602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.879092216491699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023522084578871727,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08870782454808553,
      "backward_entropy": 0.03383045033975081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9214112758636475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02360067330300808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08868084351221721,
      "backward_entropy": 0.02869293364611539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.895984649658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023678595200181007,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0886583924293518,
      "backward_entropy": 0.03314249894835732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.322472095489502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023755881935358047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08863874276479085,
      "backward_entropy": 0.027973819862712513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2074475288391113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02383299358189106,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0886170466740926,
      "backward_entropy": 0.03245899623090571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.046301364898682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023908939212560654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08860377470652263,
      "backward_entropy": 0.027264925566586582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.909592866897583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023984581232070923,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08858774105707805,
      "backward_entropy": 0.02835599129850214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4991376399993896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02405986562371254,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08857158819834392,
      "backward_entropy": 0.027991481802680275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.907029390335083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024134425446391106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08855752150217693,
      "backward_entropy": 0.026219080794941296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.498171091079712,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024208754301071167,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08854202429453532,
      "backward_entropy": 0.02726955305446278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.444795846939087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024282440543174744,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08852614959081014,
      "backward_entropy": 0.030425572937185116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.267867088317871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024355530738830566,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08851117889086406,
      "backward_entropy": 0.03008940815925598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.878471612930298,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024428900331258774,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08848795294761658,
      "backward_entropy": 0.02620526064525951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3842930793762207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02450215257704258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08846049507459004,
      "backward_entropy": 0.024500524455850773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4334943294525146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024574842303991318,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08843496441841125,
      "backward_entropy": 0.029081176627766003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0306990146636963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02464705891907215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08840889732042949,
      "backward_entropy": 0.023819554935802113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3457908630371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02471846714615822,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08838699261347453,
      "backward_entropy": 0.028417982838370583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1319429874420166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024789495393633842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08836548527081807,
      "backward_entropy": 0.02315428853034973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4336657524108887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024859905242919922,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08834292491277058,
      "backward_entropy": 0.027763296257365833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3303399085998535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024930128827691078,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08831736445426941,
      "backward_entropy": 0.022497441280971874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0891146659851074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025000102818012238,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0882902443408966,
      "backward_entropy": 0.022170326926491478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.992140293121338,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0250695813447237,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08826285600662231,
      "backward_entropy": 0.02679287845438177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.23761248588562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025138510391116142,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08823515971501668,
      "backward_entropy": 0.026473427360708065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0034255981445312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02520720660686493,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08820246656735738,
      "backward_entropy": 0.02244582772254944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.73980975151062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025275450199842453,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08816747864087422,
      "backward_entropy": 0.022120803594589233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5838358402252197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025343017652630806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08813390135765076,
      "backward_entropy": 0.020571956580335445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0028648376464844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025409802794456482,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08810275793075562,
      "backward_entropy": 0.021482445976950905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.503729820251465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02547636814415455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08806695540746053,
      "backward_entropy": 0.01995551044290716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.44688081741333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025542158633470535,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08803258339564006,
      "backward_entropy": 0.020858504555442116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.329271078109741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025607189163565636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08799949288368225,
      "backward_entropy": 0.019354757937518032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.006131649017334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02567140944302082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08796889583269756,
      "backward_entropy": 0.02025383169000799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2477588653564453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02573452517390251,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08794517318407695,
      "backward_entropy": 0.01877779852260243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4881997108459473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02579694241285324,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08792303999265035,
      "backward_entropy": 0.018497762354937466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.058816909790039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025859007611870766,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08789644638697307,
      "backward_entropy": 0.02310848507014188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3085336685180664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02592024952173233,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08787280321121216,
      "backward_entropy": 0.022819153287193993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2292675971984863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025981079787015915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08784725268681844,
      "backward_entropy": 0.01767457073385065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4548604488372803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026041436940431595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08781992395718892,
      "backward_entropy": 0.01740607754750685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1611926555633545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02610170468688011,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08778773744901021,
      "backward_entropy": 0.018265800042585892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9909377098083496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026161445304751396,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08775197466214497,
      "backward_entropy": 0.021682244810191067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.012482166290283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026220526546239853,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08771643042564392,
      "backward_entropy": 0.02140342647379095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0522420406341553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026279054582118988,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08767998218536377,
      "backward_entropy": 0.01635224304415963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9172518253326416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026337161660194397,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08764164646466573,
      "backward_entropy": 0.020854608579115433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7186211347579956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263946745544672,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08760152260462443,
      "backward_entropy": 0.020584335381334477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9397104978561401,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026451390236616135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08756318688392639,
      "backward_entropy": 0.015597557479685003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.605363130569458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02650773525238037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08752210934956868,
      "backward_entropy": 0.015352743593129244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5501269102096558,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026563234627246857,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08748286962509155,
      "backward_entropy": 0.016210092739625412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5778005123138428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02661792002618313,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08744646112124126,
      "backward_entropy": 0.014879211783409119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5497790575027466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02667189948260784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08741029103597005,
      "backward_entropy": 0.01464937220920216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4449591636657715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02672521583735943,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08737437923749287,
      "backward_entropy": 0.014423553239215504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.512610912322998,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02677777223289013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08733978867530823,
      "backward_entropy": 0.015281070362437855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.474836826324463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026829734444618225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08730298280715942,
      "backward_entropy": 0.01398441195487976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5426617860794067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268811397254467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08726548155148824,
      "backward_entropy": 0.013769699768586592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3783529996871948,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02693217620253563,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08722513914108276,
      "backward_entropy": 0.013557054779746315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.185362458229065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02698262594640255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0871855616569519,
      "backward_entropy": 0.01334812424399636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.162008285522461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027032187208533287,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0871486763159434,
      "backward_entropy": 0.013144564899531279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.138778805732727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027080919593572617,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.087114284435908,
      "backward_entropy": 0.014000892639160156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1875587701797485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027128875255584717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08708220720291138,
      "backward_entropy": 0.012752031738107855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0622761249542236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027176225557923317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08705005049705505,
      "backward_entropy": 0.012561494653875177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0059962272644043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02722277119755745,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0870186984539032,
      "backward_entropy": 0.01674959740855477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8931704163551331,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027268502861261368,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0869892140229543,
      "backward_entropy": 0.01654190095988187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.006328821182251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027313288301229477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08696353435516357,
      "backward_entropy": 0.012017675421454689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0520097017288208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0273574311286211,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0869369904200236,
      "backward_entropy": 0.016138713468204845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0288177728652954,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02740112692117691,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08690878748893738,
      "backward_entropy": 0.015941825780001553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0560822486877441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744438871741295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08687917391459148,
      "backward_entropy": 0.011505741964687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9185958504676819,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027487315237522125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08684614300727844,
      "backward_entropy": 0.012339253317226063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9176317453384399,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027529630810022354,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0868118405342102,
      "backward_entropy": 0.015369090166958895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7703579664230347,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027571428567171097,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08677659432093303,
      "backward_entropy": 0.012005017562346025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.780708909034729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02761242911219597,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08674347400665283,
      "backward_entropy": 0.01500371369448575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7065771818161011,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02765277586877346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08671259880065918,
      "backward_entropy": 0.011683556166562166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6271044015884399,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02769235335290432,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08668450514475505,
      "backward_entropy": 0.011527469212358648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7672216892242432,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027731062844395638,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.086660901705424,
      "backward_entropy": 0.014486387372016907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6642577648162842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0277693048119545,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0866353710492452,
      "backward_entropy": 0.011224784634330055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5742483139038086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027806861326098442,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08660983045895894,
      "backward_entropy": 0.010130099274895409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5598442554473877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027843566611409187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08658609787623088,
      "backward_entropy": 0.009995404969562183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6076021194458008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02787947840988636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08656399448712666,
      "backward_entropy": 0.009864540939981287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5616155862808228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02791482023894787,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08654163281122844,
      "backward_entropy": 0.009736322543837807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6146538257598877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027949534356594086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0865199367205302,
      "backward_entropy": 0.009611075574701483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6865971684455872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02798382379114628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08649606506029765,
      "backward_entropy": 0.009487581523981962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4551391899585724,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028017928823828697,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08646663029988606,
      "backward_entropy": 0.013257304375821894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4489016532897949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028051244094967842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08644022544225057,
      "backward_entropy": 0.009245359762148424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5151128172874451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028083769604563713,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08641430735588074,
      "backward_entropy": 0.012980428608981047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.409885436296463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028115805238485336,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08638643225034077,
      "backward_entropy": 0.009904157708991657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4176698327064514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028147095814347267,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08636032541592915,
      "backward_entropy": 0.012715342369946566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5253004431724548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028177741914987564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08633486429850261,
      "backward_entropy": 0.008798285641453484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4859788119792938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028208190575242043,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08630624413490295,
      "backward_entropy": 0.012461865490133112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3318733870983124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02823830023407936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08627436558405559,
      "backward_entropy": 0.00945366241715171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5006059408187866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028267614543437958,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08624520897865295,
      "backward_entropy": 0.008484156294302507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29976797103881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028296805918216705,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08621158202489217,
      "backward_entropy": 0.012098921970887617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40922388434410095,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028325118124485016,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08617949485778809,
      "backward_entropy": 0.011983600529757414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39255741238594055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028353065252304077,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08614448706309001,
      "backward_entropy": 0.008188139308582653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32106706500053406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028380630537867546,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08610682686169942,
      "backward_entropy": 0.008942138742316853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34556448459625244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028407631441950798,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08607011040051778,
      "backward_entropy": 0.011650168082930824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29014313220977783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028434185311198235,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08603181441624959,
      "backward_entropy": 0.007909381254152819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24585293233394623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028460150584578514,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08599444230397542,
      "backward_entropy": 0.011440174146132036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30325448513031006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028485408052802086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08595924576123555,
      "backward_entropy": 0.007735491476275704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20478175580501556,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028510240837931633,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08592246969540913,
      "backward_entropy": 0.0112414996732365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30365195870399475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02853422611951828,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08588706453641255,
      "backward_entropy": 0.0075710158456455574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25331422686576843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028557920828461647,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08584852019945781,
      "backward_entropy": 0.007491386072202163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23460224270820618,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028581153601408005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08580921093622844,
      "backward_entropy": 0.007413526150313291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19845223426818848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028603913262486458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08577009042104085,
      "backward_entropy": 0.007337518036365509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23231743276119232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028626078739762306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08573236068089803,
      "backward_entropy": 0.008091273632916536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23291648924350739,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864784561097622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08569318056106567,
      "backward_entropy": 0.007191723720593886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17677727341651917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669260442256927,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0856520136197408,
      "backward_entropy": 0.007120735265991904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15668509900569916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028690071776509285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08561146259307861,
      "backward_entropy": 0.007052030075680126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21311093866825104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028710227459669113,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08557204405466716,
      "backward_entropy": 0.010460760783065449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18467818200588226,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028730107471346855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0855301817258199,
      "backward_entropy": 0.00692038508978757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.145990252494812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028749598190188408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08548733592033386,
      "backward_entropy": 0.006856365637345748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14175772666931152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02876851335167885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08544537425041199,
      "backward_entropy": 0.006794448603283276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14477995038032532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028786910697817802,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08540425697962443,
      "backward_entropy": 0.00673446465622295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12864890694618225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028804868459701538,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08536336819330852,
      "backward_entropy": 0.007497485388409008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14730723202228546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02882232703268528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08532320459683736,
      "backward_entropy": 0.006619500165635889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1613120436668396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028839455917477608,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0852820873260498,
      "backward_entropy": 0.007384647022594105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09549648314714432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02885635383427143,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08523833751678467,
      "backward_entropy": 0.007330057295885953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11103741824626923,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028872637078166008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0851966142654419,
      "backward_entropy": 0.006456591866233132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10146494209766388,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02888845093548298,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08515494068463643,
      "backward_entropy": 0.009786760265176947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0806322917342186,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028903815895318985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0851140817006429,
      "backward_entropy": 0.007177185605872761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10818032175302505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028918582946062088,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08507455388704936,
      "backward_entropy": 0.007129824974320151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11123433709144592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028933003544807434,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08503377437591553,
      "backward_entropy": 0.006262657317248258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11139265447854996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028947172686457634,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0849917729695638,
      "backward_entropy": 0.009569909084926952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08449889719486237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02896110899746418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08494802316029866,
      "backward_entropy": 0.0061723210594870825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06693758070468903,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02897464856505394,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08490467071533203,
      "backward_entropy": 0.009469360113143921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07628533244132996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028987616300582886,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08486191431681316,
      "backward_entropy": 0.006087237461046739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09327910840511322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029000207781791687,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0848193069299062,
      "backward_entropy": 0.006046881729906256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05000808462500572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029012629762291908,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08477532863616943,
      "backward_entropy": 0.006007012318481098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06248921900987625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02902449108660221,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08473328749338786,
      "backward_entropy": 0.0059690698981285095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09478262066841125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029036005958914757,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0846920907497406,
      "backward_entropy": 0.005932299928231673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06429951637983322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029047522693872452,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0846484899520874,
      "backward_entropy": 0.009206121618097479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06571567803621292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029058709740638733,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08460477987925212,
      "backward_entropy": 0.0058595646511424675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06610658019781113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02906964160501957,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08456090092658997,
      "backward_entropy": 0.005824510346759449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060043592005968094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029080327600240707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08451632658640544,
      "backward_entropy": 0.005790180103345351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05299784988164902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029090799391269684,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08447189132372539,
      "backward_entropy": 0.006584733724594116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04374609887599945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029100941494107246,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08442749579747517,
      "backward_entropy": 0.009016544981436296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04490340128540993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029110686853528023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08438388506571452,
      "backward_entropy": 0.005692738700996746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05524127185344696,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02912008762359619,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08434063196182251,
      "backward_entropy": 0.006492521275173534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04378713667392731,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029129333794116974,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08429655432701111,
      "backward_entropy": 0.006463554772463712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033226899802684784,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02913830429315567,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08425272504488628,
      "backward_entropy": 0.006435466760938818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045090071856975555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029146844521164894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0842097798983256,
      "backward_entropy": 0.005575648762963035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03780199587345123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029155220836400986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08416648705800374,
      "backward_entropy": 0.005548200824043967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038581930100917816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029163356870412827,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08412354191144307,
      "backward_entropy": 0.005521496927196329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03647949546575546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029171250760555267,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08408043781916301,
      "backward_entropy": 0.005495467646555467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03937218710780144,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02917897142469883,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08403768142064412,
      "backward_entropy": 0.008745887740091845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03933948650956154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029186544939875603,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08399443825085957,
      "backward_entropy": 0.006285179067741741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0257469043135643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919403463602066,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0839506983757019,
      "backward_entropy": 0.005419983782551505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02783857472240925,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201168566942215,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08390774329503377,
      "backward_entropy": 0.006240110505710949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018394362181425095,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029208090156316757,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08386539419492085,
      "backward_entropy": 0.0086464908989993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023459970951080322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029214534908533096,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08382413784662883,
      "backward_entropy": 0.00862479954957962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024272341281175613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029220767319202423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08378362655639648,
      "backward_entropy": 0.005330698395317251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025003792718052864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029226800426840782,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08374333381652832,
      "backward_entropy": 0.005310273983261802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03105871193110943,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029232647269964218,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08370176951090495,
      "backward_entropy": 0.0061434094201434745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022725019603967667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02923848293721676,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08365875482559204,
      "backward_entropy": 0.005270385945385153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024346761405467987,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02924412116408348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08361560106277466,
      "backward_entropy": 0.005251001227985729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009105691686272621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02924962341785431,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08357198039690654,
      "backward_entropy": 0.005231951109387658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01772829331457615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029254667460918427,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08353035648663838,
      "backward_entropy": 0.00849106569181789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02026178129017353,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02925945818424225,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08348880211512248,
      "backward_entropy": 0.008475501428950916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016062401235103607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02926420420408249,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08344719807306926,
      "backward_entropy": 0.00604766539551995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019712107256054878,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029268713667988777,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08340577284495036,
      "backward_entropy": 0.008445467461239208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013869479298591614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02927318401634693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08336404959360759,
      "backward_entropy": 0.0051490552723407745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012181147933006287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029277386143803596,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08332269390424092,
      "backward_entropy": 0.006008038466626947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01508378330618143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029281320050358772,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08328202863534291,
      "backward_entropy": 0.008405163206837395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013536636717617512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029285188764333725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08324165145556132,
      "backward_entropy": 0.005105760287154804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009308900684118271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029288889840245247,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08320150276025136,
      "backward_entropy": 0.005092245949940248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01189403049647808,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029292287304997444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08316220839818318,
      "backward_entropy": 0.00507966936989264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010435381904244423,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02929557114839554,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08312330643335979,
      "backward_entropy": 0.005067467350851406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009655546396970749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02929867058992386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08308487137158711,
      "backward_entropy": 0.005055821754715659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007184705697000027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029301553964614868,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.083046888311704,
      "backward_entropy": 0.005044834857637232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013376099988818169,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029304232448339462,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08301002780596416,
      "backward_entropy": 0.00503451173955744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010026057250797749,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029306935146450996,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0829726258913676,
      "backward_entropy": 0.00592031329870224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008251178078353405,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029309529811143875,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08293544252713521,
      "backward_entropy": 0.008319159800356085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009895790368318558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931193634867668,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0828987459341685,
      "backward_entropy": 0.005004521798003803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00803846213966608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931426465511322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08286208907763164,
      "backward_entropy": 0.0049952089109204035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011337696574628353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029316496104002,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0828259785970052,
      "backward_entropy": 0.004986219108104706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00692352931946516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931876853108406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08278940618038177,
      "backward_entropy": 0.004977084696292877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0076193735003471375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029320918023586273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08275353411833446,
      "backward_entropy": 0.005879377776926214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008399534970521927,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029322942718863487,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08271792531013489,
      "backward_entropy": 0.008281436833468351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008030653931200504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029324917122721672,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08268231153488159,
      "backward_entropy": 0.00827609883113341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007431440986692905,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932688221335411,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08264686167240143,
      "backward_entropy": 0.004943733188239011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006752140820026398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029328806325793266,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08261163532733917,
      "backward_entropy": 0.005856415087526495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004682007245719433,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029330668970942497,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0825767715771993,
      "backward_entropy": 0.008260510861873627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007068366277962923,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933238446712494,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08254284660021464,
      "backward_entropy": 0.008255972103639082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005658265668898821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029334140941500664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0825091004371643,
      "backward_entropy": 0.004913332787427035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005696461535990238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029335781931877136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08247572183609009,
      "backward_entropy": 0.0049063177271322774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005878636613488197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029337400570511818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08244278033574422,
      "backward_entropy": 0.004899385977875103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004327279515564442,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933896705508232,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08241003751754761,
      "backward_entropy": 0.004892610690810464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005294672679156065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029340464621782303,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08237804969151814,
      "backward_entropy": 0.004886100915345279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004109307657927275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02934194914996624,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08234633008639018,
      "backward_entropy": 0.008230749856341969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0044958083890378475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029343293979763985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0823151171207428,
      "backward_entropy": 0.004873678088188171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041907839477062225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029344594106078148,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08228427171707153,
      "backward_entropy": 0.005811584266749295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003537794342264533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02934582717716694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08225381374359131,
      "backward_entropy": 0.005808136002583938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003291528206318617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029347000643610954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08222401142120361,
      "backward_entropy": 0.004856814376332543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0040977634489536285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029348067939281464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08219482004642487,
      "backward_entropy": 0.004851753061467951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003340962342917919,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029349133372306824,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08216586709022522,
      "backward_entropy": 0.008213503794236616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003903906559571624,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02935015596449375,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08213743567466736,
      "backward_entropy": 0.005796289579434829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033174483105540276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029351163655519485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08210913836956024,
      "backward_entropy": 0.00483702157031406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030685686506330967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029352204874157906,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08208130796750386,
      "backward_entropy": 0.008206424388018522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027460118290036917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293531883507967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08205387989679973,
      "backward_entropy": 0.004827479747208682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027606463991105556,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02935408428311348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08202687899271648,
      "backward_entropy": 0.004823092709888111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030540162697434425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02935497649013996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08200036982695262,
      "backward_entropy": 0.004818749698725614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025159684009850025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029355833306908607,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08197404444217682,
      "backward_entropy": 0.0048145238648761406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023391214199364185,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02935662306845188,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08194813132286072,
      "backward_entropy": 0.008196830749511719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002135657938197255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02935735695064068,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08192269504070282,
      "backward_entropy": 0.00480668077414686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002352712908759713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029358025640249252,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08189775546391805,
      "backward_entropy": 0.008194279941645536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023712755646556616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029358649626374245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0818730890750885,
      "backward_entropy": 0.00479959865862673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020333300344645977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02935929410159588,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08184871574242909,
      "backward_entropy": 0.004796101288361983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00185694161336869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029359973967075348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08182486891746521,
      "backward_entropy": 0.0047925460067662325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017995329108089209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029360637068748474,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08180150389671326,
      "backward_entropy": 0.008189575915986841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001501105260103941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029361262917518616,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0817785660425822,
      "backward_entropy": 0.008188401433554563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001695937942713499,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029361823573708534,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0817561795314153,
      "backward_entropy": 0.008187437599355524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016288749175146222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029362397268414497,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08173422018686931,
      "backward_entropy": 0.005763313309712844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014317187014967203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02936295047402382,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08171261350313823,
      "backward_entropy": 0.008185393430969932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014686365611851215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029363416135311127,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0816913644472758,
      "backward_entropy": 0.004773768173022704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001371651072986424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029363853856921196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08167049288749695,
      "backward_entropy": 0.004771119152957743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012032304657623172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02936428412795067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08164999882380168,
      "backward_entropy": 0.004768521948294206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010397182777523994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029364686459302902,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08162995179494222,
      "backward_entropy": 0.008183144710280678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012955450220033526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029365088790655136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08161051074663798,
      "backward_entropy": 0.005756521766835993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010738556738942862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029365459457039833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08159129818280537,
      "backward_entropy": 0.004761244085702029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011387286940589547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029365791007876396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08157246311505635,
      "backward_entropy": 0.004759031263264743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009990176185965538,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029366087168455124,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08155388633410136,
      "backward_entropy": 0.005754092200235887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010239244438707829,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02936638705432415,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08153572181860606,
      "backward_entropy": 0.008181572637774727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008853367762640119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029366692528128624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0815178652604421,
      "backward_entropy": 0.004752800545909188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008499808027409017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029366955161094666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08150037129720052,
      "backward_entropy": 0.0047508749094876375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007194633362814784,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02936718799173832,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08148323496182759,
      "backward_entropy": 0.005751455372030085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007915116148069501,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029367394745349884,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08146656552950542,
      "backward_entropy": 0.008181374858726154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008385843830183148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02936762012541294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08145028352737427,
      "backward_entropy": 0.005750482732599432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006204313249327242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02936786226928234,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08143425484498341,
      "backward_entropy": 0.008181252940134569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007560609956271946,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029368067160248756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08141865332921346,
      "backward_entropy": 0.0047422362999482584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006770935142412782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029368270188570023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08140326539675395,
      "backward_entropy": 0.004740634763782675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006397418910637498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029368484392762184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08138818542162578,
      "backward_entropy": 0.004739015617153861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000590658513829112,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02936869114637375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08137339353561401,
      "backward_entropy": 0.004737456075169824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006464086472988129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02936890348792076,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08135894934336345,
      "backward_entropy": 0.005747539753263647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000554056721739471,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029369106516242027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0813446839650472,
      "backward_entropy": 0.005747039209712635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004683497245423496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029369302093982697,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08133073151111603,
      "backward_entropy": 0.008181088350035927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000512460945174098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02936949022114277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08131715655326843,
      "backward_entropy": 0.0047314458272673865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004247895267326385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029369618743658066,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08130377531051636,
      "backward_entropy": 0.005745815959843722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037222696118988097,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029369747266173363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0812907616297404,
      "backward_entropy": 0.004728949882767417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004342860192991793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029369888827204704,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08127817511558533,
      "backward_entropy": 0.0057452117854898625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040320210973732173,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937001921236515,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0812658170859019,
      "backward_entropy": 0.005744921212846582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040973848081193864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029370173811912537,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08125374714533488,
      "backward_entropy": 0.004725294356996363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037909424281679094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937031351029873,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08124188085397084,
      "backward_entropy": 0.004724111746657978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037317926762625575,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029370466247200966,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08123027284940083,
      "backward_entropy": 0.008181887594136324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003991563571617007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029370611533522606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08121887346108754,
      "backward_entropy": 0.00472175736318935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003785638546105474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029370784759521484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08120765288670857,
      "backward_entropy": 0.0047205266627398405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002977928379550576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937096729874611,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08119657138983409,
      "backward_entropy": 0.005742579021237113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028270043549127877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029371144250035286,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08118577301502228,
      "backward_entropy": 0.008181612599979748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026912332396022975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937130257487297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08117522795995076,
      "backward_entropy": 0.004716928709637035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028812841628678143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937145158648491,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08116492629051208,
      "backward_entropy": 0.004715833135626533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030434312066063285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293715950101614,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08115479350090027,
      "backward_entropy": 0.004714761606671594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023184252495411783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029371771961450577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08114481965700786,
      "backward_entropy": 0.004713613878596912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002573597594164312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029371917247772217,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08113506436347961,
      "backward_entropy": 0.004712564362721009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023475647321902215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029372043907642365,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08112543821334839,
      "backward_entropy": 0.00573962926864624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018956681014969945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937217243015766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0811160256465276,
      "backward_entropy": 0.004710592329502106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002116271498380229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937229536473751,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08110688130060832,
      "backward_entropy": 0.004709647460417314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020045574638061225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937242016196251,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08109792073567708,
      "backward_entropy": 0.004708705639297312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019669393077492714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029372552409768105,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0810891588528951,
      "backward_entropy": 0.004707766527479345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001883723889477551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029372697696089745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08108057578404744,
      "backward_entropy": 0.004706789824095639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001529955625301227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937283366918564,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08107215166091919,
      "backward_entropy": 0.005737280981107192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013267008762340993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029372956603765488,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08106395602226257,
      "backward_entropy": 0.004704957658594305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014579803973902017,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029373064637184143,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08105600376923879,
      "backward_entropy": 0.008181367408145557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015975914720911533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937314473092556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08104822039604187,
      "backward_entropy": 0.005736304955048995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001318022550549358,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029373209923505783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08104053636391957,
      "backward_entropy": 0.004702700471336191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013504385424312204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937329187989235,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08103305598100026,
      "backward_entropy": 0.004701980812983079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012893886014353484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937338687479496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08102572957674663,
      "backward_entropy": 0.004701227965680036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001210011905641295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937348559498787,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08101855715115865,
      "backward_entropy": 0.004700481552969326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.511104872217402e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029373595491051674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08101154367129008,
      "backward_entropy": 0.0046997026286341925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.007474000100046e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029373696073889732,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08100475867589314,
      "backward_entropy": 0.00573447888547724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011815186007879674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029373787343502045,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08099818726380666,
      "backward_entropy": 0.005734182894229889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.275929187424481e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029373889788985252,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08099169035752614,
      "backward_entropy": 0.008181932297619906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.785709749441594e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029374003410339355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08098537723223369,
      "backward_entropy": 0.004696844992312518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.455206989310682e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029374118894338608,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08097925782203674,
      "backward_entropy": 0.008181760934266176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.005860970821232e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937423065304756,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08097329239050548,
      "backward_entropy": 0.008181670849973505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.302855712827295e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029374340549111366,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08096749583880107,
      "backward_entropy": 0.004694737493991852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.448164251400158e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029374441131949425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08096180359522502,
      "backward_entropy": 0.00469408319755034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.849241617601365e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937455289065838,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08095622559388478,
      "backward_entropy": 0.005731721493330869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.30492068012245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937466837465763,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0809507817029953,
      "backward_entropy": 0.0057313482869755135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.817807686980814e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937477082014084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08094547192255656,
      "backward_entropy": 0.004692101343111558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.420363959274255e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293748676776886,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0809403012196223,
      "backward_entropy": 0.004691493782130155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.299321856000461e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937496267259121,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08093527456124623,
      "backward_entropy": 0.008181036873297258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.564248229144141e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937505766749382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0809303770462672,
      "backward_entropy": 0.004690316929058595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.939995415043086e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029375143349170685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08092563350995381,
      "backward_entropy": 0.0057297680865634575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4550040911417454e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375214129686356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08092098434766133,
      "backward_entropy": 0.004689272831786762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7079011235618964e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375271871685982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0809164543946584,
      "backward_entropy": 0.004688810218464245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8271129596978426e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029375329613685608,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08091207842032115,
      "backward_entropy": 0.005729109726168893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.708691292558797e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375392943620682,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08090782165527344,
      "backward_entropy": 0.004687909375537525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.421492510824464e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937544696033001,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08090367913246155,
      "backward_entropy": 0.008181078867478804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.564102735253982e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375500977039337,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08089965581893921,
      "backward_entropy": 0.004687060009349476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4113698347937316e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937554381787777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08089571197827657,
      "backward_entropy": 0.004686690866947174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2443935197079554e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375579208135605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08089185257752736,
      "backward_entropy": 0.004686326465823434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8400583687471226e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029375625774264336,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08088807264963786,
      "backward_entropy": 0.00818137214942412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7047602998209186e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375676065683365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08088438709576924,
      "backward_entropy": 0.004685566506602548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4140883397194557e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029375724494457245,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08088080088297527,
      "backward_entropy": 0.00818144597790458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7780191885540262e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029375772923231125,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08087733387947083,
      "backward_entropy": 0.00818148526278409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4276881958940066e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375813901424408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08087390661239624,
      "backward_entropy": 0.00468450276689096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8813645510817878e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375847429037094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08087056378523509,
      "backward_entropy": 0.004684190858494152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.063568535959348e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029375890269875526,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08086734016736348,
      "backward_entropy": 0.004683857614343817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7920108803082258e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937592938542366,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08086420595645905,
      "backward_entropy": 0.004683547060598026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4311545783129986e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029375968500971794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08086117108662923,
      "backward_entropy": 0.00572663816538724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.78824266185984e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376007616519928,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08085825542608897,
      "backward_entropy": 0.004682921889153394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.949656507349573e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376046732068062,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08085540433724721,
      "backward_entropy": 0.008181840181350708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2303844414418563e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937607653439045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08085258801778157,
      "backward_entropy": 0.004682362418283115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.536891795694828e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937610074877739,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08084988097349803,
      "backward_entropy": 0.005726081403818997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4470607311523054e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937612682580948,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08084723353385925,
      "backward_entropy": 0.004681870341300964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3273020158521831e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937614917755127,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08084465066591899,
      "backward_entropy": 0.005725849758494984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35083062358899e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376167804002762,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08084212740262349,
      "backward_entropy": 0.005725748159668662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0789566658786498e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376188293099403,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08083972334861755,
      "backward_entropy": 0.005725643851540305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0463289072504267e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376208782196045,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08083737889925639,
      "backward_entropy": 0.00572554428469051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.234080607711803e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376229271292686,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08083510398864746,
      "backward_entropy": 0.00468077307397669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0186601684836205e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376251623034477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08083290855089824,
      "backward_entropy": 0.005725330249829726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.607192623661831e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937626838684082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08083075781663258,
      "backward_entropy": 0.004680372774600983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.000319212442264e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376281425356865,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08082865675290425,
      "backward_entropy": 0.004680199040607972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.48645777296042e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937629446387291,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08082662026087443,
      "backward_entropy": 0.004680021919987418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.207065664260881e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376305639743805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08082463343938191,
      "backward_entropy": 0.004679863764481111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.848503628338221e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376320540905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08082270622253418,
      "backward_entropy": 0.004679695787754926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.079344191472046e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376329854130745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08082081874211629,
      "backward_entropy": 0.004679544405503707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.745093403675128e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937634103000164,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08081901570161183,
      "backward_entropy": 0.008183216506784613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.965381205896847e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376350343227386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08081727723280589,
      "backward_entropy": 0.004679247398268093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.196489382797154e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376357793807983,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08081558346748352,
      "backward_entropy": 0.005724633281881159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.520115337276366e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937636710703373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08081395427385966,
      "backward_entropy": 0.005724568258632313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.150806373421801e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376376420259476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08081235488255818,
      "backward_entropy": 0.004678842696276578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.411613645061152e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937638759613037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08081079026063283,
      "backward_entropy": 0.004678705199198289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.486573743633926e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376396909356117,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08080928524335225,
      "backward_entropy": 0.004678577862002633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6770811675523873e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376406222581863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0808078149954478,
      "backward_entropy": 0.004678458314050327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.170031277477392e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937641739845276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08080639938513438,
      "backward_entropy": 0.004678328944878144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8919980650243815e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376428574323654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.080805038412412,
      "backward_entropy": 0.0046782097355885935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1057195428729756e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937643975019455,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08080374201138814,
      "backward_entropy": 0.005724095485427163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.473809783827164e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376449063420296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08080250024795532,
      "backward_entropy": 0.004677974703637036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7729174714986584e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376458376646042,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08080127835273743,
      "backward_entropy": 0.0057239613749764185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.793595513139735e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376471415162086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08080012599627177,
      "backward_entropy": 0.005723881450566379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5954834654839942e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376482591032982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079900840918224,
      "backward_entropy": 0.0046776458621025085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4648302314744797e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376491904258728,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08079793055852254,
      "backward_entropy": 0.008184218948537653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.421132876406773e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376501217484474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079687754313152,
      "backward_entropy": 0.004677447744391181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9521821741363965e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937651053071022,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08079585433006287,
      "backward_entropy": 0.008184307678179308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0703946574940346e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376519843935966,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08079488078753154,
      "backward_entropy": 0.005723575299436396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6125214870044147e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376529157161713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079391221205394,
      "backward_entropy": 0.0046771700409325686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8833042076948914e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937653847038746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079299330711365,
      "backward_entropy": 0.004677090116522529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6583542219450464e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376547783613205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079211413860321,
      "backward_entropy": 0.0046769996935671024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7215920706803445e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937655709683895,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08079124490420024,
      "backward_entropy": 0.008184503425251354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5565296962449793e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376564547419548,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079041043917339,
      "backward_entropy": 0.004676841199398041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2851095334553975e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376570135354996,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08078959584236145,
      "backward_entropy": 0.008184586736288938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.099506996790296e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376577585935593,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0807888110478719,
      "backward_entropy": 0.005723163485527039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5129209032238577e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376588761806488,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078807592391968,
      "backward_entropy": 0.004676609892736782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.184720986202592e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376596212387085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078733583291371,
      "backward_entropy": 0.004676538096232848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.684488304628758e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376603662967682,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0807866354783376,
      "backward_entropy": 0.005723006346008994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.499107136434759e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376612976193428,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078595002492268,
      "backward_entropy": 0.004676396873864261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.342220437247306e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376620426774025,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08078530430793762,
      "backward_entropy": 0.005722890523346988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.998188718578604e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376627877354622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078467845916748,
      "backward_entropy": 0.004676261747425253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.928963666221534e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937663532793522,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08078407247861226,
      "backward_entropy": 0.005722788247195157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.154904437811638e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376642778515816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078348636627197,
      "backward_entropy": 0.004676139490170913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.402820187962789e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376652091741562,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08078291515509288,
      "backward_entropy": 0.0057226866483688354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.838587402555277e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376661404967308,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078237374623616,
      "backward_entropy": 0.004676006395708431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.024522119536414e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376668855547905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078181743621826,
      "backward_entropy": 0.004675949839028445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.980776336400595e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376676306128502,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08078129092852275,
      "backward_entropy": 0.005722541023384441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.286426241786103e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293766837567091,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078077435493469,
      "backward_entropy": 0.004675842144272544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.887414312790497e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376689344644547,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08078028758366902,
      "backward_entropy": 0.004675796424800699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.97644145727827e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376693069934845,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08077981571356456,
      "backward_entropy": 0.008184959265318785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.617897388925485e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376696795225143,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077934384346008,
      "backward_entropy": 0.004675706001845273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.953494905952539e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376700520515442,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807788868745168,
      "backward_entropy": 0.004675660959698937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.976839136361377e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937670424580574,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077844977378845,
      "backward_entropy": 0.004675617272203619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.651539822792984e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937670797109604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807780275742213,
      "backward_entropy": 0.00467557663267309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.317064051268972e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376709833741188,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077760537465413,
      "backward_entropy": 0.004675547169013457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6365491951073636e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376711696386337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08077720801035564,
      "backward_entropy": 0.0057222111658616496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.708328222273849e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376713559031487,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077681561311086,
      "backward_entropy": 0.004675489257682453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.801460479735397e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376715421676636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077644308408101,
      "backward_entropy": 0.004675454714081504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.377588768671558e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376717284321785,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08077608048915863,
      "backward_entropy": 0.005722125145522031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.14817356183994e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376719146966934,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077573776245117,
      "backward_entropy": 0.004675397818738764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.226281819479482e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376721009612083,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08077540000279744,
      "backward_entropy": 0.008185297928073189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.451366185596271e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376722872257233,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077507714430492,
      "backward_entropy": 0.00467534058473327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0784912041781354e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376724734902382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807747741540273,
      "backward_entropy": 0.004675308411771601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.621069003476805e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937672659754753,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077446619669597,
      "backward_entropy": 0.004675288092006336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.61313260807583e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937672846019268,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08077417810757954,
      "backward_entropy": 0.008185398849574003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2974955982135725e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937673032283783,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08077390988667806,
      "backward_entropy": 0.008185421878641302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5031127393049246e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02937673218548298,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08077364166577657,
      "backward_entropy": 0.0057219043374061584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0732788641453226e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376734048128128,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08077338337898254,
      "backward_entropy": 0.005721884694966403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1110530212808953e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376735910773277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077313999334972,
      "backward_entropy": 0.004675154320218347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0188507221519103e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376737773418427,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08077290157477061,
      "backward_entropy": 0.008185501125725832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9027750397526688e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376739636063576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077266812324524,
      "backward_entropy": 0.004675110632723028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.913296330258163e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376741498708725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807724545399348,
      "backward_entropy": 0.004675094376910816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8352943698118906e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376741498708725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077224095662434,
      "backward_entropy": 0.004675069993192499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1697469659566195e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376741498708725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077202240626018,
      "backward_entropy": 0.004675055092031305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7481846725786454e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08077182372411092,
      "backward_entropy": 0.005721712654287165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7580060784894158e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077162504196167,
      "backward_entropy": 0.004675019193779339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.509047060873854e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077142635981242,
      "backward_entropy": 0.00467500700192018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2964964923867228e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807712326447169,
      "backward_entropy": 0.004674995826049285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2645510594211373e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077104389667511,
      "backward_entropy": 0.004674970426342704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.310465998169093e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077086011568706,
      "backward_entropy": 0.004674958911809054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1071522010297485e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077069620291392,
      "backward_entropy": 0.004674950106577439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.36722177205229e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376743361353874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077052235603333,
      "backward_entropy": 0.004674937237392773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.765290715473384e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376745223999023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077037334442139,
      "backward_entropy": 0.00467491556297649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.958479221135349e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376747086644173,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08077023426691692,
      "backward_entropy": 0.004674902016466314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.538707163552317e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376748949289322,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08077009518941243,
      "backward_entropy": 0.0081857984716242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.024756515898844e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937675081193447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076995611190796,
      "backward_entropy": 0.004674869166179137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763743781197263e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937675267457962,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076983690261841,
      "backward_entropy": 0.004674856974319978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.724763489453835e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937675453722477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076970775922139,
      "backward_entropy": 0.004674846814437346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94243186166932e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937675639986992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076958854993184,
      "backward_entropy": 0.004674825140021064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.964613336573166e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376758262515068,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076945940653484,
      "backward_entropy": 0.008185851303013887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.626385319284054e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376760125160217,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076935013135274,
      "backward_entropy": 0.0046748065135695715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.577278265420318e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376761987805367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076926072438557,
      "backward_entropy": 0.004674794660373168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.136409069767979e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076915144920349,
      "backward_entropy": 0.004674788903106342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0620823088820543e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076905210812886,
      "backward_entropy": 0.00572137399153276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.837801708707957e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807689627011617,
      "backward_entropy": 0.004674762487411499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.204950864230341e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076886336008708,
      "backward_entropy": 0.00572135096246546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9760554787781075e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076877395311992,
      "backward_entropy": 0.00818593596870249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.004261455747837e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076869448026021,
      "backward_entropy": 0.005721318450841037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2087280266732705e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076861500740051,
      "backward_entropy": 0.005721310322934931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.572687390374085e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076852560043335,
      "backward_entropy": 0.00572129948572679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.020356397267278e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076845109462738,
      "backward_entropy": 0.005721279165961526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6808438136072255e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076837162176768,
      "backward_entropy": 0.005721269683404403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9432823228935376e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076829711596172,
      "backward_entropy": 0.008186013861136003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7120108825329226e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076822757720947,
      "backward_entropy": 0.005721241235733032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8406544672066047e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076816300551097,
      "backward_entropy": 0.004674698141488162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.689376271154288e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076809843381245,
      "backward_entropy": 0.005721224979920821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1267887834474095e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076803882916768,
      "backward_entropy": 0.005721216852014715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.049537511401468e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807679792245229,
      "backward_entropy": 0.0046746866269545126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2185312193178106e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076790968577068,
      "backward_entropy": 0.0046746852723034945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8354621761650378e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076785504817963,
      "backward_entropy": 0.004674670709805055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7362232540563127e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076780041058858,
      "backward_entropy": 0.008186105300079693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4388437996615266e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076775074005127,
      "backward_entropy": 0.0046746619045734406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0364120107151393e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076770106951396,
      "backward_entropy": 0.004674658856608651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3487691791501675e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076765139897664,
      "backward_entropy": 0.004674658856608651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2418534584289773e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0807676116625468,
      "backward_entropy": 0.00818614119833166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.363162465712776e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076756199200948,
      "backward_entropy": 0.008186147971586748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.771722502041939e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076751232147217,
      "backward_entropy": 0.005721126767722043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5631959726647437e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076747258504231,
      "backward_entropy": 0.005721120671792464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.614615641187811e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807674378156662,
      "backward_entropy": 0.0046746446327729655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6946625436276008e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076739311218262,
      "backward_entropy": 0.005721097642725164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2836433249674428e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076735337575276,
      "backward_entropy": 0.004674641584808176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3931185094406828e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076730370521545,
      "backward_entropy": 0.005721088837493549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1099355212706996e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076726893583934,
      "backward_entropy": 0.008186223832043734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1412508271746447e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076723416646321,
      "backward_entropy": 0.004674635827541351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3541131771432902e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076719443003337,
      "backward_entropy": 0.004674622281031175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0893131729972083e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076716462771098,
      "backward_entropy": 0.004674622281031175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2497259227473023e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076712985833485,
      "backward_entropy": 0.008186258375644684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3025811540501309e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076710005601247,
      "backward_entropy": 0.00467461957172914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.248225078853693e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076706528663635,
      "backward_entropy": 0.004674616862427105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.422652631954406e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076703051726024,
      "backward_entropy": 0.008186278695409948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.17406231590212e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076700071493785,
      "backward_entropy": 0.004674615169113333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2217384437462897e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076697587966919,
      "backward_entropy": 0.008186303756453774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0915397170902e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076695104440053,
      "backward_entropy": 0.005721036683429371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.780840860505123e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076691627502441,
      "backward_entropy": 0.005721033296801827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.386923073227081e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807668964068095,
      "backward_entropy": 0.004674611105160279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.645599791634595e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0807668666044871,
      "backward_entropy": 0.005721024491570212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.843461157288402e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076684673627217,
      "backward_entropy": 0.004674609750509262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2977073273250426e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076681693394978,
      "backward_entropy": 0.004674608395858245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.354003628279315e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076679706573486,
      "backward_entropy": 0.004674608395858245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.366338650172111e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076678216457367,
      "backward_entropy": 0.004674606702544473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.757797794103681e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076675732930501,
      "backward_entropy": 0.004674608395858245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.597779934556456e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076673746109009,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.121236933471664e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076671759287517,
      "backward_entropy": 0.004674606702544473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.288029569783248e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076669772466023,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3671415634635196e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076667785644531,
      "backward_entropy": 0.004674603993242437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.427864380180836e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076666792233785,
      "backward_entropy": 0.005720981820063157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.040195733523433e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076664805412292,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.037612993419316e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076661825180054,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5829614830618084e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076660335063934,
      "backward_entropy": 0.00572097436948256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.389281909629062e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076658844947815,
      "backward_entropy": 0.005720973014831543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2872193855837395e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076655864715576,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7785489464804414e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0807665487130483,
      "backward_entropy": 0.005720958113670349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.32228830504755e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076652884483337,
      "backward_entropy": 0.005720958113670349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.960330730023998e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076651394367218,
      "backward_entropy": 0.008186444640159607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7549020842343452e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076649904251099,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5151259680787916e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076648414134979,
      "backward_entropy": 0.005720950663089752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9364707049571734e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807664692401886,
      "backward_entropy": 0.004674603993242437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5269315528930747e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076644937197368,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1586288312391844e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076643943786621,
      "backward_entropy": 0.004674605347893455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3272548332897713e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076641956965129,
      "backward_entropy": 0.005720943889834664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.59361598864416e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076640963554382,
      "backward_entropy": 0.004674603993242437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.071196547603904e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08076639970143636,
      "backward_entropy": 0.005720941180532629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.514692371529236e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076637983322144,
      "backward_entropy": 0.008186501535502348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4168471668417624e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076636989911397,
      "backward_entropy": 0.004674602299928665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8401067336526467e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076635996500652,
      "backward_entropy": 0.004674603993242437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.985483777389163e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076635003089905,
      "backward_entropy": 0.0081865055994554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9357955238774593e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076634009679158,
      "backward_entropy": 0.004674602299928665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8219665776086913e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076632519563039,
      "backward_entropy": 0.004674603993242437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2600196441781009e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076632519563039,
      "backward_entropy": 0.004674602299928665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5653114360247855e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076630532741547,
      "backward_entropy": 0.004674602299928665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6934791347011924e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076630036036174,
      "backward_entropy": 0.00818652253259312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.238859681507165e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029376763850450516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08076629042625427,
      "backward_entropy": 0.008186525241895155,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.255382397426843e-08,
    "avg_log_Z": 0.029376760739833117,
    "success_rate": 1.0,
    "avg_reward": 47.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.16,
      "1": 0.26,
      "2": 0.58
    },
    "avg_forward_entropy": 0.08076787754893303,
    "avg_backward_entropy": 0.005508629676293243,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}