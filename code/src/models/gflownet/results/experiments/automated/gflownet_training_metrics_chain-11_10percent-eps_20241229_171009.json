{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06295807253230702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06295807253230702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06295807253230702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06295807253230702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06295807253230702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06295807253230702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06295807253230702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.06293030218644576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.656675338745117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151987234751384,
      "backward_entropy": 0.0629651654850353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.651419639587402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152085582415263,
      "backward_entropy": 0.06295534697445956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.756978988647461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0001999995147343725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152175982793172,
      "backward_entropy": 0.06295940009030429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.530028343200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003000241704285145,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152263402938843,
      "backward_entropy": 0.06291857632723721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.000625610351562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003999987675342709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152340888977051,
      "backward_entropy": 0.06295328790491278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.107488632202148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004998259246349335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152408440907796,
      "backward_entropy": 0.06294393539428711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.625486373901367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000599598279222846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152473012606303,
      "backward_entropy": 0.06294680725444447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.992050170898438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000699457130394876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152527650197347,
      "backward_entropy": 0.0629434585571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.09766960144043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007994745392352343,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0915257732073466,
      "backward_entropy": 0.06294006651098077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.462875366210938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008996454416774213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152621030807495,
      "backward_entropy": 0.06293657692995938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.234058380126953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010000295005738735,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152659773826599,
      "backward_entropy": 0.0629276145588268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.969339370727539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011005004635080695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152689576148987,
      "backward_entropy": 0.06292948939583519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.963587760925293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012009718921035528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152710437774658,
      "backward_entropy": 0.06292591853575273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.807353973388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001301440759561956,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152724345525105,
      "backward_entropy": 0.06287275661121715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.063669204711914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014021615497767925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152732292811076,
      "backward_entropy": 0.06291848962957208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.16965389251709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015028660418465734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152735273043315,
      "backward_entropy": 0.06291462616486983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.461033821105957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016035970766097307,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152735273043315,
      "backward_entropy": 0.06285789879885587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.557015419006348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017040938837453723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152722358703613,
      "backward_entropy": 0.0629065524448048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.56210994720459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018047465709969401,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152700503667195,
      "backward_entropy": 0.06289704821326515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.302552223205566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019052140414714813,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152668714523315,
      "backward_entropy": 0.06289274042302911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.029267311096191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0020054448395967484,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152630964914958,
      "backward_entropy": 0.06283618103374135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.276704788208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021057219710201025,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152588248252869,
      "backward_entropy": 0.0628302964297208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.79335880279541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022061127237975597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0915253758430481,
      "backward_entropy": 0.0628842982378873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.012076377868652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023064236156642437,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152474999427795,
      "backward_entropy": 0.06287473982030695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.417680740356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024067626800388098,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152409434318542,
      "backward_entropy": 0.06281173229217529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.251702308654785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025068928953260183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152332941691081,
      "backward_entropy": 0.06286978721618652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.88240909576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026071532629430294,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152249495188396,
      "backward_entropy": 0.06279887936332008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.101818084716797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027073933742940426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152157107988994,
      "backward_entropy": 0.06285949186845259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.120162963867188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002807716839015484,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152063727378845,
      "backward_entropy": 0.0628501068462025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.700918197631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002908088266849518,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151959419250488,
      "backward_entropy": 0.06277830492366444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.58124828338623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030087358318269253,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151849150657654,
      "backward_entropy": 0.06284284591674805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.852834701538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031095684971660376,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0915173093477885,
      "backward_entropy": 0.06276364759965376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.733824729919434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003210288006812334,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151602784792583,
      "backward_entropy": 0.06275600736791437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.254868507385254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003310851287096739,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151464700698853,
      "backward_entropy": 0.0628247857093811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.678894996643066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034110797569155693,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151311715443929,
      "backward_entropy": 0.06281883066350763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.715739250183105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003510403214022517,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151153763135274,
      "backward_entropy": 0.06273136355660179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.46473503112793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036097413394600153,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150986870129903,
      "backward_entropy": 0.06280718066475609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.930807113647461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037090054247528315,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150813023249309,
      "backward_entropy": 0.06280105764215643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.94196891784668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003808404551818967,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150634209314983,
      "backward_entropy": 0.06279469620097768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.961495399475098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003907895181328058,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150443474451701,
      "backward_entropy": 0.06278824806213379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.298346519470215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004007113631814718,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09150253732999165,
      "backward_entropy": 0.06277905810963023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.210159301757812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00410626782104373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150079886118571,
      "backward_entropy": 0.06277440894733775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.015952110290527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00420524924993515,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914988915125529,
      "backward_entropy": 0.06276443871584805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.816567420959473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0043044621124863625,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149697422981262,
      "backward_entropy": 0.06275971369309859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.294719696044922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0044034025631845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149515628814697,
      "backward_entropy": 0.06274901736866344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.289953231811523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004502283409237862,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149332841237386,
      "backward_entropy": 0.06263388286937367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.119443893432617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004601112101227045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149149060249329,
      "backward_entropy": 0.06273277239366011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447391510009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0047002253122627735,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148950378100078,
      "backward_entropy": 0.06261130896481601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.286510467529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004798924084752798,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148764610290527,
      "backward_entropy": 0.0625995397567749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.737613677978516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004897561389952898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148561954498291,
      "backward_entropy": 0.06270906600085172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.312677383422852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004996389616280794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148360292116801,
      "backward_entropy": 0.0626997405832464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.909038543701172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005094804335385561,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148180484771729,
      "backward_entropy": 0.06268997625871138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.009510040283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005193069577217102,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147998690605164,
      "backward_entropy": 0.06255102157592773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.321026802062988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005291298031806946,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147831797599792,
      "backward_entropy": 0.06253814697265625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.781993865966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005389118101447821,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147652983665466,
      "backward_entropy": 0.06252482262524692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.242074012756348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005486797541379929,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147459268569946,
      "backward_entropy": 0.06251112981276079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.959169387817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0055845738388597965,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914725661277771,
      "backward_entropy": 0.06249710104682229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.662213325500488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005681836511939764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147040049235027,
      "backward_entropy": 0.06262534314935858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.697819709777832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0057789296843111515,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.091467946767807,
      "backward_entropy": 0.062467672608115456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.1083984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0058763823471963406,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914652943611145,
      "backward_entropy": 0.0624524246562611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.715503692626953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005973903927952051,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146255254745483,
      "backward_entropy": 0.06259007345546376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.516414642333984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006070813629776239,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145966172218323,
      "backward_entropy": 0.06258151747963646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.393228530883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0061676036566495895,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145679076512654,
      "backward_entropy": 0.062404079870744186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.156624794006348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00626426050439477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145407875378926,
      "backward_entropy": 0.06255166097120805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.503730773925781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006360705941915512,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145158529281616,
      "backward_entropy": 0.06253672729838979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.385068893432617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006457092240452766,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144906202952068,
      "backward_entropy": 0.06235307455062866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14907169342041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006553362589329481,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914464791615804,
      "backward_entropy": 0.06250506639480591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45363998413086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006649436894804239,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914439062277476,
      "backward_entropy": 0.06248838251287287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.139191627502441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0067450120113790035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144142270088196,
      "backward_entropy": 0.06248999725688587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.559922218322754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006840511690825224,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143913785616557,
      "backward_entropy": 0.062278904698111794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.133439064025879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0069356863386929035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143720070521037,
      "backward_entropy": 0.062461224469271576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.211835861206055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00703080091625452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914352039496104,
      "backward_entropy": 0.062446334145285866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.435114860534668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007125397678464651,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143313765525818,
      "backward_entropy": 0.06239485740661621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.925398826599121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0072197504341602325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143155813217163,
      "backward_entropy": 0.06241568652066318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002405166625977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007314469665288925,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142945210138957,
      "backward_entropy": 0.06235214796933261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.11373519897461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007409166544675827,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142755468686421,
      "backward_entropy": 0.062329920855435456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.766045570373535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007503838744014502,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142541885375977,
      "backward_entropy": 0.06236665899103338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.647844314575195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007598364260047674,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142328302065532,
      "backward_entropy": 0.062284328720786354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.986498832702637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007692733313888311,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142130613327026,
      "backward_entropy": 0.0623321533203125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.438690185546875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00778713496401906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141942858695984,
      "backward_entropy": 0.06231431527571245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.889593124389648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00788180623203516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141764044761658,
      "backward_entropy": 0.062210446054285225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.997300148010254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00797691848129034,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141568342844646,
      "backward_entropy": 0.06198252872987227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.856114387512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008072417229413986,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141319990158081,
      "backward_entropy": 0.0619536584073847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.191753387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008167807944118977,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141100446383159,
      "backward_entropy": 0.06192397529428655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.321523666381836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008263234980404377,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140878915786743,
      "backward_entropy": 0.06222115321592851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.976200103759766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008359229192137718,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140618642171223,
      "backward_entropy": 0.06220114231109619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.176654815673828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008455602452158928,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140353401501973,
      "backward_entropy": 0.062180616638877174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.830270767211914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00855190958827734,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140088160832723,
      "backward_entropy": 0.06179889223792336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.279749870300293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008647950366139412,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139804045359294,
      "backward_entropy": 0.06198793107813055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.272300720214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008744033984839916,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139526883761089,
      "backward_entropy": 0.06173164736140858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.604948997497559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00884011760354042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139228860537212,
      "backward_entropy": 0.062093024904077705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.388123512268066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00893637165427208,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138906995455424,
      "backward_entropy": 0.06166088581085205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.354692459106445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009033184498548508,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138554334640503,
      "backward_entropy": 0.061859423463994805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69849967956543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009129481390118599,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138226509094238,
      "backward_entropy": 0.06182527542114258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24136734008789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009225997142493725,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137885769208272,
      "backward_entropy": 0.06179022789001465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46146011352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009322470054030418,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137529134750366,
      "backward_entropy": 0.06150797280398282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.005273818969727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009419044479727745,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913717250029246,
      "backward_entropy": 0.06171747229316018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.67268180847168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009515470825135708,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136801958084106,
      "backward_entropy": 0.06167964501814409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.435816764831543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009612568654119968,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136367837587993,
      "backward_entropy": 0.06164143302223899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.546538352966309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009709659963846207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.091359148422877,
      "backward_entropy": 0.06182878125797619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.210359573364258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009806856513023376,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135478734970093,
      "backward_entropy": 0.061561931263316765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.197359085083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009904018603265285,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09135093291600545,
      "backward_entropy": 0.061240082437341865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8622307777404785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0100011071190238,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134722749392192,
      "backward_entropy": 0.06147662076083096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.623242378234863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010097489692270756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134435653686523,
      "backward_entropy": 0.06168277155269276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.166447639465332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010193569585680962,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134145577748616,
      "backward_entropy": 0.06164408813823353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289247512817383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010290159843862057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09133803844451904,
      "backward_entropy": 0.06160415302623402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.260809898376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010386338457465172,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09133534630139668,
      "backward_entropy": 0.06098747253417969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.600616455078125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010483085177838802,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133216738700867,
      "backward_entropy": 0.0612430680881847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.804435729980469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010579530149698257,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132927656173706,
      "backward_entropy": 0.06119304353540594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26069450378418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010676315985620022,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913262168566386,
      "backward_entropy": 0.06082276864485307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.90202522277832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010772665031254292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132381280263265,
      "backward_entropy": 0.06139338558370417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.117167472839355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010868879966437817,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09132121006647746,
      "backward_entropy": 0.060706815936348656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.326178550720215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010965117253363132,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131854772567749,
      "backward_entropy": 0.06130228259346702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.242858409881592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011061472818255424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131566683451335,
      "backward_entropy": 0.06125495650551536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.221016883850098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011156915687024593,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131370981534322,
      "backward_entropy": 0.06052241542122581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.970871925354004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011252058669924736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131221969922383,
      "backward_entropy": 0.061158917166969994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.195893287658691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011347264051437378,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131048123041789,
      "backward_entropy": 0.06110944531180642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.258989334106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011442109942436218,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130868315696716,
      "backward_entropy": 0.060325795953924004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.380748748779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01153769250959158,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130595127741496,
      "backward_entropy": 0.06025716391476718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.040566444396973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011633530259132385,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130301078160603,
      "backward_entropy": 0.06018714471296831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.817350387573242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011729382909834385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129971265792847,
      "backward_entropy": 0.060898948799480095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69173812866211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011825187131762505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912965436776479,
      "backward_entropy": 0.060433756221424446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.44780158996582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011920792981982231,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129282832145691,
      "backward_entropy": 0.06036492911252109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.97695541381836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012016716413199902,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09128902355829875,
      "backward_entropy": 0.06029458479447798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45174789428711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012113192118704319,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.091284841299057,
      "backward_entropy": 0.06066598675467751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.220841407775879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012209372594952583,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912809173266093,
      "backward_entropy": 0.059732155366377396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.104803085327148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012305103242397308,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127683440844218,
      "backward_entropy": 0.06008252230557529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.954998016357422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012400399893522263,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912728210290273,
      "backward_entropy": 0.06000953370874578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.946393966674805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012495752424001694,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126847982406616,
      "backward_entropy": 0.05948129025372592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.151388168334961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012591192498803139,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126410881678264,
      "backward_entropy": 0.059858603910966354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.705794334411621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012686850503087044,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125985701878865,
      "backward_entropy": 0.059305667877197266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.660122871398926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012782416306436062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125543634096782,
      "backward_entropy": 0.05969972502101551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.001526832580566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012878453359007835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125079711278279,
      "backward_entropy": 0.05961718884381381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988051414489746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012974523939192295,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124586979548137,
      "backward_entropy": 0.05953322757374157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.61677074432373,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01307061966508627,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124066432317098,
      "backward_entropy": 0.05944751609455456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.748641014099121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013167118653655052,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123528003692627,
      "backward_entropy": 0.058819705789739433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9905877113342285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013263488188385963,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122985601425171,
      "backward_entropy": 0.059780305082147774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72028636932373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01335932221263647,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122458100318909,
      "backward_entropy": 0.059691364114934746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.642939567565918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013455089181661606,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121922651926677,
      "backward_entropy": 0.058499813079833984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.90056037902832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013550160452723503,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09121385216712952,
      "backward_entropy": 0.058989882469177246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.107931137084961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013645336963236332,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120811025301616,
      "backward_entropy": 0.0594114444472573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.868922233581543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01374082826077938,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120283524195354,
      "backward_entropy": 0.05879336595535278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.27393913269043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013836370781064034,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119718273480733,
      "backward_entropy": 0.05803220922296697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.313591957092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01393219642341137,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119109312693278,
      "backward_entropy": 0.05790924484079534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606363296508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014027753844857216,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09118505318959554,
      "backward_entropy": 0.05778348445892334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.912132263183594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014123196713626385,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911785364151001,
      "backward_entropy": 0.05837316404689442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.058029174804688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014218785800039768,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09117213884989421,
      "backward_entropy": 0.05878711288625544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870848655700684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014314013533294201,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116603930791219,
      "backward_entropy": 0.05867481231689453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.358222007751465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014409356750547886,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115946292877197,
      "backward_entropy": 0.05855976451526989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447729110717773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014504984021186829,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911513368288676,
      "backward_entropy": 0.05711244994943792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.989719867706299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014600971713662148,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114228685696919,
      "backward_entropy": 0.05831899426200173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.213171005249023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014696530066430569,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091133713722229,
      "backward_entropy": 0.057676765051755036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.79440689086914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014792425557971,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112521012624104,
      "backward_entropy": 0.05806814540516247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.163039207458496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014888870529830456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09111567338307698,
      "backward_entropy": 0.05793739990754561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.616280555725098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01498549897223711,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09110584855079651,
      "backward_entropy": 0.05636872486634688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7912516593933105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015081471763551235,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109719594319661,
      "backward_entropy": 0.057159889828075065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.391668319702148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015176905319094658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09108890096346538,
      "backward_entropy": 0.057531454346396706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.759367942810059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015272730030119419,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09107957283655803,
      "backward_entropy": 0.05688599022951993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.549695014953613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015368057414889336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910710593064626,
      "backward_entropy": 0.05724747072566639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5112528800964355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01546391099691391,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106162190437317,
      "backward_entropy": 0.05710041522979736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.791397094726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015559103339910507,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09105287988980611,
      "backward_entropy": 0.05538071827455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.161728858947754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01565440371632576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09104348222414653,
      "backward_entropy": 0.056799119169061836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.049363136291504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015749990940093994,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103276332219441,
      "backward_entropy": 0.056148881261998955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528136730194092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01584583893418312,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09102177619934082,
      "backward_entropy": 0.05648192492398349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.501379013061523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015941057354211807,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0910113255182902,
      "backward_entropy": 0.05582535266876221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35710620880127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01603628508746624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100077549616496,
      "backward_entropy": 0.056158699772574684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642378807067871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016131974756717682,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098901351292928,
      "backward_entropy": 0.05599251660433682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.913643836975098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01622769981622696,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09097699324289958,
      "backward_entropy": 0.05531310493295843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.493521690368652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016322989016771317,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09096475442250569,
      "backward_entropy": 0.05387771129608154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4667744636535645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016418304294347763,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09095265467961629,
      "backward_entropy": 0.05495589429681951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.718804359436035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01651296205818653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09094057480494182,
      "backward_entropy": 0.05529730970209295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2322611808776855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01660780981183052,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09092781941095988,
      "backward_entropy": 0.05458747256885876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.457696914672852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016701970249414444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09091591835021973,
      "backward_entropy": 0.05493164604360407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.956798076629639,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016796207055449486,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0909031331539154,
      "backward_entropy": 0.05281767520037564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.115797996520996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016890274360775948,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09089066584904988,
      "backward_entropy": 0.05455297231674194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.272930145263672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016984274610877037,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0908781389395396,
      "backward_entropy": 0.05379558151418513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.85570764541626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017078299075365067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09086511532465617,
      "backward_entropy": 0.054159988056529655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198539733886719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017172090709209442,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09085187315940857,
      "backward_entropy": 0.05336762558330189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.546361923217773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01726585440337658,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09083764751752217,
      "backward_entropy": 0.05314864895560525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.483458518981934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017359817400574684,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09082222978274028,
      "backward_entropy": 0.0529236685145985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.781722545623779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017453383654356003,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09080757697423299,
      "backward_entropy": 0.05117098851637407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.224859237670898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01754612661898136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09079379836718242,
      "backward_entropy": 0.05246156995946711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.73618745803833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017638426274061203,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907805363337199,
      "backward_entropy": 0.05066444657065652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.035256385803223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017730090767145157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09076909224192302,
      "backward_entropy": 0.052673870866948906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220590591430664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01782067120075226,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09075909852981567,
      "backward_entropy": 0.05245331200686368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295104026794434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01791105419397354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09074934323628743,
      "backward_entropy": 0.052229312333193695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.59575080871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018001919612288475,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907382865746816,
      "backward_entropy": 0.04960827935825695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.10792350769043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018092704936861992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0907256801923116,
      "backward_entropy": 0.05176490545272827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.351085662841797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01818261481821537,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09071516990661621,
      "backward_entropy": 0.05152966759421609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.135683059692383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01827305741608143,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09070240457852681,
      "backward_entropy": 0.05047895149751143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7320990562438965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01836390420794487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09068850676218669,
      "backward_entropy": 0.05021258917721835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2374267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018454251810908318,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09067549308141072,
      "backward_entropy": 0.048197789625688034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824335098266602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01854446902871132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09066275755564372,
      "backward_entropy": 0.04966680570082231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.963882923126221,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018634915351867676,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09064932664235432,
      "backward_entropy": 0.04760848392139782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.760330677032471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01872568577528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09063481291135152,
      "backward_entropy": 0.05001553622159091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.425602912902832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0188160240650177,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09062137206395467,
      "backward_entropy": 0.04700558835809881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.763606071472168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01890634559094906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09060704708099365,
      "backward_entropy": 0.049478975209322845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.423227310180664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018996264785528183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09059329827626546,
      "backward_entropy": 0.04821989753029563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.116344928741455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019086195155978203,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09057808915774028,
      "backward_entropy": 0.047918075864965264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.458438396453857,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01917598582804203,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905625323454539,
      "backward_entropy": 0.04760920459573919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.241488456726074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019265219569206238,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09054750204086304,
      "backward_entropy": 0.04836073788729581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.49738073348999,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019353831186890602,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09053344527880351,
      "backward_entropy": 0.0469794056632302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.412968635559082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01944270357489586,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09051795800526936,
      "backward_entropy": 0.04665754058144309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.367288589477539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019531110301613808,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09050297737121582,
      "backward_entropy": 0.046332364732568916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.236200332641602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01961907371878624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09048846364021301,
      "backward_entropy": 0.047190709547563034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.786633014678955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019706543534994125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09047432740529378,
      "backward_entropy": 0.045672817663712936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.397223472595215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019793912768363953,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0904589593410492,
      "backward_entropy": 0.04533903436227278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.023345947265625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01988096721470356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09044349193572998,
      "backward_entropy": 0.04628003727306019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.884556770324707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019968146458268166,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09042640527089436,
      "backward_entropy": 0.042729114944284614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.499180316925049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0200553797185421,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09040833512941997,
      "backward_entropy": 0.04564907334067605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.772599220275879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020142395049333572,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09038981795310974,
      "backward_entropy": 0.04396561871875416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.555506706237793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020229460671544075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09037100275357564,
      "backward_entropy": 0.04500190778212114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2603302001953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020316405221819878,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09035179018974304,
      "backward_entropy": 0.04324948245828802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.603686332702637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020403003320097923,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0903321107228597,
      "backward_entropy": 0.040939927101135254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.817042350769043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02048959955573082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09031212329864502,
      "backward_entropy": 0.04251985116438432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.685076713562012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020575659349560738,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0902934471766154,
      "backward_entropy": 0.04020921479571949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.080565452575684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020661136135458946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09027594327926636,
      "backward_entropy": 0.04332903298464688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.586030006408691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020747028291225433,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09025558829307556,
      "backward_entropy": 0.0413913293318315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.294650554656982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020832251757383347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09023589889208476,
      "backward_entropy": 0.042638938535343514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.701613903045654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02091667242348194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09021742145220439,
      "backward_entropy": 0.040625490925528786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.273335933685303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021000707522034645,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09019947052001953,
      "backward_entropy": 0.0402387949553403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.065465450286865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021084798499941826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09018017848332723,
      "backward_entropy": 0.03984797542745417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.308474540710449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021168770268559456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09016017119089763,
      "backward_entropy": 0.04124526544050737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4684553146362305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021252833306789398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09013919035593669,
      "backward_entropy": 0.04088725285096602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.550148010253906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021336400881409645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09011894464492798,
      "backward_entropy": 0.04052832451733676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.115923881530762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021419616416096687,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09009988109270732,
      "backward_entropy": 0.040168014439669525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.218493461608887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021502884104847908,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09007904926935832,
      "backward_entropy": 0.0360275154764002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.449965476989746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021585553884506226,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09005896250406902,
      "backward_entropy": 0.037448194893923675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.653124809265137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021667879074811935,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09003885587056477,
      "backward_entropy": 0.035246448083357376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6323018074035645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021749282255768776,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09002077579498291,
      "backward_entropy": 0.03663490035317161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.413363456726074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021830594167113304,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09000114599863689,
      "backward_entropy": 0.036227204582907936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.613439083099365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021911676973104477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08998072147369385,
      "backward_entropy": 0.035818026824430985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.218884468078613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021992631256580353,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.089957594871521,
      "backward_entropy": 0.03367394750768488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.367643356323242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02207324281334877,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08993387222290039,
      "backward_entropy": 0.03327751430598172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.087623119354248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022153671830892563,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08990877866744995,
      "backward_entropy": 0.03459349003705112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.205083847045898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02223372273147106,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08988318840662639,
      "backward_entropy": 0.034184073859995064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.806170463562012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02231357991695404,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08985706170399983,
      "backward_entropy": 0.032086632468483665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.859122276306152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022392921149730682,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08983113368352254,
      "backward_entropy": 0.03566324710845947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.761909484863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022471876814961433,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0898053248723348,
      "backward_entropy": 0.03129530223933133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.024523735046387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02255035564303398,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08977897961934407,
      "backward_entropy": 0.03253638202493841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.919102191925049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02262789011001587,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0897556444009145,
      "backward_entropy": 0.030507545579563488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.418057441711426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022705208510160446,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08973005414009094,
      "backward_entropy": 0.030114924365823918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.495369911193848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02278280444443226,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08970096707344055,
      "backward_entropy": 0.03130613131956621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7519116401672363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022859865799546242,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08967146277427673,
      "backward_entropy": 0.03333433649756692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.695892810821533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02293584682047367,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08964456121126811,
      "backward_entropy": 0.0304928719997406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.608048439025879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02301163040101528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08961555361747742,
      "backward_entropy": 0.03255614096468145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.086960792541504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02308710850775242,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08958402276039124,
      "backward_entropy": 0.02969002452763644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.381928443908691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023161953315138817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08955288926760356,
      "backward_entropy": 0.03177280317653309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.240260601043701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023236438632011414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08951996763547261,
      "backward_entropy": 0.03138003836978565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.56722354888916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023310573771595955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08948659896850586,
      "backward_entropy": 0.030987241051413796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.783407688140869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023383773863315582,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.089455246925354,
      "backward_entropy": 0.03059829365123402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.103820323944092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02345636859536171,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0894248088200887,
      "backward_entropy": 0.030211356553164394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.377307415008545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02352861315011978,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08939234415690105,
      "backward_entropy": 0.0298240835016424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5875468254089355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02359994687139988,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08936173717180888,
      "backward_entropy": 0.029440928589213978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.342005491256714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023671569302678108,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08932667970657349,
      "backward_entropy": 0.025077521800994873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6546151638031006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023742349818348885,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08929355939229329,
      "backward_entropy": 0.024701690131967716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6632845401763916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023812567815184593,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08925926685333252,
      "backward_entropy": 0.025761869820681484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6508679389953613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023881472647190094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08923010031382243,
      "backward_entropy": 0.027916875752535732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3340327739715576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023950066417455673,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08919921517372131,
      "backward_entropy": 0.02754379944367842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5558557510375977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024018103256821632,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0891682505607605,
      "backward_entropy": 0.027172920378771694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.446424961090088,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02408585511147976,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08913558721542358,
      "backward_entropy": 0.024238765239715576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.059220552444458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02415323071181774,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08910135428110759,
      "backward_entropy": 0.02251187508756464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8749988079071045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024219803512096405,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08906670411427815,
      "backward_entropy": 0.023496782237833195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3827855587005615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02428554929792881,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08903303742408752,
      "backward_entropy": 0.02180699055845087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5942423343658447,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024350041523575783,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08900283773740132,
      "backward_entropy": 0.021462218327955765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3035075664520264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024413686245679855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08897474408149719,
      "backward_entropy": 0.022421430457722057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.627544403076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02447628416121006,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08895017703374226,
      "backward_entropy": 0.020789265632629395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.725605010986328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02453826554119587,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08892624576886494,
      "backward_entropy": 0.021721193736249752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1514041423797607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02459973655641079,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08890135089556377,
      "backward_entropy": 0.020135211673649876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.796483039855957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024661188945174217,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08887225389480591,
      "backward_entropy": 0.02103492346676913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.086632013320923,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024722222238779068,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08884098132451375,
      "backward_entropy": 0.01949190687049519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3011584281921387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024783266708254814,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08880595366160075,
      "backward_entropy": 0.02036380496892062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1364805698394775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484346739947796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08877230683962505,
      "backward_entropy": 0.022641554474830627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7229318618774414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02490272931754589,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08874070644378662,
      "backward_entropy": 0.022315839474851436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6320958137512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02496175840497017,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08870609601338704,
      "backward_entropy": 0.018253577026453884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6571977138519287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025020457804203033,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0886687437693278,
      "backward_entropy": 0.019068121910095215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0520472526550293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02507895976305008,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08862871925036113,
      "backward_entropy": 0.018753532658923756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.27571964263916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025136591866612434,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08859026432037354,
      "backward_entropy": 0.021029018542983315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9179686307907104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025193659588694572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08855080604553223,
      "backward_entropy": 0.020716076547449284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.236945390701294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02524980902671814,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08851279815038045,
      "backward_entropy": 0.020409147847782482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.230815887451172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02530546672642231,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08847288290659587,
      "backward_entropy": 0.020105036822232334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1498537063598633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025360723957419395,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08843110005060832,
      "backward_entropy": 0.016242203387347134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.904986023902893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02541559748351574,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.088389386733373,
      "backward_entropy": 0.01950461756099354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.367147445678711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02546972595155239,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08834920326868693,
      "backward_entropy": 0.01921064474365928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3238952159881592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025523798540234566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08830461899439494,
      "backward_entropy": 0.01891712573441592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7317030429840088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025576338171958923,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08826373020807902,
      "backward_entropy": 0.015187392180616205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.724825382232666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0256281029433012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08822246392567952,
      "backward_entropy": 0.018354610963301224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8532366752624512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02567920833826065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08818068106969197,
      "backward_entropy": 0.018080169504339046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7160013914108276,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025729883462190628,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08813680211702983,
      "backward_entropy": 0.014447596940127287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2886006832122803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025779984891414642,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08809173107147217,
      "backward_entropy": 0.017540670254013756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4480671882629395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025828931480646133,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08804903427759807,
      "backward_entropy": 0.017280309037728744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.841876745223999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025876961648464203,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08800594011942546,
      "backward_entropy": 0.01375162195075642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.906704068183899,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02592487633228302,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08795905113220215,
      "backward_entropy": 0.014356052333658392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6938856840133667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025972837582230568,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08790789047876994,
      "backward_entropy": 0.013306804678656838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6776684522628784,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026020536199212074,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0878543754418691,
      "backward_entropy": 0.013089402155442671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6921451091766357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02606789395213127,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08779790004094441,
      "backward_entropy": 0.013657074082981457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.283933162689209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026114938780665398,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08773790796597798,
      "backward_entropy": 0.013432043519887056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0691851377487183,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026160966604948044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08767778674761455,
      "backward_entropy": 0.015527955510399559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4182528257369995,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026205675676465034,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08761907617251079,
      "backward_entropy": 0.015295020558617332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.581177830696106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026249945163726807,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0875584085782369,
      "backward_entropy": 0.015065095641396263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7431252002716064,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026294229552149773,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08749487002690633,
      "backward_entropy": 0.012591970237818632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1320868730545044,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633880265057087,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08742952346801758,
      "backward_entropy": 0.011681717905131254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1841734647750854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026382410898804665,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08736428618431091,
      "backward_entropy": 0.012187602845105257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9288597106933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02642529457807541,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08729838331540425,
      "backward_entropy": 0.011315338990905068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9614187479019165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026467014104127884,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08723420898119609,
      "backward_entropy": 0.01114046031778509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.25227689743042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026507731527090073,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08717071016629536,
      "backward_entropy": 0.011620071801272306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7762927412986755,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026548102498054504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08710381388664246,
      "backward_entropy": 0.01354210756041787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9203318953514099,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026587244123220444,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08703937133153279,
      "backward_entropy": 0.01064388250762766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8827018141746521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026625508442521095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08697457114855449,
      "backward_entropy": 0.013155327601866289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9271477460861206,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02666287124156952,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08690927426020305,
      "backward_entropy": 0.01033694635738026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8635779023170471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026699567213654518,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08684280514717102,
      "backward_entropy": 0.012788030234250155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7258197069168091,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02673562802374363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08677627642949422,
      "backward_entropy": 0.012610285119576887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7544631958007812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026770563796162605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08670970797538757,
      "backward_entropy": 0.012438688765872608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6069036722183228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680479921400547,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08664384484291077,
      "backward_entropy": 0.012271306731484154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6825860142707825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683797851204872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08657989899317424,
      "backward_entropy": 0.012109895998781378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5878864526748657,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026870327070355415,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.086515873670578,
      "backward_entropy": 0.009519537741487677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7036433815956116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02690187282860279,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08645392457644145,
      "backward_entropy": 0.009398452260277489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6721311807632446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026932884007692337,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08639114101727803,
      "backward_entropy": 0.011651763861829584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6469460129737854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026963265612721443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0863272746404012,
      "backward_entropy": 0.011505996639078314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47911983728408813,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026992980390787125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0862622360388438,
      "backward_entropy": 0.009525349194353277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6560892462730408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02702156826853752,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08619803190231323,
      "backward_entropy": 0.008948273956775665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6396486759185791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02704971469938755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08613188068072002,
      "backward_entropy": 0.009290963411331177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6623290777206421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027077453210949898,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08606404066085815,
      "backward_entropy": 0.010961461473595013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5569762587547302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027104884386062622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08599385619163513,
      "backward_entropy": 0.010831265964291313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7931836247444153,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027131717652082443,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08592283725738525,
      "backward_entropy": 0.008958572013811632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5269289612770081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027158841490745544,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08584735790888469,
      "backward_entropy": 0.010575901378284801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7403144836425781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027185380458831787,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08577171961466472,
      "backward_entropy": 0.00874563374302604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4557202458381653,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027212044224143028,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0856917401154836,
      "backward_entropy": 0.008265008980577642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5139779448509216,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02723795548081398,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0856126348177592,
      "backward_entropy": 0.008539954369718378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3169136345386505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027263397350907326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08553299307823181,
      "backward_entropy": 0.010084967044266787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4790266156196594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02728765644133091,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08545577526092529,
      "backward_entropy": 0.008346789262511513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4971621632575989,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027311425656080246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08537742495536804,
      "backward_entropy": 0.00986186076294292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4494023621082306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733481302857399,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08529726664225261,
      "backward_entropy": 0.009753538126295263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3108350336551666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02735770307481289,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08521616458892822,
      "backward_entropy": 0.007772367108951916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45187169313430786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027379749342799187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08513729770978291,
      "backward_entropy": 0.009546327320012178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37922704219818115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027401363477110863,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08505618572235107,
      "backward_entropy": 0.007914527573368767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3386731743812561,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02742237225174904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08497452735900879,
      "backward_entropy": 0.007836167107928883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.496380478143692,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027442805469036102,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08489356438318889,
      "backward_entropy": 0.007760210470719771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3732733130455017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027463190257549286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0848086675008138,
      "backward_entropy": 0.009163776581937616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2025611698627472,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027483031153678894,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08472256859143575,
      "backward_entropy": 0.007372801954096014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22182156145572662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027501830831170082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08463984727859497,
      "backward_entropy": 0.008987506004897032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24391183257102966,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02751976065337658,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08455953001976013,
      "backward_entropy": 0.007260702550411224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23753418028354645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0275367870926857,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08447966972986858,
      "backward_entropy": 0.007417422803965482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3226855993270874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02755296602845192,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08440014719963074,
      "backward_entropy": 0.008755517954176123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28689002990722656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027568869292736053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08431900540987651,
      "backward_entropy": 0.008683331310749054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3488278388977051,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027584532275795937,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08423779408137004,
      "backward_entropy": 0.007246282290328632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19258663058280945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760014310479164,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08415401975313823,
      "backward_entropy": 0.008541515605016188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31016236543655396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027614828199148178,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08407130837440491,
      "backward_entropy": 0.007139324464581229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29913586378097534,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02762935496866703,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08398665984471639,
      "backward_entropy": 0.007088472220030698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26955920457839966,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027643779292702675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08390066027641296,
      "backward_entropy": 0.008343991908160124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2098766416311264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027658013626933098,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08381439248720805,
      "backward_entropy": 0.006988673047585921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25758087635040283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02767161652445793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08372850219408672,
      "backward_entropy": 0.008217421444979582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1975705772638321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027684984728693962,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08364167809486389,
      "backward_entropy": 0.00815638696605509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2676878869533539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027697788551449776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0835554301738739,
      "backward_entropy": 0.008097815242680636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2479008585214615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771034650504589,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0834668477376302,
      "backward_entropy": 0.008040118623863567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13746435940265656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027722913771867752,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08337784806887309,
      "backward_entropy": 0.007982423359697515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1567053496837616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02773454040288925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08329047759373982,
      "backward_entropy": 0.007928869263692335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27475422620773315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027745675295591354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0832047959168752,
      "backward_entropy": 0.00787755169651725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16720786690711975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027757160365581512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0831168641646703,
      "backward_entropy": 0.00782468847253106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1464727222919464,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027768155559897423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08302963773409526,
      "backward_entropy": 0.007773983884941448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2018565833568573,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777862548828125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08294374744097392,
      "backward_entropy": 0.007725630294192921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18611286580562592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02778894081711769,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08285681406656902,
      "backward_entropy": 0.0076779167760502205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1932034194469452,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02779894508421421,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08276901145776112,
      "backward_entropy": 0.0065122571858492765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1733696162700653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027808768674731255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08268011609713237,
      "backward_entropy": 0.0075859522277658634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22319072484970093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781834825873375,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08259110152721405,
      "backward_entropy": 0.006448918445543809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1941646933555603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02782798931002617,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08249971767266591,
      "backward_entropy": 0.007496175440874967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14969149231910706,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02783745899796486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08240669965744019,
      "backward_entropy": 0.006386382335966284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14747276902198792,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02784654311835766,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08231401940186818,
      "backward_entropy": 0.006356946446678855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15155953168869019,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02785523794591427,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0822214384873708,
      "backward_entropy": 0.006328976289792495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1567947268486023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027863703668117523,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08212890724341075,
      "backward_entropy": 0.007328384979204698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1680610030889511,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027872059494256973,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08203621208667755,
      "backward_entropy": 0.006337220018560236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1279400736093521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027880307286977768,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08194281160831451,
      "backward_entropy": 0.007250023836439306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1360999494791031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027888260781764984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08185048898061116,
      "backward_entropy": 0.007212397049773823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11326812952756882,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02789599448442459,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08175832033157349,
      "backward_entropy": 0.007175745611841028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1477152556180954,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027903348207473755,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08166712025801341,
      "backward_entropy": 0.006271517412229018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1421968787908554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02791067585349083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08157518009344737,
      "backward_entropy": 0.007105911319906061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1604260802268982,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02791798859834671,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08148278295993805,
      "backward_entropy": 0.0061328194358132105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14840541779994965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027925364673137665,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08138882120450337,
      "backward_entropy": 0.006110058589415116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09925051778554916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027932893484830856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08129444718360901,
      "backward_entropy": 0.007000528275966644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14132727682590485,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027939999476075172,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0812012751897176,
      "backward_entropy": 0.006064925004135479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13573554158210754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02794722653925419,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08110729853312175,
      "backward_entropy": 0.006932595914060419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11682069301605225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027954567223787308,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08101284007231395,
      "backward_entropy": 0.006020557474006306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09751764684915543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027961837127804756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08091870943705241,
      "backward_entropy": 0.006863881241191517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08241637796163559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027968712151050568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08082520961761475,
      "backward_entropy": 0.006831403483044018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1257094442844391,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027975047007203102,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08073282241821289,
      "backward_entropy": 0.006801188669421456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11534542590379715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027981430292129517,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0806392381588618,
      "backward_entropy": 0.006770923056385734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09709194302558899,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027987943962216377,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08054571847120921,
      "backward_entropy": 0.006740047850392081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10159517824649811,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027994276955723763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08045272032419841,
      "backward_entropy": 0.00670988451350819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11151700466871262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0280004870146513,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08035955826441447,
      "backward_entropy": 0.006680373441089283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07269218564033508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028006697073578835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08026547233263652,
      "backward_entropy": 0.0066508847204121676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10124024003744125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028012339025735855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0801720917224884,
      "backward_entropy": 0.005849486724896865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1081894263625145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02801806665956974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08007813493410747,
      "backward_entropy": 0.006596271964636716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06069603189826012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028023850172758102,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07998281220595042,
      "backward_entropy": 0.005816004493019797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08618796616792679,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02802903763949871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07988897959391277,
      "backward_entropy": 0.006543512371453372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06590397655963898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028034262359142303,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07979559898376465,
      "backward_entropy": 0.006518139080567794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09010648727416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028039224445819855,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07970362901687622,
      "backward_entropy": 0.005999391051855954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06203938275575638,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028044356033205986,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07961134612560272,
      "backward_entropy": 0.005757154388861222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07512570917606354,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028049083426594734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.079519917567571,
      "backward_entropy": 0.005743876099586487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06875374168157578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02805386483669281,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07942897081375122,
      "backward_entropy": 0.005730547688224099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07557269930839539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0280584879219532,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0793383667866389,
      "backward_entropy": 0.00640025328506123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05427911505103111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02806307189166546,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0792474349339803,
      "backward_entropy": 0.00570506670258262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05259557440876961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028067298233509064,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0791576753060023,
      "backward_entropy": 0.005693501369519668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07511591166257858,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028071321547031403,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07906944553057353,
      "backward_entropy": 0.005682651969519528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05981725826859474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028075475245714188,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07898069421450298,
      "backward_entropy": 0.0063164247707887125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05156970024108887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028079601004719734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07889275252819061,
      "backward_entropy": 0.006296071816574444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041960690170526505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028083454817533493,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07880554596583049,
      "backward_entropy": 0.00627684390003031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06691887229681015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02808697149157524,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0787198394536972,
      "backward_entropy": 0.005640082399953495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05667697638273239,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02809073217213154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07863377531369527,
      "backward_entropy": 0.006240274418484081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05700862035155296,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028094515204429626,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07854797442754109,
      "backward_entropy": 0.005620029162276875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04158822447061539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02809838019311428,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07846242189407349,
      "backward_entropy": 0.005902122367512096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06194816157221794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02810192108154297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07837785283724467,
      "backward_entropy": 0.0061848062005910006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038793452084064484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028105812147259712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07829315463701884,
      "backward_entropy": 0.006165847859599374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050771910697221756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02810947597026825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07820986211299896,
      "backward_entropy": 0.006147945469075983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0412258580327034,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02811318449676037,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07812659939130147,
      "backward_entropy": 0.005876372483643619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04427015036344528,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028116777539253235,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07804364959398906,
      "backward_entropy": 0.006112279539758509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04240601882338524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02812027372419834,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07796077926953633,
      "backward_entropy": 0.005863724107092077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.043141596019268036,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028123779222369194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07787852982680003,
      "backward_entropy": 0.005543252622539347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04281514883041382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028127335011959076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0777966280778249,
      "backward_entropy": 0.006060448559847745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03827867656946182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813081257045269,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07771454254786174,
      "backward_entropy": 0.006043467332016338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03689763322472572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813427709043026,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07763317227363586,
      "backward_entropy": 0.006026632406494834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03812980279326439,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028137635439634323,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07755220929781596,
      "backward_entropy": 0.00601024248383262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028022846207022667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814101055264473,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07747167348861694,
      "backward_entropy": 0.005993851206519387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040063243359327316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814415656030178,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07739244898160298,
      "backward_entropy": 0.005978717722676017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027325838804244995,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814747579395771,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731378575166066,
      "backward_entropy": 0.005962717262181369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036322757601737976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028150539845228195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07723636428515117,
      "backward_entropy": 0.00594753162427382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030893424525856972,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02815362624824047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07715917627016704,
      "backward_entropy": 0.005932168527082963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02652760036289692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028156738728284836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07708273828029633,
      "backward_entropy": 0.005917028269984506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029385371133685112,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028159715235233307,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0770072340965271,
      "backward_entropy": 0.00579029998996041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02572435326874256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028162624686956406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07693205277125041,
      "backward_entropy": 0.005888204682957043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029913432896137238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028165383264422417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07685751219590505,
      "backward_entropy": 0.0054356652227315035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02472573332488537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028168167918920517,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07678308089574178,
      "backward_entropy": 0.005428594621745023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022908566519618034,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028170855715870857,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07670947909355164,
      "backward_entropy": 0.005421779711138119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020777154713869095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02817334048449993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07663652797540028,
      "backward_entropy": 0.005835075947371396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023728761821985245,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02817567065358162,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656466960906982,
      "backward_entropy": 0.005823140117255124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017334960401058197,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028177963569760323,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07649335265159607,
      "backward_entropy": 0.005404021590948105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02368926629424095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02817991003394127,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07642285525798798,
      "backward_entropy": 0.005800921808589588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01939571090042591,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028181934729218483,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.076352725426356,
      "backward_entropy": 0.005790241739966653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016697309911251068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028183868154883385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07628336548805237,
      "backward_entropy": 0.005779985677112232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017907556146383286,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028185587376356125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07621509333451588,
      "backward_entropy": 0.005385915664109317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022124845534563065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028187187388539314,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07614767551422119,
      "backward_entropy": 0.005761522461067547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01734643429517746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028188899159431458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07608069976170857,
      "backward_entropy": 0.005752074447545138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018635164946317673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02819047123193741,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07601411143938701,
      "backward_entropy": 0.005743212997913361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016403697431087494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02819209173321724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07594802975654602,
      "backward_entropy": 0.005734220824458383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014000301249325275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028193684294819832,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07588272293408711,
      "backward_entropy": 0.005747049369595267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011893256567418575,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028195194900035858,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07581851383050282,
      "backward_entropy": 0.005362983454357494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014550925232470036,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028196515515446663,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07575546701749165,
      "backward_entropy": 0.005745899270881306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016517329961061478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02819778583943844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07569310069084167,
      "backward_entropy": 0.0057017823511903935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013804223388433456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028199248015880585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07563150922457378,
      "backward_entropy": 0.005693600936369462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010759345255792141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02820073999464512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07557087143262227,
      "backward_entropy": 0.005685339597138492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01254267804324627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028202135115861893,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07551154494285583,
      "backward_entropy": 0.005677525970068845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012953100726008415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02820347063243389,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0754527747631073,
      "backward_entropy": 0.005669986998493021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013357849791646004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028204869478940964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07539472977320354,
      "backward_entropy": 0.005662278018214486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011338510550558567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028206292539834976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07533699770768483,
      "backward_entropy": 0.005654596469619058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009318919852375984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028207695111632347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07528017958005269,
      "backward_entropy": 0.0056469579311934385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010124036110937595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02820899337530136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07522452871004741,
      "backward_entropy": 0.005330734632231973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008202903904020786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028210293501615524,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07517002026240031,
      "backward_entropy": 0.005632542751052163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0097538772970438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028211424127221107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07511639595031738,
      "backward_entropy": 0.00562602010640231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010152246803045273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02821255661547184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07506350676218669,
      "backward_entropy": 0.005619508298960599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009119857102632523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028213748708367348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07501128812630971,
      "backward_entropy": 0.005612780086018823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010393342934548855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028215019032359123,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07496013243993123,
      "backward_entropy": 0.005316536534916271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009250394068658352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028216417878866196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07490945359071095,
      "backward_entropy": 0.0055985684421929445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007214002311229706,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028217792510986328,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07485908269882202,
      "backward_entropy": 0.0053095228292725305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007704270537942648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028219131752848625,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07480976978937785,
      "backward_entropy": 0.005726934833960099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007858031429350376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028220485895872116,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07476132611433665,
      "backward_entropy": 0.005577378313649784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006935732904821634,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02822178788483143,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0747132549683253,
      "backward_entropy": 0.005570570176297968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0077301389537751675,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028223032131791115,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07466586927572887,
      "backward_entropy": 0.005721712654287165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005627235397696495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028224250301718712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0746189256509145,
      "backward_entropy": 0.005557625469836322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005957106128334999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028225379064679146,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07457338770230611,
      "backward_entropy": 0.005551546812057495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006029883399605751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02822643704712391,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07452866435050964,
      "backward_entropy": 0.005545778369361704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005874835420399904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02822745218873024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07448455691337585,
      "backward_entropy": 0.0055401623249053955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005285363178700209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028228459879755974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07444113989671071,
      "backward_entropy": 0.005534578453410755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004239254165440798,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028229407966136932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07439842323462169,
      "backward_entropy": 0.0055292099714279175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005669216625392437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028230279684066772,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07435675462086995,
      "backward_entropy": 0.005278450521555814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004775305278599262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028231164440512657,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07431551814079285,
      "backward_entropy": 0.0052761811424385414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003934040199965239,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028231997042894363,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07427488764127095,
      "backward_entropy": 0.005714594640515067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004323752596974373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028232721611857414,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07423495252927144,
      "backward_entropy": 0.005714611573652787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004153161775320768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028233416378498077,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07419564326604207,
      "backward_entropy": 0.005714682015505704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004441358149051666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02823408506810665,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07415696481863658,
      "backward_entropy": 0.005268854851072485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004340629559010267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028234796598553658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07411890228589375,
      "backward_entropy": 0.005497006530111486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034198788926005363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0282355435192585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07408152023951213,
      "backward_entropy": 0.005492637780579654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003934319131076336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028236277401447296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07404510180155437,
      "backward_entropy": 0.005488338795575229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036058423575013876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02823701687157154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07400915026664734,
      "backward_entropy": 0.005484097044576298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003466045018285513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02823777310550213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0739738941192627,
      "backward_entropy": 0.005479810251431031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038204221054911613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02823854424059391,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07393933335940044,
      "backward_entropy": 0.005475481125441464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036965482868254185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028239378705620766,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07390530407428741,
      "backward_entropy": 0.0052553174847906284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002925523556768894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02824023738503456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07387165228525798,
      "backward_entropy": 0.005466306751424616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034975935705006123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028241051360964775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07383854190508525,
      "backward_entropy": 0.005461931905963204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028006669599562883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02824193798005581,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07380624612172444,
      "backward_entropy": 0.00570824606852098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036870737094432116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028242792934179306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07377447684605916,
      "backward_entropy": 0.005452813072638078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027360962703824043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02824377827346325,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07374310493469238,
      "backward_entropy": 0.00524309209801934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002403987804427743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028244759887456894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07371227443218231,
      "backward_entropy": 0.005443063987927003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026937290094792843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028245678171515465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07368189096450806,
      "backward_entropy": 0.005438465963710438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021182866767048836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028246628120541573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07365203897158305,
      "backward_entropy": 0.005433805286884308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024489713832736015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028247548267245293,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07362296183904012,
      "backward_entropy": 0.005429299717599695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025037494488060474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02824847213923931,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07359432180722554,
      "backward_entropy": 0.005424780940467661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002008712850511074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028249429538846016,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07356613874435425,
      "backward_entropy": 0.005420162257823077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019965539686381817,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028250383213162422,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0735387106736501,
      "backward_entropy": 0.005693288011984391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017263564513996243,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028251299634575844,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07351166009902954,
      "backward_entropy": 0.0056915052912452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002058562124148011,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02825217694044113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07348516583442688,
      "backward_entropy": 0.00540693307464773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016321883304044604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028253082185983658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07345908880233765,
      "backward_entropy": 0.0054026147858663035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018250757129862905,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028253940865397453,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07343344887097676,
      "backward_entropy": 0.0052148574455217886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015719577204436064,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028254829347133636,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07340831061204274,
      "backward_entropy": 0.005212423476305875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001327215926721692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028255680575966835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07338358461856842,
      "backward_entropy": 0.005390258675271814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001202314393594861,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028256477788090706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.073359414935112,
      "backward_entropy": 0.005386447703296488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015344423009082675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028257252648472786,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07333600521087646,
      "backward_entropy": 0.005382712591778149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016605251003056765,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028258033096790314,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07331299781799316,
      "backward_entropy": 0.005677924914793534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001478972495533526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028258847072720528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07329017917315166,
      "backward_entropy": 0.005375157025727359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001448808703571558,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028259683400392532,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07326769828796387,
      "backward_entropy": 0.0056743377988988705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010681081330403686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028260530903935432,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0732455054918925,
      "backward_entropy": 0.005367356945167889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010522960219532251,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028261326253414154,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0732237199942271,
      "backward_entropy": 0.0056707164780660105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011139773996546865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02826208434998989,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07320236166318257,
      "backward_entropy": 0.00519247827204791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007610616157762706,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02826284058392048,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0731813907623291,
      "backward_entropy": 0.005190413106571545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008786203688941896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028263511136174202,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07316089669863383,
      "backward_entropy": 0.005353397943756797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008890689932741225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028264155611395836,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07314087450504303,
      "backward_entropy": 0.005186907947063446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009352636407129467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028264770284295082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07312121490637462,
      "backward_entropy": 0.005347341637719761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007193478522822261,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02826538495719433,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0731019675731659,
      "backward_entropy": 0.005662356926636262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009423415758647025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028265956789255142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07308316230773926,
      "backward_entropy": 0.005341553552584214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008103079744614661,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02826651558279991,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07306445638338725,
      "backward_entropy": 0.005180602385239167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007185945869423449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02826707623898983,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07304615279038747,
      "backward_entropy": 0.00565919889645143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006275844643823802,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02826760709285736,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07302815715471904,
      "backward_entropy": 0.00565825572068041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008193511166609824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028268106281757355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07301052411397298,
      "backward_entropy": 0.0053309750827876005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005853998591192067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02826864831149578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07299318412939708,
      "backward_entropy": 0.0053283453664996405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000571348937228322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028269164264202118,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07297629117965698,
      "backward_entropy": 0.005325817926363511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006539433379657567,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02826966717839241,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07295980056126912,
      "backward_entropy": 0.005654406479813836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005987148033455014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827017940580845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07294355829556783,
      "backward_entropy": 0.005320875482125716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048295751912519336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028270693495869637,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07292758425076802,
      "backward_entropy": 0.005318400534716519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004892789875157177,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028271161019802094,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07291187345981598,
      "backward_entropy": 0.005168164318258112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043550136615522206,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028271619230508804,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07289652029673259,
      "backward_entropy": 0.005650585009293122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00045629229862242937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827206440269947,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07288154462973277,
      "backward_entropy": 0.005311664532531391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004676721873693168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827247977256775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07286680738131206,
      "backward_entropy": 0.005309577015313235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043800429557450116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827288769185543,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07285235325495402,
      "backward_entropy": 0.005307524041696029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003651871520560235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827328070998192,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07283809781074524,
      "backward_entropy": 0.0053055388006297026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004208690661471337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827366255223751,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07282416025797527,
      "backward_entropy": 0.005303638225251978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003133455466013402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028274059295654297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07281053562959035,
      "backward_entropy": 0.005301670594648881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031053696875460446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827444300055504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07279730836550395,
      "backward_entropy": 0.005299749699505893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039226075750775635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028274821117520332,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0727844089269638,
      "backward_entropy": 0.005644753236662258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003099203750025481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827521786093712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07277168830235799,
      "backward_entropy": 0.005295982415025885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026159730623476207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028275584802031517,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07275915145874023,
      "backward_entropy": 0.005294187841090289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026576564414426684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827593684196472,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0727469523747762,
      "backward_entropy": 0.005292450501160188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018911578808911145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827627770602703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07273502151171367,
      "backward_entropy": 0.005290760912678458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002528125187382102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827656827867031,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.072723388671875,
      "backward_entropy": 0.005289246412840756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002497847890481353,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028276830911636353,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07271189490954082,
      "backward_entropy": 0.005641091614961624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022487797832582146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028277110308408737,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0727007786432902,
      "backward_entropy": 0.005152532322840257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023343527573160827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028277387842535973,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07268994053204854,
      "backward_entropy": 0.00528497655283321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020281437900848687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827766351401806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07267928123474121,
      "backward_entropy": 0.005283554169264707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018320619710721076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028277935460209846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07266884545485179,
      "backward_entropy": 0.005282172763889486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019370413792785257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028278188779950142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07265860835711162,
      "backward_entropy": 0.005280846221880479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001787192013580352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827843651175499,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07264856497446696,
      "backward_entropy": 0.005279563367366791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016387549112550914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02827868051826954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07263871530691783,
      "backward_entropy": 0.005278289656747471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016153251635842025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028278915211558342,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07262906928857167,
      "backward_entropy": 0.0056377070193940945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001461105712223798,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028279149904847145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07261964678764343,
      "backward_entropy": 0.005275845527648926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001301355951000005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02827935665845871,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07261036833127339,
      "backward_entropy": 0.005637041885744442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011966593592660502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02827954664826393,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.072601318359375,
      "backward_entropy": 0.005636822770942341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001262137375306338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028279731050133705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07259254157543182,
      "backward_entropy": 0.00527270951054313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014073406055103987,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028279900550842285,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07258395353953044,
      "backward_entropy": 0.005636428228833459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011397543858038262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028280068188905716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07257551451524098,
      "backward_entropy": 0.005270792679353194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.691459126770496e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028280222788453102,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0725672443707784,
      "backward_entropy": 0.005636145784096284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012408808106556535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828037366271019,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07255922754605611,
      "backward_entropy": 0.005269006233323704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.787715680431575e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828053943812847,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07255136966705322,
      "backward_entropy": 0.005635832859711213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.976432920666412e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828068472445011,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07254364093144734,
      "backward_entropy": 0.005635731938210401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.083982149604708e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028280803933739662,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07253600160280864,
      "backward_entropy": 0.005266489969058471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.59266656334512e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028280921280384064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07252852618694305,
      "backward_entropy": 0.0052657540548931465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.322227560915053e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028281044214963913,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07252124448617299,
      "backward_entropy": 0.005142694847150283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.752407691441476e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028281159698963165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07251404722531636,
      "backward_entropy": 0.0052642937410961495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.105026063276455e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828126959502697,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07250702381134033,
      "backward_entropy": 0.005263600159775127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.937774014659226e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028281377628445625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07250014940897624,
      "backward_entropy": 0.005262926898219369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8891742810374126e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828148752450943,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07249346375465393,
      "backward_entropy": 0.005262241444804452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.223024684004486e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028281591832637787,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0724869817495346,
      "backward_entropy": 0.005635696378621188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.098550511524081e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028281698003411293,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07248066862424214,
      "backward_entropy": 0.005260968750173395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.990715751773678e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028281807899475098,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07247451941172282,
      "backward_entropy": 0.005260317501696673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.291857087286189e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028281914070248604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07246854901313782,
      "backward_entropy": 0.005259688266298987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1861054089386016e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828201837837696,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07246274252732594,
      "backward_entropy": 0.005259078673341058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.42794625996612e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028282122686505318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07245706518491109,
      "backward_entropy": 0.005258461291139776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.648702815757133e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828221395611763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07245153188705444,
      "backward_entropy": 0.005257895385677164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3113130232086405e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028282305225729942,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07244610786437988,
      "backward_entropy": 0.005139462988484989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.171570617472753e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028282374143600464,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07244076331456502,
      "backward_entropy": 0.00563555278561332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1275441870093346e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028282443061470985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07243552803993225,
      "backward_entropy": 0.005139101635326038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.999477485194802e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828250080347061,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07243045667807262,
      "backward_entropy": 0.005255988714369861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9099526727804914e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028282562270760536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07242550452550252,
      "backward_entropy": 0.005138811062682758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3480293495813385e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028282616287469864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07242071131865184,
      "backward_entropy": 0.005255161022598093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0491115467157215e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828267030417919,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07241604725519817,
      "backward_entropy": 0.005138544873757796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5720759367686696e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828272245824337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07241148749987285,
      "backward_entropy": 0.0051384087313305245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.400115226919297e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828277461230755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07240708669026692,
      "backward_entropy": 0.0051382800394838505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.55685572483344e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828281745314598,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07240278522173564,
      "backward_entropy": 0.005253662439909848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8888052838738076e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028282854706048965,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07239859302838643,
      "backward_entropy": 0.005636426535519687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9827652067760937e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828289195895195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07239445050557454,
      "backward_entropy": 0.005253030156547373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.160040457965806e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028282931074500084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07239045699437459,
      "backward_entropy": 0.00525271012024446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7096486772061326e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828296832740307,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07238656282424927,
      "backward_entropy": 0.005636797032573007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.768586844264064e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028282999992370605,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0723827878634135,
      "backward_entropy": 0.005636913193897767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0608746126526967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828303538262844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0723791519800822,
      "backward_entropy": 0.005137622695077549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5292647731257603e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283072635531425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07237560550371806,
      "backward_entropy": 0.00525155866687948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.847316525527276e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828310802578926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07237216830253601,
      "backward_entropy": 0.005251292139291763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7479555026511662e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028283145278692245,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07236881057421367,
      "backward_entropy": 0.005137324671853672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.562462239235174e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828318439424038,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07236551741758983,
      "backward_entropy": 0.005137202414599332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.344810334558133e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828322723507881,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0723623236020406,
      "backward_entropy": 0.005137085914611816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4232079593057279e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283266350626945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07235921422640483,
      "backward_entropy": 0.00525015728040175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4536338312609587e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283309191465378,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07235617935657501,
      "backward_entropy": 0.005249869417060505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0357805876992643e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283359482884407,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0723532388607661,
      "backward_entropy": 0.005249562588605014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1426329365349375e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283411636948586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07235041757424672,
      "backward_entropy": 0.005249263210730119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1109588740509935e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028283467516303062,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07234769066174825,
      "backward_entropy": 0.005637504499066959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1682128388201818e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828352525830269,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07234504818916321,
      "backward_entropy": 0.005248633975332434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0915868188021705e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028283588588237762,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07234248518943787,
      "backward_entropy": 0.005637385628440164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0116849807673134e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283653780817986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07233997186024983,
      "backward_entropy": 0.00524796410040422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.546945537091233e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828371897339821,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07233751316865285,
      "backward_entropy": 0.005247635597532446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.544201253040228e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283780440688133,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07233513394991557,
      "backward_entropy": 0.005247323011810129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145781976054423e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283841907978058,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07233281930287679,
      "backward_entropy": 0.005247003652832725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.196191629394889e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828390710055828,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07233058412869771,
      "backward_entropy": 0.0052466809072277765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.499977189378114e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283970430493355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07232838869094849,
      "backward_entropy": 0.005246375433423303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.635282832372468e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828403189778328,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07232626279195149,
      "backward_entropy": 0.005636818029663779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.794217370043043e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284091502428055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07232420643170674,
      "backward_entropy": 0.005245784805579619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4736979109293316e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828415110707283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07232220967610677,
      "backward_entropy": 0.005245492200959812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.514037638931768e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028284210711717606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0723202923933665,
      "backward_entropy": 0.005134111778302627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.765667992818635e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828427031636238,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0723184198141098,
      "backward_entropy": 0.005244914780963551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.049575520388316e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284331783652306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07231660187244415,
      "backward_entropy": 0.0052446245469830255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.78949641546933e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828439511358738,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.072314848502477,
      "backward_entropy": 0.0052443255077708854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.385560714581516e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284456580877304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07231312990188599,
      "backward_entropy": 0.005244044079021974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.324564431750332e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828451432287693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07231144110361735,
      "backward_entropy": 0.005243765698237853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.113071443294757e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284570202231407,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07230982681115468,
      "backward_entropy": 0.005243510007858276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9384873414528556e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284620493650436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07230825225512187,
      "backward_entropy": 0.005243269218639894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.013297828147188e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284668922424316,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0723067323366801,
      "backward_entropy": 0.005243037234653126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1220063192449743e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028284715488553047,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07230526208877563,
      "backward_entropy": 0.0056356347419998865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2432485568278935e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828475832939148,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07230382164319356,
      "backward_entropy": 0.0052426074716177854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.606225962153985e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284801170229912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07230241596698761,
      "backward_entropy": 0.00524240258065137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4169842163246358e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284842148423195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07230105996131897,
      "backward_entropy": 0.005242200737649744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.35302923101699e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828487940132618,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07229972879091899,
      "backward_entropy": 0.005635387856851925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8426053429720923e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028284916654229164,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07229844729105632,
      "backward_entropy": 0.00513196126981215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4616881546535296e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828495390713215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07229721546173096,
      "backward_entropy": 0.005241646346720782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.099877519867732e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284989297389984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07229599853356679,
      "backward_entropy": 0.005241477015343579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7405601511200075e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828502468764782,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07229482134183247,
      "backward_entropy": 0.005241296169432727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6451123201477458e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285058215260506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07229367395242055,
      "backward_entropy": 0.0052411319179968404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.805564465939824e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285091742873192,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07229255636533101,
      "backward_entropy": 0.005240959538654847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7573760260347626e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285125270485878,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07229148348172505,
      "backward_entropy": 0.0051313117146492004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.422739160261699e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285158798098564,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07229044040044148,
      "backward_entropy": 0.005131208761171861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4240163181966636e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0282851904630661,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722894271214803,
      "backward_entropy": 0.0052404867654496975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4345133649840136e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285222128033638,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07228843371073405,
      "backward_entropy": 0.005240331996570934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2963730569026666e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285251930356026,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07228746016820271,
      "backward_entropy": 0.005130939524282108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1313115919620031e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285281732678413,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07228651146094005,
      "backward_entropy": 0.005634728480469097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.057411395777308e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285309672355652,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07228558262189229,
      "backward_entropy": 0.005239907652139664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0530521876717103e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285333886742592,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722846786181132,
      "backward_entropy": 0.00523978742686185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.796918677944632e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285356238484383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722837895154953,
      "backward_entropy": 0.005239678716117685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.62705712481693e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285378590226173,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07228293518225352,
      "backward_entropy": 0.005239557813514362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.04775197593699e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285400941967964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722821056842804,
      "backward_entropy": 0.005239451134746725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.744700608076528e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285421431064606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722812960545222,
      "backward_entropy": 0.005239347165281122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.099331125777098e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285440057516098,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07228050629297893,
      "backward_entropy": 0.005130362104285847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.503889610736223e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828546054661274,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0722797413667043,
      "backward_entropy": 0.005130290985107422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.589677923329873e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285477310419083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227899134159088,
      "backward_entropy": 0.0052390511740337715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.410502919607097e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285494074225426,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07227827608585358,
      "backward_entropy": 0.005634477192705328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.51086600353301e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828550897538662,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07227758566538493,
      "backward_entropy": 0.005634456534277309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.177652724341897e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285523876547813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227689027786255,
      "backward_entropy": 0.005238787017085336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.376992706056626e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285538777709007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227624456087749,
      "backward_entropy": 0.005238716236569665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3125769505204516e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285551816225052,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07227559884389241,
      "backward_entropy": 0.005130022086880424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.897818826066214e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285564854741096,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07227498789628346,
      "backward_entropy": 0.005129983479326422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.05520233673451e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285576030611992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722744067509969,
      "backward_entropy": 0.005238499831069599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.729045599560777e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285587206482887,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07227381070454915,
      "backward_entropy": 0.005129922858693383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.77933304207545e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285598382353783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227323452631633,
      "backward_entropy": 0.005238386040384119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.528926981744007e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828560769557953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227267324924469,
      "backward_entropy": 0.005238330838355151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2439174901810475e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285615146160126,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227212190628052,
      "backward_entropy": 0.005238279022953727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.599067781578924e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285622596740723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.072271595398585,
      "backward_entropy": 0.005238216709006916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0382426530195517e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828563004732132,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227107882499695,
      "backward_entropy": 0.005238167941570282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.162053587857372e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285637497901917,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07227058211962382,
      "backward_entropy": 0.005238119512796402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1928283899796952e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285644948482513,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07227008044719696,
      "backward_entropy": 0.005634456534277309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.198945452391854e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828565239906311,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07226960857709248,
      "backward_entropy": 0.005634461614218625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0664310795837082e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285657986998558,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226914167404175,
      "backward_entropy": 0.0052379925142635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.393533691247285e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285663574934006,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07226870954036713,
      "backward_entropy": 0.005634488029913468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.427645426905656e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285671025514603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722682774066925,
      "backward_entropy": 0.005237906493923881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8720456296250632e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828567661345005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226785024007161,
      "backward_entropy": 0.0052378658543933525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5467254854684143e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285682201385498,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226744294166565,
      "backward_entropy": 0.005237840116024017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.060660335700959e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285687789320946,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226704557736714,
      "backward_entropy": 0.0051296102729710665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2046874076077074e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285693377256393,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0722666581471761,
      "backward_entropy": 0.005634525282816453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3976709567486978e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828569896519184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722662905852,
      "backward_entropy": 0.005237719552083449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.347436722198836e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828570455312729,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722659428914388,
      "backward_entropy": 0.005237677219239148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.344989470908331e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285710141062737,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226559519767761,
      "backward_entropy": 0.005237649787556042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3403179366378026e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285715728998184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226526240507762,
      "backward_entropy": 0.005237612534653057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3695627387733111e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285721316933632,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226493954658508,
      "backward_entropy": 0.005237574604424563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2155351214460097e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828572690486908,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07226462165514629,
      "backward_entropy": 0.00563453882932663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.467641521292535e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285730630159378,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226430873076121,
      "backward_entropy": 0.00512946600263769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0607297440401453e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285734355449677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226399580637614,
      "backward_entropy": 0.0052374865521084175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.528955047244381e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285738080739975,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226370771725972,
      "backward_entropy": 0.005129445682872425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.220879348958988e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285741806030273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226342956225078,
      "backward_entropy": 0.005129436200315302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.892280962096265e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285745531320572,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226315140724182,
      "backward_entropy": 0.005129428072409196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.044032284715286e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828574925661087,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07226287325223286,
      "backward_entropy": 0.005634589967402545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.433904076175168e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828575298190117,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226260999838512,
      "backward_entropy": 0.005129398947412317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.785346329252206e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285756707191467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226236164569855,
      "backward_entropy": 0.005237358537587253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.306700583991187e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285758569836617,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226211329301198,
      "backward_entropy": 0.005129383368925614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.859446889327046e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285760432481766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226187487443288,
      "backward_entropy": 0.005237313156778162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.450009865626271e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285764157772064,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07226164142290752,
      "backward_entropy": 0.005634634332223372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2375639825186227e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285766020417213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226142287254333,
      "backward_entropy": 0.005237272517247634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.862831204377471e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285767883062363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226121425628662,
      "backward_entropy": 0.0052372610027139836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.539740316999996e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285769745707512,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226099570592244,
      "backward_entropy": 0.005129335278814489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.217367077785639e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828577160835266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722607970237732,
      "backward_entropy": 0.005237225443124771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.071563625667295e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828577347099781,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226060330867767,
      "backward_entropy": 0.005237200720743699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.262434233874956e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828577533364296,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07226041952768962,
      "backward_entropy": 0.005634685808962042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5079701870822646e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828577719628811,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07226023077964783,
      "backward_entropy": 0.005237174982374365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0669567390996235e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285779058933258,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07226006189982097,
      "backward_entropy": 0.005129290236668153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2592899995288462e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285780921578407,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225989798704784,
      "backward_entropy": 0.005237144502726468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9871094991685823e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285782784223557,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07225974400838216,
      "backward_entropy": 0.005634699355472218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.276925314959044e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285784646868706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225959499677022,
      "backward_entropy": 0.005237116732380607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.068912863251171e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028285786509513855,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07225945591926575,
      "backward_entropy": 0.005634715272621675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.659697979050634e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285788372159004,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225931684176128,
      "backward_entropy": 0.005129243501208045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8295395420864224e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285790234804153,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225918769836426,
      "backward_entropy": 0.005129236050627448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9140186324762e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285792097449303,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225905855496724,
      "backward_entropy": 0.00523704933849248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5902287486824207e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285793960094452,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225893934567769,
      "backward_entropy": 0.005129209973595359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6087700061007126e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828579768538475,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225882510344188,
      "backward_entropy": 0.005129201845689254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2299783413993737e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0282857995480299,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225871086120605,
      "backward_entropy": 0.0052370022643696175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3990376857009323e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828580141067505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225860158602397,
      "backward_entropy": 0.005129186267202551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1342734751451644e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285803273320198,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225849231084187,
      "backward_entropy": 0.005129167979413813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0966706653903202e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285805135965347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225838303565979,
      "backward_entropy": 0.0052369704300707035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.979197024279074e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028285806998610497,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07225829362869263,
      "backward_entropy": 0.0051291554488919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.960626018961193e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285808861255646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.072258194287618,
      "backward_entropy": 0.005236941305073825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.90936746600346e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285810723900795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225810984770457,
      "backward_entropy": 0.005236931483853947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.51052925302065e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285812586545944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225802540779114,
      "backward_entropy": 0.0052369220012968235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4910354303247e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285814449191093,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225793600082397,
      "backward_entropy": 0.005236902020194314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.465338404064823e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285816311836243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225785652796428,
      "backward_entropy": 0.005236892198974436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.897348387406964e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285818174481392,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225777208805084,
      "backward_entropy": 0.005236882716417313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.300751920207404e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828582003712654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0722577025492986,
      "backward_entropy": 0.005236876281824979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.103334726503817e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828582189977169,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225762804349263,
      "backward_entropy": 0.005236859348687259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.641847795028298e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828582376241684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225755353768666,
      "backward_entropy": 0.0052368498661301355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9531188867367746e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02828582562506199,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225748896598816,
      "backward_entropy": 0.0052368417382240295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4661910553477355e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028285827487707138,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07225742439428966,
      "backward_entropy": 0.00523683564229445,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.448789985074143e-07,
    "avg_log_Z": 0.028285563997924326,
    "success_rate": 1.0,
    "avg_reward": 48.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.25,
      "2": 0.6
    },
    "avg_forward_entropy": 0.07227151677012443,
    "avg_backward_entropy": 0.005270746892148797,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}