{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13641315698623657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13745287656784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.054956436157227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290966749191284,
      "backward_entropy": 0.13722729682922363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.051630973815918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291056156158447,
      "backward_entropy": 0.13742401599884033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.048274993896484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019999963114969432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182911217212677,
      "backward_entropy": 0.136323881149292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.163291931152344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0002999986754730344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291167418162027,
      "backward_entropy": 0.13736519813537598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.908379554748535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00040003383764997125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291246891021729,
      "backward_entropy": 0.13733508586883544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.904152870178223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005002694088034332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291356166203818,
      "backward_entropy": 0.13618582487106323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.271637916564941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006006340845488012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829151709874471,
      "backward_entropy": 0.13613859415054322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.386492729187012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007009174441918731,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291745583216348,
      "backward_entropy": 0.13608977794647217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.638110637664795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008011856116354465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292051553726196,
      "backward_entropy": 0.1360398769378662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.12527847290039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009011963265947998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182923952738444,
      "backward_entropy": 0.13598880767822266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.375539779663086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010011864360421896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292818466822305,
      "backward_entropy": 0.13593676090240478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.353195190429688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011012341128662229,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293271462122598,
      "backward_entropy": 0.13588390350341797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485164642333984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012013509403914213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293797969818115,
      "backward_entropy": 0.1370794177055359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.597844123840332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013015475124120712,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294348319371542,
      "backward_entropy": 0.13704544305801392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.243552207946777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014018580550327897,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18294926484425864,
      "backward_entropy": 0.13572025299072266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.472395896911621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001502102822996676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18295466899871826,
      "backward_entropy": 0.13566441535949708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.699819564819336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016023981152102351,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829601526260376,
      "backward_entropy": 0.13694076538085936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.201189041137695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017028397414833307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829659342765808,
      "backward_entropy": 0.13690669536590577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827584266662598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018035623943433166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297165632247925,
      "backward_entropy": 0.13549227714538575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.684212684631348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019043829524889588,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297733863194784,
      "backward_entropy": 0.13543378114700316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.678848266601562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020052529871463776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298312028249106,
      "backward_entropy": 0.1368013858795166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673394203186035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00210616085678339,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298896153767905,
      "backward_entropy": 0.1365433931350708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.467156410217285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022070971317589283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299480279286703,
      "backward_entropy": 0.13672869205474852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.915610313415527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002307915361598134,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299990892410278,
      "backward_entropy": 0.13519363403320311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.27588939666748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024088562931865454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830049753189087,
      "backward_entropy": 0.13665399551391602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.286130905151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002510043326765299,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300998210906982,
      "backward_entropy": 0.13638923168182374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.757723808288574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00261105177924037,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301494916280112,
      "backward_entropy": 0.13634908199310303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.164331436157227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002712109824642539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301997582117716,
      "backward_entropy": 0.13653829097747802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.28303050994873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00281293666921556,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830245852470398,
      "backward_entropy": 0.13626656532287598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.771618843078613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029139933176338673,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302857875823975,
      "backward_entropy": 0.13622435331344604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.888792991638184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003015057882294059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303235371907553,
      "backward_entropy": 0.13641905784606934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.596609115600586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031165590044111013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830355922381083,
      "backward_entropy": 0.13468170166015625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.227676391601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032183630391955376,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830387314160665,
      "backward_entropy": 0.13609414100646972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.532327651977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003320271847769618,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304171164830527,
      "backward_entropy": 0.13604819774627686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.973109245300293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034219303634017706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304429451624551,
      "backward_entropy": 0.13447904586791992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27053165435791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0035239902790635824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830464998881022,
      "backward_entropy": 0.13440988063812256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.48221492767334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003625666256994009,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304844697316489,
      "backward_entropy": 0.13433892726898194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.037293910980225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037271222099661827,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830502152442932,
      "backward_entropy": 0.1358548402786255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.401322364807129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003827720182016492,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305200338363647,
      "backward_entropy": 0.1341928243637085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.504179000854492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003928139340132475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305341402689615,
      "backward_entropy": 0.13411831855773926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03374195098877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004028460942208767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305456638336182,
      "backward_entropy": 0.13404276371002197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.921618461608887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004128464963287115,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305538098017374,
      "backward_entropy": 0.13564541339874267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.093350410461426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004228667356073856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18305635452270508,
      "backward_entropy": 0.13589727878570557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.842665672302246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004328644834458828,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830574075380961,
      "backward_entropy": 0.13553473949432374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.83736515045166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004428736865520477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18305820226669312,
      "backward_entropy": 0.1357991337776184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.972874641418457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0045289285480976105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305877844492593,
      "backward_entropy": 0.1336461901664734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89156723022461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004628822673112154,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830593744913737,
      "backward_entropy": 0.13356192111968995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.858114719390869,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004728919826447964,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.183060089747111,
      "backward_entropy": 0.13530197143554687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.129801750183105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004828659817576408,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306068579355875,
      "backward_entropy": 0.13338840007781982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.057652473449707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004928724840283394,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830612818400065,
      "backward_entropy": 0.13517976999282838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.260470390319824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005028558894991875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306191762288412,
      "backward_entropy": 0.13320868015289306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.401066780090332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005128315184265375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306275208791098,
      "backward_entropy": 0.13311569690704345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.99713134765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005228044930845499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306354681650797,
      "backward_entropy": 0.13302114009857177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.784473419189453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005327593069523573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306454022725424,
      "backward_entropy": 0.13531570434570311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.149561882019043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0054268487729132175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306559324264526,
      "backward_entropy": 0.13282614946365356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12864875793457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005526995286345482,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306638797124228,
      "backward_entropy": 0.13478970527648926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.322548866271973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005627391394227743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.183066725730896,
      "backward_entropy": 0.13262546062469482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.411376953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005727688781917095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306722243626913,
      "backward_entropy": 0.1350792646408081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261801719665527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005827862769365311,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306734164555868,
      "backward_entropy": 0.13458598852157594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75093936920166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005928417667746544,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306734164555868,
      "backward_entropy": 0.1345160961151123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.693746566772461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006028988864272833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306692441304526,
      "backward_entropy": 0.13220505714416503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.387540817260742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0061295852065086365,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830663283665975,
      "backward_entropy": 0.13209574222564696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.530158519744873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006230009254068136,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830654740333557,
      "backward_entropy": 0.13429980278015136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.820897579193115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006329868920147419,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830646594365438,
      "backward_entropy": 0.13422505855560302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.813816070556641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006429417058825493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306406339009604,
      "backward_entropy": 0.1345996379852295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0141019821167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006528685800731182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306358655293783,
      "backward_entropy": 0.13452529907226562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.353604793548584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006627743132412434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306289116541544,
      "backward_entropy": 0.13444995880126953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.390751838684082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006726324558258057,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306243419647217,
      "backward_entropy": 0.1339111566543579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.32894229888916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0068250237964093685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18306187788645426,
      "backward_entropy": 0.13127955198287963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.491927146911621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006924299988895655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.183060884475708,
      "backward_entropy": 0.1342158794403076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.692332744598389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007023590616881847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305949370066324,
      "backward_entropy": 0.1310267686843872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.415248870849609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007121989503502846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18305842081705728,
      "backward_entropy": 0.13405368328094483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.910037517547607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007220033090561628,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305758635203043,
      "backward_entropy": 0.13346545696258544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.907611846923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007317997049540281,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305681149164835,
      "backward_entropy": 0.1333710789680481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.272181510925293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007416364271193743,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305552005767822,
      "backward_entropy": 0.1332756519317627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.957058906555176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007514864206314087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830542286237081,
      "backward_entropy": 0.13371553421020507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.63425350189209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007613698951900005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305236101150513,
      "backward_entropy": 0.13023009300231933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56125545501709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007712715771049261,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830502152442932,
      "backward_entropy": 0.13353710174560546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.679309844970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007811897434294224,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830479105313619,
      "backward_entropy": 0.13287751674652098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.795303344726562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007910730317234993,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304568529129028,
      "backward_entropy": 0.12980372905731202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6649169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008009863086044788,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304314215977988,
      "backward_entropy": 0.13266513347625733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.211878776550293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008108646608889103,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304069836934408,
      "backward_entropy": 0.1325541615486145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.741172790527344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008207973092794418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303783734639487,
      "backward_entropy": 0.1330610990524292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.598641395568848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008306984789669514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303505579630533,
      "backward_entropy": 0.12919812202453612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3833088874816895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008406204171478748,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303205569585165,
      "backward_entropy": 0.12903873920440673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.673171043395996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008504927158355713,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302927414576212,
      "backward_entropy": 0.1320828914642334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.249876022338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008604427799582481,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302579720815024,
      "backward_entropy": 0.13195956945419313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.035557270050049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00870443508028984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830218235651652,
      "backward_entropy": 0.13253387212753295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.192368507385254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008803722448647022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301832675933838,
      "backward_entropy": 0.1324223041534424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.536638259887695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008902918547391891,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301467100779215,
      "backward_entropy": 0.12820127010345458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.92332124710083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00900227390229702,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301073710123697,
      "backward_entropy": 0.1314433693885803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.765629768371582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009101399220526218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830068031946818,
      "backward_entropy": 0.13207902908325195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426153182983398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00920080579817295,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300249179204306,
      "backward_entropy": 0.13117135763168336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.981273651123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009300329722464085,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299790223439535,
      "backward_entropy": 0.13103172779083253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7198638916015625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009399651549756527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299329280853271,
      "backward_entropy": 0.13171608448028566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.633587837219238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009498663246631622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298874298731485,
      "backward_entropy": 0.1315913200378418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.116151809692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009597888216376305,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829837958017985,
      "backward_entropy": 0.13059786558151246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.272554397583008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009696993976831436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297882874806723,
      "backward_entropy": 0.13132967948913574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6770405769348145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009796055033802986,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18297376235326132,
      "backward_entropy": 0.13029630184173585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502778053283691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009894813410937786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18296881516774496,
      "backward_entropy": 0.13105580806732178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.739631652832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009993732906877995,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829635500907898,
      "backward_entropy": 0.12998406887054442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.397250175476074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010092361830174923,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829584836959839,
      "backward_entropy": 0.1298237681388855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.215240478515625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010191650129854679,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18295262257258096,
      "backward_entropy": 0.12556878328323365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.625367164611816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010291452519595623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829460859298706,
      "backward_entropy": 0.12534210681915284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.184930801391602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010390793904662132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829399267832438,
      "backward_entropy": 0.1251131534576416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.102650165557861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01049012504518032,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293344974517822,
      "backward_entropy": 0.12487354278564453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495214462280273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01058877818286419,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292754888534546,
      "backward_entropy": 0.12896170616149902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.891496658325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010687620379030704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829212506612142,
      "backward_entropy": 0.12437806129455567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.227447509765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010786865837872028,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291427691777548,
      "backward_entropy": 0.12412103414535522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.793425559997559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010885539464652538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829080581665039,
      "backward_entropy": 0.1238590955734253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.701613903045654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010984009131789207,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829018791516622,
      "backward_entropy": 0.1281665086746216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.608842372894287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011081716977059841,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182896355787913,
      "backward_entropy": 0.12332093715667725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.28464412689209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011179197579622269,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289105097452799,
      "backward_entropy": 0.12304635047912597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547147750854492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011275720782577991,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18288703759511313,
      "backward_entropy": 0.12752555608749389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.414488792419434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011372731067240238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18288207054138184,
      "backward_entropy": 0.12248635292053223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.535068035125732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011469458229839802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287758032480875,
      "backward_entropy": 0.12220135927200318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671555519104004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011566078290343285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287289142608643,
      "backward_entropy": 0.1219100832939148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.026426792144775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011663229204714298,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18286732832590738,
      "backward_entropy": 0.12661699056625367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.16231107711792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011759914457798004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828622817993164,
      "backward_entropy": 0.1277461528778076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.320284843444824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011856287717819214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285735448201498,
      "backward_entropy": 0.12100262641906738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.278956413269043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011952977627515793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285208940505981,
      "backward_entropy": 0.12069156169891357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.86234712600708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012049450539052486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828466256459554,
      "backward_entropy": 0.12037078142166138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.741682052612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012146007269620895,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18284094333648682,
      "backward_entropy": 0.12532405853271483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.253486633300781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012243135832250118,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18283438682556152,
      "backward_entropy": 0.1266148567199707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1958489418029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012340471148490906,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828276515007019,
      "backward_entropy": 0.12477771043777466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2196784019470215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01243736781179905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18282175064086914,
      "backward_entropy": 0.126118803024292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.16852331161499,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012533947825431824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828160285949707,
      "backward_entropy": 0.11866313219070435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.07732629776001,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012630267068743706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281006813049316,
      "backward_entropy": 0.11830049753189087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.133203983306885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01272628828883171,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280404806137085,
      "backward_entropy": 0.1253425121307373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.469139575958252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01282143872231245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279935916264853,
      "backward_entropy": 0.12507741451263427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.585761547088623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012916071340441704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279488881429037,
      "backward_entropy": 0.12480847835540772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.535373687744141,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013010879047214985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278974294662476,
      "backward_entropy": 0.12271814346313477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.473462104797363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013105754740536213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182784636815389,
      "backward_entropy": 0.12425276041030883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.881823539733887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01320070680230856,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277905384699503,
      "backward_entropy": 0.12207531929016113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.811907768249512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013295934535562992,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277273575464884,
      "backward_entropy": 0.1155316710472107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.453705310821533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01339196227490902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276468912760416,
      "backward_entropy": 0.12337239980697631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.450454235076904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013487890362739563,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827568213144938,
      "backward_entropy": 0.12106213569641114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.110939979553223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013583789579570293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274839719136557,
      "backward_entropy": 0.11422872543334961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279653549194336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013679462485015392,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18273971478144327,
      "backward_entropy": 0.12243485450744629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.062219142913818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01377562154084444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18272972106933594,
      "backward_entropy": 0.11331872940063477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.156714916229248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01387150026857853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18271954854329428,
      "backward_entropy": 0.11960475444793701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.260247707366943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013967150822281837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18270981311798096,
      "backward_entropy": 0.12143751382827758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.911980628967285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014062684960663319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18269975980122885,
      "backward_entropy": 0.12109408378601075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.959900379180908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014158405363559723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826902429262797,
      "backward_entropy": 0.11141932010650635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.685377597808838,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014253835193812847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826805273691813,
      "backward_entropy": 0.1109315276145935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.348963260650635,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014348851516842842,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18267075220743814,
      "backward_entropy": 0.11043453216552734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.496984004974365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014443292282521725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266141414642334,
      "backward_entropy": 0.1172157883644104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.910823822021484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014537910930812359,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826508641242981,
      "backward_entropy": 0.10939325094223022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.890836238861084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01463234331458807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18264049291610718,
      "backward_entropy": 0.10885260105133057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2497076988220215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014726541005074978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18263187011082968,
      "backward_entropy": 0.10830738544464111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.281428337097168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014820133335888386,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826249361038208,
      "backward_entropy": 0.11547801494598389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3691511154174805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014913216233253479,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261913458506265,
      "backward_entropy": 0.11770135164260864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.511298179626465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015005921944975853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261361122131348,
      "backward_entropy": 0.1145623803138733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.918368339538574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01509841438382864,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18260711431503296,
      "backward_entropy": 0.11685563325881958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.502833843231201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015190938487648964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18259984254837036,
      "backward_entropy": 0.10549283027648926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6886444091796875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01528327725827694,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18259143829345703,
      "backward_entropy": 0.10490145683288574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.123575687408447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015375490300357342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18258355061213175,
      "backward_entropy": 0.1155355453491211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.939949989318848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015467900782823563,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825744311014811,
      "backward_entropy": 0.11214151382446289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.452425479888916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015560993924736977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256314595540366,
      "backward_entropy": 0.10308893918991088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.927521705627441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01565377227962017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18255198001861572,
      "backward_entropy": 0.10246880054473877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.774941444396973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015746615827083588,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825389266014099,
      "backward_entropy": 0.110598886013031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.100471019744873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015839336439967155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18252662817637125,
      "backward_entropy": 0.10117160081863404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.458701133728027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015931570902466774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18251466751098633,
      "backward_entropy": 0.10050375461578369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.534937381744385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016023557633161545,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250352144241333,
      "backward_entropy": 0.10899614095687866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.039645195007324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016114726662635803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824948787689209,
      "backward_entropy": 0.11157307624816895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.845105171203613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016205545514822006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18248583873112997,
      "backward_entropy": 0.11104536056518555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.702692985534668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016296500340104103,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182477076848348,
      "backward_entropy": 0.10733159780502319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.553286075592041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01638752967119217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18246744076410928,
      "backward_entropy": 0.10996320247650146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2858405113220215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01647782139480114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18246094385782877,
      "backward_entropy": 0.10941605567932129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.091736316680908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016567979007959366,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18245438734690347,
      "backward_entropy": 0.105605947971344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.743167877197266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01665792055428028,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244697650273642,
      "backward_entropy": 0.09499043822288514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7397332191467285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016748059540987015,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824388106664022,
      "backward_entropy": 0.10441741943359376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.127121448516846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01683782786130905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242832024892172,
      "backward_entropy": 0.09354318380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.330479621887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01692741923034191,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824184457461039,
      "backward_entropy": 0.1031991720199585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.394970417022705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017016978934407234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240865071614584,
      "backward_entropy": 0.10595083236694336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.205025672912598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017105944454669952,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239814043045044,
      "backward_entropy": 0.09131537675857544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.999643802642822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017194854095578194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238832553227743,
      "backward_entropy": 0.09056408405303955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.864127159118652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0172836072742939,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18237817287445068,
      "backward_entropy": 0.08980722427368164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.514071941375732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01737145520746708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823697884877523,
      "backward_entropy": 0.1034963846206665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.708828449249268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017459623515605927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823592185974121,
      "backward_entropy": 0.10286390781402588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.913691520690918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017548205330967903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18234662214914957,
      "backward_entropy": 0.10221858024597168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.218410015106201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017636563628911972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233646949132284,
      "backward_entropy": 0.101567542552948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.451585292816162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017724288627505302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18232738971710205,
      "backward_entropy": 0.10091223716735839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.094557762145996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01781160943210125,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18231858809789023,
      "backward_entropy": 0.0967100977897644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.774202823638916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017898308113217354,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18231125672658285,
      "backward_entropy": 0.09602925777435303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2378668785095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01798497699201107,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18230120340983072,
      "backward_entropy": 0.09534245729446411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.539165496826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018071863800287247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822914481163025,
      "backward_entropy": 0.09464963674545288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.238715171813965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018158499151468277,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18228129545847574,
      "backward_entropy": 0.08201740384101867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.110237121582031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01824539341032505,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18226985136667886,
      "backward_entropy": 0.08122581243515015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.928709506988525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01833248697221279,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18225491046905518,
      "backward_entropy": 0.08042297959327697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.310545444488525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018419595435261726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822387178738912,
      "backward_entropy": 0.09542464017868042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3525590896606445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018506260588765144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18222316106160483,
      "backward_entropy": 0.07880640029907227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.975020408630371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018593300133943558,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822051207224528,
      "backward_entropy": 0.09037944674491882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.187222003936768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018679669126868248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18218801418940225,
      "backward_entropy": 0.09324060082435608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.628936290740967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018765592947602272,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18217102686564127,
      "backward_entropy": 0.0889202356338501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.000879764556885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01885143853724003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18215330441792807,
      "backward_entropy": 0.09176096916198731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.234515190124512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018936730921268463,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821372906366984,
      "backward_entropy": 0.08744584321975708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.001628875732422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019021710380911827,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18212159474690756,
      "backward_entropy": 0.07391100525856018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.127230644226074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01910701021552086,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821031173070272,
      "backward_entropy": 0.08595693111419678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.652663707733154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019191918894648552,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18208505709966025,
      "backward_entropy": 0.08874778747558594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.48171854019165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019276907667517662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820646127065023,
      "backward_entropy": 0.07144977450370789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.713721752166748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019361119717359543,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18204230070114136,
      "backward_entropy": 0.08369982242584229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.930523872375488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019444739446043968,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18202133973439535,
      "backward_entropy": 0.06979508399963379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.388066291809082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01952800340950489,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820006569226583,
      "backward_entropy": 0.08218594789505004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.703571319580078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01961131952702999,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18197792768478394,
      "backward_entropy": 0.06813806295394897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.136650562286377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01969338208436966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195684750874838,
      "backward_entropy": 0.06731023788452148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.963017702102661,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0197746604681015,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18193556865056357,
      "backward_entropy": 0.0664819061756134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.730452299118042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019855044782161713,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18191750844319662,
      "backward_entropy": 0.07914606928825378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756337642669678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019934456795454025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18190157413482666,
      "backward_entropy": 0.06484723091125488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.500356197357178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02001378871500492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18188651402791342,
      "backward_entropy": 0.08097555041313172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.513211250305176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020092854276299477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18187193075815836,
      "backward_entropy": 0.0801950216293335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.109588861465454,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020171720534563065,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18185553948084512,
      "backward_entropy": 0.0760956883430481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9191646575927734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0202492568641901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18184145291646323,
      "backward_entropy": 0.0786320686340332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8802297115325928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020326245576143265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818279226620992,
      "backward_entropy": 0.07785505652427674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.99446177482605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020402712747454643,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818143129348755,
      "backward_entropy": 0.05997709035873413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.420452117919922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020478783175349236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18180185556411743,
      "backward_entropy": 0.0763003408908844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.504560708999634,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02055487595498562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1817875107129415,
      "backward_entropy": 0.058377033472061156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1056227684021,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020630212500691414,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817734440167745,
      "backward_entropy": 0.07152637243270873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.770871639251709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020705386996269226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18175737063090006,
      "backward_entropy": 0.05678528547286987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.184550762176514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020779259502887726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18174304564793906,
      "backward_entropy": 0.07317655086517334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.01765775680542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020853178575634956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18172681331634521,
      "backward_entropy": 0.07239596247673034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.711851596832275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020927898585796356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18170448144276938,
      "backward_entropy": 0.07160000205039978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8003008365631104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021003060042858124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1816784938176473,
      "backward_entropy": 0.0707947075366974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7499141693115234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021077800542116165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18165196975072226,
      "backward_entropy": 0.06999080777168273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.654916286468506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02115212008357048,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1816244125366211,
      "backward_entropy": 0.06621620655059815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.247488260269165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021225953474640846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18159890174865723,
      "backward_entropy": 0.05128387212753296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7484195232391357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021299004554748535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18157410621643066,
      "backward_entropy": 0.050516325235366824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8972408771514893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02137085422873497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18155227104822794,
      "backward_entropy": 0.04976069927215576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6671712398529053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021442703902721405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18152866760889688,
      "backward_entropy": 0.06602644920349121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.181927442550659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02151435613632202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1815018653869629,
      "backward_entropy": 0.048262757062911985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.707569122314453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021585341542959213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814760367075602,
      "backward_entropy": 0.04752501845359802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.271188497543335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021656235679984093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18144917488098145,
      "backward_entropy": 0.0636766493320465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.628431558609009,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02172662876546383,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18142167727152506,
      "backward_entropy": 0.06023859977722168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9554100036621094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02179591730237007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18139729897181192,
      "backward_entropy": 0.045361435413360594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.47619891166687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02186453528702259,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813741127649943,
      "backward_entropy": 0.06133931875228882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.126600742340088,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021933089941740036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18134788672129312,
      "backward_entropy": 0.043964159488677976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7991161346435547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022000201046466827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18132301171620688,
      "backward_entropy": 0.0598027765750885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.47704815864563,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022066693753004074,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18129817644755045,
      "backward_entropy": 0.05658581256866455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5150961875915527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022133344784379005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18126930793126425,
      "backward_entropy": 0.05828694701194763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1673824787139893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02219911478459835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18124077717463175,
      "backward_entropy": 0.05753554105758667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1208279132843018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022264784201979637,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18121081590652466,
      "backward_entropy": 0.04058549702167511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.188950300216675,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022330325096845627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18117626508076987,
      "backward_entropy": 0.039924952387809756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7894343137741089,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02239471673965454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18114203214645386,
      "backward_entropy": 0.055291390419006346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5956368446350098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022457608953118324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18111294507980347,
      "backward_entropy": 0.05457049608230591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.711846113204956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022520054131746292,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18108383814493814,
      "backward_entropy": 0.051712030172348024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1600210666656494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02258222922682762,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18105314175287882,
      "backward_entropy": 0.03740077018737793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.112067937850952,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022643515840172768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810231606165568,
      "backward_entropy": 0.03679519295692444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5510354042053223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02270393818616867,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18099341789881387,
      "backward_entropy": 0.04972948431968689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3388144969940186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02276409976184368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18096184730529785,
      "backward_entropy": 0.05105363726615906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8088458776474,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022823769599199295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18092966079711914,
      "backward_entropy": 0.03503211438655853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2395219802856445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022882333025336266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808961033821106,
      "backward_entropy": 0.034461164474487306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.341701030731201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022940432652831078,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18086196978886923,
      "backward_entropy": 0.04715958833694458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.293621301651001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022998236119747162,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18082523345947266,
      "backward_entropy": 0.04653030037879944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9435561895370483,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02305571362376213,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18078688780466715,
      "backward_entropy": 0.045906245708465576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.339092254638672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02311244048178196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18074878056844076,
      "backward_entropy": 0.04704627990722656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1425719261169434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023169001564383507,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18070747454961142,
      "backward_entropy": 0.04467918872833252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6573454141616821,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023225154727697372,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18066424131393433,
      "backward_entropy": 0.04407423734664917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.045468330383301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023280270397663116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18062090873718262,
      "backward_entropy": 0.045108604431152347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.730676531791687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023334985598921776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18057564894358316,
      "backward_entropy": 0.04447743594646454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.946473240852356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02338891476392746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18053247531255087,
      "backward_entropy": 0.043857496976852414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9152936935424805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023442408069968224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18048638105392456,
      "backward_entropy": 0.043242552876472475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3375457525253296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02349548600614071,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18043986956278482,
      "backward_entropy": 0.04263392686843872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9400224685668945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023547343909740448,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.180396835009257,
      "backward_entropy": 0.04204201698303223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5138065814971924,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02359895408153534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18034948905309042,
      "backward_entropy": 0.027819982171058653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5978773832321167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023649711161851883,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18030202388763428,
      "backward_entropy": 0.03953647911548615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4563665390014648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023699810728430748,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18025275071461996,
      "backward_entropy": 0.03900795578956604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.136415958404541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02374914102256298,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18020594120025635,
      "backward_entropy": 0.03974531888961792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1244536638259888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023798804730176926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18015289306640625,
      "backward_entropy": 0.0391826868057251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.318838357925415,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023847157135605812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18010212977727255,
      "backward_entropy": 0.02567628026008606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6485121250152588,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023894604295492172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18004997571309408,
      "backward_entropy": 0.025274658203125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.257729172706604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02394181303679943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17999531825383505,
      "backward_entropy": 0.03757227063179016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1158748865127563,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02398812770843506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17994038263956705,
      "backward_entropy": 0.024493888020515442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.082730770111084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02403339557349682,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17988665898640951,
      "backward_entropy": 0.03552160859107971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5968104600906372,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02407764084637165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17983359098434448,
      "backward_entropy": 0.036055263876914975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2318271398544312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024121873080730438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17977609237035116,
      "backward_entropy": 0.02339559644460678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0988489389419556,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02416541427373886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17971664667129517,
      "backward_entropy": 0.035079896450042725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3756588697433472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02420809306204319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1796568234761556,
      "backward_entropy": 0.03460744917392731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.241371512413025,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02425050176680088,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17959328492482504,
      "backward_entropy": 0.022361941635608673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6102635264396667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024292415007948875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1795270840326945,
      "backward_entropy": 0.03367617130279541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0803955793380737,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024332618340849876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17946380376815796,
      "backward_entropy": 0.021713091433048247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9562922716140747,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024372214451432228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17939873536427817,
      "backward_entropy": 0.021402719616889953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1102337837219238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024411000311374664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17933273315429688,
      "backward_entropy": 0.032377249002456664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8202200531959534,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024449331685900688,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17926295598347983,
      "backward_entropy": 0.031306684017181396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7978906631469727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02448670007288456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17919421195983887,
      "backward_entropy": 0.03155202567577362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.132958173751831,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024523140862584114,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17912634213765463,
      "backward_entropy": 0.030576264858245848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1024625301361084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024559497833251953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1790553331375122,
      "backward_entropy": 0.030763670802116394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8173951506614685,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024595703929662704,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17898112535476685,
      "backward_entropy": 0.029863420128822326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7865739464759827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02463109791278839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17890650033950806,
      "backward_entropy": 0.029991766810417174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.854163646697998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02466561831533909,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17883030573527017,
      "backward_entropy": 0.029182559251785277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8401089310646057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024699557572603226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17875242233276367,
      "backward_entropy": 0.02925715446472168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0412300825119019,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024733001366257668,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17867382367451987,
      "backward_entropy": 0.018688012659549714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8622722625732422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024766409769654274,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1785900592803955,
      "backward_entropy": 0.018448460102081298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4741007685661316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02479933202266693,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17850341399510702,
      "backward_entropy": 0.027898839116096495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.821109414100647,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024830862879753113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17842012643814087,
      "backward_entropy": 0.01799136698246002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9460546374320984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024862015619874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1783339778582255,
      "backward_entropy": 0.027528682351112367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9205074310302734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02489321678876877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1782435178756714,
      "backward_entropy": 0.017556488513946533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6847939491271973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024924386292696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17814882596333823,
      "backward_entropy": 0.026870447397232055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5409384369850159,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02495473437011242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17805182933807373,
      "backward_entropy": 0.017135071754455566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7818201780319214,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024984028190374374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1779558261235555,
      "backward_entropy": 0.016936565935611724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6987656950950623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025013018399477005,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17785584926605225,
      "backward_entropy": 0.025901105999946595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49826863408088684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025041488930583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17775285243988037,
      "backward_entropy": 0.01655174195766449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7258958220481873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025068912655115128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17765043179194132,
      "backward_entropy": 0.025356653332710265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8246356844902039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025096135213971138,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1775444746017456,
      "backward_entropy": 0.016191405057907105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6304492950439453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02512352541089058,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17743317286173502,
      "backward_entropy": 0.024788686633110048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6146355867385864,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02515036053955555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17731948693593344,
      "backward_entropy": 0.01583951711654663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5447376370429993,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02517668344080448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17720367511113486,
      "backward_entropy": 0.024424991011619566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5300614237785339,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025202324613928795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17708688974380493,
      "backward_entropy": 0.023973342776298524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6703802347183228,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025227218866348267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17696871360143027,
      "backward_entropy": 0.015350796282291412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5532539486885071,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025251999497413635,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17684614658355713,
      "backward_entropy": 0.023761665821075438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3933127224445343,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025276292115449905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17672171195348105,
      "backward_entropy": 0.01504485309123993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2889591157436371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02529957704246044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17659878730773926,
      "backward_entropy": 0.02297404408454895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4675438106060028,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025321558117866516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17647941907246908,
      "backward_entropy": 0.022749806940555572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45434245467185974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025342920795083046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17635820309321085,
      "backward_entropy": 0.014638277888298034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6645179390907288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025363828986883163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17623573541641235,
      "backward_entropy": 0.022318989038467407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.646187424659729,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025385020300745964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17610605557759604,
      "backward_entropy": 0.01438608467578888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4237162470817566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025406505912542343,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1759699583053589,
      "backward_entropy": 0.022432519495487212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45207661390304565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02542729489505291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17583302656809488,
      "backward_entropy": 0.02167249321937561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3611324429512024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02544763870537281,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1756942868232727,
      "backward_entropy": 0.014016932249069214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.355185329914093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025467243045568466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17555604378382364,
      "backward_entropy": 0.013903124630451203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4912295341491699,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025486057624220848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17541786034901938,
      "backward_entropy": 0.02107613831758499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4100404381752014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025504902005195618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17527560393015543,
      "backward_entropy": 0.020885249972343443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40098410844802856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025523314252495766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17513140042622885,
      "backward_entropy": 0.020698820054531098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42304280400276184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0255412757396698,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17498517036437988,
      "backward_entropy": 0.02131369262933731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34444084763526917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025559015572071075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17483611901601157,
      "backward_entropy": 0.013381564617156982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36766746640205383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025576230138540268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17468651135762533,
      "backward_entropy": 0.02016345113515854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42859894037246704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0255931094288826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1745352347691854,
      "backward_entropy": 0.01999284029006958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2593132555484772,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025609828531742096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17437990506490073,
      "backward_entropy": 0.019823838770389558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4659321904182434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025625696405768394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1742262840270996,
      "backward_entropy": 0.019663421809673308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2791348099708557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025641774758696556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17406664292017618,
      "backward_entropy": 0.01950094699859619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19395460188388824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025657109916210175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1739075779914856,
      "backward_entropy": 0.019345860183238982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4062149226665497,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02567119523882866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17375195026397705,
      "backward_entropy": 0.01276981383562088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2917085587978363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025685390457510948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17359115680058798,
      "backward_entropy": 0.01905915141105652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35971102118492126,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02569902502000332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17342954874038696,
      "backward_entropy": 0.01262574940919876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37929439544677734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025712627917528152,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1732641855875651,
      "backward_entropy": 0.012556111812591553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4316432774066925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02572627179324627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17309417327245077,
      "backward_entropy": 0.018643715977668764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23371170461177826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025740541517734528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17291726668675741,
      "backward_entropy": 0.01849919408559799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30226659774780273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02575412392616272,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17274177074432373,
      "backward_entropy": 0.012343443185091018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2693086266517639,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025767415761947632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17256428798039755,
      "backward_entropy": 0.01822657883167267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2876303195953369,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025780320167541504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1723860502243042,
      "backward_entropy": 0.012210637331008911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30337589979171753,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025792943313717842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1722059448560079,
      "backward_entropy": 0.017967146635055543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23239479959011078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0258054006844759,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17202301820119223,
      "backward_entropy": 0.012085488438606263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21003107726573944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025817295536398888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1718403697013855,
      "backward_entropy": 0.01771911233663559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2800827622413635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02582848258316517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17165873448053995,
      "backward_entropy": 0.017604511976242066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2323049008846283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025839587673544884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17147429784138998,
      "backward_entropy": 0.011920354515314101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.202744260430336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02585037238895893,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17128916581471762,
      "backward_entropy": 0.01737990975379944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19527825713157654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025860412046313286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1711048682530721,
      "backward_entropy": 0.01727605313062668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24775806069374084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025869805365800858,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17092132568359375,
      "backward_entropy": 0.017178153991699217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24646589159965515,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025879288092255592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17073512077331543,
      "backward_entropy": 0.01173841655254364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2288641631603241,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02588876523077488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.170546293258667,
      "backward_entropy": 0.011695538461208344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12961970269680023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025898028165102005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1703557769457499,
      "backward_entropy": 0.016884173452854156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2104739397764206,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025906303897500038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1701690355936686,
      "backward_entropy": 0.011618985235691071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18794725835323334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025914553552865982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16998064517974854,
      "backward_entropy": 0.011583471298217773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23153746128082275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025922348722815514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16979201634724936,
      "backward_entropy": 0.011551133543252944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18469266593456268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025930354371666908,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16960004965464273,
      "backward_entropy": 0.018361571431159972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23423756659030914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02593814954161644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16940752665201822,
      "backward_entropy": 0.01148432269692421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21789969503879547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0259462408721447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1692111094792684,
      "backward_entropy": 0.01637197732925415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2108389437198639,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025954417884349823,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16901183128356934,
      "backward_entropy": 0.01819636523723602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1764705628156662,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025962674990296364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1688100496927897,
      "backward_entropy": 0.011378109455108643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20154806971549988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025970513001084328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16860810915629068,
      "backward_entropy": 0.01808517873287201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19327612221240997,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02597840689122677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1684038241704305,
      "backward_entropy": 0.01131187304854393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21116478741168976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02598637156188488,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16819753249486288,
      "backward_entropy": 0.015947438776493073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13818582892417908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02599460817873478,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16798776388168335,
      "backward_entropy": 0.017918068170547485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1852359026670456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026002399623394012,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16777974367141724,
      "backward_entropy": 0.015778787434101105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16395971179008484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026010116562247276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16756975650787354,
      "backward_entropy": 0.015697290003299714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1652797907590866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026017718017101288,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16735907395680746,
      "backward_entropy": 0.011143410950899124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14099480211734772,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602512016892433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16714749733606973,
      "backward_entropy": 0.015538500249385833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1617574840784073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026032358407974243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1669363776842753,
      "backward_entropy": 0.015461625158786773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14949066936969757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039564982056618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16672390699386597,
      "backward_entropy": 0.015385167300701141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10103658586740494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02604660391807556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1665109097957611,
      "backward_entropy": 0.015310300886631012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11293946206569672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026052962988615036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1663011908531189,
      "backward_entropy": 0.015241482853889465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14891576766967773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026058942079544067,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16609315077463785,
      "backward_entropy": 0.010974349826574326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11381740123033524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02606511116027832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16588322321573892,
      "backward_entropy": 0.015109053254127503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10829726606607437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02607102133333683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16567441821098328,
      "backward_entropy": 0.010926029086112976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12692873179912567,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026076512411236763,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16546703378359476,
      "backward_entropy": 0.017366747558116912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1243542954325676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026081928983330727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16525896390279135,
      "backward_entropy": 0.01492333859205246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10849101841449738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026087457314133644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505008935928345,
      "backward_entropy": 0.014862331748008727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09309347718954086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026092657819390297,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16484198967615762,
      "backward_entropy": 0.010843539237976074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10877133905887604,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02609734982252121,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16463589668273926,
      "backward_entropy": 0.017234115302562712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08223182708024979,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026102079078555107,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1644296646118164,
      "backward_entropy": 0.014696721732616425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12065812200307846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02610643208026886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16422594587008157,
      "backward_entropy": 0.014646361768245696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08049608021974564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02611112780869007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1640202800432841,
      "backward_entropy": 0.014593172073364257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09242391586303711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02611558698117733,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16381686925888062,
      "backward_entropy": 0.010761751979589462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11305996030569077,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026119787245988846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16361416379610697,
      "backward_entropy": 0.010747028142213821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09307663142681122,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026124095544219017,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16340959072113037,
      "backward_entropy": 0.014443543553352357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08612438291311264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026128411293029785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16320530573527017,
      "backward_entropy": 0.010716661810874939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07118837535381317,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026132622733712196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16300185521443686,
      "backward_entropy": 0.014345279335975647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10693813860416412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026136429980397224,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16280078887939453,
      "backward_entropy": 0.01699422299861908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08505113422870636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02614058181643486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16259736816088358,
      "backward_entropy": 0.014252245426177979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08326292037963867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026144690811634064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16239428520202637,
      "backward_entropy": 0.014204812049865723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07451952993869781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026148904114961624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1621915102005005,
      "backward_entropy": 0.014156726002693177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07684129476547241,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026152992621064186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16198993722597757,
      "backward_entropy": 0.014109791815280914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06923242658376694,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026157040148973465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178898016611734,
      "backward_entropy": 0.014063352346420288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0729709267616272,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026160983368754387,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16158942381540933,
      "backward_entropy": 0.010600437223911286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06393726915121078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026164719834923744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16139042377471924,
      "backward_entropy": 0.01397436559200287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06880731880664825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02616824582219124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16119305292765299,
      "backward_entropy": 0.013932655751705169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06317416578531265,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026171598583459854,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16099623839060465,
      "backward_entropy": 0.01677360534667969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05669260397553444,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026174860075116158,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16080063581466675,
      "backward_entropy": 0.010555344820022582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05964509770274162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02617798000574112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16060697038968405,
      "backward_entropy": 0.013815249502658843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055053967982530594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026181161403656006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16041457653045654,
      "backward_entropy": 0.013776952028274536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05249553546309471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026184171438217163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16022376219431558,
      "backward_entropy": 0.013740180432796479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05103570967912674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026186905801296234,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003464659055075,
      "backward_entropy": 0.01668047308921814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058350443840026855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026189526543021202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15984721978505453,
      "backward_entropy": 0.01367247849702835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056597597897052765,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026192257180809975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1596600612004598,
      "backward_entropy": 0.010504071414470673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04730352386832237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026195082813501358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15947329998016357,
      "backward_entropy": 0.013603712618350982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055452048778533936,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0261977631598711,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1592882772286733,
      "backward_entropy": 0.010487827658653259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039472222328186035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026200739666819572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15910353263219199,
      "backward_entropy": 0.013534745573997498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04308046028017998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02620328590273857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15892136096954346,
      "backward_entropy": 0.013502752780914307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03574163094162941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02620558626949787,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15874079863230386,
      "backward_entropy": 0.010465219616889954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042414553463459015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026207560673356056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15856300791104636,
      "backward_entropy": 0.01046171635389328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0462186262011528,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026209423318505287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15838640928268433,
      "backward_entropy": 0.013419675827026366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0442112572491169,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02621142379939556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15821013847986856,
      "backward_entropy": 0.013392612338066101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04218381270766258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02621356211602688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1580345630645752,
      "backward_entropy": 0.013364572823047639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04261711984872818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026215720921754837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15785975257555643,
      "backward_entropy": 0.013336533308029174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04072050005197525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02621796727180481,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15768547852834067,
      "backward_entropy": 0.013307929039001465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03379886597394943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026220303028821945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15751200914382935,
      "backward_entropy": 0.013278765976428986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0332917645573616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026222413405776024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.157340407371521,
      "backward_entropy": 0.013251540064811707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032682325690984726,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026224417611956596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15717065334320068,
      "backward_entropy": 0.010424817353487015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03021484985947609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026226313784718513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15700271725654602,
      "backward_entropy": 0.013200463354587555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029065461829304695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026228154078125954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15683706601460776,
      "backward_entropy": 0.010417914390563965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0247421283274889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026229839771986008,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15667349100112915,
      "backward_entropy": 0.010415482521057128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033079735934734344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026231277734041214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.156512717405955,
      "backward_entropy": 0.010414546728134156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026071226224303246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02623295783996582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15635292728741965,
      "backward_entropy": 0.013108786940574647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024230297654867172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026234621182084084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15619554122289023,
      "backward_entropy": 0.013086150586605071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021477356553077698,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026236196979880333,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1560406486193339,
      "backward_entropy": 0.010406394302845002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025600491091609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026237552985548973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1558884084224701,
      "backward_entropy": 0.013044388592243194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030200332403182983,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02623896300792694,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15573777755101523,
      "backward_entropy": 0.016355280578136445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020859094336628914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026240641251206398,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1555874546368917,
      "backward_entropy": 0.010400000959634781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02137562446296215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026242250576615334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15543979406356812,
      "backward_entropy": 0.012980279326438905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01595289632678032,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624385617673397,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15529441833496094,
      "backward_entropy": 0.012958981096744537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02286333218216896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0262452382594347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15515234073003134,
      "backward_entropy": 0.01293969452381134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018147066235542297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026246726512908936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15501136581103006,
      "backward_entropy": 0.01291971206665039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024986637756228447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624807506799698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15487241744995117,
      "backward_entropy": 0.012900973856449127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01812046766281128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026249678805470467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1547335982322693,
      "backward_entropy": 0.012880326807498932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021925190463662148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026251282542943954,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15459693471590677,
      "backward_entropy": 0.016270896792411803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016135375946760178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026253078132867813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15446112553278604,
      "backward_entropy": 0.012838044762611389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013770833611488342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026254793629050255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15432769060134888,
      "backward_entropy": 0.012816989421844482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015267652459442616,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02625642716884613,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15419737497965494,
      "backward_entropy": 0.010362206399440766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015304015018045902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026257988065481186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.154069056113561,
      "backward_entropy": 0.010357756167650223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013172668404877186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02625954896211624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1539426843325297,
      "backward_entropy": 0.012757918238639832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019785013049840927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626100927591324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15381863713264465,
      "backward_entropy": 0.01273946464061737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015198970213532448,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626265585422516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1536942720413208,
      "backward_entropy": 0.012719678878784179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015839455649256706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026264311745762825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.153571218252182,
      "backward_entropy": 0.01269988864660263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01306196115911007,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026266003027558327,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15344899892807007,
      "backward_entropy": 0.01616656482219696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013543403707444668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626767009496689,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1533287763595581,
      "backward_entropy": 0.012660391628742218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010806085541844368,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026269350200891495,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15321019291877747,
      "backward_entropy": 0.016142061352729796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008408728055655956,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0262709129601717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1530940035978953,
      "backward_entropy": 0.01031658574938774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01221226342022419,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026272321119904518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15298117200533548,
      "backward_entropy": 0.012605178356170654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016471603885293007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026273764669895172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15286984046300253,
      "backward_entropy": 0.012587843835353852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011872218921780586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026275448501110077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15275792280832926,
      "backward_entropy": 0.010301724076271057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0074614183977246284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026277104392647743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15264703830083212,
      "backward_entropy": 0.012549781799316406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010719510726630688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026278670877218246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15253976980845133,
      "backward_entropy": 0.012531831860542297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012068741023540497,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026280242949724197,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15243369340896606,
      "backward_entropy": 0.010284541547298432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011333649978041649,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026281937956809998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15232829252878824,
      "backward_entropy": 0.01249522715806961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007520281709730625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026283761486411095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15222400426864624,
      "backward_entropy": 0.016034278273582458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008536050096154213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026285478845238686,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15212223927179971,
      "backward_entropy": 0.01602136194705963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008479861542582512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026287155225872993,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15202216307322183,
      "backward_entropy": 0.010256724059581756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01083408948034048,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026288850232958794,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15192389488220215,
      "backward_entropy": 0.015996013581752778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007994421757757664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0262906476855278,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15182564655939737,
      "backward_entropy": 0.012401601672172547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00957751739770174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026292361319065094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15172863006591797,
      "backward_entropy": 0.012383366376161576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007497316692024469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026294132694602013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15163197120030722,
      "backward_entropy": 0.012364743649959565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007172624114900827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629595249891281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15153743823369345,
      "backward_entropy": 0.012345928698778152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007287184242159128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629774622619152,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15144463380177817,
      "backward_entropy": 0.012327412515878678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005844234023243189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026299480348825455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15135284264882407,
      "backward_entropy": 0.012309417128562927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009557828307151794,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026301126927137375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1512630581855774,
      "backward_entropy": 0.015902420878410338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007356674410402775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026302924379706383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15117276708285013,
      "backward_entropy": 0.012273742258548737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007689703721553087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02630470134317875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1510829528172811,
      "backward_entropy": 0.015874700248241426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006375758443027735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263065192848444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15099342664082846,
      "backward_entropy": 0.012237229198217393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005110159981995821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026308342814445496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15090525150299072,
      "backward_entropy": 0.012218883633613587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004781428724527359,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263100266456604,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15081860621770224,
      "backward_entropy": 0.01583317816257477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00574158038944006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026311594992876053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15073362986246744,
      "backward_entropy": 0.012185432761907578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004957109224051237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026313168928027153,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1506496767203013,
      "backward_entropy": 0.012169218063354493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005018293857574463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026314688846468925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.150567094484965,
      "backward_entropy": 0.01013750433921814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037541999481618404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026316184550523758,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1504856546719869,
      "backward_entropy": 0.015785187482833862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005258385557681322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02631755731999874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15040608247121176,
      "backward_entropy": 0.010125554352998733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004274689592421055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026318948715925217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15032712618509927,
      "backward_entropy": 0.012109111994504929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004245810676366091,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026320336386561394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15024966994921365,
      "backward_entropy": 0.012094680219888687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003201835323125124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632170170545578,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1501733660697937,
      "backward_entropy": 0.012080502510070801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037028626538813114,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026322996243834496,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15009910861651102,
      "backward_entropy": 0.01573203206062317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002901333849877119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026324249804019928,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.150026003519694,
      "backward_entropy": 0.01572228968143463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027712732553482056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026325445622205734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14995493491490683,
      "backward_entropy": 0.012041191011667252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035433643497526646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632654644548893,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14988553524017334,
      "backward_entropy": 0.012029342353343964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037278083618730307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327673345804214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14981709917386374,
      "backward_entropy": 0.012017398327589034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025741986464709044,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632882446050644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1497491498788198,
      "backward_entropy": 0.012005278468132019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004203760530799627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632990851998329,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14968277017275491,
      "backward_entropy": 0.011993765830993652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023664585314691067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633112110197544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14961644013722739,
      "backward_entropy": 0.011981317400932312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002268251497298479,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633225917816162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14955168962478638,
      "backward_entropy": 0.011969485878944397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024440342094749212,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633332833647728,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14948847889900208,
      "backward_entropy": 0.015651941299438477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019888910464942455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026334375143051147,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14942650000254312,
      "backward_entropy": 0.015643872320652008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029558048117905855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335373520851135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1493662198384603,
      "backward_entropy": 0.01193678006529808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002828998491168022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336397975683212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14930614829063416,
      "backward_entropy": 0.011926059424877167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021757404319941998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026337480172514915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14924663305282593,
      "backward_entropy": 0.015619847178459167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023519450332969427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633851207792759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14918800195058188,
      "backward_entropy": 0.011904311180114747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019391215173527598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633952721953392,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14912993709246317,
      "backward_entropy": 0.010033327341079711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018991254037246108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026340505108237267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14907294511795044,
      "backward_entropy": 0.011883637309074402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021666723769158125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026341471821069717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14901711543401083,
      "backward_entropy": 0.01187361478805542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001982041634619236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026342466473579407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14896196126937866,
      "backward_entropy": 0.011863422393798829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001974528655409813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026343466714024544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14890754222869873,
      "backward_entropy": 0.01185327023267746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001680804998613894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026344485580921173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1488538384437561,
      "backward_entropy": 0.011843016743659973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001551424153149128,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026345493271946907,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14880114793777466,
      "backward_entropy": 0.015557359158992767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017538449028506875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026346469298005104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14874951044718424,
      "backward_entropy": 0.011823077499866486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001605661236681044,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263474490493536,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14869842926661173,
      "backward_entropy": 0.015542078018188476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010779770091176033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263484138995409,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14864802360534668,
      "backward_entropy": 0.011803587526082992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015559865860268474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263492614030838,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14859875043233237,
      "backward_entropy": 0.011794822663068772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011297836899757385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02635013498365879,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14855007330576578,
      "backward_entropy": 0.015520913898944855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010065777460113168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026350971311330795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1485025684038798,
      "backward_entropy": 0.009983101487159729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010586519492790103,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02635176293551922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14845633506774902,
      "backward_entropy": 0.015508176386356353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010727326152846217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352539658546448,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1484112242857615,
      "backward_entropy": 0.011761173605918884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010825862409546971,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635331079363823,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1483670473098755,
      "backward_entropy": 0.009973002970218659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007256321841850877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635408379137516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14832374453544617,
      "backward_entropy": 0.011745350062847137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011623708996921778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026354772970080376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14828160405158997,
      "backward_entropy": 0.01173814684152603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006997936288826168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635549195110798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1482398509979248,
      "backward_entropy": 0.01173076257109642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008716210722923279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02635614201426506,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1481991708278656,
      "backward_entropy": 0.01547412872314453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007461624918505549,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026356784626841545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14815925558408102,
      "backward_entropy": 0.011717145144939423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005510275950655341,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02635737881064415,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1481200655301412,
      "backward_entropy": 0.015464508533477783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006024175090715289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635791152715683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14808207750320435,
      "backward_entropy": 0.011704950034618378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007790827075950801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635842375457287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14804524183273315,
      "backward_entropy": 0.011699303984642029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006893598474562168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026358958333730698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14800896247227988,
      "backward_entropy": 0.0116935133934021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005811155424453318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635948918759823,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1479733387629191,
      "backward_entropy": 0.01168784722685814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048408456495963037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026359982788562775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1479384203751882,
      "backward_entropy": 0.011682437360286712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005634947447106242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02636042982339859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14790438612302145,
      "backward_entropy": 0.01167740449309349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005056718946434557,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026360854506492615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14787093798319498,
      "backward_entropy": 0.015437610447406769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006523906486108899,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02636125311255455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1478381852308909,
      "backward_entropy": 0.00994076132774353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005891806213185191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026361705735325813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14780586957931519,
      "backward_entropy": 0.011663027107715607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003739843668881804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026362167671322823,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14777396122614542,
      "backward_entropy": 0.01165803223848343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004818808811251074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263625867664814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14774298667907715,
      "backward_entropy": 0.01165337860584259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005532390205189586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026363003998994827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1477125883102417,
      "backward_entropy": 0.011648768186569214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036454590735957026,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026363445445895195,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14768244822820029,
      "backward_entropy": 0.015417356789112092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041650148341432214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026363862678408623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1476531426111857,
      "backward_entropy": 0.011639486998319626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036780774826183915,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026364274322986603,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14762438337008157,
      "backward_entropy": 0.015410834550857544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042642452172003686,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02636468969285488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14759634931882223,
      "backward_entropy": 0.015407562255859375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003391596837900579,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026365119963884354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14756874243418375,
      "backward_entropy": 0.011626011878252029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003478964790701866,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026365548372268677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1475418210029602,
      "backward_entropy": 0.015400810539722443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026567670283839107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026365963742136955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14751535654067993,
      "backward_entropy": 0.011617157608270645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034196171327494085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263663437217474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14748955766359964,
      "backward_entropy": 0.011613071709871293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025207133148796856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026366738602519035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1474642554918925,
      "backward_entropy": 0.011608924716711044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002889405586756766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026367096230387688,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1474394996960958,
      "backward_entropy": 0.009917581826448441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029304338386282325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02636745385825634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1474152406056722,
      "backward_entropy": 0.011601229012012482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025326653849333525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026367824524641037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1473914384841919,
      "backward_entropy": 0.011597320437431335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000273383833700791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026368174701929092,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14736801385879517,
      "backward_entropy": 0.011593595892190934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001855043083196506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026368532329797745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14734496672948202,
      "backward_entropy": 0.011589820683002471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027481067809276283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026368869468569756,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14732261498769125,
      "backward_entropy": 0.015374387800693511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024136643332894892,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026369236409664154,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14730058113733926,
      "backward_entropy": 0.015371443331241607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021623286011163145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026369601488113403,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1472787857055664,
      "backward_entropy": 0.01536853015422821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016144398250617087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026369968429207802,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14725741744041443,
      "backward_entropy": 0.011574995517730714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016790404333733022,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026370322331786156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14723676443099976,
      "backward_entropy": 0.009904376417398452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001543856633361429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026370657607913017,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14721657832463583,
      "backward_entropy": 0.011567920446395874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016452062118332833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637099288403988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14719701806704202,
      "backward_entropy": 0.011564503610134124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014949528849683702,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026371324434876442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14717787504196167,
      "backward_entropy": 0.009900136291980744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001358936569886282,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026371661573648453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14715927839279175,
      "backward_entropy": 0.011557777971029281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011830717994598672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637198567390442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1471411089102427,
      "backward_entropy": 0.011554501205682754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.06768803158775e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026372287422418594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14712345600128174,
      "backward_entropy": 0.011551424860954285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010343976464355364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026372559368610382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1471064885457357,
      "backward_entropy": 0.011548615247011184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.961022831499577e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637280896306038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1470899780591329,
      "backward_entropy": 0.011545960605144501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001172913471236825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026373041793704033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14707395434379578,
      "backward_entropy": 0.011543473601341248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.778496314538643e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637326531112194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14705818891525269,
      "backward_entropy": 0.01154104620218277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010488749103387818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026373494416475296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14704281091690063,
      "backward_entropy": 0.011538617312908173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.032711386680603e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263737253844738,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14702773094177246,
      "backward_entropy": 0.015335486829280853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.708854536758736e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026373950764536858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1470129688580831,
      "backward_entropy": 0.009889335930347442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.697280670981854e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637416683137417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.146998663743337,
      "backward_entropy": 0.011531513929367066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.87896424299106e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026374375447630882,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1469846765200297,
      "backward_entropy": 0.009887665510177612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.251604256452993e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637457847595215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14697099725405374,
      "backward_entropy": 0.011527153849601745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.934670091141015e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026374775916337967,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14695767561594644,
      "backward_entropy": 0.015327028930187225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.491374369943514e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02637496404349804,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1469445824623108,
      "backward_entropy": 0.015325486660003662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.140798359410837e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026375148445367813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14693182706832886,
      "backward_entropy": 0.011521045863628388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.885626913164742e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637532912194729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14691937963167825,
      "backward_entropy": 0.0115191251039505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.630564944818616e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637549489736557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14690730969111124,
      "backward_entropy": 0.01151730865240097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.360939394449815e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026375647634267807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14689560731252035,
      "backward_entropy": 0.01151561439037323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.242621045908891e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637581340968609,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14688424269358316,
      "backward_entropy": 0.011513844132423401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.073652235092595e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026375971734523773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14687307675679526,
      "backward_entropy": 0.01151212900876999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.767434463952668e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02637612260878086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14686225851376852,
      "backward_entropy": 0.009881022572517394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.559006629278883e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637627348303795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14685185750325522,
      "backward_entropy": 0.011508899182081223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.590104097384028e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026376422494649887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14684160550435385,
      "backward_entropy": 0.011507298797369003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1284987673861906e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02637656405568123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14683167139689127,
      "backward_entropy": 0.009879355132579804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.626623220043257e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026376698166131973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1468218465646108,
      "backward_entropy": 0.011504314839839935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.133860809612088e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637682482600212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1468122402826945,
      "backward_entropy": 0.011502924561500549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.87033105653245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026376940310001373,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14680288235346475,
      "backward_entropy": 0.015309397876262665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.646245022537187e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026377061381936073,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14679361383120218,
      "backward_entropy": 0.015308399498462678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9055518098175526e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026377171277999878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14678444465001425,
      "backward_entropy": 0.011499010771512986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4915065296227112e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026377275586128235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14677546421686807,
      "backward_entropy": 0.011497825384140015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3546384909423068e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026377368718385696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14676676193873087,
      "backward_entropy": 0.015305812656879424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.002375367737841e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026377452537417412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14675830801328024,
      "backward_entropy": 0.00987653136253357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.117782787536271e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026377538219094276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1467501918474833,
      "backward_entropy": 0.0098763108253479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9086970496573485e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026377616450190544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14674229423205057,
      "backward_entropy": 0.011493687331676484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9688364773173817e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026377687230706215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14673466483751932,
      "backward_entropy": 0.011492810398340225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0275245333323255e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026377752423286438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14672720432281494,
      "backward_entropy": 0.011491956561803818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8596463633002713e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026377813890576363,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1467199126879374,
      "backward_entropy": 0.015301969647407532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5848680050112307e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026377875357866287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14671278993288675,
      "backward_entropy": 0.01149035468697548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5524827176705003e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026377931237220764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14670586585998535,
      "backward_entropy": 0.01148960441350937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6250482076429762e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637799084186554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1466991901397705,
      "backward_entropy": 0.011488841474056244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3766686606686562e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026378048583865166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14669264356295267,
      "backward_entropy": 0.01148810312151909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4907940567354672e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637810818850994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14668632547060648,
      "backward_entropy": 0.011487352848052978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.378762044623727e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026378173381090164,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14668013652165732,
      "backward_entropy": 0.015298756957054137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3095470421831124e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026378238573670387,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1466741363207499,
      "backward_entropy": 0.01529817283153534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0342797395423986e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637830562889576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14666825532913208,
      "backward_entropy": 0.011485016345977784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1691028703353368e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026378370821475983,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14666261275609335,
      "backward_entropy": 0.011484266817569732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.144711839326192e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637842856347561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14665702978769937,
      "backward_entropy": 0.011483565717935563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0839802598638926e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026378482580184937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14665168523788452,
      "backward_entropy": 0.01148291751742363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.59313638304593e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026378540322184563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14664642016092935,
      "backward_entropy": 0.011482243239879609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.672131116327364e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637859433889389,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14664132396380106,
      "backward_entropy": 0.011481598019599915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.566266842535697e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637864649295807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1466363271077474,
      "backward_entropy": 0.011480965465307236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.935687790450174e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026378696784377098,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14663144946098328,
      "backward_entropy": 0.009873914718627929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.334979389066575e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026378750801086426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14662675062815347,
      "backward_entropy": 0.011479748785495758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.420045338018099e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026378799229860306,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14662220080693564,
      "backward_entropy": 0.011479179561138152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.401228802133119e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026378847658634186,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1466178297996521,
      "backward_entropy": 0.01529262661933899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.610850050492445e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026378892362117767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1466135780016581,
      "backward_entropy": 0.00987350195646286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.88413013247191e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637893706560135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14660940567652384,
      "backward_entropy": 0.01147756353020668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.732215074909618e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637898363173008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1466053823630015,
      "backward_entropy": 0.01147702857851982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9160103117174e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02637903392314911,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14660151799519858,
      "backward_entropy": 0.01529083400964737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.853844868397573e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637908235192299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14659780263900757,
      "backward_entropy": 0.011475937813520432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.430617536854697e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379134505987167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14659413695335388,
      "backward_entropy": 0.011475358903408051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.310406893637264e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379188522696495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465905706087748,
      "backward_entropy": 0.011474817991256714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.014526439277688e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379244402050972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14658716320991516,
      "backward_entropy": 0.011474254727363586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.76273897018109e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637929655611515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465838352839152,
      "backward_entropy": 0.01147371605038643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0049698125367286e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637934312224388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14658057689666748,
      "backward_entropy": 0.011473208665847778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.731119932126603e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637939155101776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465774675210317,
      "backward_entropy": 0.011472713202238083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1294166547013447e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379434391856194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14657443761825562,
      "backward_entropy": 0.01147225797176361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0298149340524105e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379477232694626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14657147725423178,
      "backward_entropy": 0.011471805721521377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8455756364564877e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379521936178207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14656861623128256,
      "backward_entropy": 0.011471327394247055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6078425889863865e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379568502306938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14656581481297812,
      "backward_entropy": 0.011470867693424225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3055422389006708e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637961134314537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465631127357483,
      "backward_entropy": 0.011470425873994827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8583515384307248e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379650458693504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14656050006548563,
      "backward_entropy": 0.011470022797584533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.036319983744761e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379691436886787,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14655801653862,
      "backward_entropy": 0.011469605565071105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.928134906847845e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026379728689789772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14655562241872153,
      "backward_entropy": 0.015284281969070435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7467848465457791e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379765942692757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14655329783757529,
      "backward_entropy": 0.011468842625617981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8061131186186685e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379801332950592,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14655107259750366,
      "backward_entropy": 0.01146848201751709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7627331772018806e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026379834860563278,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1465489069620768,
      "backward_entropy": 0.015283229947090148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5221406783894054e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026379868388175964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14654678106307983,
      "backward_entropy": 0.009870447218418121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3828760074829916e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379898190498352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14654471476872763,
      "backward_entropy": 0.011467470228672028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3737779909206438e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02637992799282074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14654273788134256,
      "backward_entropy": 0.011467156559228897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1990031225650455e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026379955932497978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465408205986023,
      "backward_entropy": 0.011466880142688752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1292473800494918e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026379980146884918,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14653895298639932,
      "backward_entropy": 0.015281756222248078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1417643008826417e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380006223917007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14653716484705606,
      "backward_entropy": 0.009870071709156037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.171269332189695e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380032300949097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14653541644414267,
      "backward_entropy": 0.011466048657894135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1546037512744078e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380056515336037,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14653372764587402,
      "backward_entropy": 0.009869910031557082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.364198376715649e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380077004432678,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14653203884760538,
      "backward_entropy": 0.015280762314796447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295414204440021e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638009749352932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14653043945630392,
      "backward_entropy": 0.011465327441692352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5214333012118e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380116119980812,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14652888973553976,
      "backward_entropy": 0.01528034806251526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.683330747771834e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380132883787155,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.146527369817098,
      "backward_entropy": 0.015280158817768097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.319475798794883e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638014778494835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465258995691935,
      "backward_entropy": 0.011464769393205643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.058069743630767e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380162686109543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14652445912361145,
      "backward_entropy": 0.011464590579271317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.538300911211991e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380177587270737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14652307828267416,
      "backward_entropy": 0.011464431136846542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.297838694990787e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02638019248843193,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1465217967828115,
      "backward_entropy": 0.015279482305049896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.184359679333284e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380207389593124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14652052521705627,
      "backward_entropy": 0.011464070528745651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.593850005425338e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380222290754318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14651930332183838,
      "backward_entropy": 0.011463917791843414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.379054132641613e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380235329270363,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1465181310971578,
      "backward_entropy": 0.01527898758649826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.069290469033149e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380248367786407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465169886747996,
      "backward_entropy": 0.01146361455321312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.353410301722761e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380261406302452,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14651590585708618,
      "backward_entropy": 0.009869621694087982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7066731667655404e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380272582173347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14651484290758768,
      "backward_entropy": 0.011463315039873124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.88890845467904e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380285620689392,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1465137799580892,
      "backward_entropy": 0.009869572520256043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.565626170460746e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380298659205437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1465127964814504,
      "backward_entropy": 0.00986955463886261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.98650149943569e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380309835076332,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14651183287302652,
      "backward_entropy": 0.01527811586856842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2823288026738737e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380321010947227,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465108891328176,
      "backward_entropy": 0.011462794244289398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.037011708784121e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380330324172974,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14650994539260864,
      "backward_entropy": 0.015277871489524841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.859036669633497e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02638033777475357,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.146509051322937,
      "backward_entropy": 0.009869532287120819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5781125145840633e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380345225334167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14650817712148032,
      "backward_entropy": 0.011462502181529999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9480321472874493e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380352675914764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465073525905609,
      "backward_entropy": 0.01146240308880806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.809045440699265e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638036012649536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14650654792785645,
      "backward_entropy": 0.011462317407131195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.602040183319332e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638036571443081,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465057631333669,
      "backward_entropy": 0.011462239921092987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9545477414339985e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380371302366257,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14650497833887735,
      "backward_entropy": 0.015277296304702759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1103763003793574e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380376890301704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1465042233467102,
      "backward_entropy": 0.011462097615003585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.726121183764917e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380382478237152,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1465035080909729,
      "backward_entropy": 0.015277142822742461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6539827640826843e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0263803880661726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14650283257166544,
      "backward_entropy": 0.009869587421417237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6522086809800385e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380393654108047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.146502157052358,
      "backward_entropy": 0.011461880058050156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6641318723031873e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380399242043495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14650151133537292,
      "backward_entropy": 0.011461804807186126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6294436022690206e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380404829978943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14650089542071024,
      "backward_entropy": 0.009869620203971863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0414782991574612e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02638041041791439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14650028944015503,
      "backward_entropy": 0.00986962541937828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4291902061813744e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380416005849838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14649972319602966,
      "backward_entropy": 0.00986962541937828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.124133817143047e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380421593785286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1464991569519043,
      "backward_entropy": 0.00986962541937828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1470389438272832e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380427181720734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649863044420877,
      "backward_entropy": 0.011461473256349563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2899076295980194e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638043276965618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649811387062073,
      "backward_entropy": 0.011461402475833892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2419420158948924e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02638043649494648,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1464976171652476,
      "backward_entropy": 0.009869632124900819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.732860206668192e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380440220236778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649713039398193,
      "backward_entropy": 0.011461298912763596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.390334471641836e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380443945527077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1464966336886088,
      "backward_entropy": 0.011461260169744492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.737096296978052e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380447670817375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649617671966553,
      "backward_entropy": 0.011461198329925537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.041262506390922e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380451396107674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649573961893717,
      "backward_entropy": 0.011461155116558075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.36099110554278e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380455121397972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649532238642374,
      "backward_entropy": 0.011461123824119568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.413485920120365e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638045884668827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649492502212524,
      "backward_entropy": 0.011461059749126434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.255477558170242e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02638046257197857,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14649452765782675,
      "backward_entropy": 0.015275967121124268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.913830302186398e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380466297268867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1464941700299581,
      "backward_entropy": 0.009869662672281265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.962984062080068e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380470022559166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14649381240208945,
      "backward_entropy": 0.009869665652513505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0498934690022e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380473747849464,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1464934547742208,
      "backward_entropy": 0.0152757927775383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.18214725073085e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380477473139763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649309714635214,
      "backward_entropy": 0.011460845172405244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7274597509149316e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638048119843006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649276932080588,
      "backward_entropy": 0.011460817605257034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.936211439598992e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02638048306107521,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1464924414952596,
      "backward_entropy": 0.009869682043790818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.704009270994902e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638048492372036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1464921236038208,
      "backward_entropy": 0.011460746824741363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.589048797574378e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638048678636551,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649182558059692,
      "backward_entropy": 0.011460717022418975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.953734406536569e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380490511655807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1464915374914805,
      "backward_entropy": 0.011460688710212708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8195402396468126e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380494236946106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.146491269270579,
      "backward_entropy": 0.011460638791322707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9924727584784705e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026380497962236404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14649097124735513,
      "backward_entropy": 0.00986969992518425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9327034073721734e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380501687526703,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649073282877603,
      "backward_entropy": 0.011460593342781067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.890632527259186e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380503550171852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649047454198202,
      "backward_entropy": 0.011460546404123306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.156231542789101e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380505412817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14649023612340292,
      "backward_entropy": 0.011460528522729874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3726540732127432e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638050727546215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1464899778366089,
      "backward_entropy": 0.011460511386394501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8120812345378e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263805091381073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648972948392233,
      "backward_entropy": 0.01146049052476883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.91281310182967e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638051100075245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648952086766562,
      "backward_entropy": 0.011460445821285248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1750468093273412e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263805128633976,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14648928244908652,
      "backward_entropy": 0.015275180339813232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.466971515957539e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380514726042747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648906389872232,
      "backward_entropy": 0.01146041750907898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0148320345469983e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380516588687897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648884534835815,
      "backward_entropy": 0.011460398137569428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7700926946417894e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380518451333046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1464886466662089,
      "backward_entropy": 0.011460386216640472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9528471284502302e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380520313978195,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14648845791816711,
      "backward_entropy": 0.015275055170059204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.585723197194966e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380522176623344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648826917012533,
      "backward_entropy": 0.011460339277982711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5293572630525887e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380524039268494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14648808042208353,
      "backward_entropy": 0.015275014936923981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6103513189591467e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026380525901913643,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14648791154225668,
      "backward_entropy": 0.015275000035762787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4052133678887913e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026380527764558792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648770292599997,
      "backward_entropy": 0.011460300534963608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4236135825740348e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638052962720394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648755391438803,
      "backward_entropy": 0.011460283398628235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2536801818896492e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02638053148984909,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1464873751004537,
      "backward_entropy": 0.015274916589260102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3375327512221702e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02638053335249424,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14648722608884177,
      "backward_entropy": 0.015274903178215027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1054908100049943e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053521513939,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648706714312235,
      "backward_entropy": 0.011460226029157639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3225871953181922e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14648690819740295,
      "backward_entropy": 0.015274848043918609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.113421128859045e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648674925168356,
      "backward_entropy": 0.011460211127996445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.359567177900317e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648662010828653,
      "backward_entropy": 0.01146020069718361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0359457291997387e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648649096488953,
      "backward_entropy": 0.011460193991661071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.628589398540498e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648636182149252,
      "backward_entropy": 0.011460182815790176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.662162377324421e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648624261220297,
      "backward_entropy": 0.011460182815790176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262901474154205e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648613333702087,
      "backward_entropy": 0.011460172384977341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.619707614343497e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14648602406183878,
      "backward_entropy": 0.011460162699222565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.683368773494294e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1464859147866567,
      "backward_entropy": 0.015274721384048461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0348597230586165e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1464858055114746,
      "backward_entropy": 0.01146012544631958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.666127205789962e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02638053707778454,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1464857061704,
      "backward_entropy": 0.00986989364027977,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.914657010994915e-07,
    "avg_log_Z": 0.02638033153489232,
    "success_rate": 1.0,
    "avg_reward": 47.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.22,
      "1": 0.18,
      "2": 0.6
    },
    "avg_forward_entropy": 0.14650663326183955,
    "avg_backward_entropy": 0.01201514198631048,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}