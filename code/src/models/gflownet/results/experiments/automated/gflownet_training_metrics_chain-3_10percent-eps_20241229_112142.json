{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23098901907602945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23103628555933634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.713724136352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743239998817444,
      "backward_entropy": 0.23085041840871176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.588313102722168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27433595061302185,
      "backward_entropy": 0.23083090782165527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.223977088928223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019997518393211067,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743365168571472,
      "backward_entropy": 0.23081092039744058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.943345069885254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00029985798755660653,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274334192276001,
      "backward_entropy": 0.23104453086853027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.579805374145508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000399873562855646,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274330735206604,
      "backward_entropy": 0.23076667388280234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.576939582824707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004998747608624399,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743261158466339,
      "backward_entropy": 0.23104774951934814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.405704498291016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005998667911626399,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743203938007355,
      "backward_entropy": 0.2310486634572347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449705123901367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000700064585544169,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743133306503296,
      "backward_entropy": 0.2310490608215332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8035888671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008001403184607625,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27430427074432373,
      "backward_entropy": 0.2306662400563558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.921452522277832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009002363658510149,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27429383993148804,
      "backward_entropy": 0.2306386629740397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31974983215332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010003938805311918,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27428340911865234,
      "backward_entropy": 0.23104683558146158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.147110939025879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011003832332789898,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27427035570144653,
      "backward_entropy": 0.23104480902353922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.667497634887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012005246244370937,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742564380168915,
      "backward_entropy": 0.2305530309677124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.894915580749512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013006185181438923,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742406725883484,
      "backward_entropy": 0.23052374521891275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890172958374023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001400743261910975,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742226719856262,
      "backward_entropy": 0.2307654619216919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.655959129333496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015008922200649977,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742026448249817,
      "backward_entropy": 0.23046461741129556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.301349639892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016009877435863018,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741812467575073,
      "backward_entropy": 0.2304335037867228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.525617599487305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017009079456329346,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741588056087494,
      "backward_entropy": 0.23101492722829184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.569429397583008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018007558537647128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741347551345825,
      "backward_entropy": 0.23100666205088297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.886299133300781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019009299576282501,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741093337535858,
      "backward_entropy": 0.230997363726298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.455390930175781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002001158194616437,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740851044654846,
      "backward_entropy": 0.2309866944948832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.326597213745117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021016362588852644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27406075596809387,
      "backward_entropy": 0.23097487290700278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.727174758911133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002202268224209547,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27403539419174194,
      "backward_entropy": 0.23096183935801187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.845757484436035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023027765564620495,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740077078342438,
      "backward_entropy": 0.2301795482635498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.096487045288086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002403236459940672,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273978590965271,
      "backward_entropy": 0.2309321165084839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.615447998046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025041336193680763,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273947536945343,
      "backward_entropy": 0.23009562492370605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.860526084899902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026048398576676846,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739161252975464,
      "backward_entropy": 0.2304112116495768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.324451446533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027058711275458336,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738833427429199,
      "backward_entropy": 0.2300009330113729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.187190055847168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002807010430842638,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738533020019531,
      "backward_entropy": 0.2299500306447347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.723418235778809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002908546244725585,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273822546005249,
      "backward_entropy": 0.23028898239135742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.934246063232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0030098448041826487,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737922668457031,
      "backward_entropy": 0.22984262307484946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.143289566040039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031110120471566916,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737618386745453,
      "backward_entropy": 0.23019723097483316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.049757957458496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003212140640243888,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273730605840683,
      "backward_entropy": 0.2307457129160563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.933340072631836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003313217079266906,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736995220184326,
      "backward_entropy": 0.23009737332661948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.58851432800293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003414611564949155,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273667573928833,
      "backward_entropy": 0.2300442854563395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034540176391602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035161355044692755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27363449335098267,
      "backward_entropy": 0.23064271608988443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.945585250854492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036175420973449945,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736015319824219,
      "backward_entropy": 0.22946212689081827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.898153305053711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037188278511166573,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2735714018344879,
      "backward_entropy": 0.2298689285914103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.229569435119629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003819950157776475,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27353957295417786,
      "backward_entropy": 0.2305177847544352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.472869873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003921515308320522,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27350544929504395,
      "backward_entropy": 0.2292403777440389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630014419555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0040231565944850445,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2734719514846802,
      "backward_entropy": 0.22916158040364584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.670816421508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004124436527490616,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2734358310699463,
      "backward_entropy": 0.22907954454421997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.713500022888184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0042254505679011345,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2734004259109497,
      "backward_entropy": 0.22899373372395834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.331277847290039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004326283931732178,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733694911003113,
      "backward_entropy": 0.23025858402252197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.201287269592285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0044267443008720875,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27333950996398926,
      "backward_entropy": 0.23019830385843912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.44938850402832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004526801407337189,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2733094096183777,
      "backward_entropy": 0.2292924722035726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.697450637817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004626644309610128,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2732815742492676,
      "backward_entropy": 0.22860964139302573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.441184043884277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00472644018009305,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732577323913574,
      "backward_entropy": 0.22999962170918783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839499473571777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004826049320399761,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732352912425995,
      "backward_entropy": 0.22992732127507529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.538080215454102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004925661254674196,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732108533382416,
      "backward_entropy": 0.2289281686147054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02903938293457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0050256457179784775,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2731868326663971,
      "backward_entropy": 0.22817307710647583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.697534561157227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0051256692968308926,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27315932512283325,
      "backward_entropy": 0.2287264863650004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.18956470489502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0052255685441195965,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27312931418418884,
      "backward_entropy": 0.22862229744593301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.442317962646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005326063837856054,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730933725833893,
      "backward_entropy": 0.2278127670288086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.128589630126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005425798706710339,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27306246757507324,
      "backward_entropy": 0.22768473625183105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.081925392150879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005525665823370218,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730296850204468,
      "backward_entropy": 0.22755475838979086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722137451171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0056251599453389645,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730000913143158,
      "backward_entropy": 0.2274249792098999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.570839881896973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005724641960114241,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729717493057251,
      "backward_entropy": 0.22805607318878174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.515687942504883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005823489744216204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27294257283210754,
      "backward_entropy": 0.22904417912165323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.604737758636475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005922312848269939,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729165554046631,
      "backward_entropy": 0.2278077999750773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.669936180114746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0060206931084394455,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27290061116218567,
      "backward_entropy": 0.227680504322052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.793121337890625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006118690129369497,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728908956050873,
      "backward_entropy": 0.22872070471445718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.757771492004395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006217348854988813,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.272872656583786,
      "backward_entropy": 0.2274161179860433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.489115715026855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0063160997815430164,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728520929813385,
      "backward_entropy": 0.22848614056905112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.813505172729492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006414835806936026,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27283424139022827,
      "backward_entropy": 0.22623280684153238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.533010005950928,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006513664033263922,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27281132340431213,
      "backward_entropy": 0.2270050048828125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606616020202637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0066119167022407055,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27278757095336914,
      "backward_entropy": 0.22686409950256348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.203580379486084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00671022804453969,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27276116609573364,
      "backward_entropy": 0.2257076899210612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.825882911682129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006807851139456034,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727354168891907,
      "backward_entropy": 0.22657505671183267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02840805053711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006905253045260906,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727147936820984,
      "backward_entropy": 0.226423978805542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50999927520752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007003049831837416,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726917862892151,
      "backward_entropy": 0.22755571206410727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823235511779785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007101006340235472,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726762294769287,
      "backward_entropy": 0.22740701834360758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.373723983764648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007199208252131939,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27265873551368713,
      "backward_entropy": 0.2259441614151001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429104804992676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007297382690012455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27263975143432617,
      "backward_entropy": 0.22710134585698447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485742568969727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00739560229703784,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27262330055236816,
      "backward_entropy": 0.2256035010019938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.974173545837402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007493868470191956,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2726064920425415,
      "backward_entropy": 0.2240907351175944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.101642608642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00759192043915391,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27259328961372375,
      "backward_entropy": 0.22387230396270752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.338354110717773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007690431084483862,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2725849747657776,
      "backward_entropy": 0.22507377465566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.582551002502441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007788871880620718,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725743055343628,
      "backward_entropy": 0.22630488872528076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449236869812012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007887408137321472,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27256351709365845,
      "backward_entropy": 0.2247065305709839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.378751754760742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007985946722328663,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725515365600586,
      "backward_entropy": 0.22595715522766113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.057817459106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008084413595497608,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2725345492362976,
      "backward_entropy": 0.22271323204040527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73941421508789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008182710967957973,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27252137660980225,
      "backward_entropy": 0.22412918011347452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730643272399902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008281262591481209,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27251338958740234,
      "backward_entropy": 0.22392650445302328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.284019470214844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008380037732422352,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.272509902715683,
      "backward_entropy": 0.22521531581878662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.837339401245117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008478760719299316,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2725105881690979,
      "backward_entropy": 0.2216942310333252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.638761520385742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008577698841691017,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2725086212158203,
      "backward_entropy": 0.22328631083170572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.072351455688477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008677247911691666,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27249956130981445,
      "backward_entropy": 0.22115627924601236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.617353439331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008776497095823288,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27249038219451904,
      "backward_entropy": 0.2208791176478068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.868060111999512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008876314386725426,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27247482538223267,
      "backward_entropy": 0.2206080953280131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.97542953491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008975704200565815,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27246180176734924,
      "backward_entropy": 0.22033015886942545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.146125793457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009075304493308067,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27244511246681213,
      "backward_entropy": 0.22004695733388266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841860771179199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009175235405564308,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.272429883480072,
      "backward_entropy": 0.22190884749094644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.019216537475586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009274712763726711,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724170386791229,
      "backward_entropy": 0.22166780630747476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.144015312194824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009373871609568596,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27240413427352905,
      "backward_entropy": 0.21916248401006064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.00072956085205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009472301229834557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723994553089142,
      "backward_entropy": 0.22284936904907227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.419696807861328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00957051757723093,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27239394187927246,
      "backward_entropy": 0.2226186196009318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.288518905639648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009668789803981781,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723870575428009,
      "backward_entropy": 0.22069748242696127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.036492347717285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009767028503119946,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723780870437622,
      "backward_entropy": 0.22045226891835532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.655376434326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00986507348716259,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2723655700683594,
      "backward_entropy": 0.21752856175104776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.403844356536865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009962759912014008,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723543643951416,
      "backward_entropy": 0.22162729501724243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42406940460205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01005996111780405,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723427712917328,
      "backward_entropy": 0.22136525313059488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.484091758728027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010157381184399128,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27233442664146423,
      "backward_entropy": 0.21648534138997397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.097335815429688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010254940949380398,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723187208175659,
      "backward_entropy": 0.2208247184753418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.454626083374023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010352501645684242,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2723080515861511,
      "backward_entropy": 0.21576249599456787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.379972457885742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010450240224599838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722972333431244,
      "backward_entropy": 0.22026352087656656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919061660766602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0105481231585145,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27228933572769165,
      "backward_entropy": 0.2150339682896932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5709710121154785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010646400973200798,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27227717638015747,
      "backward_entropy": 0.21466139952341715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.076253890991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01074425969272852,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27226632833480835,
      "backward_entropy": 0.21428040663401285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9709625244140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010842597112059593,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722492218017578,
      "backward_entropy": 0.2190419634183248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198488235473633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010940751060843468,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27223315834999084,
      "backward_entropy": 0.21723113457361856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0657320022583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01103889849036932,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27221959829330444,
      "backward_entropy": 0.2169274091720581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.109720230102539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011136953718960285,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27220743894577026,
      "backward_entropy": 0.21661007404327393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.794675350189209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011234992183744907,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722005248069763,
      "backward_entropy": 0.21628127495447794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.724651336669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011332837864756584,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2721995711326599,
      "backward_entropy": 0.21186455090840658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1658034324646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01143043301999569,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722000479698181,
      "backward_entropy": 0.2156031926472982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.279116153717041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011527523398399353,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27220895886421204,
      "backward_entropy": 0.2152559757232666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.764914512634277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011624177917838097,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27221933007240295,
      "backward_entropy": 0.2105705738067627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.91576623916626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011721301823854446,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2722230553627014,
      "backward_entropy": 0.2101276715596517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.809994697570801,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011818330734968185,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722224295139313,
      "backward_entropy": 0.21417280038197836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485414505004883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011914714239537716,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722316384315491,
      "backward_entropy": 0.21380027135213217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.288233757019043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01201141718775034,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722328305244446,
      "backward_entropy": 0.21342164278030396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312281608581543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01210830733180046,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2722291350364685,
      "backward_entropy": 0.2082765301068624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.635697841644287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012204824015498161,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27222856879234314,
      "backward_entropy": 0.2126401662826538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.761133670806885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012300637550652027,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27223700284957886,
      "backward_entropy": 0.21360470851262411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.158783912658691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01239644642919302,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27224355936050415,
      "backward_entropy": 0.21319774786631265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.728769779205322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012492499314248562,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722475230693817,
      "backward_entropy": 0.21278937657674155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.530566215515137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012588507495820522,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27225005626678467,
      "backward_entropy": 0.212373157342275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.969126224517822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012684374116361141,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27225345373153687,
      "backward_entropy": 0.21195427576700845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61797046661377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012779824435710907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722642123699188,
      "backward_entropy": 0.21153336763381958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.599264144897461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012875867076218128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722713053226471,
      "backward_entropy": 0.21110379695892334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.168949127197266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012972431257367134,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27227598428726196,
      "backward_entropy": 0.20918460687001547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.103307723999023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013069195672869682,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27227869629859924,
      "backward_entropy": 0.2028584082921346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.015987396240234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013166061602532864,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722759544849396,
      "backward_entropy": 0.20823419094085693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.292445182800293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013262385502457619,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27227285504341125,
      "backward_entropy": 0.2093039552370707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.974849700927734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013359002768993378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27226415276527405,
      "backward_entropy": 0.20883444945017496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.90804672241211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013456305488944054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27224913239479065,
      "backward_entropy": 0.20835459232330322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092660903930664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013554141856729984,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27222490310668945,
      "backward_entropy": 0.20786339044570923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.042744636535645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013652052730321884,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27220410108566284,
      "backward_entropy": 0.20736650625864664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4207353591918945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01375050563365221,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2721722424030304,
      "backward_entropy": 0.2051560084025065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.385220527648926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013848526403307915,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2721444368362427,
      "backward_entropy": 0.20460979143778482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.780264377593994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013946756720542908,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.272115558385849,
      "backward_entropy": 0.2058220108350118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.936902046203613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014044811949133873,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2720889151096344,
      "backward_entropy": 0.19655632972717285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.404480934143066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014142792671918869,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2720620930194855,
      "backward_entropy": 0.2047602335611979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.682942867279053,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014240359887480736,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2720356583595276,
      "backward_entropy": 0.20233402649561563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.97712516784668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01433783583343029,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2720174491405487,
      "backward_entropy": 0.20367552836736044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.764307975769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014435897581279278,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2719879746437073,
      "backward_entropy": 0.19383136431376138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.671037197113037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01453314907848835,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271962970495224,
      "backward_entropy": 0.20255724589029947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.222151756286621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014630205929279327,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2719336748123169,
      "backward_entropy": 0.1924086014429728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3061347007751465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014726868830621243,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.271908164024353,
      "backward_entropy": 0.19930360714594522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.203939437866211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014823246747255325,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27188652753829956,
      "backward_entropy": 0.19867624839146933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.653749942779541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014919898472726345,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2718597650527954,
      "backward_entropy": 0.20022676388422647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.63039493560791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01501582469791174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2718375623226166,
      "backward_entropy": 0.19962014754613241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.276976108551025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015111086890101433,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27181950211524963,
      "backward_entropy": 0.1990086038907369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.215731620788574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015206174924969673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2718014717102051,
      "backward_entropy": 0.19838895400365195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.962959289550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015301029197871685,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2717800736427307,
      "backward_entropy": 0.1870680054028829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.934772491455078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015396173112094402,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27175259590148926,
      "backward_entropy": 0.1947206656138102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.507826328277588,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015491562895476818,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2717195153236389,
      "backward_entropy": 0.19400699933369955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.213590145111084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015586274676024914,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27169135212898254,
      "backward_entropy": 0.1932831605275472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.124614715576172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015680816024541855,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2716609239578247,
      "backward_entropy": 0.19254783789316812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.532920837402344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01577579788863659,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.271622896194458,
      "backward_entropy": 0.19179850816726685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.372100830078125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01587017811834812,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2715907096862793,
      "backward_entropy": 0.1936763127644857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.409337043762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015964601188898087,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27156102657318115,
      "backward_entropy": 0.18116931120554605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.724052429199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016059687361121178,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2715221047401428,
      "backward_entropy": 0.1802829702695211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.206642150878906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01615428924560547,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27148744463920593,
      "backward_entropy": 0.19147404034932455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4483642578125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016248730942606926,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27144932746887207,
      "backward_entropy": 0.19071650505065918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.997244358062744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016343187540769577,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2714049220085144,
      "backward_entropy": 0.18708272775014242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4555511474609375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016438057646155357,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27135440707206726,
      "backward_entropy": 0.18626906474431357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.42160177230835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01653299480676651,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2713063955307007,
      "backward_entropy": 0.17567425966262817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.270603656768799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016627972945570946,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2712606191635132,
      "backward_entropy": 0.18758676449457803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.471519470214844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016722196713089943,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27122220396995544,
      "backward_entropy": 0.18678967157999674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.178711891174316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016815833747386932,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2711843252182007,
      "backward_entropy": 0.1829037070274353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.977771759033203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016909444704651833,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27114337682724,
      "backward_entropy": 0.1851684252421061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.90572452545166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01700291596353054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2711023688316345,
      "backward_entropy": 0.18434188763300577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.477179050445557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017096176743507385,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2710573077201843,
      "backward_entropy": 0.1834972103436788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.484703063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01718902215361595,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2710178792476654,
      "backward_entropy": 0.16876872380574545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.842439651489258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017282754182815552,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2709578275680542,
      "backward_entropy": 0.18177354335784912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.858717918395996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01737758331000805,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27088192105293274,
      "backward_entropy": 0.17758095264434814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1194844245910645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017472054809331894,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2708057761192322,
      "backward_entropy": 0.17997602621714273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.880789279937744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017565608024597168,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27072659134864807,
      "backward_entropy": 0.1790661613146464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.364720821380615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01765897497534752,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27064794301986694,
      "backward_entropy": 0.17814737558364868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.543638706207275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017751868814229965,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27057862281799316,
      "backward_entropy": 0.16238771875699362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.520632743835449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017844421789050102,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2705113887786865,
      "backward_entropy": 0.17630193630854288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.721549987792969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017936009913682938,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27046018838882446,
      "backward_entropy": 0.17195266485214233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.960355281829834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018027523532509804,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27040666341781616,
      "backward_entropy": 0.17445061604181925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.854682922363281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018118487671017647,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27036288380622864,
      "backward_entropy": 0.17351718743642172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.401492118835449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01821027137339115,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27031102776527405,
      "backward_entropy": 0.1568586826324463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.601784706115723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018301719799637794,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2702569365501404,
      "backward_entropy": 0.17160298426946005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.264556884765625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01839308813214302,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27020516991615295,
      "backward_entropy": 0.17063377300898233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.223053932189941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018484104424715042,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27015385031700134,
      "backward_entropy": 0.16599307457605997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.678907871246338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018574779853224754,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.270102858543396,
      "backward_entropy": 0.16867355505625406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.439390659332275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018665479496121407,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27004677057266235,
      "backward_entropy": 0.1639369328816732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.297670841217041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01875600405037403,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2699849009513855,
      "backward_entropy": 0.1628986398379008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.744333744049072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018846260383725166,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26991695165634155,
      "backward_entropy": 0.1618561347325643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.595399379730225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018936604261398315,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26983773708343506,
      "backward_entropy": 0.16466168562571207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0623955726623535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01902698539197445,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26975592970848083,
      "backward_entropy": 0.15974777936935425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.210930824279785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019117016345262527,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2696775794029236,
      "backward_entropy": 0.1452602744102478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.695618629455566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019206877797842026,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2696036696434021,
      "backward_entropy": 0.16158042351404825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.119367599487305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019296919927001,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26952388882637024,
      "backward_entropy": 0.16053730249404907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4058685302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01938665844500065,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2694397568702698,
      "backward_entropy": 0.14166855812072754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.500292778015137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019476357847452164,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2693491578102112,
      "backward_entropy": 0.14045886198679605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.392823696136475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019566165283322334,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26925820112228394,
      "backward_entropy": 0.15735717614491782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.322317123413086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019656747579574585,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26915591955184937,
      "backward_entropy": 0.1562726398309072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.788100242614746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019746480509638786,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26907017827033997,
      "backward_entropy": 0.15096014738082886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3894429206848145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019835779443383217,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26898902654647827,
      "backward_entropy": 0.1541117231051127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.677720546722412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0199251901358366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2689087688922882,
      "backward_entropy": 0.15302231907844543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.366034507751465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02001333422958851,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26884520053863525,
      "backward_entropy": 0.15194096167882284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.818582534790039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020100846886634827,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26878249645233154,
      "backward_entropy": 0.15084155400594076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8179121017456055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020188122987747192,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.268709272146225,
      "backward_entropy": 0.14972686767578125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.179045677185059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020274432376027107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2686438262462616,
      "backward_entropy": 0.1441065470377604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.251300811767578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020360197871923447,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2685835361480713,
      "backward_entropy": 0.14296001195907593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.329391956329346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020446335896849632,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2685120403766632,
      "backward_entropy": 0.14637011289596558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.565995216369629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020532865077257156,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2684265971183777,
      "backward_entropy": 0.1406370004018148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.209056854248047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020619170740246773,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2683422267436981,
      "backward_entropy": 0.1394649843374888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6792473793029785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02070505917072296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26827144622802734,
      "backward_entropy": 0.14293126265207926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.578987121582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02079089917242527,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2681971788406372,
      "backward_entropy": 0.12206982572873433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.872397422790527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020876571536064148,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2681141793727875,
      "backward_entropy": 0.13591335217158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.028929710388184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020962411537766457,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2680261731147766,
      "backward_entropy": 0.13471782207489014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.457353115081787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021048543974757195,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26793068647384644,
      "backward_entropy": 0.13827173908551535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.905719757080078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021134452894330025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2678334712982178,
      "backward_entropy": 0.13709392150243124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.343142032623291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021220482885837555,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.267719030380249,
      "backward_entropy": 0.13590381542841592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.118467330932617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021306220442056656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26760461926460266,
      "backward_entropy": 0.13470983505249023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.566749572753906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021391479298472404,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26748865842819214,
      "backward_entropy": 0.12856781482696533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.678732395172119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02147582173347473,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26737767457962036,
      "backward_entropy": 0.1323192318280538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8544070720672607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021559476852416992,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.267272412776947,
      "backward_entropy": 0.11089370648066203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.055912971496582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021641848608851433,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26719290018081665,
      "backward_entropy": 0.12995747725168863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.478353977203369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021724099293351173,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26711007952690125,
      "backward_entropy": 0.10843722025553386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.663303375244141,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02180575393140316,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2670355439186096,
      "backward_entropy": 0.10721535483996074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.726709842681885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02188700996339321,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26695990562438965,
      "backward_entropy": 0.12123169501622517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.904196262359619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02196795679628849,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26687851548194885,
      "backward_entropy": 0.12001253167788188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.845387935638428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02204885147511959,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2667941153049469,
      "backward_entropy": 0.11878953377405803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.48087739944458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02212965488433838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2667068541049957,
      "backward_entropy": 0.12285480896631877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.958151817321777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022209975868463516,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2666137218475342,
      "backward_entropy": 0.11634368697802226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.024255275726318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02229035645723343,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2665097117424011,
      "backward_entropy": 0.11512208978335063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.158413887023926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02236993797123432,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26641446352005005,
      "backward_entropy": 0.09872589508692424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5826005935668945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022448936477303505,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2663235664367676,
      "backward_entropy": 0.11269452174504598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.051092147827148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022527901455760002,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2662357985973358,
      "backward_entropy": 0.09634620944658916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.469290733337402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02260715328156948,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2661232054233551,
      "backward_entropy": 0.11026221513748169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9359593391418457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022686166688799858,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2660044729709625,
      "backward_entropy": 0.11450660228729248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.498219966888428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02276446856558323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2658920884132385,
      "backward_entropy": 0.11331645647684734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9631717205047607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02284262701869011,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2657640278339386,
      "backward_entropy": 0.11212186018625896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3365397453308105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022920243442058563,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26564455032348633,
      "backward_entropy": 0.1109354595343272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.410679340362549,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02299768663942814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26551496982574463,
      "backward_entropy": 0.10974728067715962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.147096633911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023075101897120476,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26537761092185974,
      "backward_entropy": 0.08818003535270691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.256943702697754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023152178153395653,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2652309536933899,
      "backward_entropy": 0.1018681526184082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.247027635574341,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023229075595736504,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2650720775127411,
      "backward_entropy": 0.08589229981104533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6477749347686768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023304780945181847,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26492494344711304,
      "backward_entropy": 0.10500387350718181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7669386863708496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023379985243082047,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26479414105415344,
      "backward_entropy": 0.08365186055501302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.482365131378174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023454781621694565,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26466265320777893,
      "backward_entropy": 0.08254711826642354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.339947462081909,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023528892546892166,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26453351974487305,
      "backward_entropy": 0.1015382707118988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5566468238830566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023602157831192017,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2643994092941284,
      "backward_entropy": 0.0803652008374532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.475811004638672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02367505617439747,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2642701268196106,
      "backward_entropy": 0.09377304712931316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4429359436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023747485131025314,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2641388475894928,
      "backward_entropy": 0.07822227974732716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.959144353866577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02381952852010727,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26401209831237793,
      "backward_entropy": 0.09152816732724507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.672520875930786,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02389063872396946,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2638953626155853,
      "backward_entropy": 0.07612685362497966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4408316612243652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0239617470651865,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26376816630363464,
      "backward_entropy": 0.0893147091070811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.347395420074463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024032536894083023,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26362860202789307,
      "backward_entropy": 0.08821862936019897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.792311906814575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024102983996272087,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26348334550857544,
      "backward_entropy": 0.0926155944665273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.761415958404541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024172447621822357,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2633436322212219,
      "backward_entropy": 0.09153332312901814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5132336616516113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024241061881184578,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26321566104888916,
      "backward_entropy": 0.09046644965807597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.608625888824463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024308588355779648,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26310157775878906,
      "backward_entropy": 0.08394057552019756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3149445056915283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02437526360154152,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26299595832824707,
      "backward_entropy": 0.08289939165115356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8432116508483887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024440761655569077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26290029287338257,
      "backward_entropy": 0.08736903468767802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.756249189376831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024505948647856712,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2628040313720703,
      "backward_entropy": 0.08635903398195903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5054736137390137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024570800364017487,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26271286606788635,
      "backward_entropy": 0.06631085276603699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0682766437530518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024634940549731255,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2626229226589203,
      "backward_entropy": 0.08436473210652669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6780924797058105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024697935208678246,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26255205273628235,
      "backward_entropy": 0.08339430888493855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4612181186676025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0247606560587883,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2624707520008087,
      "backward_entropy": 0.0636153370141983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4412128925323486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024822890758514404,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26239046454429626,
      "backward_entropy": 0.08146806557973225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4043266773223877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024884553626179695,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26229923963546753,
      "backward_entropy": 0.08051586151123047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.65625262260437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024945730343461037,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26220396161079407,
      "backward_entropy": 0.061017374197642006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1431822776794434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025006862357258797,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2620978057384491,
      "backward_entropy": 0.07862735291322072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.390202045440674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025067182257771492,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2619922161102295,
      "backward_entropy": 0.059334377447764076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.227303981781006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025127165019512177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2618798017501831,
      "backward_entropy": 0.07677152752876282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1356732845306396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0251866914331913,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26177123188972473,
      "backward_entropy": 0.0758561243613561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4071640968322754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025245578959584236,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26165878772735596,
      "backward_entropy": 0.05689442654450735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.209524631500244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025304289534687996,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2615305185317993,
      "backward_entropy": 0.06852497160434723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.166206121444702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025362681597471237,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26140308380126953,
      "backward_entropy": 0.07315229872862498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.118150234222412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025420812889933586,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26128262281417847,
      "backward_entropy": 0.07226517796516418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.072253465652466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02547856979072094,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26116207242012024,
      "backward_entropy": 0.07138640681902568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1019287109375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02553584985435009,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2610349953174591,
      "backward_entropy": 0.06503477692604065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6595655679702759,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025592735037207603,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2608972489833832,
      "backward_entropy": 0.05229268471399943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3335192203521729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0256485752761364,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26076555252075195,
      "backward_entropy": 0.051567792892456055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6909879446029663,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025703124701976776,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26066431403160095,
      "backward_entropy": 0.06254284580548604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5834249258041382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025756927207112312,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26056191325187683,
      "backward_entropy": 0.0671801467736562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.13688325881958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02580990642309189,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26046252250671387,
      "backward_entropy": 0.06638781726360321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5170392990112305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025862926617264748,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2603304088115692,
      "backward_entropy": 0.06018234292666117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8478431701660156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025915009900927544,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.260197252035141,
      "backward_entropy": 0.06481062372525533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6074711084365845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02596682868897915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2600513994693756,
      "backward_entropy": 0.06403321027755737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8884559869766235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02601807191967964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2599090337753296,
      "backward_entropy": 0.0632664958635966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8107411861419678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026069365441799164,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25975435972213745,
      "backward_entropy": 0.04621403415997823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6560297012329102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026120638474822044,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2595938444137573,
      "backward_entropy": 0.056477561593055725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7089054584503174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026171492412686348,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2594241499900818,
      "backward_entropy": 0.06098299225171407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1176637411117554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026222091168165207,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2592424750328064,
      "backward_entropy": 0.06023329496383667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3950018882751465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026271482929587364,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2590852975845337,
      "backward_entropy": 0.05950722098350525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2851231098175049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632019855082035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2589263319969177,
      "backward_entropy": 0.05879325668017069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2947332859039307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026367992162704468,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25876250863075256,
      "backward_entropy": 0.05809406936168671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5325682163238525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0264151468873024,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2586028277873993,
      "backward_entropy": 0.05234691500663757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1849660873413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026462053880095482,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2584230899810791,
      "backward_entropy": 0.04150081177552541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9274705052375793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026508130133152008,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25824642181396484,
      "backward_entropy": 0.056054910024007164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2736361026763916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02655279077589512,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2580759525299072,
      "backward_entropy": 0.04044351478417715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.38608717918396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026596928015351295,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2578926980495453,
      "backward_entropy": 0.05477075278759003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.266292929649353,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02664097212255001,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25769761204719543,
      "backward_entropy": 0.04927170276641846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3005828857421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026684777811169624,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2575015723705292,
      "backward_entropy": 0.038932030399640404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3414359092712402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026728330180048943,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.257293701171875,
      "backward_entropy": 0.04810425639152527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3988033533096313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026771776378154755,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25707167387008667,
      "backward_entropy": 0.04753027359644572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9741746783256531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026815330609679222,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2568347752094269,
      "backward_entropy": 0.03747589886188507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1326969861984253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026858117431402206,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.256612628698349,
      "backward_entropy": 0.05102849006652832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3452210426330566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026900602504611015,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2563928961753845,
      "backward_entropy": 0.05042865872383118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8756780624389648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026943210512399673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25615382194519043,
      "backward_entropy": 0.049828022718429565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1049124002456665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026984738186001778,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25591984391212463,
      "backward_entropy": 0.035639877120653786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1537901163101196,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02702593430876732,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2556779980659485,
      "backward_entropy": 0.03520182271798452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0474644899368286,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0270670335739851,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25542721152305603,
      "backward_entropy": 0.04369798302650452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0480895042419434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027107732370495796,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25516992807388306,
      "backward_entropy": 0.03434372444947561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9344266057014465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027148021385073662,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2549012005329132,
      "backward_entropy": 0.04697189728418986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8113175630569458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027187708765268326,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25463035702705383,
      "backward_entropy": 0.033518269658088684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8021687269210815,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027226703241467476,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2543730139732361,
      "backward_entropy": 0.03312082588672638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5946967601776123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027264941483736038,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2541208267211914,
      "backward_entropy": 0.03273533284664154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.783561110496521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02730177342891693,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.253879189491272,
      "backward_entropy": 0.04486785332361857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9157301783561707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027338126674294472,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2536439001560211,
      "backward_entropy": 0.032006651163101196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6450575590133667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02737434208393097,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2533976137638092,
      "backward_entropy": 0.043889135122299194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7713875770568848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027409540489315987,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2531548738479614,
      "backward_entropy": 0.03942660987377167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.548717200756073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027444278821349144,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2529070973396301,
      "backward_entropy": 0.04295144478480021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6040560007095337,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027477962896227837,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.252672404050827,
      "backward_entropy": 0.03064979612827301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7014827728271484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02751081995666027,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25244104862213135,
      "backward_entropy": 0.03819183508555094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5131815671920776,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027543220669031143,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25220170617103577,
      "backward_entropy": 0.04163175821304321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7761923670768738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757474221289158,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25197547674179077,
      "backward_entropy": 0.029740703602631886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.541178822517395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606414631009102,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25174006819725037,
      "backward_entropy": 0.04079498598972956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6779542565345764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02763727866113186,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2515072524547577,
      "backward_entropy": 0.04038790116707484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.69899982213974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027667706832289696,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2512553334236145,
      "backward_entropy": 0.03630815943082174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.63456791639328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02769809402525425,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2509934902191162,
      "backward_entropy": 0.03595048189163208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.529504656791687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027728155255317688,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2507235109806061,
      "backward_entropy": 0.028350154558817547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4412538409233093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027757402509450912,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2504476308822632,
      "backward_entropy": 0.035259366035461426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46377286314964294,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027785783633589745,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25018101930618286,
      "backward_entropy": 0.027846882740656536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5524293184280396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781350165605545,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24992036819458008,
      "backward_entropy": 0.038072330256303154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5800257921218872,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027841057628393173,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24965831637382507,
      "backward_entropy": 0.03429083774487177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5056634545326233,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02786843106150627,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24938422441482544,
      "backward_entropy": 0.03735895703236262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5018613934516907,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027895361185073853,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24910511076450348,
      "backward_entropy": 0.033670430382092796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3515661954879761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027922002598643303,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24882453680038452,
      "backward_entropy": 0.03666578729947408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.474001944065094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027947796508669853,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24855804443359375,
      "backward_entropy": 0.03633450965086619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36709755659103394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02797333337366581,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24828892946243286,
      "backward_entropy": 0.036007377008597054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.550058901309967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02799798920750618,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24802017211914062,
      "backward_entropy": 0.03569226463635763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2940620183944702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028022879734635353,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2477378249168396,
      "backward_entropy": 0.03537432849407196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4867580831050873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028046581894159317,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24746069312095642,
      "backward_entropy": 0.025696692367394764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39242613315582275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02807023376226425,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24716982245445251,
      "backward_entropy": 0.03477118661006292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3323233723640442,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028093643486499786,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2468840628862381,
      "backward_entropy": 0.025329808394114178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41452449560165405,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02811650186777115,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24660667777061462,
      "backward_entropy": 0.031207901736100514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34353286027908325,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028139343485236168,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24632784724235535,
      "backward_entropy": 0.024972766637802124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34641075134277344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028161484748125076,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24604272842407227,
      "backward_entropy": 0.03361899654070536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4090617597103119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028183314949274063,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24576014280319214,
      "backward_entropy": 0.024634629487991333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3204880654811859,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028204983100295067,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24546308815479279,
      "backward_entropy": 0.03307292113701502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22910785675048828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028226109221577644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2451648712158203,
      "backward_entropy": 0.03280807286500931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30474716424942017,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0282460767775774,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2448704093694687,
      "backward_entropy": 0.024165213108062744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31062862277030945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02826567552983761,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24457630515098572,
      "backward_entropy": 0.03231553236643473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3008999526500702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028284847736358643,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2442767173051834,
      "backward_entropy": 0.03207788368066152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26128292083740234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028303537517786026,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24397045373916626,
      "backward_entropy": 0.03184599429368973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3426636755466461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02832169272005558,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2436666190624237,
      "backward_entropy": 0.031620716055234276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2837463915348053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340153396129608,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24336162209510803,
      "backward_entropy": 0.03139129529396693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22803886234760284,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028358517214655876,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24306151270866394,
      "backward_entropy": 0.028614908456802368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.219892218708992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02837642841041088,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24277153611183167,
      "backward_entropy": 0.030941198269526165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22754283249378204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02839377149939537,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24248725175857544,
      "backward_entropy": 0.023119769990444183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2955194413661957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02841058000922203,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24220331013202667,
      "backward_entropy": 0.030518189072608948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2590002119541168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028427664190530777,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24191704392433167,
      "backward_entropy": 0.027879709998766582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20965352654457092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028444766998291016,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24163244664669037,
      "backward_entropy": 0.030095964670181274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2815389335155487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02846134454011917,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24134954810142517,
      "backward_entropy": 0.02989208698272705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1598295271396637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028477877378463745,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24105137586593628,
      "backward_entropy": 0.022536329925060272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2537008225917816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849351055920124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24075879156589508,
      "backward_entropy": 0.02949845294157664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.163204163312912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028509194031357765,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24045813083648682,
      "backward_entropy": 0.029306747019290924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21642515063285828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028524024412035942,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24015794694423676,
      "backward_entropy": 0.02687840660413106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2096668779850006,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028538504615426064,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23984768986701965,
      "backward_entropy": 0.02673370639483134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1499650478363037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028553003445267677,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23953869938850403,
      "backward_entropy": 0.02877075473467509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1661306917667389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028566833585500717,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2392345666885376,
      "backward_entropy": 0.02645063151915868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13096068799495697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028580401092767715,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23893645405769348,
      "backward_entropy": 0.028437115252017975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2260507047176361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028593413531780243,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2386491596698761,
      "backward_entropy": 0.028279460966587067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21996617317199707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02860679291188717,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2383541464805603,
      "backward_entropy": 0.026051712532838184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1947275847196579,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620364144444466,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23804888129234314,
      "backward_entropy": 0.027948200702667236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1795540750026703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028633909299969673,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2377380132675171,
      "backward_entropy": 0.025784209370613098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14688946306705475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028647350147366524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2374258041381836,
      "backward_entropy": 0.02761521687110265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12506340444087982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866055630147457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23712152242660522,
      "backward_entropy": 0.027451664209365845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18865475058555603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02867341786623001,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2368295043706894,
      "backward_entropy": 0.027292524774869282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16387756168842316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028686286881566048,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2365250289440155,
      "backward_entropy": 0.027132757008075714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1516813039779663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028699291869997978,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23622286319732666,
      "backward_entropy": 0.026971787214279175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.146588996052742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028712235391139984,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23592102527618408,
      "backward_entropy": 0.021176102260748546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14036649465560913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028725098818540573,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23562407493591309,
      "backward_entropy": 0.02665491650501887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12207243591547012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02873796783387661,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2353326678276062,
      "backward_entropy": 0.024768563608328503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13557781279087067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875065989792347,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23504795134067535,
      "backward_entropy": 0.026343020300070446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13480809330940247,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028762971982359886,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23475584387779236,
      "backward_entropy": 0.020878002047538757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1008063554763794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0287751704454422,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2344607412815094,
      "backward_entropy": 0.02604404091835022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0906478613615036,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02878684364259243,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23416997492313385,
      "backward_entropy": 0.02074488252401352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0723453089594841,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028798025101423264,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2338869571685791,
      "backward_entropy": 0.025765709578990936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08255021274089813,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028808455914258957,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23361262679100037,
      "backward_entropy": 0.02409382164478302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07987141609191895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028818629682064056,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23334988951683044,
      "backward_entropy": 0.025515372554461162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08343823254108429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028828555718064308,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2330978363752365,
      "backward_entropy": 0.02539554238319397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10150589793920517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02883824333548546,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2328520566225052,
      "backward_entropy": 0.023817559083302815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06738696992397308,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028847886249423027,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23260411620140076,
      "backward_entropy": 0.023728137214978535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11296854168176651,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028857240453362465,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23236778378486633,
      "backward_entropy": 0.02039363607764244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07101502269506454,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02886682003736496,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23212328553199768,
      "backward_entropy": 0.02493435392777125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07999756932258606,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028875956311821938,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23188111186027527,
      "backward_entropy": 0.023466954628626507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06502899527549744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028884943574666977,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2316400110721588,
      "backward_entropy": 0.024716700116793316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0722975954413414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0288936085999012,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23140475153923035,
      "backward_entropy": 0.024612943331400555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06590168178081512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02890201285481453,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2311697155237198,
      "backward_entropy": 0.024512072404225666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06623432785272598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02891012839972973,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23093685507774353,
      "backward_entropy": 0.020144933213790257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07801391184329987,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02891809493303299,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23070776462554932,
      "backward_entropy": 0.023081685105959576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.057511258870363235,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028926165774464607,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2304781973361969,
      "backward_entropy": 0.020074602216482162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05952368304133415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028934065252542496,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23025555908679962,
      "backward_entropy": 0.024126961827278137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052623242139816284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028941601514816284,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23003187775611877,
      "backward_entropy": 0.02403617650270462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06794141978025436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028948837891221046,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22981181740760803,
      "backward_entropy": 0.0239491139849027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05950134992599487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028955994173884392,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22958633303642273,
      "backward_entropy": 0.023862816393375397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06607430428266525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028963178396224976,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22936362028121948,
      "backward_entropy": 0.019923885663350422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045963652431964874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02897034026682377,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22913673520088196,
      "backward_entropy": 0.02369004487991333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054435551166534424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02897701784968376,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22891035676002502,
      "backward_entropy": 0.02255767087141673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.047568514943122864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028983695432543755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22868642210960388,
      "backward_entropy": 0.02352851877609889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041664499789476395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028990253806114197,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22846662998199463,
      "backward_entropy": 0.023449381192525227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06531891226768494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02899637259542942,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22824719548225403,
      "backward_entropy": 0.023375019431114197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04289483651518822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029002731665968895,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2280212640762329,
      "backward_entropy": 0.023297893504301708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050932783633470535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029008803889155388,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22779595851898193,
      "backward_entropy": 0.023223986228307087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050374697893857956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02901495434343815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22757072746753693,
      "backward_entropy": 0.023151695728302002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03701534867286682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02902109920978546,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2273450642824173,
      "backward_entropy": 0.019727199027935665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04371420666575432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029027059674263,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2271260917186737,
      "backward_entropy": 0.02301060160001119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03398510441184044,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029033206403255463,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.226914644241333,
      "backward_entropy": 0.019675736625989277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04276559501886368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029039183631539345,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22671006619930267,
      "backward_entropy": 0.022860683500766754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04020709544420242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02904503233730793,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2265022248029709,
      "backward_entropy": 0.021999975045522053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032590217888355255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029050815850496292,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22629351913928986,
      "backward_entropy": 0.021947786211967468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039314884692430496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029056314378976822,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22608590126037598,
      "backward_entropy": 0.021899431943893433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028752898797392845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02906179428100586,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22587689757347107,
      "backward_entropy": 0.022585501273473103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03440209478139877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02906724624335766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22567714750766754,
      "backward_entropy": 0.022522124151388805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03653145581483841,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029072662815451622,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22547844052314758,
      "backward_entropy": 0.02175399164358775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029677456244826317,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029078098013997078,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22527851164340973,
      "backward_entropy": 0.021704355875651043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032798461616039276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029083363711833954,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22508013248443604,
      "backward_entropy": 0.022327639162540436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024726001545786858,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0290885828435421,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22488132119178772,
      "backward_entropy": 0.0216086283326149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026010815054178238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02909369207918644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22468876838684082,
      "backward_entropy": 0.02156224598487218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023281153291463852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02909855730831623,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2244962453842163,
      "backward_entropy": 0.02214318762222926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022967392578721046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029103197157382965,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22430619597434998,
      "backward_entropy": 0.022089608013629913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0243854857981205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029107708483934402,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22412070631980896,
      "backward_entropy": 0.022036691506703694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024660322815179825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029112281277775764,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22394070029258728,
      "backward_entropy": 0.021981241802374523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019395623356103897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02911682054400444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2237626314163208,
      "backward_entropy": 0.02192478875319163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019842540845274925,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029121195897459984,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2235894352197647,
      "backward_entropy": 0.021313853561878204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022404495626688004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02912553958594799,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2234216034412384,
      "backward_entropy": 0.02127286543448766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02161000296473503,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02912992052733898,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22325479984283447,
      "backward_entropy": 0.0192362442612648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017779795452952385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029134226962924004,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22308728098869324,
      "backward_entropy": 0.021716279288132984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0233285091817379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029138388112187386,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22292283177375793,
      "backward_entropy": 0.021667033433914185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019307779148221016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029142526909708977,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22275468707084656,
      "backward_entropy": 0.021618172526359558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014985230751335621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029146593064069748,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2225871980190277,
      "backward_entropy": 0.019164131333430607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013986153528094292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029150497168302536,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2224242389202118,
      "backward_entropy": 0.02105081578095754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015344696119427681,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029154114425182343,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22226335108280182,
      "backward_entropy": 0.02147948493560155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01717151701450348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02915758080780506,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22210384905338287,
      "backward_entropy": 0.021437438825766247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014619164168834686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02916097082197666,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22194302082061768,
      "backward_entropy": 0.02139801283677419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013893919996917248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029164353385567665,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22178679704666138,
      "backward_entropy": 0.021358370780944824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013643445447087288,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02916765958070755,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22163346409797668,
      "backward_entropy": 0.01909352590640386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014576028101146221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029170872643589973,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22148224711418152,
      "backward_entropy": 0.021279188493887585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01131235621869564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02917417883872986,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22133450210094452,
      "backward_entropy": 0.021237410604953766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013171965256333351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029177343472838402,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22119005024433136,
      "backward_entropy": 0.021198848883310955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014761494472622871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918047085404396,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22104644775390625,
      "backward_entropy": 0.02116102973620097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012077930383384228,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029183732345700264,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22090309858322144,
      "backward_entropy": 0.020757101476192474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010595010593533516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918701246380806,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22076201438903809,
      "backward_entropy": 0.021083034574985504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012316888198256493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029190190136432648,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2206231653690338,
      "backward_entropy": 0.0210451806584994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010680140927433968,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029193341732025146,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2204834520816803,
      "backward_entropy": 0.020671976109345753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00938735343515873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196500778198242,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2203466296195984,
      "backward_entropy": 0.02097024768590927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009605644270777702,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919955551624298,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22021234035491943,
      "backward_entropy": 0.02061911424001058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009546938352286816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029202457517385483,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22007817029953003,
      "backward_entropy": 0.020594999194145203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007441890891641378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029205303639173508,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21994543075561523,
      "backward_entropy": 0.020571205765008926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0077245356515049934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920803241431713,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21981683373451233,
      "backward_entropy": 0.020832693825165432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00759834423661232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029210815206170082,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2196943759918213,
      "backward_entropy": 0.02079978088537852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007348265498876572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02921346016228199,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195734977722168,
      "backward_entropy": 0.020769032339255016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006052391137927771,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02921602688729763,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21945512294769287,
      "backward_entropy": 0.020480507363875706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008170348592102528,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029218364506959915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21933850646018982,
      "backward_entropy": 0.02071071167786916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007210341282188892,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0292207021266222,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2192220240831375,
      "backward_entropy": 0.02043930192788442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0061370679177343845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02922305464744568,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2191077470779419,
      "backward_entropy": 0.020652224620183308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005917784292250872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02922540344297886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2189968377351761,
      "backward_entropy": 0.020624152074257534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005023641977459192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029227787628769875,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21888992190361023,
      "backward_entropy": 0.020595888296763103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005835830233991146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029230041429400444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21878552436828613,
      "backward_entropy": 0.020569076140721638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005712606944143772,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029232284054160118,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21868263185024261,
      "backward_entropy": 0.020542658865451813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005226958077400923,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02923445589840412,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21858006715774536,
      "backward_entropy": 0.018836998691161472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005519982893019915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029236547648906708,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21847859025001526,
      "backward_entropy": 0.020492105434338253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005763269495218992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029238630086183548,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21837806701660156,
      "backward_entropy": 0.01882455249627431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004394241608679295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029240721836686134,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21827754378318787,
      "backward_entropy": 0.020261564602454502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004410663619637489,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029242761433124542,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21817967295646667,
      "backward_entropy": 0.02041805535554886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004445140715688467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029244687408208847,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21808233857154846,
      "backward_entropy": 0.0188081959883372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004770155064761639,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029246555641293526,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21798618137836456,
      "backward_entropy": 0.020214964946111042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035175438970327377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029248451814055443,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21789129078388214,
      "backward_entropy": 0.020198486745357513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004196551628410816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029250258579850197,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2177990972995758,
      "backward_entropy": 0.020182359963655472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004256617743521929,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02925211563706398,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21770936250686646,
      "backward_entropy": 0.020305760204792023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003257256466895342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029253941029310226,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2176194041967392,
      "backward_entropy": 0.02028353015581767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030404231511056423,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029255753383040428,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21753272414207458,
      "backward_entropy": 0.018767893314361572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038127689622342587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029257528483867645,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21744900941848755,
      "backward_entropy": 0.02024064213037491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002935315016657114,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029259290546178818,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21736449003219604,
      "backward_entropy": 0.018753156065940857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026095325592905283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029260991141200066,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2172815203666687,
      "backward_entropy": 0.020199425518512726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028269002214074135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0292626041918993,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21720045804977417,
      "backward_entropy": 0.02018016328414281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021510268561542034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029264142736792564,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21711991727352142,
      "backward_entropy": 0.02016175041596095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002531887963414192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02926555834710598,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21704165637493134,
      "backward_entropy": 0.020144755641619366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022399206645786762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029266897588968277,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21696411073207855,
      "backward_entropy": 0.02003240833679835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002364502754062414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029268227517604828,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21688950061798096,
      "backward_entropy": 0.02002199615041415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002157378476113081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029269535094499588,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21681630611419678,
      "backward_entropy": 0.020096555352211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024124388583004475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0292708408087492,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21674537658691406,
      "backward_entropy": 0.020080956319967907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018826175946742296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029272155836224556,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667525172233582,
      "backward_entropy": 0.020065573354562122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002121135126799345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02927342988550663,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21660734713077545,
      "backward_entropy": 0.020050910611947376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019896035082638264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029274703934788704,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2165406048297882,
      "backward_entropy": 0.020035532613595326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017741881310939789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029276037588715553,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2164766639471054,
      "backward_entropy": 0.020019111533959705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015401869313791394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029277320951223373,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2164137363433838,
      "backward_entropy": 0.020003522435824077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016587066929787397,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029278544709086418,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2163524627685547,
      "backward_entropy": 0.01998852441708247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015162902418524027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029279813170433044,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2162938416004181,
      "backward_entropy": 0.01992081602414449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015160016482695937,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029281064867973328,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21623681485652924,
      "backward_entropy": 0.019908854116996128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001130552962422371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029282327741384506,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21618159115314484,
      "backward_entropy": 0.019943855702877045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013035722076892853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029283521696925163,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21612854301929474,
      "backward_entropy": 0.018686556567748386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001589789753779769,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029284661635756493,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21607612073421478,
      "backward_entropy": 0.01991656795144081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012710212031379342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02928585186600685,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21602383255958557,
      "backward_entropy": 0.01986475537220637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012143837520852685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029287025332450867,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21597248315811157,
      "backward_entropy": 0.019889165957768757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001049252925440669,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02928818203508854,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21592210233211517,
      "backward_entropy": 0.01866961643099785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011153568048030138,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029289254918694496,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21587224304676056,
      "backward_entropy": 0.018666543066501617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011864954140037298,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029290296137332916,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2158230096101761,
      "backward_entropy": 0.01866382857163747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000778043526224792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029291309416294098,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21577365696430206,
      "backward_entropy": 0.019839877883593243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009192984434776008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029292255640029907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21572646498680115,
      "backward_entropy": 0.019829002519448597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009488388895988464,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029293211176991463,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2156813144683838,
      "backward_entropy": 0.019817682603995006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008583351736888289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029294151812791824,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2156369388103485,
      "backward_entropy": 0.01865299791097641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009258998325094581,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029295042157173157,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21559306979179382,
      "backward_entropy": 0.018650429944197338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000784686766564846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029295966029167175,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2155502587556839,
      "backward_entropy": 0.01978464052081108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007572618778795004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029296839609742165,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21550777554512024,
      "backward_entropy": 0.019774768501520157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006728172884322703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02929769456386566,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21546626091003418,
      "backward_entropy": 0.019764941185712814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006006444455124438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029298532754182816,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2154262363910675,
      "backward_entropy": 0.01975513994693756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007657743990421295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029299341142177582,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.215387761592865,
      "backward_entropy": 0.0197456032037735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006375947850756347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029300138354301453,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.215349018573761,
      "backward_entropy": 0.019736022998889286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005661517498083413,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029300902038812637,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2153107225894928,
      "backward_entropy": 0.018633238971233368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006750947213731706,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029301637783646584,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21527346968650818,
      "backward_entropy": 0.019725407163302105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005282561178319156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02930237539112568,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21523627638816833,
      "backward_entropy": 0.019718510409196217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004650048795156181,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02930305339396,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21519942581653595,
      "backward_entropy": 0.01970098416010539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005495159421116114,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029303720220923424,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21516430377960205,
      "backward_entropy": 0.01862604667743047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003878890711348504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029304368421435356,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21512925624847412,
      "backward_entropy": 0.01969976971546809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037330581108108163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02930498495697975,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21509578824043274,
      "backward_entropy": 0.01967742294073105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004081293591298163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02930559404194355,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2150641679763794,
      "backward_entropy": 0.019670162349939346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00045335936010815203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029306162148714066,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21503287553787231,
      "backward_entropy": 0.019683033227920532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004397724405862391,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02930673211812973,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2150018811225891,
      "backward_entropy": 0.0196564681828022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003246027627028525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029307309538125992,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21497124433517456,
      "backward_entropy": 0.019649571428696316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004168018640484661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029307896271348,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21494244039058685,
      "backward_entropy": 0.019642837345600128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041246297769248486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029308490455150604,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2149137258529663,
      "backward_entropy": 0.019635771711667378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002940460399258882,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029309092089533806,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21488499641418457,
      "backward_entropy": 0.01861448089281718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000334442884195596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029309678822755814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21485750377178192,
      "backward_entropy": 0.019621805598338444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029162588180042803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029310261830687523,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21483048796653748,
      "backward_entropy": 0.019615011910597484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003082863404415548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029310865327715874,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21480487287044525,
      "backward_entropy": 0.019608035683631897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035140971885994077,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029311468824744225,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21477967500686646,
      "backward_entropy": 0.018606096506118774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000264698697719723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02931208163499832,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2147541642189026,
      "backward_entropy": 0.018603496253490448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022781788720749319,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02931266464293003,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2147289216518402,
      "backward_entropy": 0.01962389051914215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026788408285938203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293132234364748,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2147045135498047,
      "backward_entropy": 0.019580955306688946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025408685905858874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029313737526535988,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2146795094013214,
      "backward_entropy": 0.019574925303459167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001966447598533705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029314229264855385,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21465438604354858,
      "backward_entropy": 0.01956912750999133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020512743503786623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931470237672329,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21463023126125336,
      "backward_entropy": 0.019563928246498108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002080485428450629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029315149411559105,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21460643410682678,
      "backward_entropy": 0.01955895498394966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020330694678705186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029315585270524025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21458309888839722,
      "backward_entropy": 0.019553857545057934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000190556442248635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931600622832775,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21455997228622437,
      "backward_entropy": 0.019548868139584858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014468411973211914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931642159819603,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2145373523235321,
      "backward_entropy": 0.01954379181067149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001557259529363364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931683138012886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21451613306999207,
      "backward_entropy": 0.019538750251134235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015767753939144313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293172225356102,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21449536085128784,
      "backward_entropy": 0.0195338341097037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001417163002770394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931760810315609,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2144751250743866,
      "backward_entropy": 0.019529058287541073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013821675383951515,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02931799367070198,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21445566415786743,
      "backward_entropy": 0.018588195244471233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013955669419374317,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02931835688650608,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21443641185760498,
      "backward_entropy": 0.01957249144713084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013195566134527326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029318710789084435,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21441742777824402,
      "backward_entropy": 0.01951598251859347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011873037146870047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029319068416953087,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21439900994300842,
      "backward_entropy": 0.019511739412943523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010601535905152559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029319435358047485,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2143813967704773,
      "backward_entropy": 0.019507333636283875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011843456013593823,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029319798573851585,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21436452865600586,
      "backward_entropy": 0.018583523730436962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010455562733113766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029320167377591133,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21434801816940308,
      "backward_entropy": 0.019498827556769054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011848039866890758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932053618133068,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21433193981647491,
      "backward_entropy": 0.019494531055291493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.393005166202784e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029320916160941124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21431589126586914,
      "backward_entropy": 0.019490177432696026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528071728302166e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029321294277906418,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21430033445358276,
      "backward_entropy": 0.019485828777154286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.650036372477189e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029321661219000816,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21428558230400085,
      "backward_entropy": 0.019481676320234936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902352808741853e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029322030022740364,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21427090466022491,
      "backward_entropy": 0.01953860620657603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.678396650590003e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029322387650609016,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21425661444664001,
      "backward_entropy": 0.01947345460454623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.400068377843127e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932271920144558,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21424242854118347,
      "backward_entropy": 0.01946968212723732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.502198812086135e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029323052614927292,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2142290621995926,
      "backward_entropy": 0.019529619564612705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.859038694528863e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932337112724781,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21421608328819275,
      "backward_entropy": 0.019462468723456066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.537988519994542e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029323680326342583,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21420331299304962,
      "backward_entropy": 0.019458965708812077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.385985761880875e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029323969036340714,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2141905575990677,
      "backward_entropy": 0.019455621639887493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.315867358352989e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029324248433113098,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2141779065132141,
      "backward_entropy": 0.018566787242889404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.959226473351009e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932450734078884,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21416515111923218,
      "backward_entropy": 0.019449283679326374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.832003833143972e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02932475320994854,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21415236592292786,
      "backward_entropy": 0.019513944784800213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.675221837009303e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029325006529688835,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21414022147655487,
      "backward_entropy": 0.019443367918332417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0192251617554575e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029325248673558235,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21412792801856995,
      "backward_entropy": 0.019440514345963795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.434214497450739e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029325492680072784,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21411633491516113,
      "backward_entropy": 0.019506809612115223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4979100493947044e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029325734823942184,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2141050100326538,
      "backward_entropy": 0.019434839487075806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.530622780090198e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029325958341360092,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21409371495246887,
      "backward_entropy": 0.01950252056121826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9408500267891213e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029326174408197403,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21408285200595856,
      "backward_entropy": 0.019429622838894527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.839221244561486e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029326384887099266,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21407276391983032,
      "backward_entropy": 0.018560389677683514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9179826015024446e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02932658977806568,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2140626609325409,
      "backward_entropy": 0.01949680969119072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.292057226644829e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293267872184515,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21405303478240967,
      "backward_entropy": 0.019422471523284912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.67525374511024e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029326967895030975,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2140435129404068,
      "backward_entropy": 0.019420335690180462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.814452091115527e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029327144846320152,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21403439342975616,
      "backward_entropy": 0.01941820979118347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.779121496132575e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932731807231903,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21402551233768463,
      "backward_entropy": 0.019416195650895435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4702458176761866e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029327495023608208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.214016854763031,
      "backward_entropy": 0.018558308482170105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.42834139498882e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932766266167164,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2140084058046341,
      "backward_entropy": 0.019412202139695484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.414005393802654e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02932782843708992,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21400021016597748,
      "backward_entropy": 0.01948544631401698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3073611373547465e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029327984899282455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21399205923080444,
      "backward_entropy": 0.01940825581550598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0269351807655767e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029328135773539543,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21398398280143738,
      "backward_entropy": 0.019406460225582123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6613386833341792e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029328281059861183,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21397608518600464,
      "backward_entropy": 0.01940475155909856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.503313978901133e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029328424483537674,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2139686644077301,
      "backward_entropy": 0.019403081387281418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.652955324971117e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029328569769859314,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21396176517009735,
      "backward_entropy": 0.01947850485642751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6905029042391106e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029328709468245506,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2139550745487213,
      "backward_entropy": 0.019477137674887974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4519959222525358e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293288454413414,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21394848823547363,
      "backward_entropy": 0.019398123025894165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5212647667794954e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029328975826501846,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21394217014312744,
      "backward_entropy": 0.019396572063366573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.612612140888814e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029329098761081696,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2139359414577484,
      "backward_entropy": 0.01939516266187032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.403926307830261e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029329214245080948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21392971277236938,
      "backward_entropy": 0.019393826524416607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1442463801358826e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029329324141144753,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21392351388931274,
      "backward_entropy": 0.01939247300227483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.268738014914561e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029329434037208557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21391767263412476,
      "backward_entropy": 0.01939118653535843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2450643225747626e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029329534620046616,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21391189098358154,
      "backward_entropy": 0.019469164311885834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0039312655862886e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029329633340239525,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21390613913536072,
      "backward_entropy": 0.018554856379826862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0672651114873588e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029329730197787285,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.213900625705719,
      "backward_entropy": 0.01855481540163358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0509253115742467e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029329825192689896,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21389520168304443,
      "backward_entropy": 0.019466324398914974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.707457138574682e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02932991459965706,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21388985216617584,
      "backward_entropy": 0.01946546509861946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.245232493209187e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029329998418688774,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21388459205627441,
      "backward_entropy": 0.019464631875356037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.041967132361606e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029330087825655937,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21387949585914612,
      "backward_entropy": 0.019463735322157543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.485467671765946e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029330167919397354,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21387448906898499,
      "backward_entropy": 0.01946297784646352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.965153261262458e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029330240562558174,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21386942267417908,
      "backward_entropy": 0.018554985523223877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.45098668630817e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029330311343073845,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21386462450027466,
      "backward_entropy": 0.019380512336889904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.759130883438047e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029330380260944366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2138599157333374,
      "backward_entropy": 0.019379649311304092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.377669251378393e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933044545352459,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21385537087917328,
      "backward_entropy": 0.019460337857405346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.161258170322981e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029330510646104813,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2138509601354599,
      "backward_entropy": 0.01945968096454938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9893350226047914e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029330572113394737,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21384666860103607,
      "backward_entropy": 0.01937723656495412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.569499990087934e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029330629855394363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2138424962759018,
      "backward_entropy": 0.01937651013334592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.655366749124369e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933068759739399,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21383842825889587,
      "backward_entropy": 0.019457906484603882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.38902804692043e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029330741614103317,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21383436024188995,
      "backward_entropy": 0.01937507341305415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0016757338889875e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029330790042877197,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21383041143417358,
      "backward_entropy": 0.018556473155816395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3089194150525145e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029330842196941376,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21382665634155273,
      "backward_entropy": 0.018556630859772365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.344737590145087e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029330894351005554,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21382305026054382,
      "backward_entropy": 0.018556777387857437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.420332061272347e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029330946505069733,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2138194441795349,
      "backward_entropy": 0.019455270220836002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3671028631943045e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029330993071198463,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21381589770317078,
      "backward_entropy": 0.019371911883354187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.525788997649215e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331039637327194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21381258964538574,
      "backward_entropy": 0.019371330738067627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3628675737418234e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029331088066101074,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21380934119224548,
      "backward_entropy": 0.019453865786393482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7629296255327063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331132769584656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21380624175071716,
      "backward_entropy": 0.019370132436354954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.81300458482292e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331181198358536,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21380332112312317,
      "backward_entropy": 0.01936956246693929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.65878679783782e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331227764487267,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2138006091117859,
      "backward_entropy": 0.019368956486384075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.57228907685203e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331276193261147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21379798650741577,
      "backward_entropy": 0.019368375341097515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.423668547635316e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331324622035027,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21379545331001282,
      "backward_entropy": 0.019367811580499012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.375511030550115e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331373050808907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21379297971725464,
      "backward_entropy": 0.019367252786954243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1271348487061914e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029331419616937637,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21379056572914124,
      "backward_entropy": 0.019450294474760692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9278827494417783e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331466183066368,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21378828585147858,
      "backward_entropy": 0.019366107881069183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8581001768325223e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331514611840248,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137860804796219,
      "backward_entropy": 0.019365576406319935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.885442202365084e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331563040614128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21378400921821594,
      "backward_entropy": 0.019365017612775166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.135467639163835e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933160960674286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21378202736377716,
      "backward_entropy": 0.019364483654499054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5861982092246762e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331648722290993,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.213780015707016,
      "backward_entropy": 0.019364065180222195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6203988479901454e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331687837839127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21377809345722198,
      "backward_entropy": 0.019363590826590855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.47194953115104e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933172509074211,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21377629041671753,
      "backward_entropy": 0.019363115231196087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.300771941714629e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331762343645096,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21377454698085785,
      "backward_entropy": 0.019362684339284897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4593463220080594e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933179959654808,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2137729525566101,
      "backward_entropy": 0.019446189204851787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.227189386554528e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331834986805916,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21377134323120117,
      "backward_entropy": 0.019361786544322968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.073570160770032e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933187037706375,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2137698233127594,
      "backward_entropy": 0.019445327421029408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0396790912636789e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029331905767321587,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21376840770244598,
      "backward_entropy": 0.019444863001505535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1171918004038162e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331941157579422,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21376708149909973,
      "backward_entropy": 0.019360570857922237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.535195661352191e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331974685192108,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21376575529575348,
      "backward_entropy": 0.019360192120075226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.075750426745799e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029332010075449944,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21376457810401917,
      "backward_entropy": 0.018557115147511166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.692823823570507e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933204546570778,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21376344561576843,
      "backward_entropy": 0.019359381248553593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.379441851502634e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332077130675316,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137623131275177,
      "backward_entropy": 0.01935902362068494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471473051940848e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332108795642853,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21376124024391174,
      "backward_entropy": 0.01935867468516032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.500834501821373e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933213859796524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21376018226146698,
      "backward_entropy": 0.019358325749635696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.588961127818038e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332168400287628,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2137591540813446,
      "backward_entropy": 0.019441769768794376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.179144520501723e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332198202610016,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.213758185505867,
      "backward_entropy": 0.019357673823833466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.603866609111719e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029332228004932404,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21375726163387299,
      "backward_entropy": 0.018556727717320125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.792929075847496e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332255944609642,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21375635266304016,
      "backward_entropy": 0.019440704335769016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.219960144131619e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933228574693203,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137555032968521,
      "backward_entropy": 0.019356704006592434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2386994891785434e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332315549254417,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21375471353530884,
      "backward_entropy": 0.019356379906336468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.863342724092945e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332345351576805,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21375393867492676,
      "backward_entropy": 0.01935604338844617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1799248151619395e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332373291254044,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21375322341918945,
      "backward_entropy": 0.01935575654109319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6046548618505767e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332401230931282,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21375250816345215,
      "backward_entropy": 0.019355451067288715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1051461607821693e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933242730796337,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21375176310539246,
      "backward_entropy": 0.01855609069267909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.592583024987107e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933245338499546,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21375112235546112,
      "backward_entropy": 0.01935487985610962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.005914948062127e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293324775993824,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137504518032074,
      "backward_entropy": 0.019354605426390965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1825265384431987e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933250181376934,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21374982595443726,
      "backward_entropy": 0.018555904428164165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.770254011215002e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933252416551113,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21374920010566711,
      "backward_entropy": 0.018555882076422375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7796204449259676e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332544654607773,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21374854445457458,
      "backward_entropy": 0.019353891412417095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3789393683036906e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332565143704414,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21374788880348206,
      "backward_entropy": 0.019353677829106648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0702977937835385e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332583770155907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21374724805355072,
      "backward_entropy": 0.01935348038872083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.05570154068846e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933260053396225,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2137465476989746,
      "backward_entropy": 0.018555834889411926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.717144411690242e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332617297768593,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21374589204788208,
      "backward_entropy": 0.01943662390112877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0577836323809606e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332632198929787,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21374523639678955,
      "backward_entropy": 0.019436436394850414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7980482286693587e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933264710009098,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137446403503418,
      "backward_entropy": 0.019352785001198452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8219034220455796e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332662001252174,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21374401450157166,
      "backward_entropy": 0.01943608249227206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.52779102538625e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933267503976822,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2137433886528015,
      "backward_entropy": 0.019435930997133255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.548003408264776e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332686215639114,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21374276280403137,
      "backward_entropy": 0.019435780743757885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7052065004463657e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933269552886486,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21374207735061646,
      "backward_entropy": 0.01855599383513133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2820010769919463e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332704842090607,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2137414515018463,
      "backward_entropy": 0.019435560951630276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.518816787893229e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332714155316353,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21374082565307617,
      "backward_entropy": 0.0193520188331604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.801260367528812e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0293327234685421,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21374022960662842,
      "backward_entropy": 0.01935189093152682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3584578084646637e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332732781767845,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373964846134186,
      "backward_entropy": 0.019351765513420105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.284385433564239e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933274209499359,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373909711837769,
      "backward_entropy": 0.019351682315270107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5223440641420893e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332751408219337,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137385606765747,
      "backward_entropy": 0.01935155565539996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2544094829536334e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332758858799934,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373805403709412,
      "backward_entropy": 0.01935144141316414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.640902667077171e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933276630938053,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21373754739761353,
      "backward_entropy": 0.018556353946526844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.347998997100149e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029332773759961128,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21373704075813293,
      "backward_entropy": 0.018556401133537292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3835212087087712e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332781210541725,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21373656392097473,
      "backward_entropy": 0.01943456505735715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0677458561758613e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332786798477173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373605728149414,
      "backward_entropy": 0.019351052741209667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.453678728732484e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933279238641262,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373558044433594,
      "backward_entropy": 0.019350994378328323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929390560297179e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029332797974348068,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21373513340950012,
      "backward_entropy": 0.018556578705708187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0992916799068553e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332803562283516,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137346863746643,
      "backward_entropy": 0.019350836674372356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.887466324518755e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332809150218964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137342393398285,
      "backward_entropy": 0.019350783278544743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.919913424027982e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933281473815441,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373382210731506,
      "backward_entropy": 0.019350691388050716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.163020481788408e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933282032608986,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373340487480164,
      "backward_entropy": 0.019350639233986538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.640311767114326e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332824051380157,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2137329876422882,
      "backward_entropy": 0.019433985153834026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.227327358805269e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332827776670456,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373260021209717,
      "backward_entropy": 0.019350518782933552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.035570265794377e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332831501960754,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373218297958374,
      "backward_entropy": 0.01935047780474027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.187774204136076e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332835227251053,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137318253517151,
      "backward_entropy": 0.019350430617729824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.349664888854022e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933283895254135,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373149752616882,
      "backward_entropy": 0.01935035114487012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.273229047337736e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933284267783165,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21373118460178375,
      "backward_entropy": 0.019433702031771343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3042413128423505e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332846403121948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21373087167739868,
      "backward_entropy": 0.019350262979666393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4360074724636434e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332850128412247,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137305736541748,
      "backward_entropy": 0.019350181023279827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.757678422924073e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029332853853702545,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21373027563095093,
      "backward_entropy": 0.018557194620370865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.453551127880928e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332857578992844,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21372997760772705,
      "backward_entropy": 0.01943349838256836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5045935931066197e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332861304283142,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372967958450317,
      "backward_entropy": 0.019350069264570873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5571691370250846e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02933286502957344,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21372941136360168,
      "backward_entropy": 0.019433364272117615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.629087158036782e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933286875486374,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2137291431427002,
      "backward_entropy": 0.01855735977490743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.597580189307337e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332872480154037,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137288749217987,
      "backward_entropy": 0.0193499190111955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9248372612755702e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332876205444336,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372860670089722,
      "backward_entropy": 0.019349890450636547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.608070381882044e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332879930734634,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372836828231812,
      "backward_entropy": 0.01934981718659401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.513453978281177e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332883656024933,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137281596660614,
      "backward_entropy": 0.01934978738427162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0034431830472386e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933288738131523,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137279212474823,
      "backward_entropy": 0.019349753856658936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.928531372958787e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933289110660553,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372771263122559,
      "backward_entropy": 0.019349735230207443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6271777642250527e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029332894831895828,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21372753381729126,
      "backward_entropy": 0.01855761557817459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.474059179746746e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029332896694540977,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21372731029987335,
      "backward_entropy": 0.019432969391345978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9666124728701107e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332898557186127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372711658477783,
      "backward_entropy": 0.01934961477915446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7751744962879457e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332902282476425,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137269675731659,
      "backward_entropy": 0.019349578768014908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0177395754217287e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332906007766724,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372675895690918,
      "backward_entropy": 0.01934955393274625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.626472112548072e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332907870411873,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372660994529724,
      "backward_entropy": 0.01934952661395073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6507989641922904e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029332909733057022,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372643113136292,
      "backward_entropy": 0.01934945707519849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.630822765719131e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933291159570217,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372629702091217,
      "backward_entropy": 0.0193494347234567,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.43470664943402e-07,
    "avg_log_Z": 0.029332350417971612,
    "success_rate": 1.0,
    "avg_reward": 51.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.14,
      "1": 0.2,
      "2": 0.66
    },
    "avg_forward_entropy": 0.21375314220786096,
    "avg_backward_entropy": 0.019261015852292375,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}