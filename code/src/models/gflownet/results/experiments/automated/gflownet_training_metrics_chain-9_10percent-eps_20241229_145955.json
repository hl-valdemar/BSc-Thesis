{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07633613215552436,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07633613215552436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07633613215552436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07633613215552436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07633613215552436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07633613215552436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07647234863705105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.393431186676025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961000919342041,
      "backward_entropy": 0.07624479134877522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2813801765441895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961029529571534,
      "backward_entropy": 0.0762301418516371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.989494800567627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019997454364784062,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961003303527832,
      "backward_entropy": 0.07644757297303942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.096590042114258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0002998769923578948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960897207260131,
      "backward_entropy": 0.0764350692431132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.493670463562012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003997857857029885,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960769653320312,
      "backward_entropy": 0.07618547810448541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.800887584686279,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004998084041289985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960696935653687,
      "backward_entropy": 0.07640997568766277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.197773456573486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000599703227635473,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960581302642822,
      "backward_entropy": 0.07615543736351861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2695536613464355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006996396696195006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960462093353271,
      "backward_entropy": 0.07623034715652466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.867825031280518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007995976484380662,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960354804992675,
      "backward_entropy": 0.07612495952182347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.465954303741455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008994334493763745,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960198640823364,
      "backward_entropy": 0.07610939608679877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.971487045288086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009990278631448746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959961414337158,
      "backward_entropy": 0.07634578810797797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.261630058288574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001098636188544333,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959714651107788,
      "backward_entropy": 0.076168245739407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.552309036254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011983509175479412,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959492921829224,
      "backward_entropy": 0.07606159978442723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1502366065979,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012982459738850594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959341526031494,
      "backward_entropy": 0.07630505826738146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763188362121582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013981376541778445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959193706512452,
      "backward_entropy": 0.07612035671869914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.082417488098145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014982816064730287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959122180938721,
      "backward_entropy": 0.07610452175140381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.865701198577881,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015987862134352326,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959112644195557,
      "backward_entropy": 0.07626244756910536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.756383895874023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016994841862469912,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109591543674469,
      "backward_entropy": 0.07607234848870172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9538726806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001800287514925003,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959231853485107,
      "backward_entropy": 0.07596159643597072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.045190811157227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019008559174835682,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959259271621705,
      "backward_entropy": 0.07603938049740261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8304243087768555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002001650631427765,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959357023239136,
      "backward_entropy": 0.07602259847852919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.947423934936523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021025233436375856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959503650665284,
      "backward_entropy": 0.07618810070885552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.918852806091309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022031329572200775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095960021018982,
      "backward_entropy": 0.07598865032196045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704570770263672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023042738903313875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959812402725219,
      "backward_entropy": 0.07597267627716064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.936525344848633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002405754290521145,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960094928741455,
      "backward_entropy": 0.07585886451933119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.616409301757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002507694298401475,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960427522659302,
      "backward_entropy": 0.0758415593041314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.23057746887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026098545640707016,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960795879364013,
      "backward_entropy": 0.07582415474785699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.926074028015137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002711635548621416,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096112608909607,
      "backward_entropy": 0.07590728335910374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.04509162902832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002813824685290456,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961490869522095,
      "backward_entropy": 0.07578864362504747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.913769721984863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029160280246287584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961840152740479,
      "backward_entropy": 0.07577068275875515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9069719314575195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030181112233549356,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962190628051757,
      "backward_entropy": 0.0758561823103163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.406688213348389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003119601169601083,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962487459182739,
      "backward_entropy": 0.07573388020197551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.112690448760986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032208135817199945,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962767601013183,
      "backward_entropy": 0.07571495903862847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.506701469421387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003321658819913864,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963011980056762,
      "backward_entropy": 0.0756956868701511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.482641220092773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003422364592552185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963245630264282,
      "backward_entropy": 0.07578278912438287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.106029033660889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003523368388414383,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963521003723145,
      "backward_entropy": 0.07565636105007595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.057456016540527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036240171175450087,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963761806488037,
      "backward_entropy": 0.07563626103931004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.972838878631592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003724713809788227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964026451110839,
      "backward_entropy": 0.07572477393680149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.550653457641602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003825456602498889,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964301824569703,
      "backward_entropy": 0.07559547821680705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07090950012207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0039259749464690685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964570045471192,
      "backward_entropy": 0.07568595144483778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.173942565917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004026622511446476,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964852571487427,
      "backward_entropy": 0.07555404636594984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642349243164062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004126930609345436,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965104103088379,
      "backward_entropy": 0.07584497663709852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13927936553955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004227639641612768,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965381860733033,
      "backward_entropy": 0.07551348209381104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.952043056488037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0043284404091537,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965667963027954,
      "backward_entropy": 0.07560772365993923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.524276733398438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004429259803146124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965954065322876,
      "backward_entropy": 0.07558766338560316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.050078392028809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004530345089733601,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966260433197021,
      "backward_entropy": 0.07556741767459446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.042716979980469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004631475545465946,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966567993164063,
      "backward_entropy": 0.07574607266320123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.932862281799316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004733164794743061,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966911315917968,
      "backward_entropy": 0.07552597257826063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.038969993591309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00483527360484004,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967278480529785,
      "backward_entropy": 0.07538721958796184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606741905212402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004937289748340845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967639684677125,
      "backward_entropy": 0.07548320293426514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.707798957824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005039473529905081,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968008041381835,
      "backward_entropy": 0.07534337043762207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.192764282226562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005141868721693754,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968387126922607,
      "backward_entropy": 0.07563966512680054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80394172668457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005245226435363293,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968823432922363,
      "backward_entropy": 0.07529882589975993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.116754531860352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00534870894625783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10969265699386596,
      "backward_entropy": 0.07559459739261204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.183127403259277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005452500190585852,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969717502593994,
      "backward_entropy": 0.07537117931577894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.223036766052246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005556544288992882,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970182418823242,
      "backward_entropy": 0.07554772165086535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.359659194946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0056603532284498215,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970625877380372,
      "backward_entropy": 0.0752069354057312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.884385108947754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005763922352343798,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971053838729858,
      "backward_entropy": 0.0754995346069336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.104591369628906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005867622327059507,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971484184265137,
      "backward_entropy": 0.07547555367151897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.312509536743164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005971033126115799,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109718918800354,
      "backward_entropy": 0.07545124159918891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.497814655303955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006074323318898678,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972286462783813,
      "backward_entropy": 0.07510977321200901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198202133178711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00617701280862093,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972645282745361,
      "backward_entropy": 0.07520145840115017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.473483085632324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006279582157731056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972990989685058,
      "backward_entropy": 0.07537539800008138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.207720756530762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006382168736308813,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973336696624755,
      "backward_entropy": 0.07534921169281006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.300085067749023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006484083831310272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973639488220215,
      "backward_entropy": 0.07532291942172581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.757333755493164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0065864697098731995,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973966121673584,
      "backward_entropy": 0.0752977795071072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.561487197875977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006688458379358053,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974272489547729,
      "backward_entropy": 0.07495807939105564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.61924409866333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006790583953261375,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974583625793458,
      "backward_entropy": 0.07493213812510173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65859317779541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0068923612125217915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974864959716797,
      "backward_entropy": 0.07501572370529175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.911458969116211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006994364317506552,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975157022476197,
      "backward_entropy": 0.07498761018117268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.396822929382324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0070955948904156685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975403785705566,
      "backward_entropy": 0.07516562938690186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.114189147949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007196416612714529,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975627899169922,
      "backward_entropy": 0.07482398880852593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6024017333984375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007297195494174957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975853204727173,
      "backward_entropy": 0.07510962751176622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.873898029327393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007397758774459362,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976057052612305,
      "backward_entropy": 0.07476761606004503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.064615249633789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007498260587453842,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976254940032959,
      "backward_entropy": 0.07505149311489528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.414963722229004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007598197087645531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976426601409912,
      "backward_entropy": 0.07481198840671116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.551047325134277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007698403671383858,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976610183715821,
      "backward_entropy": 0.07499194145202637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.339248180389404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00779946381226182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976837873458863,
      "backward_entropy": 0.07475217183430989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.266558647155762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007899558171629906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977009534835816,
      "backward_entropy": 0.07493052217695448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.880067348480225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008000383153557777,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977215766906738,
      "backward_entropy": 0.0745903386010064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.134495258331299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008100530132651329,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977386236190796,
      "backward_entropy": 0.07455944352679783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.49380111694336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008200316689908504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977531671524048,
      "backward_entropy": 0.07462911473380195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.973441123962402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008300449699163437,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977694988250733,
      "backward_entropy": 0.07459708054860432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.346182823181152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008401170372962952,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977883338928222,
      "backward_entropy": 0.07446410258611043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.917186737060547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008502615615725517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978103876113891,
      "backward_entropy": 0.07453089290195042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.368595123291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008604402653872967,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978338718414307,
      "backward_entropy": 0.0743990871641371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.775530815124512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008706223219633102,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978577136993409,
      "backward_entropy": 0.07436600658628675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35848331451416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008807709440588951,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978801250457763,
      "backward_entropy": 0.07462698883480495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.368035793304443,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008909255266189575,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097902536392212,
      "backward_entropy": 0.07429720295800103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09953498840332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00900971982628107,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979201793670654,
      "backward_entropy": 0.0745560195710924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.888858318328857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009110766462981701,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10979399681091309,
      "backward_entropy": 0.07422512107425266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.15473747253418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009211162105202675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979565382003784,
      "backward_entropy": 0.07448274559444851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4601521492004395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009311109781265259,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10979710817337036,
      "backward_entropy": 0.07415050268173218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.731721878051758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009410210885107517,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979819297790527,
      "backward_entropy": 0.07440655761294895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.5510835647583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009509366005659103,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979926586151123,
      "backward_entropy": 0.07436727815204197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.633772850036621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00960952416062355,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980072021484374,
      "backward_entropy": 0.07432747549480861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.550839424133301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009710094891488552,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980232954025268,
      "backward_entropy": 0.07412185271581014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.725254535675049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009809817187488079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980359315872193,
      "backward_entropy": 0.0740855269961887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198269844055176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009909401647746563,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098048210144043,
      "backward_entropy": 0.07420461707644993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.23837423324585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010009149089455605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980613231658935,
      "backward_entropy": 0.07401218679216173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.966672897338867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010108460672199726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980727672576904,
      "backward_entropy": 0.07397598690456814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.496601104736328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010207920335233212,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980845689773559,
      "backward_entropy": 0.07407877180311415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8412556648254395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010307780466973782,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980976819992065,
      "backward_entropy": 0.07374408509996203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.057609558105469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010407084599137306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981084108352661,
      "backward_entropy": 0.0738634533352322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.965243339538574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010505931451916695,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981174707412719,
      "backward_entropy": 0.07394617795944214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.619491100311279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010606082156300545,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981310606002807,
      "backward_entropy": 0.07361055745018853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.831460475921631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01070548128336668,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981419086456298,
      "backward_entropy": 0.07356506586074829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625205039978027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010804926976561546,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981526374816894,
      "backward_entropy": 0.07351975970798069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.022315502166748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010904818773269653,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981649160385132,
      "backward_entropy": 0.07375962866677178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.03010368347168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011004287749528885,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981754064559937,
      "backward_entropy": 0.07342727979024251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.134197235107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01110326312482357,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109818434715271,
      "backward_entropy": 0.07337994045681423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.236577987670898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011202438734471798,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981941223144531,
      "backward_entropy": 0.0736122793621487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.33320426940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01130242832005024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982065200805664,
      "backward_entropy": 0.07349965307447645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.219913482666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011403216049075127,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982215404510498,
      "backward_entropy": 0.07323461108737522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.580416679382324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011504074558615685,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982365608215332,
      "backward_entropy": 0.07318498690923055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.471492290496826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011604641564190388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982507467269897,
      "backward_entropy": 0.07336673471662733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5690460205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011704868637025356,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982635021209716,
      "backward_entropy": 0.0730860365761651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.93043851852417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011804865673184395,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982756614685059,
      "backward_entropy": 0.07303569051954481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.926902770996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011904868297278881,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982877016067505,
      "backward_entropy": 0.0729845298661126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.021011352539062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012004305608570576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982979536056518,
      "backward_entropy": 0.07318143049875896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.75128173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012103879824280739,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983084440231324,
      "backward_entropy": 0.07287987073262532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.957732200622559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01220343541353941,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983188152313232,
      "backward_entropy": 0.07308120197719997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26412582397461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012303576804697514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983307361602783,
      "backward_entropy": 0.07302519347932604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.694536209106445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01240390446037054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983431339263916,
      "backward_entropy": 0.07296713193257649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2134318351745605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012503459118306637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983531475067139,
      "backward_entropy": 0.07290848096211751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.616626262664795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01260259561240673,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983622074127197,
      "backward_entropy": 0.0726047224468655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.076294898986816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012701665051281452,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983707904815673,
      "backward_entropy": 0.07254726356930202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.694127082824707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012800963595509529,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983799695968628,
      "backward_entropy": 0.07272783915201823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.959730625152588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012900813482701778,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983903408050537,
      "backward_entropy": 0.07242976956897312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.111248016357422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013000723905861378,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984007120132447,
      "backward_entropy": 0.07264352507061428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930099487304688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013100743293762207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984113216400146,
      "backward_entropy": 0.07258428467644586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.315051078796387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013201359659433365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984230041503906,
      "backward_entropy": 0.07252369986640082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.872673511505127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013301590457558632,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984337329864502,
      "backward_entropy": 0.07218421830071343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02304744720459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013401840813457966,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098444104194641,
      "backward_entropy": 0.07233658764097425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.970717906951904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01350216381251812,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984543561935425,
      "backward_entropy": 0.07205567095014784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.646554946899414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013602451421320438,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984644889831544,
      "backward_entropy": 0.07227219475640191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.516125679016113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01370258443057537,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984737873077392,
      "backward_entropy": 0.07212865352630615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.362914085388184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013803061097860336,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098483920097351,
      "backward_entropy": 0.07205720742543538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.421544075012207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013903669081628323,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984939336776733,
      "backward_entropy": 0.0719855891333686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.671566963195801,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014003919437527657,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985028743743896,
      "backward_entropy": 0.07191299729877049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720218181610107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014103981666266918,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985114574432372,
      "backward_entropy": 0.07183953126271565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.497967720031738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014203853905200958,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985193252563477,
      "backward_entropy": 0.0717657142215305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.976242542266846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014303509145975113,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985265970230103,
      "backward_entropy": 0.07150364584392971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7379469871521,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014402692206203938,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985329151153564,
      "backward_entropy": 0.07143015331692165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753917694091797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014501859433948994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985389947891236,
      "backward_entropy": 0.07165039910210504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.288260459899902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014601553790271282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985456705093384,
      "backward_entropy": 0.07157624430126613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.256762981414795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014701424166560173,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985521078109742,
      "backward_entropy": 0.07138544983334011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.049017429351807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014800899662077427,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098557710647583,
      "backward_entropy": 0.07112585173712836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854976654052734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014899862930178642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098562240600586,
      "backward_entropy": 0.07134807109832764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89897346496582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014999525621533394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985673666000366,
      "backward_entropy": 0.07126951217651367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.619709491729736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015099789015948772,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985726118087769,
      "backward_entropy": 0.07106730673048231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.411567687988281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015199904330074787,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985774993896484,
      "backward_entropy": 0.07110793060726589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513404846191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015299727208912373,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985817909240722,
      "backward_entropy": 0.07072088453504774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.446356773376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015400555916130543,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985864400863647,
      "backward_entropy": 0.07063549757003784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.178014755249023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015501641668379307,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985908508300782,
      "backward_entropy": 0.07054834895663792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.722986221313477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01560161355882883,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985941886901855,
      "backward_entropy": 0.07045998838212755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.465407371520996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015701495110988617,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985970497131348,
      "backward_entropy": 0.0705390175183614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.10444164276123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015801697969436646,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985993146896363,
      "backward_entropy": 0.07027928034464519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.244050979614258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015901967883110046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986011028289795,
      "backward_entropy": 0.07035105758243138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.375534057617188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016001807525753975,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986024141311646,
      "backward_entropy": 0.07025370332929823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.528557300567627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01610196940600872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098603367805481,
      "backward_entropy": 0.07031076484256321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.363696098327637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01620127446949482,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986037254333496,
      "backward_entropy": 0.06990159882439508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.397207736968994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016300290822982788,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986037254333496,
      "backward_entropy": 0.06995091173383924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.281380653381348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016399137675762177,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986034870147705,
      "backward_entropy": 0.07002149687872992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.330346584320068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016498291864991188,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986025333404541,
      "backward_entropy": 0.06992200348112318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.363236904144287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01659715361893177,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098601222038269,
      "backward_entropy": 0.06982045703464085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.963174819946289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016695844009518623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985997915267945,
      "backward_entropy": 0.06952895058525933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.229293823242188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01679406501352787,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985980033874512,
      "backward_entropy": 0.06942113902833727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.134275913238525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016892632469534874,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098595380783081,
      "backward_entropy": 0.06931189033720228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.149829864501953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016990885138511658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985925197601318,
      "backward_entropy": 0.06920075416564941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.961780071258545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017089486122131348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985891819000244,
      "backward_entropy": 0.0692856576707628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246569633483887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0171876959502697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985859632492065,
      "backward_entropy": 0.06917358769310845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5746846199035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01728566735982895,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109858238697052,
      "backward_entropy": 0.06874490446514553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.681585788726807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017383629456162453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985782146453857,
      "backward_entropy": 0.06873571872711182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.835748672485352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017481112852692604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985746383666992,
      "backward_entropy": 0.06861058208677503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.334810256958008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0175788551568985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985707044601441,
      "backward_entropy": 0.0684821605682373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.726375579833984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017676550894975662,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985668897628784,
      "backward_entropy": 0.06835052702162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.924680709838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017775025218725204,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985610485076905,
      "backward_entropy": 0.06815091768900554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.343365669250488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01787305437028408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098555088043213,
      "backward_entropy": 0.0683301223648919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.940427780151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017970964312553406,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985485315322877,
      "backward_entropy": 0.0679000351164076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.831277370452881,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018068566918373108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985426902770996,
      "backward_entropy": 0.06806994809044732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.34120512008667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01816580817103386,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985372066497803,
      "backward_entropy": 0.06764216555489434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.618009567260742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018263084813952446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109853196144104,
      "backward_entropy": 0.06780296564102173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.45545768737793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018360499292612076,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985257625579833,
      "backward_entropy": 0.06736072566774157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.105627059936523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018457971513271332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985194444656372,
      "backward_entropy": 0.06751847929424709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.182208061218262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018555907532572746,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985115766525269,
      "backward_entropy": 0.0671070549223158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.072264194488525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018653692677617073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985037088394164,
      "backward_entropy": 0.06721817784839207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.77152681350708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01875125616788864,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984958410263061,
      "backward_entropy": 0.0668284363216824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.092042446136475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018849017098546028,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984861850738525,
      "backward_entropy": 0.06657516294055515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.588534355163574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01894652470946312,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984761714935302,
      "backward_entropy": 0.06654169162114461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.558192729949951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01904415525496006,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984648466110229,
      "backward_entropy": 0.06639526949988471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.474646091461182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01914052851498127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984561443328858,
      "backward_entropy": 0.06642464796702068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.058954238891602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01923641562461853,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098448395729065,
      "backward_entropy": 0.0660976833767361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.257823944091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019332295283675194,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984406471252442,
      "backward_entropy": 0.06594606902864245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145842552185059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019428923726081848,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984303951263427,
      "backward_entropy": 0.06579207049475776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8535871505737305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01952613703906536,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984172821044921,
      "backward_entropy": 0.06538820928997463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.299047470092773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019623637199401855,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984021425247192,
      "backward_entropy": 0.06547692086961535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.018409252166748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019720409065485,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983881950378419,
      "backward_entropy": 0.0653862754503886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.998556137084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019817011430859566,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983736515045166,
      "backward_entropy": 0.0651537643538581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.944705009460449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019913451746106148,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983587503433227,
      "backward_entropy": 0.06498906347486708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.957808971405029,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020010361447930336,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983412265777588,
      "backward_entropy": 0.06446752945582072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.561427593231201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020107053220272064,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983233451843262,
      "backward_entropy": 0.06464850240283543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4856858253479,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02020334079861641,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983067750930786,
      "backward_entropy": 0.06408164898554485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.543163776397705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020299268886446953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982937812805176,
      "backward_entropy": 0.06424776050779554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.236549377441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020394746214151382,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982811450958252,
      "backward_entropy": 0.06409618589613172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.889276504516602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020489685237407684,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982701778411866,
      "backward_entropy": 0.06348424487643772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.318154811859131,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020585250109434128,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098254680633545,
      "backward_entropy": 0.0637086100048489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.240265846252441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020681018009781837,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982373952865601,
      "backward_entropy": 0.06351031197441949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.837414264678955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02077757753431797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982153415679932,
      "backward_entropy": 0.06285589933395386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2129058837890625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02087322436273098,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981963872909546,
      "backward_entropy": 0.06301224893993801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.131842136383057,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020968934521079063,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981751680374145,
      "backward_entropy": 0.06242239475250244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.546834468841553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021064700558781624,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981523990631104,
      "backward_entropy": 0.06220026148690118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.221127033233643,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0211594570428133,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981342792510987,
      "backward_entropy": 0.06197672420077854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.039984703063965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0212543997913599,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981132984161376,
      "backward_entropy": 0.06175014045503405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.476259231567383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021350044757127762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980864763259887,
      "backward_entropy": 0.061899542808532715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.915443420410156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02144595980644226,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980558395385742,
      "backward_entropy": 0.06166546212302314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.446496486663818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021541757509112358,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980242490768433,
      "backward_entropy": 0.06159990363650852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.748823642730713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02163786068558693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097989559173584,
      "backward_entropy": 0.06118749247656928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6069111824035645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0217343308031559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979493856430053,
      "backward_entropy": 0.06094190809461805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.242964267730713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02183113433420658,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979055166244507,
      "backward_entropy": 0.06069221099217733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9767069816589355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021927926689386368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978587865829467,
      "backward_entropy": 0.06043914953867594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.785512924194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022023962810635567,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978164672851562,
      "backward_entropy": 0.06043595737881131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.704735279083252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022119157016277313,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977787971496582,
      "backward_entropy": 0.05993209944831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5473713874816895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022213589400053024,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977466106414795,
      "backward_entropy": 0.059955603546566434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.708465576171875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022307856008410454,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097713828086853,
      "backward_entropy": 0.05903816885418362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1357526779174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022402005270123482,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097678542137146,
      "backward_entropy": 0.05946515666113959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.945737838745117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022496379911899567,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976386070251465,
      "backward_entropy": 0.05921315484576755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.425634384155273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02259019948542118,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976017713546753,
      "backward_entropy": 0.05895853042602539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.100961208343506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02268384024500847,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097564458847046,
      "backward_entropy": 0.0587011112107171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.812157154083252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022777095437049866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975284576416015,
      "backward_entropy": 0.05809140867657132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.550529956817627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022870540618896484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097489356994629,
      "backward_entropy": 0.05781669749153985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.565733432769775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022964593023061752,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974417924880982,
      "backward_entropy": 0.057536032464769155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.820301532745361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023058487102389336,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973918437957764,
      "backward_entropy": 0.0576413803630405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8814616203308105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023152420297265053,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973376035690308,
      "backward_entropy": 0.05696460935804579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.405129909515381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023246517404913902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972795486450196,
      "backward_entropy": 0.05667298369937473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.306924819946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023340392857789993,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972204208374023,
      "backward_entropy": 0.056812034712897405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.691680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023433303460478783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971682071685791,
      "backward_entropy": 0.05563794242011176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.862204074859619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02352559007704258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971188545227051,
      "backward_entropy": 0.055790199173821345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3359293937683105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0236181803047657,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970633029937744,
      "backward_entropy": 0.05502500136693319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.459827899932861,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02371068298816681,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970056056976318,
      "backward_entropy": 0.05518794059753418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.245184421539307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02380247414112091,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969527959823608,
      "backward_entropy": 0.05537134408950806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.245765686035156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023894134908914566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968968868255616,
      "backward_entropy": 0.05457861224810282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.763843059539795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023984983563423157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096846580505371,
      "backward_entropy": 0.05427237351735433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.962209701538086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02407548390328884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967966318130493,
      "backward_entropy": 0.05344935920503405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.094656467437744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02416503243148327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096753716468811,
      "backward_entropy": 0.05313248766793145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.67191743850708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024254584684967995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967061519622803,
      "backward_entropy": 0.05334489213095771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.474986553192139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024344589561223984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096649169921875,
      "backward_entropy": 0.053021894560919866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3168864250183105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02443409338593483,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965937376022339,
      "backward_entropy": 0.05322101049953037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4128737449646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024523800238966942,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965312719345092,
      "backward_entropy": 0.05236622360017565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0222978591918945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02461306005716324,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964713096618653,
      "backward_entropy": 0.05258080694410536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.853885173797607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0247022844851017,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964057445526124,
      "backward_entropy": 0.051175316174825035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.075867176055908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024791385978460312,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963363647460937,
      "backward_entropy": 0.05084147718217638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9760966300964355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024880550801753998,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962609052658082,
      "backward_entropy": 0.05159383349948459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.981388807296753,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02496975101530552,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961813926696777,
      "backward_entropy": 0.05125915341907077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.599071979522705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025057477876544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961207151412963,
      "backward_entropy": 0.04982481731308831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.911766529083252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025145862251520157,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960460901260376,
      "backward_entropy": 0.050588021675745644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.218181133270264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025234341621398926,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109596586227417,
      "backward_entropy": 0.05024814936849806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.874630451202393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025322334840893745,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958874225616455,
      "backward_entropy": 0.04990673065185547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0008158683776855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025410395115613937,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095801591873169,
      "backward_entropy": 0.04956249064869351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5873332023620605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025497812777757645,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957183837890624,
      "backward_entropy": 0.04807575543721517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.167973518371582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02558436058461666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956435203552246,
      "backward_entropy": 0.04772390259636773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.508066177368164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025670558214187622,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955671072006226,
      "backward_entropy": 0.047855377197265625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.598233699798584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025755947455763817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954984426498413,
      "backward_entropy": 0.04750045471721225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.179110050201416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025840718299150467,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10954359769821168,
      "backward_entropy": 0.047824852996402316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.452104091644287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025925440713763237,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10953714847564697,
      "backward_entropy": 0.046307663122812905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9875569343566895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02600947767496109,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095313310623169,
      "backward_entropy": 0.04712419377432929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.705541610717773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02609412930905819,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952377319335938,
      "backward_entropy": 0.04676989383167691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.014242649078369,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026179175823926926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951509475708007,
      "backward_entropy": 0.04521850082609388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.763383865356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026263056322932243,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950746536254882,
      "backward_entropy": 0.04605665471818712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.94569206237793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634660340845585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949982404708862,
      "backward_entropy": 0.044974555571873985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.375797748565674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02642993815243244,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10949162244796753,
      "backward_entropy": 0.045339478386773005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.700084686279297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02651265636086464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948395729064941,
      "backward_entropy": 0.04424064026938544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.582179546356201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026594331488013268,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947805643081665,
      "backward_entropy": 0.04339229398303562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.365318775177002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0266757570207119,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947198867797851,
      "backward_entropy": 0.04302448034286499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.002007007598877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02675679139792919,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946612358093262,
      "backward_entropy": 0.0426474412282308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9286911487579346,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683795802295208,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094590187072754,
      "backward_entropy": 0.043541702959272593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.078092575073242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02691834792494774,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945264101028443,
      "backward_entropy": 0.04318003522025214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2350544929504395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02699906751513481,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094449520111084,
      "backward_entropy": 0.042816119061575994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2514753341674805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02707931026816368,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943722724914551,
      "backward_entropy": 0.042451699574788414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.64356803894043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027159228920936584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942974090576171,
      "backward_entropy": 0.042087455590566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.155792236328125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723914198577404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094213604927063,
      "backward_entropy": 0.040925926632351346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.326107978820801,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0273186843842268,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1094132423400879,
      "backward_entropy": 0.03997608688142565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9467575550079346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02739805355668068,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10940495729446412,
      "backward_entropy": 0.04016589787271288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.169669151306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02747681550681591,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939667224884034,
      "backward_entropy": 0.04062484370337592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.708588123321533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027555257081985474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938788652420044,
      "backward_entropy": 0.03881625996695624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9644432067871094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027633970603346825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937774181365967,
      "backward_entropy": 0.03901713093121847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.335366249084473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027712220326066017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936758518218995,
      "backward_entropy": 0.03952167762650384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.333570957183838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027790408581495285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093565583229065,
      "backward_entropy": 0.038244277238845825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8150320053100586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027868563309311867,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934467315673828,
      "backward_entropy": 0.03785508871078491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8956074714660645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02794617973268032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933287143707275,
      "backward_entropy": 0.037467360496520996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6645286083221436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02802424691617489,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10931836366653443,
      "backward_entropy": 0.03803476691246033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4095115661621094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02810162864625454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930411815643311,
      "backward_entropy": 0.03668405943446689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5650479793548584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028178220614790916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1092909336090088,
      "backward_entropy": 0.036297622654173106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4349923133850098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028254183009266853,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10927834510803222,
      "backward_entropy": 0.03591348727544149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6923441886901855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028328416869044304,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092688798904419,
      "backward_entropy": 0.03655877709388733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0313165187835693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02840334177017212,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109256112575531,
      "backward_entropy": 0.03619141711129083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4616973400115967,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028477273881435394,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10924444198608399,
      "backward_entropy": 0.03419275085131327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.510563850402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02855079062283039,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923269987106324,
      "backward_entropy": 0.03546373380555047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.407088279724121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028623949736356735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10922046899795532,
      "backward_entropy": 0.033446295393837824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6401307582855225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028696740046143532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10920816659927368,
      "backward_entropy": 0.033073720004823476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1833882331848145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028769411146640778,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091948390007019,
      "backward_entropy": 0.03438065118259854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1255240440368652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02884257398545742,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10917913913726807,
      "backward_entropy": 0.03401943710115221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3944616317749023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028915023431181908,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10916368961334229,
      "backward_entropy": 0.03253326813379923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2583723068237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028987105935811996,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914744138717651,
      "backward_entropy": 0.0333025852839152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4382541179656982,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029058679938316345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1091305136680603,
      "backward_entropy": 0.03121559487448798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4939467906951904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0291290320456028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10911592245101928,
      "backward_entropy": 0.03141694598727756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.146763563156128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029199397191405296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909982919692993,
      "backward_entropy": 0.031049172083536785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.951882839202881,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02926933579146862,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10908291339874268,
      "backward_entropy": 0.03012949228286743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.49826979637146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029338771477341652,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10906615257263183,
      "backward_entropy": 0.03031920724444919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8659164905548096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029408346861600876,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904744863510132,
      "backward_entropy": 0.02941107087665134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.032987117767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02947728894650936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10902854204177856,
      "backward_entropy": 0.02959168619579739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0773890018463135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545802623033524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090084195137024,
      "backward_entropy": 0.028703427977032132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.754768133163452,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029614126309752464,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10898751020431519,
      "backward_entropy": 0.030169096257951524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.475994348526001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681844636797905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10896645784378052,
      "backward_entropy": 0.028515527645746868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.91819167137146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029748646542429924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10894587039947509,
      "backward_entropy": 0.02766025894218021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3000075817108154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02981526590883732,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10892443656921387,
      "backward_entropy": 0.029161453247070312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3744542598724365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029880905523896217,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10890398025512696,
      "backward_entropy": 0.026980085505379572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.57969069480896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0299457386136055,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10888384580612183,
      "backward_entropy": 0.02850612998008728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.697251558303833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03001016564667225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1088633418083191,
      "backward_entropy": 0.026794966724183824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7795755863189697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030074303969740868,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10884133577346802,
      "backward_entropy": 0.0264593329694536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5481882095336914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03013819456100464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10881688594818115,
      "backward_entropy": 0.026124257180425856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.085561513900757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030201733112335205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10879170894622803,
      "backward_entropy": 0.02579135199387868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8589146137237549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03026558831334114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10876303911209106,
      "backward_entropy": 0.02501873837576972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.81477689743042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030328169465065002,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10873641967773437,
      "backward_entropy": 0.02657573918501536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.139242649078369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030390914529561996,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10870733261108398,
      "backward_entropy": 0.026259483562575445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.199173927307129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030452938750386238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10867899656295776,
      "backward_entropy": 0.024478193786409166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.774271011352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03051438182592392,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10865068435668945,
      "backward_entropy": 0.02563895285129547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.255472183227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030575990676879883,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10861876010894775,
      "backward_entropy": 0.025330530272589788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.617602825164795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030637068673968315,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1085858941078186,
      "backward_entropy": 0.025025010108947754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.836768627166748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030698221176862717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10855026245117187,
      "backward_entropy": 0.02320437298880683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8402647972106934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030758338049054146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10851571559906006,
      "backward_entropy": 0.022893918885125056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0224661827087402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030817465856671333,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1084815263748169,
      "backward_entropy": 0.024126546250449285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8391307592391968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03087606653571129,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10844695568084717,
      "backward_entropy": 0.022288991345299616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.58148193359375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030934005975723267,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10841342210769653,
      "backward_entropy": 0.02167317271232605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.611538052558899,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030990872532129288,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10838143825531006,
      "backward_entropy": 0.02326739165518019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3004323244094849,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031046777963638306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10835018157958984,
      "backward_entropy": 0.02142128845055898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1801083087921143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031101278960704803,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10832096338272094,
      "backward_entropy": 0.02272020445929633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8097782135009766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031154338270425797,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1082943320274353,
      "backward_entropy": 0.02088127036889394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.768396019935608,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031207123771309853,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10826582908630371,
      "backward_entropy": 0.022193872266345553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3485223054885864,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03125949203968048,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10823478698730468,
      "backward_entropy": 0.021933699647585552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1694693565368652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131093829870224,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10820496082305908,
      "backward_entropy": 0.020097922947671678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4284250736236572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03136120364069939,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10817691087722778,
      "backward_entropy": 0.01984837816821204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4358067512512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0314108245074749,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10814826488494873,
      "backward_entropy": 0.02118249734242757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.243041753768921,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031459927558898926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10811905860900879,
      "backward_entropy": 0.01911230550871955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8395085334777832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031508270651102066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10809080600738526,
      "backward_entropy": 0.01912128097481198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.529069423675537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03155693784356117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10805833339691162,
      "backward_entropy": 0.018880936834547255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9984508752822876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03160536661744118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10802406072616577,
      "backward_entropy": 0.018642021550072566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2157284021377563,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03165280818939209,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1079935908317566,
      "backward_entropy": 0.019995379779073928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0765633583068848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03169960528612137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1079633116722107,
      "backward_entropy": 0.01817999117904239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.244843602180481,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03174553066492081,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1079339861869812,
      "backward_entropy": 0.017737895250320435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5868195295333862,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031791020184755325,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10790402889251709,
      "backward_entropy": 0.017517975634998746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2526817321777344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03183670714497566,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10786973237991333,
      "backward_entropy": 0.017298302716679044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1987931728363037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03188198804855347,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10783432722091675,
      "backward_entropy": 0.01708100073867374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4682190418243408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031926896423101425,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10779885053634644,
      "backward_entropy": 0.018680802649921842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.268143653869629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03197198733687401,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10776031017303467,
      "backward_entropy": 0.01683972610367669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8734167218208313,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03201683983206749,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10772032737731933,
      "backward_entropy": 0.018259194162156846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.990574061870575,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03206055983901024,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10768169164657593,
      "backward_entropy": 0.01622565256224738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9139469265937805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032103490084409714,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10764268636703492,
      "backward_entropy": 0.017855071359210543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9245172142982483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03214558959007263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10760416984558105,
      "backward_entropy": 0.01599315471119351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7063800692558289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03218689188361168,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10756512880325317,
      "backward_entropy": 0.015628695487976074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.126196026802063,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032227177172899246,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10752911567687988,
      "backward_entropy": 0.017281568712658353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1548881530761719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03226740285754204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1074902892112732,
      "backward_entropy": 0.015249995721711053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0553799867630005,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03230763226747513,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10744807720184327,
      "backward_entropy": 0.015062173207600912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2166348695755005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03234763815999031,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10740342140197753,
      "backward_entropy": 0.015021239717801413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7455496191978455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032387830317020416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10735433101654053,
      "backward_entropy": 0.014690935611724854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8949229717254639,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032427072525024414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10730619430541992,
      "backward_entropy": 0.014510528908835517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7106582522392273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03246579319238663,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10725659132003784,
      "backward_entropy": 0.01619765990310245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5487335920333862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0325036495923996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10720797777175903,
      "backward_entropy": 0.014277107185787626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6177475452423096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03254024311900139,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.107161545753479,
      "backward_entropy": 0.014104713996251425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41592034697532654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03257596120238304,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10711661577224732,
      "backward_entropy": 0.013832317458258735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6133497953414917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03261030092835426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10707515478134155,
      "backward_entropy": 0.013777429031001197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7147372364997864,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03264389559626579,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10703368186950683,
      "backward_entropy": 0.015403641594780816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6871219873428345,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03267714008688927,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1069907784461975,
      "backward_entropy": 0.015256772438685099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6218113303184509,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03270996734499931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10694640874862671,
      "backward_entropy": 0.013314771983358595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3965604901313782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03274225443601608,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10690147876739502,
      "backward_entropy": 0.01316455172167884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6437253952026367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032773371785879135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10685887336730956,
      "backward_entropy": 0.013020388782024384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5570407509803772,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032804228365421295,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10681486129760742,
      "backward_entropy": 0.014695276816685995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6918473839759827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0328344963490963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10676987171173095,
      "backward_entropy": 0.012737290726767646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5367643237113953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03286470100283623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10672194957733154,
      "backward_entropy": 0.012538489368226793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4913032352924347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032894380390644073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1066734790802002,
      "backward_entropy": 0.012459932102097405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6053130626678467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03292351961135864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10662550926208496,
      "backward_entropy": 0.012325490514437357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4465537965297699,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03295254334807396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10657572746276855,
      "backward_entropy": 0.01215097059806188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4422949552536011,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03298085555434227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10652611255645753,
      "backward_entropy": 0.01206152058309979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6375834941864014,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03300857171416283,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10647680759429931,
      "backward_entropy": 0.013789510561360253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5556926131248474,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033036209642887115,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10642262697219848,
      "backward_entropy": 0.01366880950000551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35876286029815674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033063601702451706,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10636587142944336,
      "backward_entropy": 0.011666203538576761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3166159689426422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033090151846408844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10631051063537597,
      "backward_entropy": 0.01156004766623179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43759748339653015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03311583772301674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10625729560852051,
      "backward_entropy": 0.011442881491449144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4740803837776184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03314107656478882,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10620269775390626,
      "backward_entropy": 0.013214237987995148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24214941263198853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03316618874669075,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10614652633666992,
      "backward_entropy": 0.013106311360994974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3488733172416687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03319016844034195,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10609259605407714,
      "backward_entropy": 0.013003658917215135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3325954079627991,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033213697373867035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10603917837142944,
      "backward_entropy": 0.010998448563946618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4072938859462738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03323669359087944,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10598591566085816,
      "backward_entropy": 0.012805684573120542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5557854175567627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03325939550995827,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10593011379241943,
      "backward_entropy": 0.012709495094087388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.269654244184494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03328254818916321,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10586888790130615,
      "backward_entropy": 0.010716990464263491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4358076751232147,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03330489620566368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10580878257751465,
      "backward_entropy": 0.010584712028503418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08848755806684494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03332724794745445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10574558973312378,
      "backward_entropy": 0.010483089420530532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35063108801841736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033348143100738525,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10568816661834717,
      "backward_entropy": 0.012336744202507867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3132033050060272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03336874023079872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10562832355499267,
      "backward_entropy": 0.010295641091134813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28731992840766907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0333888903260231,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10556683540344239,
      "backward_entropy": 0.010204508072800107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24760748445987701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03340873122215271,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10550550222396851,
      "backward_entropy": 0.010114887522326576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26520398259162903,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03342796117067337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10544427633285522,
      "backward_entropy": 0.010028054316838583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32707658410072327,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033446744084358215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10538253784179688,
      "backward_entropy": 0.0100182948840989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22611184418201447,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03346538171172142,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10531803369522094,
      "backward_entropy": 0.011853333976533677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28400418162345886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03348341956734657,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10525367259979249,
      "backward_entropy": 0.009777249561415778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21354103088378906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03350110352039337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10518687963485718,
      "backward_entropy": 0.009697089592615763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22864113748073578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03351825475692749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10512046813964844,
      "backward_entropy": 0.0096194412973192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22091573476791382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03353502228856087,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10505377054214478,
      "backward_entropy": 0.009543564584520128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19360516965389252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03355133906006813,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10498645305633544,
      "backward_entropy": 0.011506197353204092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.228332057595253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03356701880693436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10491878986358642,
      "backward_entropy": 0.009398621817429861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18375526368618011,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03358246013522148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10485022068023682,
      "backward_entropy": 0.009450930688116286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23321105539798737,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033597394824028015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1047818660736084,
      "backward_entropy": 0.009260824984974332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15583902597427368,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033612094819545746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10471143722534179,
      "backward_entropy": 0.00932806564701928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25514551997184753,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03362628072500229,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10464229583740234,
      "backward_entropy": 0.009269300434324477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24770693480968475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03364059329032898,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10457049608230591,
      "backward_entropy": 0.00906426790687773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19151638448238373,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03365495800971985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10449596643447875,
      "backward_entropy": 0.009151255091031393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1703319251537323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03366899862885475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10442063808441163,
      "backward_entropy": 0.008934962252775827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13417765498161316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03368256613612175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10434490442276001,
      "backward_entropy": 0.008873081869549222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.234333336353302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033695563673973083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1042704463005066,
      "backward_entropy": 0.008813820779323578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1988162398338318,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033708736300468445,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10419292449951172,
      "backward_entropy": 0.010889158480697207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13713432848453522,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03372180089354515,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10411370992660522,
      "backward_entropy": 0.008878025743696425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14764048159122467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03373432531952858,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10403518676757813,
      "backward_entropy": 0.010790912641419305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1288916915655136,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03374636918306351,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10395629405975342,
      "backward_entropy": 0.008581852747334374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1261475533246994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033757954835891724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1038781762123108,
      "backward_entropy": 0.008528674642244974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15822696685791016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03376904875040054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10380039215087891,
      "backward_entropy": 0.008685827255249023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2249191403388977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0337800495326519,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10372166633605957,
      "backward_entropy": 0.010618575745158725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15055139362812042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03379153087735176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1036388635635376,
      "backward_entropy": 0.008374146289295621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11300487816333771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03380274772644043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10355504751205444,
      "backward_entropy": 0.008322454161114164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14232757687568665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033813394606113434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10347168445587158,
      "backward_entropy": 0.008273252182536654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1356731504201889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033823784440755844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10338704586029053,
      "backward_entropy": 0.008225083351135254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0926426574587822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033834028989076614,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1033018946647644,
      "backward_entropy": 0.008423788679970635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12566900253295898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033843688666820526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10321800708770752,
      "backward_entropy": 0.008132698635260264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09594520926475525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033853307366371155,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1031341314315796,
      "backward_entropy": 0.008346259593963623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09388910979032516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03386249765753746,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1030511736869812,
      "backward_entropy": 0.010313140021430122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14405691623687744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03387125954031944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10296887159347534,
      "backward_entropy": 0.00827407009071774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08258753269910812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03388016298413277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10288426876068116,
      "backward_entropy": 0.007962788144747416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08552718907594681,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03388846293091774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10280033349990844,
      "backward_entropy": 0.007923650244871775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11640357226133347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033896397799253464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10271728038787842,
      "backward_entropy": 0.007886077794763777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11372067779302597,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0339042954146862,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10263276100158691,
      "backward_entropy": 0.00814117408461041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1076245978474617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03391211852431297,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1025468349456787,
      "backward_entropy": 0.010136313736438751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10573132336139679,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03391994535923004,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10246024131774903,
      "backward_entropy": 0.010108570257822672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.100438691675663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03392771631479263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10237274169921876,
      "backward_entropy": 0.007737302945719825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08869146555662155,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033935483545064926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10228490829467773,
      "backward_entropy": 0.008016377687454224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08197259902954102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03394290804862976,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10219645500183105,
      "backward_entropy": 0.010027204122808244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07948064059019089,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033950138837099075,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10210838317871093,
      "backward_entropy": 0.010001919335789151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05658935010433197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03395717963576317,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10202066898345948,
      "backward_entropy": 0.009977382090356614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07547328621149063,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03396386280655861,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10193521976470947,
      "backward_entropy": 0.009954141245947944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08319822698831558,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03397035971283913,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10184986591339111,
      "backward_entropy": 0.007877364754676819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08197083324193954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033976875245571136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10176408290863037,
      "backward_entropy": 0.007502397729290856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05714782699942589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03398334980010986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1016776442527771,
      "backward_entropy": 0.007471340397993724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08784104883670807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03398950397968292,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1015925645828247,
      "backward_entropy": 0.00780164036485884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04991501569747925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03399575501680374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10150578022003173,
      "backward_entropy": 0.007411578463183509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05607783421874046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034001581370830536,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10142054557800292,
      "backward_entropy": 0.007383277018864949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039901044219732285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034007005393505096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10133562088012696,
      "backward_entropy": 0.007356528606679704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07356010377407074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03401186317205429,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10125232934951782,
      "backward_entropy": 0.009789178768793741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059475794434547424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03401681035757065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10116773843765259,
      "backward_entropy": 0.007692803111341264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05274416506290436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402158245444298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10108288526535034,
      "backward_entropy": 0.007283031940460205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04924323409795761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034026142209768295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10099838972091675,
      "backward_entropy": 0.0072597091396649676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05279958248138428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403037413954735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1009140968322754,
      "backward_entropy": 0.007637679576873779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0483386367559433,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03403452783823013,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10083004236221313,
      "backward_entropy": 0.0072159551911883885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05865353345870972,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403851017355919,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1007463812828064,
      "backward_entropy": 0.007604289386007521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05210680887103081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034042514860630035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1006618618965149,
      "backward_entropy": 0.007173918187618256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05420931801199913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404650092124939,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10057729482650757,
      "backward_entropy": 0.007152977089087169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03645213693380356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405052050948143,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10049234628677368,
      "backward_entropy": 0.007131925887531704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04270614683628082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03405439108610153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10040920972824097,
      "backward_entropy": 0.00753941469722324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045672956854104996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03405821695923805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10032685995101928,
      "backward_entropy": 0.007524025109079149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05436927080154419,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406202420592308,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10024454593658447,
      "backward_entropy": 0.007071749203734928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04689351096749306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034065961837768555,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10016106367111206,
      "backward_entropy": 0.00705135530895657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03685697540640831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406988084316254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10007719993591309,
      "backward_entropy": 0.00703107151720259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03778228536248207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340735986828804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09999397993087769,
      "backward_entropy": 0.007011608944998847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03182453662157059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407721221446991,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09991133213043213,
      "backward_entropy": 0.006992628177007039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03085753507912159,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034080591052770615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09982970952987671,
      "backward_entropy": 0.006974624262915717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04633630812168121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03408375382423401,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09974903464317322,
      "backward_entropy": 0.00956360830201043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04594649374485016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03408714383840561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09966744184494018,
      "backward_entropy": 0.007407959964540269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04161883890628815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409069404006004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09958471059799194,
      "backward_entropy": 0.006921012368467119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03654707223176956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03409433737397194,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0995015025138855,
      "backward_entropy": 0.009529691603448655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023092126473784447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409792110323906,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09941821098327637,
      "backward_entropy": 0.006883533464537727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025085419416427612,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034101102501153946,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09933643341064453,
      "backward_entropy": 0.007352145181761848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030279994010925293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03410407528281212,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09925599098205566,
      "backward_entropy": 0.0073400793804062735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034169506281614304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410700708627701,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09917598962783813,
      "backward_entropy": 0.006834444486432605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024974728003144264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411008417606354,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09909592866897583,
      "backward_entropy": 0.007315889000892639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025946475565433502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411298617720604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09901678562164307,
      "backward_entropy": 0.007304233809312184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019163358956575394,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411589190363884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09893866777420043,
      "backward_entropy": 0.007292701138390435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018815867602825165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03411856293678284,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09886220693588257,
      "backward_entropy": 0.009454389413197836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027657119557261467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412100672721863,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09878717064857483,
      "backward_entropy": 0.006758694847424825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030032336711883545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412353992462158,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09871206283569336,
      "backward_entropy": 0.006744791650109821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025837600231170654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412623703479767,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09863638877868652,
      "backward_entropy": 0.007251620292663574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02341805212199688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034128982573747635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09856083393096923,
      "backward_entropy": 0.007240845925278134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019096529111266136,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0341317281126976,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09848572015762329,
      "backward_entropy": 0.009412881400850084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026828067377209663,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413430601358414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09841151237487793,
      "backward_entropy": 0.007219993405871921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01686774380505085,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034137073904275894,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09833699464797974,
      "backward_entropy": 0.009395495884948306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02010095864534378,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413960710167885,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0982634961605072,
      "backward_entropy": 0.009387382202678256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016201211139559746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0341421440243721,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09819061160087586,
      "backward_entropy": 0.009379155106014676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016210228204727173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03414453566074371,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09811884760856629,
      "backward_entropy": 0.006632845434877608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018237434327602386,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03414677083492279,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09804787635803222,
      "backward_entropy": 0.007171178857485454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012262233532965183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034149013459682465,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09797738790512085,
      "backward_entropy": 0.007162373926904466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017735827714204788,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034150972962379456,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09790815114974975,
      "backward_entropy": 0.009351659152242873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015121427364647388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034153010696172714,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0978393316268921,
      "backward_entropy": 0.006585779703325695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013112863525748253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03415495529770851,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09777106046676635,
      "backward_entropy": 0.006574775609705184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01475216168910265,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03415679931640625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09770383834838867,
      "backward_entropy": 0.00656423634952969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013728955760598183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341586135327816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0976370930671692,
      "backward_entropy": 0.0071240199936760795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014222784899175167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03416034206748009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09757081270217896,
      "backward_entropy": 0.006543767948945363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012027239426970482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03416210040450096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09750510454177856,
      "backward_entropy": 0.006533654199706184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01083756797015667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034163739532232285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09744006395339966,
      "backward_entropy": 0.00652401852938864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014395463280379772,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03416530415415764,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09737617373466492,
      "backward_entropy": 0.009309632082780203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01376359723508358,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03416697308421135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09731241464614868,
      "backward_entropy": 0.007090091705322266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009492390789091587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03416873514652252,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09724892377853393,
      "backward_entropy": 0.006495210445589489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009875244460999966,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03417041897773743,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09718676209449768,
      "backward_entropy": 0.00707642568482293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009033231064677238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03417206183075905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09712567329406738,
      "backward_entropy": 0.006476422564850913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009085818193852901,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03417355194687843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09706538319587707,
      "backward_entropy": 0.007064022951655918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010059718042612076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034174952656030655,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09700587987899781,
      "backward_entropy": 0.006459376878208584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0067319502122700214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03417639806866646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0969470739364624,
      "backward_entropy": 0.006450945304499732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005457157269120216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03417766094207764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09688950181007386,
      "backward_entropy": 0.006443240990241368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009362260811030865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034178756177425385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09683361053466796,
      "backward_entropy": 0.006436228338215087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007791480515152216,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03417989984154701,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0967780351638794,
      "backward_entropy": 0.0070383068588044904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00788253266364336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03418097272515297,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09672297835350037,
      "backward_entropy": 0.007033824092812008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008412676863372326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03418208658695221,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09666872024536133,
      "backward_entropy": 0.009261268708440993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006957434583455324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03418324142694473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09661484956741333,
      "backward_entropy": 0.006408207532432344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006524281110614538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03418438881635666,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0965618371963501,
      "backward_entropy": 0.006401237928205066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006764106918126345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03418548032641411,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09650958776473999,
      "backward_entropy": 0.006394510881768333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006238183006644249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03418654575943947,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09645791053771972,
      "backward_entropy": 0.006387927052047517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007407097145915031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03418761119246483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09640709161758423,
      "backward_entropy": 0.006381398273838891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004071318078786135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03418874368071556,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09635657072067261,
      "backward_entropy": 0.00924252967039744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006004767492413521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03418976813554764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0963075578212738,
      "backward_entropy": 0.006368421432044771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005660267546772957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034190814942121506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0962591826915741,
      "backward_entropy": 0.006362142662207286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005797224119305611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034191835671663284,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09621131420135498,
      "backward_entropy": 0.006355972753630744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006545163691043854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03419286012649536,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09616385698318482,
      "backward_entropy": 0.006349818574057685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031632110476493835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034193966537714005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09611658453941345,
      "backward_entropy": 0.006981472174326579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005689067766070366,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034194935113191605,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0960707426071167,
      "backward_entropy": 0.009224423103862338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004271377343684435,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03419596701860428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0960252583026886,
      "backward_entropy": 0.006973438792758518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005637243390083313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03419695794582367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09598056077957154,
      "backward_entropy": 0.0063256315059132045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004141237121075392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03419802337884903,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09593604803085327,
      "backward_entropy": 0.009214996463722654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004587600473314524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034199077636003494,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09589239358901977,
      "backward_entropy": 0.006313520587152905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003598014358431101,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03420015797019005,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0958492636680603,
      "backward_entropy": 0.006307482719421387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0050568184815347195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03420119360089302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09580702781677246,
      "backward_entropy": 0.006301624907387627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004347624257206917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03420231491327286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09576494097709656,
      "backward_entropy": 0.006295500530136956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031919663306325674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03420346975326538,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09572328925132752,
      "backward_entropy": 0.00628929336865743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003537733806297183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034204572439193726,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09568253755569459,
      "backward_entropy": 0.006939711670080821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003528594272211194,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034205663949251175,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09564242959022522,
      "backward_entropy": 0.009189731544918485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00332391238771379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034206729382276535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0956027626991272,
      "backward_entropy": 0.006271650393803914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018957603024318814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342077799141407,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09556366205215454,
      "backward_entropy": 0.00626596932609876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024326390121132135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03420870378613472,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09552578926086426,
      "backward_entropy": 0.0062607891029781764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033336197957396507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03420956805348396,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09548877477645874,
      "backward_entropy": 0.0062558526794115705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027466262690722942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03421046957373619,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09545203447341918,
      "backward_entropy": 0.0062508102920320295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028263037092983723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03421137481927872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09541592597961426,
      "backward_entropy": 0.006245805985397763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032543286215513945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034212298691272736,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09538034796714782,
      "backward_entropy": 0.009167969226837158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002127313055098057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03421328589320183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09534496068954468,
      "backward_entropy": 0.006235535773966048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031995929311960936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03421422839164734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09531038403511047,
      "backward_entropy": 0.006230495042271084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002151298336684704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034215234220027924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09527583122253418,
      "backward_entropy": 0.006225234932369656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022240846883505583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034216199070215225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09524191617965698,
      "backward_entropy": 0.006894470916854011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021854033693671227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034217141568660736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09520848989486694,
      "backward_entropy": 0.00621519030796157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00172933388967067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034218087792396545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09517565965652466,
      "backward_entropy": 0.0062102435363663566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017795506864786148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034218985587358475,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09514358043670654,
      "backward_entropy": 0.006883700274758869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014879725640639663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034219853579998016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.095112144947052,
      "backward_entropy": 0.00620093113846249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002000313950702548,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034220658242702484,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09508146047592163,
      "backward_entropy": 0.009139126373661889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016741789877414703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034221481531858444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.095051109790802,
      "backward_entropy": 0.006192206508583493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013799489242956042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03422229364514351,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09502129554748535,
      "backward_entropy": 0.006187897175550461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016439150786027312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03422306850552559,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09499222040176392,
      "backward_entropy": 0.006867917461527718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001191654708236456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03422384336590767,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09496355056762695,
      "backward_entropy": 0.006179653108119965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012012203224003315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03422456607222557,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09493559002876281,
      "backward_entropy": 0.006175742381148868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009172958671115339,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034225258976221085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0949083149433136,
      "backward_entropy": 0.006172002603610356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009411951177753508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03422588109970093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09488180875778199,
      "backward_entropy": 0.006857089698314667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013393928529694676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03422645479440689,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09485602378845215,
      "backward_entropy": 0.006165266450908449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011129253543913364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03422704339027405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0948305606842041,
      "backward_entropy": 0.006161970396836598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013008237583562732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03422762453556061,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09480559229850768,
      "backward_entropy": 0.006158735189172957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013897692551836371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03422823175787926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0947809100151062,
      "backward_entropy": 0.006155432512362798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009153922437690198,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034228887408971786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09475641846656799,
      "backward_entropy": 0.006151968820227517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009403619333170354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03422951325774193,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09473248720169067,
      "backward_entropy": 0.009108788437313504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009838981786742806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034230124205350876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09470905065536499,
      "backward_entropy": 0.0061453936828507316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011143401497974992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423072770237923,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09468597173690796,
      "backward_entropy": 0.006142195728090074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010795659618452191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423135727643967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0946631371974945,
      "backward_entropy": 0.006138905882835388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000790129997767508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342320092022419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0946405291557312,
      "backward_entropy": 0.006135564711358812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007614362402819097,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423263877630234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09461840987205505,
      "backward_entropy": 0.006132321639193429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008972547948360443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423324599862099,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09459676146507263,
      "backward_entropy": 0.006129173768891228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006808728212490678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423386067152023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09457536935806274,
      "backward_entropy": 0.0061260271403524615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006132290000095963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03423445671796799,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0945544958114624,
      "backward_entropy": 0.00682474962539143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006771189509890974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423502296209335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09453412294387817,
      "backward_entropy": 0.006120036873552535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007817542646080256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423558175563812,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09451415538787841,
      "backward_entropy": 0.006117163846890132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004926021210849285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034236155450344086,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09449440836906434,
      "backward_entropy": 0.006818438569704692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007553411414846778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034236691892147064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09447520971298218,
      "backward_entropy": 0.0061114682919449275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004569549346342683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423725441098213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09445617198944092,
      "backward_entropy": 0.006108610166443719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005841144593432546,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03423777595162392,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09443764686584473,
      "backward_entropy": 0.009078789088461135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004873917205259204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0342382937669754,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09441939592361451,
      "backward_entropy": 0.009076912369992998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005254715215414762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342387929558754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0944015383720398,
      "backward_entropy": 0.006100702616903517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005112211219966412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03423928841948509,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09438397884368896,
      "backward_entropy": 0.006098160727156533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004178360104560852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03423978015780449,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09436671733856201,
      "backward_entropy": 0.009071485035949282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005477824597619474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034240253269672394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09434984922409058,
      "backward_entropy": 0.0060931916038195295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004917565383948386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424074873328209,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09433313608169555,
      "backward_entropy": 0.006090709732638465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004205470613669604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03424125164747238,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09431667327880859,
      "backward_entropy": 0.0067994606991608935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003228532732464373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424174711108208,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09430050253868102,
      "backward_entropy": 0.006085726122061412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023400323698297143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034242212772369385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09428476095199585,
      "backward_entropy": 0.006083383328384823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003608776314649731,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424263000488281,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09426953792572021,
      "backward_entropy": 0.006081216037273407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004517772176768631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03424304723739624,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09425458908081055,
      "backward_entropy": 0.00905942420164744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026901380624622107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034243494272232056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.094239741563797,
      "backward_entropy": 0.006076850824885898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004096624325029552,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03424391150474548,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09422526955604553,
      "backward_entropy": 0.0067896197239557905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029662781162187457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034244354814291,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09421089887619019,
      "backward_entropy": 0.0067879971530702375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003169625124428421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424479067325592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0941968321800232,
      "backward_entropy": 0.006070370475451152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023523186973761767,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03424523025751114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09418297410011292,
      "backward_entropy": 0.006784808304574754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027156059513799846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424564749002457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09416946768760681,
      "backward_entropy": 0.0060661617252561785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022798847930971533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034246060997247696,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09415620565414429,
      "backward_entropy": 0.0067818015813827515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002587700146250427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424645960330963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09414323568344116,
      "backward_entropy": 0.006062166144450505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001673319929977879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424685820937157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09413048028945922,
      "backward_entropy": 0.00606019463804033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025824771728366613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034247223287820816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09411809444427491,
      "backward_entropy": 0.006058363450898064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019714915833901614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424760326743126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09410586357116699,
      "backward_entropy": 0.006056498322221968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002334142627660185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03424797207117081,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09409388303756713,
      "backward_entropy": 0.0067749230398072135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024260459758806974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424834832549095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09408204555511475,
      "backward_entropy": 0.006052832222647137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014958683459553868,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03424874320626259,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09407033920288085,
      "backward_entropy": 0.009037645326720344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018813219503499568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034249112010002136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09405893087387085,
      "backward_entropy": 0.006049154119359123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016881071496754885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034249480813741684,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09404771327972412,
      "backward_entropy": 0.006769499431053798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021069281501695514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03424984589219093,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09403671622276306,
      "backward_entropy": 0.006045604331625832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019034628348890692,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034250229597091675,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09402579069137573,
      "backward_entropy": 0.009031828078958724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011315429583191872,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425062447786331,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09401499032974243,
      "backward_entropy": 0.0067653800878259875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.843164348741993e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425099328160286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09400450587272643,
      "backward_entropy": 0.006040185276005004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012021617294522002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034251321107149124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0939943790435791,
      "backward_entropy": 0.0060386016137070125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012515751586761326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425163775682449,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09398447275161743,
      "backward_entropy": 0.006037062240971459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010186410509049892,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034251950681209564,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09397475719451905,
      "backward_entropy": 0.009025092754099105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012211241119075567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425224870443344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396526217460632,
      "backward_entropy": 0.006034101049105327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010938615741906688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425255045294762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09395591616630554,
      "backward_entropy": 0.006032647358046638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.501757838530466e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425285220146179,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09394675493240356,
      "backward_entropy": 0.006031201945410835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.46131588332355e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034253135323524475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09393782019615174,
      "backward_entropy": 0.006029821104473538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76446720212698e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425340726971626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09392908215522766,
      "backward_entropy": 0.0060284944872061414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.368850881699473e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425367549061775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09392052888870239,
      "backward_entropy": 0.006027188152074814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.771311745978892e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425392135977745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09391220808029174,
      "backward_entropy": 0.006025967498620351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.327173807425424e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034254156053066254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09390408396720887,
      "backward_entropy": 0.006024792376491759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5420354581438005e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425438702106476,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0938961386680603,
      "backward_entropy": 0.009015628033214144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.51421069051139e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034254588186740875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09388843774795533,
      "backward_entropy": 0.006022609770298004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.257128603057936e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425478935241699,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09388089179992676,
      "backward_entropy": 0.006021586143308216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.302752470015548e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425496816635132,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09387356042861938,
      "backward_entropy": 0.00674993462032742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.995496783521958e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425513952970505,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09386640787124634,
      "backward_entropy": 0.006749322017033895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.08266787417233e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425530344247818,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09385941624641418,
      "backward_entropy": 0.006018858816888597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.261356636765413e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425545617938042,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09385261535644532,
      "backward_entropy": 0.009011644456121657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.806074892054312e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425561264157295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09384593963623047,
      "backward_entropy": 0.006017189058992598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.149011874687858e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425575792789459,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09383943080902099,
      "backward_entropy": 0.009010532663928138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3788077164208516e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034255899488925934,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09383307695388794,
      "backward_entropy": 0.006746585998270247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.371759885339998e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034256044775247574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09382685422897338,
      "backward_entropy": 0.00601482888062795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4247228793683462e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425618261098862,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09382078647613526,
      "backward_entropy": 0.006745552023251851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9796787202940322e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425630182027817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09381491541862488,
      "backward_entropy": 0.006013393816020753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.206604378647171e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425641730427742,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09380917549133301,
      "backward_entropy": 0.006744712591171265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.65003527601948e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425653278827667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09380357265472412,
      "backward_entropy": 0.006012107763025496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4954262698884122e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425664082169533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09379812479019164,
      "backward_entropy": 0.00601147570543819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4619277610327117e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034256745129823685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09379279613494873,
      "backward_entropy": 0.00601089745759964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6249374059261754e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425684571266174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09378762245178222,
      "backward_entropy": 0.006010311759180493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.811586116673425e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0342569500207901,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09378255605697632,
      "backward_entropy": 0.009006242785188887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0616569599951617e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425704315304756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09377763867378235,
      "backward_entropy": 0.006009208245409859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0239660443621688e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034257132560014725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09377285242080688,
      "backward_entropy": 0.006008681737714344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.06231779884547e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425722196698189,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09376817345619201,
      "backward_entropy": 0.00674186067448722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2789868378604297e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425731137394905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0937636137008667,
      "backward_entropy": 0.006007656041118834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8938515495392494e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425738960504532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09375919699668885,
      "backward_entropy": 0.006007184584935506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4579688468074892e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034257471561431885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09375487565994263,
      "backward_entropy": 0.0060067151983579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6158095604623668e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425754979252815,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09375067949295043,
      "backward_entropy": 0.00900414999988344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6334763131453656e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425762802362442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0937465786933899,
      "backward_entropy": 0.00600580374399821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2664554560615215e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034257709980010986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09374256134033203,
      "backward_entropy": 0.006740104820993211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3373633009905461e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034257788211107254,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09373866319656372,
      "backward_entropy": 0.009003281593322754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0700829989218619e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425787016749382,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09373486042022705,
      "backward_entropy": 0.006004453947146733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0929528798442334e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425794467329979,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09373117089271546,
      "backward_entropy": 0.006004029264052709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.826679161051288e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425801917910576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09372756481170655,
      "backward_entropy": 0.006003611203696992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0364231457060669e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425808995962143,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0937240719795227,
      "backward_entropy": 0.006003217564688789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.672096555528697e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0342581607401371,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09372066259384156,
      "backward_entropy": 0.006738521572616365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1113245212472975e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425822779536247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09371736049652099,
      "backward_entropy": 0.006002435253726112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.607569386891555e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425828740000725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0937141478061676,
      "backward_entropy": 0.006002095010545518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8583608481276315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425834700465202,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09371103644371033,
      "backward_entropy": 0.00900122606092029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.481842203560518e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342584028840065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09370800256729125,
      "backward_entropy": 0.006001432736714681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.791317562398035e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425845876336098,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09370505809783936,
      "backward_entropy": 0.006001101185878118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.12311168879387e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034258510917425156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09370219707489014,
      "backward_entropy": 0.0060007936424679225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2743609962344635e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034258563071489334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0936994194984436,
      "backward_entropy": 0.006000497274928623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.384183623391436e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425861895084381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09369670152664185,
      "backward_entropy": 0.006000196354256736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.830053057958139e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425867110490799,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09369406700134278,
      "backward_entropy": 0.005999890880452262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.18091576648294e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425872325897217,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09369150400161744,
      "backward_entropy": 0.005999598238203261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.395251380628906e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425877168774605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09368901848793029,
      "backward_entropy": 0.005999329603380627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.536204758347594e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425881639122963,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09368661046028137,
      "backward_entropy": 0.006736249559455448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5717509945243364e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425885736942291,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09368427991867065,
      "backward_entropy": 0.005998824205663469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.99661894334713e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342588946223259,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09368201494216918,
      "backward_entropy": 0.005998600688245561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7558386338787386e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425893560051918,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09367980360984803,
      "backward_entropy": 0.006735837707916896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3841527056210907e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425897657871246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09367766380310058,
      "backward_entropy": 0.006735683315330082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.45248793362407e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034259017556905746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09367557764053344,
      "backward_entropy": 0.006735550032721626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.75154570772429e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425905480980873,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09367356300354004,
      "backward_entropy": 0.005997694200939602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.581196667961194e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425908833742142,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09367160797119141,
      "backward_entropy": 0.006735319064723121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9802437236648984e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342591218650341,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09366971254348755,
      "backward_entropy": 0.005997285660770204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.166145577575662e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425915166735649,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09366787672042846,
      "backward_entropy": 0.005997105605072445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.341849722142797e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425918146967888,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09366609454154969,
      "backward_entropy": 0.008998255762788985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9713054371095495e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034259211272001266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09366437196731567,
      "backward_entropy": 0.006734886931048499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.789049520084518e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259241074323654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.093662691116333,
      "backward_entropy": 0.005996575372086631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.716811766527826e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425926715135574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09366105794906616,
      "backward_entropy": 0.005996408561865489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6023431044231984e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425929322838783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09365948438644409,
      "backward_entropy": 0.005996257894568973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.094628828468558e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425931930541992,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09365795850753784,
      "backward_entropy": 0.0067345185412300956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.394779701513471e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425934165716171,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09365646839141846,
      "backward_entropy": 0.00599596318271425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3238474139143364e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259360283613205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0936550498008728,
      "backward_entropy": 0.005995834453238381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0938698551399284e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342593789100647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09365365505218506,
      "backward_entropy": 0.0059957073794470895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1451924137872993e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425939753651619,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09365231394767762,
      "backward_entropy": 0.00599559023976326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1525528407219099e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425941616296768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09365101456642151,
      "backward_entropy": 0.006734180781576369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0351265018471167e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034259434789419174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09364974498748779,
      "backward_entropy": 0.006734119521247016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991448225970089e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034259453415870667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09364851713180541,
      "backward_entropy": 0.006734061572286818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449887900496833e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425947204232216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09364733099937439,
      "backward_entropy": 0.005995119611422221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.66538880977896e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425949066877365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09364619255065917,
      "backward_entropy": 0.005995007024870979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.812896569703298e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034259505569934845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09364508390426636,
      "backward_entropy": 0.006733894762065675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.177804945968091e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425952047109604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09364399909973145,
      "backward_entropy": 0.005994814137617747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.304463451873744e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425953537225723,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09364296197891235,
      "backward_entropy": 0.005994711485173967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.912212941439066e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259550273418427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09364194869995117,
      "backward_entropy": 0.005994622906049092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.24106860414031e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425956517457962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09364097118377686,
      "backward_entropy": 0.006733701874812444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.245167358225444e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034259580075740814,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0936400294303894,
      "backward_entropy": 0.006733643511931102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.066362405159452e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425959497690201,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363911151885987,
      "backward_entropy": 0.005994339783986409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.566192615129694e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0342596098780632,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363822340965271,
      "backward_entropy": 0.005994260725047853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8454427908618527e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034259624779224396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09363736510276795,
      "backward_entropy": 0.006733512712849511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7106078682190855e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425963595509529,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363653659820556,
      "backward_entropy": 0.005994095570511288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1194497296382906e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259647130966187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363572597503662,
      "backward_entropy": 0.005994024376074473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9862243877687433e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425965830683708,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363495111465454,
      "backward_entropy": 0.005993939936161041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.135964448119921e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425966948270798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363420009613037,
      "backward_entropy": 0.005993875364462535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.980139299779694e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425968065857887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363347291946411,
      "backward_entropy": 0.005993810792764028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.847877453859837e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425969183444977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363277554512024,
      "backward_entropy": 0.0059937478767500985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9484456831596617e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259699285030365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0936320960521698,
      "backward_entropy": 0.005993689099947612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.953260948539537e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425971046090126,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0936314344406128,
      "backward_entropy": 0.006733242836263444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2408748634461517e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425971791148186,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09363080859184265,
      "backward_entropy": 0.008996427059173584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2285944112354628e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259725362062454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363018274307251,
      "backward_entropy": 0.005993518564436171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.213754726199113e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425973281264305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09362959861755371,
      "backward_entropy": 0.00599347386095259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6259669166629465e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03425974026322365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09362902641296386,
      "backward_entropy": 0.006733140183819665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8981505434112478e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259747713804245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09362846612930298,
      "backward_entropy": 0.005993363757928212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0394533351009159e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03425975516438484,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09362793564796448,
      "backward_entropy": 0.008996274736192491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.256566690699401e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03425976261496544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09362741708755493,
      "backward_entropy": 0.00599325696627299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.251248562539331e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034259770065546036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09362691044807434,
      "backward_entropy": 0.005993203570445378,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.4334526302093309e-05,
    "avg_log_Z": 0.03425808377563953,
    "success_rate": 1.0,
    "avg_reward": 52.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.1,
      "1": 0.24,
      "2": 0.66
    },
    "avg_forward_entropy": 0.09371889609098437,
    "avg_backward_entropy": 0.006479579777353341,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}