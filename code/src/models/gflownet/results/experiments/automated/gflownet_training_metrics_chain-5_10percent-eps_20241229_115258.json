{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862186670303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862764835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955572128295898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235023816426596,
      "backward_entropy": 0.13862242698669433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.314054489135742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235274155934653,
      "backward_entropy": 0.13862032890319825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.089982032775879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00020004986436106265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235506614049277,
      "backward_entropy": 0.1386232018470764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.666975021362305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003000789147336036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18236116568247476,
      "backward_entropy": 0.13861534595489503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.303207397460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004002180357929319,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823654572168986,
      "backward_entropy": 0.1386217951774597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502214431762695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000500334077514708,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18236881494522095,
      "backward_entropy": 0.13862533569335939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.574715614318848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006002217414788902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18237523237864176,
      "backward_entropy": 0.13860586881637574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.431696891784668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007002644706517458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18238234519958496,
      "backward_entropy": 0.1386021852493286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.932319641113281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008003704715520144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18238919973373413,
      "backward_entropy": 0.1385981559753418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929544448852539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000900362734682858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823951005935669,
      "backward_entropy": 0.1386278510093689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.064705848693848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001000267919152975,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240018685658774,
      "backward_entropy": 0.1386021614074707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.843935012817383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011001599486917257,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824053724606832,
      "backward_entropy": 0.1385836720466614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.203048706054688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011999791022390127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18241119384765625,
      "backward_entropy": 0.13857810497283934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.546661376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013001523911952972,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824147899945577,
      "backward_entropy": 0.13858540058135987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052499771118164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014004303375259042,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18241886297861734,
      "backward_entropy": 0.13862942457199096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.913128852844238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015006153844296932,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242287635803223,
      "backward_entropy": 0.13857122659683227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.615199089050293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016006637597456574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242613474527994,
      "backward_entropy": 0.13855137825012206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.61124324798584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017008475260809064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242843945821127,
      "backward_entropy": 0.13854339122772216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.174234390258789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018011436332017183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824298898379008,
      "backward_entropy": 0.1385348320007324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.332697868347168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019017227459698915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182429830233256,
      "backward_entropy": 0.13852571249008178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.948929786682129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002002226421609521,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242808183034262,
      "backward_entropy": 0.13852283954620362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.030762672424316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021029131021350622,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242581685384116,
      "backward_entropy": 0.13862247467041017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.422607421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022034221328794956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242394924163818,
      "backward_entropy": 0.13862006664276122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.49626350402832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002304299734532833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242192268371582,
      "backward_entropy": 0.138617205619812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673571586608887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002405497943982482,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18241870403289795,
      "backward_entropy": 0.1384692907333374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.537030220031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025062900967895985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18241602182388306,
      "backward_entropy": 0.13845375776290894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.01460075378418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026066626887768507,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18241320053736368,
      "backward_entropy": 0.1386056900024414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.569315910339355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027068753261119127,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824106772740682,
      "backward_entropy": 0.13841981887817384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.196259498596191,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002807161770761013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824075977007548,
      "backward_entropy": 0.13859522342681885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.004990577697754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029074179474264383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240698178609213,
      "backward_entropy": 0.13839962482452392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76826000213623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0030075230170041323,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240630626678467,
      "backward_entropy": 0.1383620858192444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.631301879882812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031077894382178783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240429957707724,
      "backward_entropy": 0.13836615085601806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.494729042053223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0032081289682537317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240084250768027,
      "backward_entropy": 0.13834800720214843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.202092170715332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003308463841676712,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239553769429526,
      "backward_entropy": 0.1385588526725769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.749946594238281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034087058156728745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182390034198761,
      "backward_entropy": 0.13854986429214478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.613390922546387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00350908818654716,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823837161064148,
      "backward_entropy": 0.1382421612739563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.53144645690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003609523642808199,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823770006497701,
      "backward_entropy": 0.13821423053741455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.658554077148438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003709994023665786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18237022558848062,
      "backward_entropy": 0.13824241161346434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.387433052062988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038105619605630636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823637088139852,
      "backward_entropy": 0.13850648403167726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.064642906188965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003911563660949469,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235852320988974,
      "backward_entropy": 0.1381932497024536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.152975082397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004012747667729855,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235230445861816,
      "backward_entropy": 0.13808982372283934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.769896507263184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004113761708140373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18234819173812866,
      "backward_entropy": 0.1381401777267456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.297073364257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004214861895889044,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18234427769978842,
      "backward_entropy": 0.13801860809326172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.172194480895996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004315814469009638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18234026432037354,
      "backward_entropy": 0.1380833148956299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.234498023986816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00441701477393508,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233537673950195,
      "backward_entropy": 0.13805296421051025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.153836250305176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004517987836152315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823291778564453,
      "backward_entropy": 0.13802123069763184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.412734985351562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004618746228516102,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823225220044454,
      "backward_entropy": 0.1383806824684143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.555184364318848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004719908814877272,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18231582641601562,
      "backward_entropy": 0.13781068325042725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.087254524230957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00482099037617445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823078195254008,
      "backward_entropy": 0.13792071342468262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.674036026000977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004921771585941315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18229844172795615,
      "backward_entropy": 0.13788442611694335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.667708396911621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005022118333727121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18228886524836221,
      "backward_entropy": 0.1378469467163086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.865440368652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005122544709593058,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18227853377660116,
      "backward_entropy": 0.13760826587677003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.993464469909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005223121028393507,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822670896848043,
      "backward_entropy": 0.13755227327346803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.922218322753906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00532343378290534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822554071744283,
      "backward_entropy": 0.13772521018981934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.772963523864746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005423025693744421,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822450558344523,
      "backward_entropy": 0.13818802833557128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.905928611755371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005522850435227156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18223430713017783,
      "backward_entropy": 0.13763790130615233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.163535118103027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005622482392936945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18222431341807047,
      "backward_entropy": 0.1373096227645874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.627058982849121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005722506903111935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18221282958984375,
      "backward_entropy": 0.1380946159362793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5640230178833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005822637118399143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821995178858439,
      "backward_entropy": 0.1374950408935547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.069832801818848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005922373849898577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821872591972351,
      "backward_entropy": 0.13744449615478516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100834846496582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0060224770568311214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18217424551645914,
      "backward_entropy": 0.13798873424530028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.984397888183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006121949292719364,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18216200669606528,
      "backward_entropy": 0.1369709014892578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.362768173217773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006221805699169636,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821500857671102,
      "backward_entropy": 0.13689697980880738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23066520690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006321150343865156,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18213677406311035,
      "backward_entropy": 0.13682067394256592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.327413558959961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006419963203370571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821219523747762,
      "backward_entropy": 0.13716819286346435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.181572914123535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006518861278891563,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18210546175638834,
      "backward_entropy": 0.13778361082077026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85208797454834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006617814768105745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18208966652552286,
      "backward_entropy": 0.13773846626281738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.650920867919922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006716655567288399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182074765364329,
      "backward_entropy": 0.1369812607765198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84135627746582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006815310567617416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820614735285441,
      "backward_entropy": 0.13764309883117676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.708613395690918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006913885474205017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18204877773920694,
      "backward_entropy": 0.13759284019470214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.057255744934082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007012312766164541,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820362607638041,
      "backward_entropy": 0.1375408411026001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.98189640045166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007111262064427137,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18202143907546997,
      "backward_entropy": 0.1361217975616455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.808358192443848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007210663519799709,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18200568358103433,
      "backward_entropy": 0.1374300479888916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512710571289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007310866843909025,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18198819955190024,
      "backward_entropy": 0.13591796159744263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.50987720489502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007411197759211063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1819728215535482,
      "backward_entropy": 0.13648054599761963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.50575065612793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007511579897254705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18195619185765585,
      "backward_entropy": 0.1363997220993042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.492914199829102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007611944805830717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18193582693735758,
      "backward_entropy": 0.13631600141525269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.040083885192871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0077123502269387245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18191468715667725,
      "backward_entropy": 0.1362299919128418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.384280681610107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007812549360096455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18189277251561484,
      "backward_entropy": 0.13614180088043212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.782533645629883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007911739870905876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818727453549703,
      "backward_entropy": 0.13605318069458008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.448075294494629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008011252619326115,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18185130755106607,
      "backward_entropy": 0.1350948691368103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.190878868103027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008110394701361656,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18183149894078574,
      "backward_entropy": 0.13496170043945313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.697054862976074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008209111168980598,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18181554476420084,
      "backward_entropy": 0.13670964241027833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.49227237701416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00830867700278759,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18179665009180704,
      "backward_entropy": 0.13662227392196655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92034912109375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008407928049564362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18178089459737143,
      "backward_entropy": 0.13558783531188964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.601202964782715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008507072925567627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18176480134328207,
      "backward_entropy": 0.13549114465713502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.904263496398926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008607003837823868,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18174660205841064,
      "backward_entropy": 0.13634276390075684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.577108383178711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008707300759851933,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18172856171925864,
      "backward_entropy": 0.13408181667327881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82431411743164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008807694539427757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.181708296140035,
      "backward_entropy": 0.13518033027648926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.749918937683105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008907833136618137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18168904383977255,
      "backward_entropy": 0.13506791591644288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.548916816711426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009007669053971767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18166937430699667,
      "backward_entropy": 0.13495335578918458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.486968994140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009107702411711216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18165022134780884,
      "backward_entropy": 0.13483566045761108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.077317237854004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009207344613969326,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18163265784581503,
      "backward_entropy": 0.13321561813354493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.964132308959961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00930744782090187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816127896308899,
      "backward_entropy": 0.13557420969009398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700569152832031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009407452307641506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18159582217534384,
      "backward_entropy": 0.13446612358093263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.790994644165039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009507146663963795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1815778613090515,
      "backward_entropy": 0.1353228807449341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.836835861206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009607127867639065,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18155664205551147,
      "backward_entropy": 0.13243707418441772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.459227561950684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009707365185022354,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18153132994969687,
      "backward_entropy": 0.13505754470825196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.264570236206055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009807657450437546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18150399128595987,
      "backward_entropy": 0.13392260074615478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.587142944335938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009907908737659454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1814757784207662,
      "backward_entropy": 0.1337761402130127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93550968170166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010007789358496666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814490556716919,
      "backward_entropy": 0.13463008403778076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.857068061828613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010107501409947872,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18142171700795492,
      "backward_entropy": 0.1313338041305542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.236340522766113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010206986218690872,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18139280875523886,
      "backward_entropy": 0.131095027923584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.975069046020508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010307052172720432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18136155605316162,
      "backward_entropy": 0.1341543436050415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51508903503418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010407473891973495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813275416692098,
      "backward_entropy": 0.13298912048339845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.0441255569458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010507410392165184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18129251400629678,
      "backward_entropy": 0.13281883001327516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.869437217712402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010607223026454449,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18125698963801065,
      "backward_entropy": 0.13363674879074097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31253433227539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010707392357289791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1812201738357544,
      "backward_entropy": 0.13246607780456543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.945185661315918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010807067155838013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1811863382657369,
      "backward_entropy": 0.13228561878204345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.634050369262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01090661995112896,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18115260203679404,
      "backward_entropy": 0.1292658805847168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.390149116516113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01100589707493782,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18111956119537354,
      "backward_entropy": 0.12898247241973876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.314547538757324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01110587827861309,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18108352025349936,
      "backward_entropy": 0.12869105339050294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.710006713867188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01120592001825571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810473402341207,
      "backward_entropy": 0.13152140378952026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279561996459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011305687949061394,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1810123324394226,
      "backward_entropy": 0.12807912826538087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261853218078613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011404966935515404,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18097921212514242,
      "backward_entropy": 0.1277618408203125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.83112907409668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011504358612000942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18094563484191895,
      "backward_entropy": 0.13090379238128663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.194265365600586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01160360500216484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18091185887654623,
      "backward_entropy": 0.13068935871124268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722420692443848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011703433468937874,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1808727184931437,
      "backward_entropy": 0.12676830291748048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.859719276428223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01180297788232565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18083210786183676,
      "backward_entropy": 0.13106932640075683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167015075683594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011902893893420696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18078728516896567,
      "backward_entropy": 0.13081982135772705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.55467700958252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012002809904515743,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18074262142181396,
      "backward_entropy": 0.12570114135742189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.552655220031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012102953158318996,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18069779872894287,
      "backward_entropy": 0.12533259391784668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.382275581359863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012202735058963299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18065484364827475,
      "backward_entropy": 0.12927207946777344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.342605113983154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012302030809223652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18061000108718872,
      "backward_entropy": 0.12902116775512695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46669864654541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01240032259374857,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18056740363438925,
      "backward_entropy": 0.12417287826538086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538220405578613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012498976662755013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18052496512730917,
      "backward_entropy": 0.12850959300994874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.171143531799316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012596911750733852,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804900566736857,
      "backward_entropy": 0.1289016842842102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673026084899902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01269451528787613,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18045691649119058,
      "backward_entropy": 0.1286022424697876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849092960357666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012792130000889301,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18042508761088052,
      "backward_entropy": 0.12251681089401245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.270763397216797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012889268808066845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18039560317993164,
      "backward_entropy": 0.12798120975494384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.970290184020996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01298621203750372,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18036609888076782,
      "backward_entropy": 0.12766181230545043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.066218376159668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013083367608487606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18033345540364584,
      "backward_entropy": 0.12733793258666992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.921935081481934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01318022608757019,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.180302103360494,
      "backward_entropy": 0.1265719413757324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.412997245788574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013277285732328892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1802674134572347,
      "backward_entropy": 0.12626909017562865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.504654884338379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013374830596148968,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18022952477137247,
      "backward_entropy": 0.11972576379776001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.290398597717285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013472877442836761,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18018903334935507,
      "backward_entropy": 0.11923329830169678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.487204551696777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013570645824074745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18014788627624512,
      "backward_entropy": 0.12529127597808837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.081121444702148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013668865896761417,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18010270595550537,
      "backward_entropy": 0.12524547576904296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5061798095703125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01376668456941843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18005849917729697,
      "backward_entropy": 0.12459751367568969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519608497619629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013863812200725079,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1800172527631124,
      "backward_entropy": 0.11716742515563965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.157235145568848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013960308395326138,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1799770394961039,
      "backward_entropy": 0.11662511825561524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.636491775512695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014056624844670296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17993593215942383,
      "backward_entropy": 0.12351846694946289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100770950317383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014153087511658669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17989357312520346,
      "backward_entropy": 0.12333574295043945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.881670951843262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014249347150325775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17985043923060098,
      "backward_entropy": 0.12276389598846435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.699180603027344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014345334842801094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1798097292582194,
      "backward_entropy": 0.1225196123123169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.47535228729248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014441540464758873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17976615826288858,
      "backward_entropy": 0.12209837436676026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.097094535827637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014538400806486607,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17971905072530112,
      "backward_entropy": 0.11307731866836548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.948534965515137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014635037630796432,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17967291673024496,
      "backward_entropy": 0.12116575241088867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.581529140472412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014731377363204956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1796263058980306,
      "backward_entropy": 0.12078452110290527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.284080982208252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014827283099293709,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17958444356918335,
      "backward_entropy": 0.12032420635223388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.668244361877441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01492262352257967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1795481046040853,
      "backward_entropy": 0.11986877918243408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.16588306427002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015017679892480373,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17951385180155435,
      "backward_entropy": 0.11939712762832641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.362883567810059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015112785622477531,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17947882413864136,
      "backward_entropy": 0.11891483068466187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.739053726196289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01520808320492506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17944371700286865,
      "backward_entropy": 0.11842224597930909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.17505168914795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015303771942853928,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17940555016199747,
      "backward_entropy": 0.10777546167373657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.351127624511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015399472787976265,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17936716477076212,
      "backward_entropy": 0.107081937789917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.803743362426758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015494685620069504,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1793321967124939,
      "backward_entropy": 0.10637853145599366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.687262058258057,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015590316615998745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1792902946472168,
      "backward_entropy": 0.1163594126701355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.022631645202637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0156856682151556,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17924900849660239,
      "backward_entropy": 0.10494613647460938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.016073226928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015780990943312645,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17920724550882974,
      "backward_entropy": 0.10421724319458008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.976003170013428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01587626338005066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791630188624064,
      "backward_entropy": 0.11522363424301148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.370818138122559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015970824286341667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1791199247042338,
      "backward_entropy": 0.11415859460830688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.859559535980225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016065608710050583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17906930049260458,
      "backward_entropy": 0.11358925104141235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.505902290344238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01616034097969532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1790187954902649,
      "backward_entropy": 0.11364800930023193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6111931800842285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016254201531410217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.178977370262146,
      "backward_entropy": 0.11311362981796265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.196107864379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016347339376807213,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17894240220387778,
      "backward_entropy": 0.09964227676391602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.004426002502441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01644076406955719,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1788987716039022,
      "backward_entropy": 0.09885200262069702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7764177322387695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01653379201889038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17886058489481607,
      "backward_entropy": 0.11061055660247802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.808409214019775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016626272350549698,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17882504065831503,
      "backward_entropy": 0.0972650945186615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1178107261657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016718877479434013,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17878236373265585,
      "backward_entropy": 0.09645642042160034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.755478858947754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01681116782128811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17873768011728922,
      "backward_entropy": 0.10969809293746949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.636301517486572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016902998089790344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17869641383488974,
      "backward_entropy": 0.10908385515213012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.79850435256958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016994301229715347,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1786560813585917,
      "backward_entropy": 0.09397633075714111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.477939128875732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017085924744606018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17861109972000122,
      "backward_entropy": 0.10675237178802491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.792614459991455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017176998779177666,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17857114473978677,
      "backward_entropy": 0.10717592239379883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1878767013549805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017267048358917236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17853468656539917,
      "backward_entropy": 0.10539593696594238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.998386383056641,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01735713891685009,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17849395672480264,
      "backward_entropy": 0.10470346212387086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5735859870910645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017447160556912422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17845100164413452,
      "backward_entropy": 0.10520192384719848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.41437292098999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017537500709295273,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17840115229288736,
      "backward_entropy": 0.08883284330368042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.706126689910889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017628012225031853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1783447265625,
      "backward_entropy": 0.10382344722747802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.680724143981934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017718244343996048,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17828909556070963,
      "backward_entropy": 0.08707139492034913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.496559143066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01780884340405464,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17822404702504477,
      "backward_entropy": 0.08618338108062744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.951402187347412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017899008467793465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1781601905822754,
      "backward_entropy": 0.10037031173706054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.626427173614502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017989076673984528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1780922214190165,
      "backward_entropy": 0.09962302446365356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.570687770843506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018078867346048355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17802393436431885,
      "backward_entropy": 0.10023348331451416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.218647003173828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01816837675869465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17795546849568686,
      "backward_entropy": 0.09808814525604248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.858588218688965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018257446587085724,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1778926452000936,
      "backward_entropy": 0.08168573379516601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.86466646194458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018345830962061882,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1778343121210734,
      "backward_entropy": 0.08077915906906127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6027679443359375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018433554098010063,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17777574062347412,
      "backward_entropy": 0.09571553468704223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.642130374908447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018521232530474663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17771196365356445,
      "backward_entropy": 0.09491486549377441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.779075622558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018608924001455307,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17764359712600708,
      "backward_entropy": 0.0780210554599762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.351924896240234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01869676262140274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17757133642832437,
      "backward_entropy": 0.0948751449584961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.227288722991943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018783695995807648,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17750628789265951,
      "backward_entropy": 0.09406890273094178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.715513706207275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018870441243052483,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1774365504582723,
      "backward_entropy": 0.07524136304855347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.180911540985107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018956642597913742,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17736719051996866,
      "backward_entropy": 0.0743106484413147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.815983295440674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019041990861296654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1773050824801127,
      "backward_entropy": 0.09160961508750916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.505584239959717,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019127028062939644,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1772405505180359,
      "backward_entropy": 0.0724492609500885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.594336032867432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01921158842742443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17717830340067545,
      "backward_entropy": 0.089952152967453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.790919780731201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019295748323202133,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17711361249287924,
      "backward_entropy": 0.07058826684951783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.185074329376221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019379787147045135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17704947789510092,
      "backward_entropy": 0.08827487230300904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.068475246429443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019464002922177315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1769797404607137,
      "backward_entropy": 0.08742381334304809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.287088871002197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01954747922718525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17691177129745483,
      "backward_entropy": 0.0865724265575409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.698703765869141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019630517810583115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1768463651339213,
      "backward_entropy": 0.08571982383728027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.552717685699463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01971343904733658,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17677438259124756,
      "backward_entropy": 0.08485872745513916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8886613845825195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019795367494225502,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17670919497807822,
      "backward_entropy": 0.06505627036094666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.365705966949463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01987745240330696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17663317918777466,
      "backward_entropy": 0.08313196897506714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.741645812988281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019958434626460075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1765615145365397,
      "backward_entropy": 0.08226463794708253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.698394775390625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02003871090710163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17648704846700033,
      "backward_entropy": 0.07957309484481812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.106312274932861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020119162276387215,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17640014489491782,
      "backward_entropy": 0.06140687465667725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7896342277526855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020199298858642578,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17630789677302042,
      "backward_entropy": 0.07962701320648194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.342902660369873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020278960466384888,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17621741692225137,
      "backward_entropy": 0.059599381685256955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.787099361419678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020358650013804436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17612004280090332,
      "backward_entropy": 0.07784985303878784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.06732177734375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020437873899936676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17602006594340006,
      "backward_entropy": 0.07521793842315674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.189277172088623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020517008379101753,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1759184996287028,
      "backward_entropy": 0.056926262378692624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.347638130187988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020596183836460114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17581341663996378,
      "backward_entropy": 0.07516404390335082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7655558586120605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020674653351306915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17571340004603067,
      "backward_entropy": 0.05518050193786621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.524420261383057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020752862095832825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1756113568941752,
      "backward_entropy": 0.07337952256202698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.249809265136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020830590277910233,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1755069096883138,
      "backward_entropy": 0.053463757038116455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.383749485015869,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020907679572701454,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17540494600931802,
      "backward_entropy": 0.06993110179901123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.931462526321411,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02098429575562477,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17530033985773721,
      "backward_entropy": 0.06905168890953065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.899618148803711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021060103550553322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17520038286844888,
      "backward_entropy": 0.06982222199440002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.514039039611816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021135088056325912,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1750991145769755,
      "backward_entropy": 0.050118941068649295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.349630355834961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021210014820098877,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17499331633249918,
      "backward_entropy": 0.04930098652839661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.13010835647583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0212838314473629,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17490080992380777,
      "backward_entropy": 0.06558506488800049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.965817928314209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021357303485274315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1747989853223165,
      "backward_entropy": 0.06472870111465454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.067442417144775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021430332213640213,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17469346523284912,
      "backward_entropy": 0.04690670967102051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.032132863998413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021503079682588577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17458224296569824,
      "backward_entropy": 0.06460330486297608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.988010883331299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021574612706899643,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1744865576426188,
      "backward_entropy": 0.06218748688697815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6168792247772217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02164602465927601,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1743879715601603,
      "backward_entropy": 0.06134610772132874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.433166980743408,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02171686664223671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17428487539291382,
      "backward_entropy": 0.06051238775253296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.959420919418335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021787114441394806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17418638865152994,
      "backward_entropy": 0.061234128475189206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5632526874542236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021856339648365974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17409942547480264,
      "backward_entropy": 0.06041498184204101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2110073566436768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021925238892436028,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17400741577148438,
      "backward_entropy": 0.058040350675582886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.27477765083313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021993378177285194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1739091674486796,
      "backward_entropy": 0.05723519921302796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.029785394668579,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022061003372073174,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17380895217259726,
      "backward_entropy": 0.04022185504436493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8591017723083496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02212798409163952,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17371543248494467,
      "backward_entropy": 0.03952459096908569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.623427629470825,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022194061428308487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17362213134765625,
      "backward_entropy": 0.05485922694206238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.182765483856201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022259140387177467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17353761196136475,
      "backward_entropy": 0.0556164026260376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7358224391937256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022323915734887123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17344427108764648,
      "backward_entropy": 0.05484274625778198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1204874515533447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022387953475117683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1733532945315043,
      "backward_entropy": 0.05407882332801819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9929237365722656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022451771423220634,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17325429121653238,
      "backward_entropy": 0.051811707019805905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4998695850372314,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022515224292874336,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1731474002202352,
      "backward_entropy": 0.03555283546447754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6293838024139404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02257777750492096,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17304339011510214,
      "backward_entropy": 0.03492550849914551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.436694383621216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022639771923422813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1729432741800944,
      "backward_entropy": 0.05106841325759888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6741783618927,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022701021283864975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17284895976384482,
      "backward_entropy": 0.048899269104003905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.281843423843384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022761831060051918,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17274868488311768,
      "backward_entropy": 0.04961943030357361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.415520191192627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02282174862921238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17265029748280844,
      "backward_entropy": 0.047493654489517215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.810812473297119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02288108319044113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17255167166392008,
      "backward_entropy": 0.04820692539215088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5129714012145996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022940445691347122,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1724431316057841,
      "backward_entropy": 0.047503983974456786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.536954164505005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022999374195933342,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17232672373453775,
      "backward_entropy": 0.030835437774658202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.331007242202759,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023058125749230385,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.172210693359375,
      "backward_entropy": 0.030288389325141905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.091238498687744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023116298019886017,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17209001382191977,
      "backward_entropy": 0.029751241207122803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1047680377960205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023173628374934196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17196998993555704,
      "backward_entropy": 0.04475317001342773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0896859169006348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023230206221342087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17184762159983316,
      "backward_entropy": 0.04408933520317078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.918015480041504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023286184296011925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17172702153523764,
      "backward_entropy": 0.0421599268913269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.439964532852173,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023341160267591476,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17159934838612875,
      "backward_entropy": 0.02771332561969757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.505926489830017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02339625172317028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17146170139312744,
      "backward_entropy": 0.042148491740226744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8090749979019165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023449966683983803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17133583625157675,
      "backward_entropy": 0.041525596380233766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6908682584762573,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02350284904241562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1712070107460022,
      "backward_entropy": 0.0397292286157608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5015543699264526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023554878309369087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17108158270517984,
      "backward_entropy": 0.039149099588394166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5749632120132446,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02360578440129757,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17096072435379028,
      "backward_entropy": 0.025404110550880432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9520543813705444,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023655757308006287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17083813746770224,
      "backward_entropy": 0.03802905380725861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4932435750961304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023705698549747467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17070960998535156,
      "backward_entropy": 0.03858660459518433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6672111749649048,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023754898458719254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17059111595153809,
      "backward_entropy": 0.03802932500839233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5177431106567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023803649470210075,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1704703370730082,
      "backward_entropy": 0.023744574189186095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3261133432388306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0238517913967371,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1703529953956604,
      "backward_entropy": 0.03693838715553284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4729200601577759,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023898877203464508,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1702357530593872,
      "backward_entropy": 0.022970935702323912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4619979858398438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02394549921154976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17012210687001547,
      "backward_entropy": 0.03589278161525726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.457106590270996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02399156056344509,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1700045665105184,
      "backward_entropy": 0.0343404084444046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.171617865562439,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024037163704633713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16988414525985718,
      "backward_entropy": 0.03487687706947327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2005541324615479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024081747978925705,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16976694266001383,
      "backward_entropy": 0.0215296670794487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9191250801086426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024125192314386368,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16963843504587808,
      "backward_entropy": 0.0329021155834198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.458753228187561,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02416723594069481,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16951666275660196,
      "backward_entropy": 0.0208723247051239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1209430694580078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02420932799577713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1693881352742513,
      "backward_entropy": 0.03298355340957641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1662266254425049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024250680580735207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16926097869873047,
      "backward_entropy": 0.03253248333930969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2177178859710693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024291299283504486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16912521918614706,
      "backward_entropy": 0.03114756941795349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1417138576507568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024331524968147278,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16898401578267416,
      "backward_entropy": 0.019646450877189636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.219372034072876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02437126636505127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1688404083251953,
      "backward_entropy": 0.031219136714935303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7744194865226746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024410758167505264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16869012514750162,
      "backward_entropy": 0.030790957808494567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1605815887451172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024448933079838753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1685478687286377,
      "backward_entropy": 0.030380171537399293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.963302493095398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024487042799592018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16840304931004843,
      "backward_entropy": 0.029129689931869505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7635437846183777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024524610489606857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16826194524765015,
      "backward_entropy": 0.029571768641471863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0758845806121826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02456090785562992,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16812129815419516,
      "backward_entropy": 0.028376221656799316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0130553245544434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024596959352493286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16797043879826865,
      "backward_entropy": 0.028803765773773193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0395749807357788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024632811546325684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16781669855117798,
      "backward_entropy": 0.028424382209777832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9899536371231079,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024668600410223007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16765870650609335,
      "backward_entropy": 0.0272935152053833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1168102025985718,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024704167619347572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16749586661656699,
      "backward_entropy": 0.027669289708137514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8108752965927124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02473985031247139,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1673197348912557,
      "backward_entropy": 0.02658511996269226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7211679816246033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024774596095085144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16713817914326987,
      "backward_entropy": 0.026923030614852905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7154797315597534,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024808453395962715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16696087519327799,
      "backward_entropy": 0.026566532254219056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8167065382003784,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024841412901878357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16678388913472494,
      "backward_entropy": 0.016170457005500793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8219045996665955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024874068796634674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16660618782043457,
      "backward_entropy": 0.0258797287940979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.855729877948761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02490645833313465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16642538706461588,
      "backward_entropy": 0.025542563199996947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.545921266078949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024938680231571198,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16623701651891074,
      "backward_entropy": 0.02520758509635925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7187089323997498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02496975287795067,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1660568118095398,
      "backward_entropy": 0.024351106584072114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7233246564865112,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02500048093497753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1658729910850525,
      "backward_entropy": 0.02457163333892822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7804092168807983,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02503090724349022,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16568559408187866,
      "backward_entropy": 0.023767083883285522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6151990294456482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025061195716261864,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1654882331689199,
      "backward_entropy": 0.023950496315956117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6937454342842102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025090884417295456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16529246171315512,
      "backward_entropy": 0.02364853024482727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7898059487342834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025120623409748077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16509893536567688,
      "backward_entropy": 0.02334824502468109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6846718192100525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02515040896832943,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.164890726407369,
      "backward_entropy": 0.01431397646665573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5289492011070251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025180138647556305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1646803319454193,
      "backward_entropy": 0.022748136520385744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4959469735622406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025209002196788788,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16447192430496216,
      "backward_entropy": 0.0224581778049469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5806654691696167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025237075984477997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16426868240038553,
      "backward_entropy": 0.022177885472774505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6041505932807922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025264577940106392,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16405758261680603,
      "backward_entropy": 0.021903517842292785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37773826718330383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025292223319411278,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1638473073641459,
      "backward_entropy": 0.013518224656581878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47483423352241516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025318419560790062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16364061832427979,
      "backward_entropy": 0.02111481726169586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3742716610431671,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025343753397464752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16342864433924356,
      "backward_entropy": 0.021120935678482056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4025948941707611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02536783181130886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16321811079978943,
      "backward_entropy": 0.020883874595165254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4429931938648224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025391291826963425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16301260391871134,
      "backward_entropy": 0.020654177665710448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4939192831516266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025414317846298218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16280531883239746,
      "backward_entropy": 0.02042921483516693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34097859263420105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02543746866285801,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1625948945681254,
      "backward_entropy": 0.020055444538593294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40292611718177795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025459708645939827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16238913933436075,
      "backward_entropy": 0.01998811066150665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37350425124168396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02548159658908844,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16218297680219015,
      "backward_entropy": 0.012545645236968994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35515737533569336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025503069162368774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16197850306828818,
      "backward_entropy": 0.019569835066795348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31596609950065613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0255238339304924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177203257878622,
      "backward_entropy": 0.01937047839164734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2902972102165222,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02554391138255596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16156919797261557,
      "backward_entropy": 0.019178062677383423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39582428336143494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025563182309269905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16137043635050455,
      "backward_entropy": 0.01894679069519043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3152964115142822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025582483038306236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16116485993067423,
      "backward_entropy": 0.018808770179748534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23730681836605072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02560150995850563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16096243262290955,
      "backward_entropy": 0.01862765699625015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.230284184217453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02561943791806698,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16076507170995077,
      "backward_entropy": 0.018456341326236726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3088548481464386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025636162608861923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1605698068936666,
      "backward_entropy": 0.018298622965812684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25284329056739807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02565276250243187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16037205855051676,
      "backward_entropy": 0.01814103126525879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24253962934017181,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025668654590845108,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1601745088895162,
      "backward_entropy": 0.018027791380882265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2779983580112457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02568441815674305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15998517473538718,
      "backward_entropy": 0.017841438949108123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23864243924617767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025700315833091736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15979790687561035,
      "backward_entropy": 0.017692184448242186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30381539463996887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025715887546539307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1596132218837738,
      "backward_entropy": 0.017617630958557128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27231064438819885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025731468573212624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1594190001487732,
      "backward_entropy": 0.017400085926055908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2141430675983429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025747014209628105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15922072529792786,
      "backward_entropy": 0.017254051566123963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21454361081123352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025762256234884262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15902740756670633,
      "backward_entropy": 0.017111584544181824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20857664942741394,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02577732317149639,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1588381826877594,
      "backward_entropy": 0.017093935608863832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20191219449043274,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025792112573981285,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15865143140157065,
      "backward_entropy": 0.011164589971303939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20041213929653168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025806156918406487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15846266349156699,
      "backward_entropy": 0.016849258542060853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17554645240306854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02581971324980259,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15827290217081705,
      "backward_entropy": 0.016577820479869842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18706189095973969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02583279274404049,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15808685620625815,
      "backward_entropy": 0.011001837253570557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1798318773508072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025845792144536972,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15790323416392008,
      "backward_entropy": 0.01095043495297432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18657894432544708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025858404114842415,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1577198008696238,
      "backward_entropy": 0.010901480168104171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17557266354560852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02587108686566353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15753668546676636,
      "backward_entropy": 0.016301415860652924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1431504786014557,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025883400812745094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15735214948654175,
      "backward_entropy": 0.016198457777500154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13373000919818878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025894910097122192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15717009703318277,
      "backward_entropy": 0.015881717205047607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13889029622077942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025905827060341835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1569927136103312,
      "backward_entropy": 0.01578056961297989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14108934998512268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02591615542769432,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15681693951288858,
      "backward_entropy": 0.015684632956981658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13090674579143524,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025925975292921066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15664138396581015,
      "backward_entropy": 0.015839090943336485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12762786448001862,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025935277342796326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15646740794181824,
      "backward_entropy": 0.015759935975074767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11480135470628738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02594447322189808,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15629687905311584,
      "backward_entropy": 0.01568169891834259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1393055021762848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025952842086553574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1561280886332194,
      "backward_entropy": 0.01560976803302765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13436636328697205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025960655882954597,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15595471858978271,
      "backward_entropy": 0.015266771614551543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1046244278550148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02596886456012726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15578225255012512,
      "backward_entropy": 0.015188702940940857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10283397883176804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02597685344517231,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.155614972114563,
      "backward_entropy": 0.015112754702568055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11447220295667648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02598409727215767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1554494102795919,
      "backward_entropy": 0.015043215453624725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12766395509243011,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02599158324301243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1552855372428894,
      "backward_entropy": 0.014972123503684997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10218767076730728,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025999315083026886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15511855483055115,
      "backward_entropy": 0.014898884296417236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0981895700097084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02600671909749508,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1549528936545054,
      "backward_entropy": 0.014828436076641083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.085255928337574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02601398155093193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1547895073890686,
      "backward_entropy": 0.01475941389799118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10311711579561234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026020493358373642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15462875366210938,
      "backward_entropy": 0.014696633815765381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09152274578809738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026026934385299683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15446656942367554,
      "backward_entropy": 0.014976784586906433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10887069255113602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026032963767647743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1543045143286387,
      "backward_entropy": 0.014575375616550446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07366154342889786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039311662316322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1541390816370646,
      "backward_entropy": 0.014513897895812988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1031813845038414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026045547798275948,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15397965908050537,
      "backward_entropy": 0.014817820489406585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08915575593709946,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026051389053463936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1538142959276835,
      "backward_entropy": 0.014396096765995025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08281237632036209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026057258248329163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15364883343378702,
      "backward_entropy": 0.014338052272796631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0784110277891159,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0260631050914526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15348442395528158,
      "backward_entropy": 0.014669114351272583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08449729532003403,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026068497449159622,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1533200740814209,
      "backward_entropy": 0.014623233675956726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05850959196686745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026074286550283432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1531557540098826,
      "backward_entropy": 0.014574861526489258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07108493894338608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026079772040247917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15299769242604574,
      "backward_entropy": 0.014115993678569794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0628751814365387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026085369288921356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15284140904744467,
      "backward_entropy": 0.014481671154499054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0663408413529396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026090988889336586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.152688999970754,
      "backward_entropy": 0.01400817334651947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06884597986936569,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026096679270267487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1525382399559021,
      "backward_entropy": 0.014387513697147369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061690833419561386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026102397590875626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15238726139068604,
      "backward_entropy": 0.013899633288383484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05968238785862923,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02610776014626026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15223695834477743,
      "backward_entropy": 0.01384807676076889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0591604970395565,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026113176718354225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15208852291107178,
      "backward_entropy": 0.014251191914081574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06182738393545151,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02611849457025528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1519408921400706,
      "backward_entropy": 0.013745343685150147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059074025601148605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02612377144396305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15179240703582764,
      "backward_entropy": 0.013694648444652558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044412288814783096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02612883970141411,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1516431669394175,
      "backward_entropy": 0.014122501015663147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04526863619685173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026133613660931587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1514985760052999,
      "backward_entropy": 0.013599523901939392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04540616273880005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026138219982385635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15135759115219116,
      "backward_entropy": 0.013554742932319641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05050737410783768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026142543181777,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15121891101201376,
      "backward_entropy": 0.014008355140686036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046038683503866196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026147061958909035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15108060836791992,
      "backward_entropy": 0.013468053936958314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04662419110536575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026151200756430626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15094278256098428,
      "backward_entropy": 0.013426841795444488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04164723679423332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02615523710846901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.150805135567983,
      "backward_entropy": 0.013386593759059906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038596250116825104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026159189641475677,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1506692369778951,
      "backward_entropy": 0.0133471742272377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03727896884083748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02616310305893421,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1505359411239624,
      "backward_entropy": 0.013308307528495789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035982225090265274,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026167044416069984,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15040520826975504,
      "backward_entropy": 0.01007734090089798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04247334599494934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02617092989385128,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.150276780128479,
      "backward_entropy": 0.013771714270114898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0408906415104866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026174409314990044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15014618635177612,
      "backward_entropy": 0.013742348551750183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04087275266647339,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02617778815329075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15001430114110312,
      "backward_entropy": 0.013161221146583557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03832676261663437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026181092485785484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14988075693448386,
      "backward_entropy": 0.013127028942108154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024710241705179214,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02618410810828209,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14974617958068848,
      "backward_entropy": 0.010053009539842606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030259501188993454,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026187218725681305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14961783091227213,
      "backward_entropy": 0.01306265890598297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030277341604232788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02619033493101597,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1494906743367513,
      "backward_entropy": 0.013030487298965453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031048109754920006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026193534955382347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14936476945877075,
      "backward_entropy": 0.012998048961162568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025903018191456795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026196399703621864,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1492387851079305,
      "backward_entropy": 0.01296813040971756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02647806890308857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02619931288063526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14911570151646933,
      "backward_entropy": 0.012937945127487183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027477595955133438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026202049106359482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14899422725041708,
      "backward_entropy": 0.01350843608379364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024399608373641968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026204723864793777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14887329936027527,
      "backward_entropy": 0.012880814075469971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023517604917287827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026207352057099342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14875433842341104,
      "backward_entropy": 0.012852889299392701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022789863869547844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026209933683276176,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14863733450571695,
      "backward_entropy": 0.010023534297943115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024855179712176323,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026212412863969803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14852195978164673,
      "backward_entropy": 0.013419774174690247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022138312458992004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026214750483632088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1484062373638153,
      "backward_entropy": 0.012773841619491577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02062922716140747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026216968894004822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14829182624816895,
      "backward_entropy": 0.012749503552913665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01931147836148739,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02621900849044323,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14817885557810465,
      "backward_entropy": 0.01336192935705185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01816316321492195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0262211412191391,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14806787172953287,
      "backward_entropy": 0.013343241810798646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017608441412448883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026223184540867805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1479594111442566,
      "backward_entropy": 0.013325253129005432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01654633693397045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026225460693240166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1478534738222758,
      "backward_entropy": 0.012656599283218384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017278356477618217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02622777223587036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14775003989537558,
      "backward_entropy": 0.012632466852664948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021395262330770493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02623014710843563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14764792720476785,
      "backward_entropy": 0.012607969343662262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015472316183149815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026232300326228142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14754310250282288,
      "backward_entropy": 0.012585020065307618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014173666946589947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02623445726931095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1474404533704122,
      "backward_entropy": 0.012562178075313568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015800077468156815,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02623664028942585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14734051624933878,
      "backward_entropy": 0.013211756944656372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016646912321448326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026238711550831795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1472411553064982,
      "backward_entropy": 0.012517191469669342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011118153110146523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026240579783916473,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14714107910792032,
      "backward_entropy": 0.012496629357337951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01098803523927927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026242395862936974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1470449964205424,
      "backward_entropy": 0.01247674748301506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013010022230446339,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026244262233376503,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14695231119791666,
      "backward_entropy": 0.01314583420753479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011452500708401203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026246247813105583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14686073859532675,
      "backward_entropy": 0.013129034638404846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010424568317830563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026248345151543617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1467712720235189,
      "backward_entropy": 0.012414537370204926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013378902338445187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026250384747982025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14668421943982443,
      "backward_entropy": 0.012393712997436523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00934457965195179,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026252351701259613,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1465961436430613,
      "backward_entropy": 0.009984675794839859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009664197452366352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026254210621118546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14651073018709818,
      "backward_entropy": 0.012353990226984024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010284245945513248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026256036013364792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14642723401387533,
      "backward_entropy": 0.012335007637739181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009893999435007572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02625778131186962,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14634448289871216,
      "backward_entropy": 0.009977033734321595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00870541762560606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026259450241923332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14626251657803854,
      "backward_entropy": 0.012299015372991561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009486543945968151,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626105584204197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14618230859438577,
      "backward_entropy": 0.012281936407089234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006749079562723637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626260742545128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14610254764556885,
      "backward_entropy": 0.012265217304229737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008886042051017284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026264170184731483,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14602604508399963,
      "backward_entropy": 0.012248610705137252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006927568465471268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026265641674399376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1459496815999349,
      "backward_entropy": 0.012964743375778198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008517966605722904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026267115026712418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14587547381718954,
      "backward_entropy": 0.012217010557651519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007578761782497168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626870758831501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14580110708872476,
      "backward_entropy": 0.012200421839952468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008009570650756359,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026270298287272453,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14572739601135254,
      "backward_entropy": 0.009962566196918488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006510849576443434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026271842420101166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14565351605415344,
      "backward_entropy": 0.012167763710021973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007282470818608999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02627343125641346,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14558104674021402,
      "backward_entropy": 0.009957353770732879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006409543100744486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026275072246789932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14550862709681192,
      "backward_entropy": 0.012134693562984467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007043878547847271,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026276759803295135,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14543713132540384,
      "backward_entropy": 0.00995003879070282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006457171868532896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026278244331479073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14536544680595398,
      "backward_entropy": 0.012102195620536804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006062035448849201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026279564946889877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14529416958491007,
      "backward_entropy": 0.012087884545326232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00561551284044981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02628100849688053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14522337913513184,
      "backward_entropy": 0.01207268014550209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005033721216022968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026282373815774918,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14515354235967,
      "backward_entropy": 0.012058132886886596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0058726659044623375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026283646002411842,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14508525530497232,
      "backward_entropy": 0.012814931571483612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004776385612785816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026284726336598396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.145016739765803,
      "backward_entropy": 0.012032014131546021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004757661372423172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026285748928785324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14494959513346353,
      "backward_entropy": 0.01202012673020363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004803061950951815,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026286859065294266,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14488327503204346,
      "backward_entropy": 0.009939708560705186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035804917570203543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026287931948900223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14481749137242636,
      "backward_entropy": 0.011995574831962586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033013627398759127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026288967579603195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14475409189860025,
      "backward_entropy": 0.011983878165483474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034586430992931128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026290083304047585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1446930170059204,
      "backward_entropy": 0.011971765756607055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003417412983253598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026291225105524063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1446335713068644,
      "backward_entropy": 0.011959575116634369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003408826421946287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629224583506584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14457565546035767,
      "backward_entropy": 0.01194838210940361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003371024504303932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629319578409195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14451895157496134,
      "backward_entropy": 0.011937765032052993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028680446557700634,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629408799111843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1444631814956665,
      "backward_entropy": 0.011927644908428191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002839048160240054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629498578608036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14440892140070596,
      "backward_entropy": 0.011917601525783538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003225406864657998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026295892894268036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14435593287150064,
      "backward_entropy": 0.011907581984996796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028277281671762466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026296736672520638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14430327216784158,
      "backward_entropy": 0.011898016184568405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026354717556387186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026297500357031822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14425158500671387,
      "backward_entropy": 0.011889073252677917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020618487615138292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026298239827156067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14420094092686972,
      "backward_entropy": 0.011880407482385636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027129785157740116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026298996061086655,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14415224393208823,
      "backward_entropy": 0.009933633357286453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00203054235316813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026299750432372093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14410366614659628,
      "backward_entropy": 0.011863098293542863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002274587284773588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02630058117210865,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14405643939971924,
      "backward_entropy": 0.009932806342840194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020455424673855305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02630145661532879,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14400970935821533,
      "backward_entropy": 0.0126605823636055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001634768908843398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026302305981516838,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.143964022397995,
      "backward_entropy": 0.011835543066263199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018039800925180316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02630317397415638,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14392006397247314,
      "backward_entropy": 0.009929008036851882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015935009578242898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026304030790925026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1438771883646647,
      "backward_entropy": 0.011817463487386704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017485227435827255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026304911822080612,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1438355048497518,
      "backward_entropy": 0.011808433383703233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018122504698112607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263057854026556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14379443724950156,
      "backward_entropy": 0.011799460649490357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016729625640437007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026306593790650368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14375382661819458,
      "backward_entropy": 0.011791010946035385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016778279095888138,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263073593378067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14371378223101297,
      "backward_entropy": 0.011782897263765335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016123730456456542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026307998225092888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14367443323135376,
      "backward_entropy": 0.011775722354650497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012701483210548759,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026308616623282433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14363534251848856,
      "backward_entropy": 0.011768730729818344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016029005637392402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263091828674078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14359760284423828,
      "backward_entropy": 0.011762209981679917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011354812886565924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026309726759791374,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14355979363123575,
      "backward_entropy": 0.009921088069677352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012471030931919813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026310285553336143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14352309703826904,
      "backward_entropy": 0.011749406158924103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012420114362612367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026310879737138748,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1434868574142456,
      "backward_entropy": 0.009920644015073777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012027096236124635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026311423629522324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14345123370488486,
      "backward_entropy": 0.011736519634723663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010302991140633821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631196565926075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14341594775517783,
      "backward_entropy": 0.011730343103408813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001285851583816111,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026312466710805893,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14338169495264688,
      "backward_entropy": 0.009920497983694076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009893253445625305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631291374564171,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14334734280904135,
      "backward_entropy": 0.011719027161598205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010138940997421741,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026313334703445435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14331379532814026,
      "backward_entropy": 0.012558288872241974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009011529618874192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026313744485378265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14328067501386008,
      "backward_entropy": 0.011708680540323257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000815942301414907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026314150542020798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14324822028477988,
      "backward_entropy": 0.011703655868768693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007984828553162515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631450816988945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1432169477144877,
      "backward_entropy": 0.011699049174785614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008551008650101721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02631484344601631,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14318652947743735,
      "backward_entropy": 0.012543950974941254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007250724593177438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026315174996852875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14315646886825562,
      "backward_entropy": 0.011690302193164826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006044376641511917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02631550468504429,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1431270639101664,
      "backward_entropy": 0.01253742128610611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006758730742149055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026315851137042046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1430987020333608,
      "backward_entropy": 0.011681610345840454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000821994966827333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631617896258831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14307103554407755,
      "backward_entropy": 0.01167745590209961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006278518703766167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02631642296910286,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1430435578028361,
      "backward_entropy": 0.009928224235773086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005707096424885094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026316659525036812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14301668604214987,
      "backward_entropy": 0.011670392751693726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006219620699994266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631688490509987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1429905891418457,
      "backward_entropy": 0.011667026579380036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005170704680494964,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631710097193718,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14296478033065796,
      "backward_entropy": 0.011663788557052612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004198751994408667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026317307725548744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14293973644574484,
      "backward_entropy": 0.012518368661403656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005013421759940684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026317521929740906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14291580518086752,
      "backward_entropy": 0.011657535284757613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034872718970291317,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026317734271287918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14289232095082602,
      "backward_entropy": 0.012513662874698638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047291399096138775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026317957788705826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14286998907725015,
      "backward_entropy": 0.011651379615068435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041281053563579917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026318196207284927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1428477664788564,
      "backward_entropy": 0.012508760392665862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034595764009281993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026318438351154327,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1428260306517283,
      "backward_entropy": 0.011645032465457917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032090983586385846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02631869725883007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1428049405415853,
      "backward_entropy": 0.012503695487976075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032306875800713897,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026318969205021858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1427846153577169,
      "backward_entropy": 0.012501069903373718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034903446794487536,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026319243013858795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14276493589083353,
      "backward_entropy": 0.01163524091243744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023957400117069483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026319503784179688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14274561405181885,
      "backward_entropy": 0.011632094532251358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024116203712765127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026319777593016624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14272729555765787,
      "backward_entropy": 0.011628951132297515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003151940763927996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026320064440369606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14270973205566406,
      "backward_entropy": 0.011625727266073227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002569301868788898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026320340111851692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14269227782885233,
      "backward_entropy": 0.01162261813879013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002560644643381238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026320602744817734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14267541964848837,
      "backward_entropy": 0.012485674023628235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002507443423382938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632085606455803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14265902837117514,
      "backward_entropy": 0.011616766452789307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025985590764321387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026321114972233772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1426427662372589,
      "backward_entropy": 0.011613834649324417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002220873284386471,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026321349665522575,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1426268219947815,
      "backward_entropy": 0.009939373284578324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019076222088187933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632157690823078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14261130491892496,
      "backward_entropy": 0.011608493328094483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002498321409802884,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632180042564869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1425963838895162,
      "backward_entropy": 0.011605916172266006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001690250646788627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026322010904550552,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14258135358492532,
      "backward_entropy": 0.011603403091430663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001902873773360625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026322226971387863,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14256685972213745,
      "backward_entropy": 0.00994000881910324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001615109940757975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026322437450289726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14255263408025107,
      "backward_entropy": 0.011598459631204604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013336370466277003,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026322664692997932,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1425386369228363,
      "backward_entropy": 0.009940085560083389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016358513676095754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632288821041584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14252535502115884,
      "backward_entropy": 0.01159343346953392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018674701277632266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026323093101382256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14251246054967245,
      "backward_entropy": 0.012461981177330017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016861630138009787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632327564060688,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14249963561693826,
      "backward_entropy": 0.012460199743509292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013998697977513075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026323441416025162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14248691002527872,
      "backward_entropy": 0.011586974561214446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.994984429795295e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632359229028225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14247465133666992,
      "backward_entropy": 0.011585068702697755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012697048077825457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632375992834568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1424628496170044,
      "backward_entropy": 0.011583090573549271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013556740304920822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026323921978473663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1424513260523478,
      "backward_entropy": 0.011581169068813324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.416903048986569e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026324067264795303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14243996143341064,
      "backward_entropy": 0.01157938614487648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001207156601594761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026324214413762093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14242915312449136,
      "backward_entropy": 0.011577635258436202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.728968871058896e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026324354112148285,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1424184242884318,
      "backward_entropy": 0.009942145645618438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.543249325361103e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026324493810534477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14240801334381104,
      "backward_entropy": 0.0115742489695549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010439886682434008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026324626058340073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14239797989527384,
      "backward_entropy": 0.011572641879320144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.572778071742505e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026324748992919922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14238802591959634,
      "backward_entropy": 0.011571070551872254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.019994518486783e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026324862614274025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14237831036249796,
      "backward_entropy": 0.012443790584802628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417048229603097e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026324979960918427,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1423689921696981,
      "backward_entropy": 0.011568133533000947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.856680556666106e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632509358227253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14235939582188925,
      "backward_entropy": 0.012441302090883255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.606514216400683e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632521279156208,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14234975973765054,
      "backward_entropy": 0.0099441759288311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.664973574923351e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026325328275561333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14234032233556113,
      "backward_entropy": 0.011563865840435028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.705913281417452e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632542885839939,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14233063658078512,
      "backward_entropy": 0.012437736988067627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.873464008094743e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026325533166527748,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1423211395740509,
      "backward_entropy": 0.012436610460281373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.657717312918976e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026325630024075508,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1423116127649943,
      "backward_entropy": 0.009945295751094818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.255874905036762e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632571943104267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14230199654897055,
      "backward_entropy": 0.012434540688991547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.405678894021548e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026325803250074387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14229238033294678,
      "backward_entropy": 0.011557812988758086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.619666990241967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026325883343815804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14228296279907227,
      "backward_entropy": 0.011556723713874817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.280694313114509e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026325957849621773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14227360486984253,
      "backward_entropy": 0.012431783974170685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3963107347954065e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326028630137444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14226439595222473,
      "backward_entropy": 0.01155470609664917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.265065581421368e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326090097427368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14225520690282187,
      "backward_entropy": 0.01155376210808754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.180315227131359e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326151564717293,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14224645495414734,
      "backward_entropy": 0.011552885919809342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.234354491927661e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326211169362068,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14223786195119223,
      "backward_entropy": 0.011552001535892486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.560782326734625e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326267048716545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14222941795984903,
      "backward_entropy": 0.01155114769935608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.767523230635561e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326315477490425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14222111304601034,
      "backward_entropy": 0.01155036985874176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.519636291253846e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326360180974007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14221303661664328,
      "backward_entropy": 0.011549651622772217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.360597474966198e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326414197683334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14220547676086426,
      "backward_entropy": 0.011548858135938644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.426921466598287e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326464489102364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14219816525777182,
      "backward_entropy": 0.011548119783401489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2340783945983276e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326511055231094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14219093322753906,
      "backward_entropy": 0.01154743880033493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.449906060064677e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326552033424377,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14218382040659586,
      "backward_entropy": 0.011546777933835984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3183818484540097e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632659673690796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14217699567476907,
      "backward_entropy": 0.009951859712600708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1930520233581774e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632664516568184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14217044909795126,
      "backward_entropy": 0.012422577291727067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7520240362500772e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326695457100868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1421641707420349,
      "backward_entropy": 0.011544752120971679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.423703517706599e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026326751336455345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14215832948684692,
      "backward_entropy": 0.012421255558729171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7447904358268715e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326803490519524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14215247829755148,
      "backward_entropy": 0.01154337301850319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6102219888125546e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026326844468712807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14214661717414856,
      "backward_entropy": 0.012420012056827546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0481053070398048e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326891034841537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14214098453521729,
      "backward_entropy": 0.011542154848575592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0326342564658262e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632693387567997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1421354611714681,
      "backward_entropy": 0.01154157966375351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.64517987286672e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326971128582954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14212995767593384,
      "backward_entropy": 0.011541038751602173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4228249710868113e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026327010244131088,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1421247919400533,
      "backward_entropy": 0.0124177485704422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1293178431515116e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632705122232437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14211990435918173,
      "backward_entropy": 0.011539971083402633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6950147255556658e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327097788453102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14211531480153403,
      "backward_entropy": 0.011539387702941894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5562358385068364e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026327136904001236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14211068550745645,
      "backward_entropy": 0.01241607815027237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0285815733368509e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632717229425907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14210617542266846,
      "backward_entropy": 0.011538396775722503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0445505722600501e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327211409807205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14210188388824463,
      "backward_entropy": 0.011537887901067734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2571509614645038e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327254250645638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14209794998168945,
      "backward_entropy": 0.011537376046180724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0678239959815983e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632729522883892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420941948890686,
      "backward_entropy": 0.011536896973848344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.096512258111034e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327336207032204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14209063847859701,
      "backward_entropy": 0.011536403000354767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0998294177115895e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327379047870636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420873006184896,
      "backward_entropy": 0.011535931378602982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.992864422907587e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026327427476644516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420842409133911,
      "backward_entropy": 0.01241232007741928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.978903002163861e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026327474042773247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420812507470449,
      "backward_entropy": 0.009956610202789307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.713146260357462e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327522471547127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14207850893338522,
      "backward_entropy": 0.011534449458122254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.294543709373102e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327572762966156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420759658018748,
      "backward_entropy": 0.01153395026922226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.813467163941823e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327624917030334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420736312866211,
      "backward_entropy": 0.011533468216657638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.277606189541984e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026327677071094513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420715351899465,
      "backward_entropy": 0.012409453839063644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.206099780887598e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327727362513542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14206949869791666,
      "backward_entropy": 0.011532505601644516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.299383585428586e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327775791287422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14206757148106894,
      "backward_entropy": 0.011532044410705567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3625343500461895e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026327824220061302,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14206582307815552,
      "backward_entropy": 0.009956786781549454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.149032742541749e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327870786190033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14206413427988687,
      "backward_entropy": 0.011531178653240205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.297745363146532e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026327911764383316,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14206242561340332,
      "backward_entropy": 0.009956832975149155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.233133379078936e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632795460522175,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14206077655156454,
      "backward_entropy": 0.009956860542297363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.547127329919022e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632799558341503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420592466990153,
      "backward_entropy": 0.011530003696680068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.837897111225175e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328032836318016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.142057736714681,
      "backward_entropy": 0.011529664695262908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.588178287827759e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632807195186615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14205638567606607,
      "backward_entropy": 0.011529292166233062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.282123316239449e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328111067414284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14205512404441833,
      "backward_entropy": 0.011528941988945007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.044536470042658e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328150182962418,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420539120833079,
      "backward_entropy": 0.009957008808851243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.826733063760912e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632818929851055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14205278952916464,
      "backward_entropy": 0.011528252065181733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.927742000087164e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328224688768387,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14205162723859152,
      "backward_entropy": 0.012403075397014619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9318323413463077e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328256353735924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14205044507980347,
      "backward_entropy": 0.01152762547135353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.561230869308929e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632828801870346,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420492927233378,
      "backward_entropy": 0.009957060962915421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.744189032455324e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263283159583807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14204816023508707,
      "backward_entropy": 0.011527086049318314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.791578936012229e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328343898057938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14204703768094382,
      "backward_entropy": 0.011526814103126526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8911985080194427e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328369975090027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14204601446787515,
      "backward_entropy": 0.011526571214199066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.794701120161335e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328397914767265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14204510052998862,
      "backward_entropy": 0.012400908768177033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0885144042258617e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328427717089653,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420443058013916,
      "backward_entropy": 0.011526041477918626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0192203464830527e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328453794121742,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420434514681498,
      "backward_entropy": 0.012400250136852264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9663293642224744e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632847987115383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14204266667366028,
      "backward_entropy": 0.012399927526712418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.762470785455662e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632850408554077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14204190174738565,
      "backward_entropy": 0.012399622797966003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.676476697160979e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328524574637413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14204112688700357,
      "backward_entropy": 0.011525168269872665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.761570388225664e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328541338443756,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420402725537618,
      "backward_entropy": 0.009957472234964371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7652756696406868e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263285581022501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14203945795694986,
      "backward_entropy": 0.011524809896945954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5919544011921971e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328574866056442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14203877250353494,
      "backward_entropy": 0.012398592382669448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.754855361468799e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328591629862785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420380969842275,
      "backward_entropy": 0.011524495482444764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2148053656346747e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632860653102398,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420374115308126,
      "backward_entropy": 0.012398140132427215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3186843261792092e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328621432185173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420368254184723,
      "backward_entropy": 0.011524218320846557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5640665651517338e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328636333346367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.142036239306132,
      "backward_entropy": 0.011524051427841187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.59894148055173e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632865123450756,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420357326666514,
      "backward_entropy": 0.0099579356610775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2795419479516568e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328660547733307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14203506708145142,
      "backward_entropy": 0.012397260963916778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1511194770719158e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328669860959053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14203437169392905,
      "backward_entropy": 0.01152370572090149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2232661674715928e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0263286791741848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420337756474813,
      "backward_entropy": 0.012396925687789917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5257946870406158e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328688487410545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14203321933746338,
      "backward_entropy": 0.01239674910902977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1076188002334675e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328695937991142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14203262329101562,
      "backward_entropy": 0.011523409187793732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.137410307223035e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632870338857174,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420320669809977,
      "backward_entropy": 0.01152331829071045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.346635134628741e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328708976507187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14203151067097983,
      "backward_entropy": 0.011523255705833435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2503656989792944e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328716427087784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14203105370203653,
      "backward_entropy": 0.011523165553808213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.708501475965022e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632872201502323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420305371284485,
      "backward_entropy": 0.011523082852363586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.033882406583871e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632872760295868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14203002055486044,
      "backward_entropy": 0.011523033678531646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.608101100231579e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328733190894127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202958345413208,
      "backward_entropy": 0.01152295470237732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0783635389088886e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328736916184425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202906688054404,
      "backward_entropy": 0.012395678460597992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.674468290337245e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328738778829575,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202855030695596,
      "backward_entropy": 0.009959138184785842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12047994461318e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328740641474724,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202803373336792,
      "backward_entropy": 0.009959248453378677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.752491460953024e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328740641474724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202752709388733,
      "backward_entropy": 0.0115227609872818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.976592435923521e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328744366765022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202712972958884,
      "backward_entropy": 0.011522729694843293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.476328167082102e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632874622941017,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202672243118286,
      "backward_entropy": 0.011522667109966278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.145821546648222e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632874809205532,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420263151327769,
      "backward_entropy": 0.009959632903337479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.148987037908228e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632874995470047,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202590783437094,
      "backward_entropy": 0.009959729760885239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.952785843670426e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632874995470047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202551047007242,
      "backward_entropy": 0.012394928187131882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4870041076828784e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632875181734562,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202511310577393,
      "backward_entropy": 0.011522535979747773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1197432665285305e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632875367999077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202481508255005,
      "backward_entropy": 0.012394748628139496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5010944543500955e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328757405281067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420245369275411,
      "backward_entropy": 0.011522454023361207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1035701769942534e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328761130571365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.142024298508962,
      "backward_entropy": 0.011522418260574341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.835293114207161e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328764855861664,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420240600903829,
      "backward_entropy": 0.012394488602876664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.64261063370941e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328768581151962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202386140823364,
      "backward_entropy": 0.011522331833839416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9521200417548243e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632877230644226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202368259429932,
      "backward_entropy": 0.011522302031517028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.760056301871373e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632877603173256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202349384625754,
      "backward_entropy": 0.011522245407104493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.013691636828298e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328779757022858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420233150323232,
      "backward_entropy": 0.012394127994775772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8367676918605866e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328781619668007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420231262842814,
      "backward_entropy": 0.012394040822982788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.572567154857097e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328785344958305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420229971408844,
      "backward_entropy": 0.011522138118743896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.437363946228288e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328789070248604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420228878657023,
      "backward_entropy": 0.011522103101015091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.672628340860683e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632879465818405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202282826105753,
      "backward_entropy": 0.011522071063518524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0656422350384673e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0263288002461195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202276865641275,
      "backward_entropy": 0.012393695116043092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4396939579673926e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328805834054947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420227289199829,
      "backward_entropy": 0.011521977186203004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0089781571641652e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328811421990395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420226792494456,
      "backward_entropy": 0.011521942168474197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.783771352847907e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328817009925842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420226295789083,
      "backward_entropy": 0.011521906405687333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7195273471770633e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632882259786129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202258984247842,
      "backward_entropy": 0.011521879583597183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8785557642786443e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632882632315159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202255010604858,
      "backward_entropy": 0.011521819978952408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6329912000401237e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328831911087036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202256004015604,
      "backward_entropy": 0.012393161654472351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5278033060894813e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328837499022484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202256997426352,
      "backward_entropy": 0.011521728336811065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.381649497034232e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632884308695793,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202258984247842,
      "backward_entropy": 0.009960908442735672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0722317256295355e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632884867489338,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202260971069336,
      "backward_entropy": 0.011521664261817933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4158152339405206e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328854262828827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420226494471232,
      "backward_entropy": 0.011521609872579575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3153371014595905e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328859850764275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202268918355307,
      "backward_entropy": 0.011521578580141068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1063093552365899e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328865438699722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202270905176798,
      "backward_entropy": 0.011521518975496293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0500504288302182e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632886916399002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202268918355307,
      "backward_entropy": 0.012392612546682358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1088643958601097e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632887288928032,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202270905176798,
      "backward_entropy": 0.00996100902557373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2582621877754718e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328876614570618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202270905176798,
      "backward_entropy": 0.011521445214748382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1038775937777245e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328880339860916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420227289199829,
      "backward_entropy": 0.011521397531032563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.627711961002205e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328884065151215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202274878819784,
      "backward_entropy": 0.01152138113975525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.727622085620169e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328887790441513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202274878819784,
      "backward_entropy": 0.01152135580778122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986597694298325e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632889151573181,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202276865641275,
      "backward_entropy": 0.011521334946155547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.86087639426114e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632889524102211,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202279845873514,
      "backward_entropy": 0.009961113333702087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.228150357083905e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632889896631241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202280839284262,
      "backward_entropy": 0.012392109632492066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.992314093347886e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328902691602707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202281832695007,
      "backward_entropy": 0.011521249264478683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.002412954510874e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328906416893005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202282826105753,
      "backward_entropy": 0.011521228402853013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.607111740526307e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328910142183304,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420228679974874,
      "backward_entropy": 0.012391946464776992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.283862567599499e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328913867473602,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420228878657023,
      "backward_entropy": 0.00996117815375328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.42846921752971e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632891573011875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420229176680247,
      "backward_entropy": 0.01152115985751152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.889074827791774e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263289175927639,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420229176680247,
      "backward_entropy": 0.011521141976118088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.375742079787415e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632891945540905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202292760213217,
      "backward_entropy": 0.011521127820014954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.43018279838725e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0263289213180542,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202293753623962,
      "backward_entropy": 0.012391721457242965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.083411108193104e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632892318069935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.142022967338562,
      "backward_entropy": 0.012391683459281922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2651099480272023e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328925043344498,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202298720677695,
      "backward_entropy": 0.011521069705486298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.169257294961426e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328926905989647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202300707499185,
      "backward_entropy": 0.012391601502895356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.822062831839503e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328928768634796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202300707499185,
      "backward_entropy": 0.012391552329063416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.825763421147713e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328930631279945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202304681142172,
      "backward_entropy": 0.009961366653442383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3394607846257713e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420230269432068,
      "backward_entropy": 0.009961381554603577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.032903350685956e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202300707499185,
      "backward_entropy": 0.011521020531654358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2001716004638183e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202298720677695,
      "backward_entropy": 0.011521016061306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.110466906264264e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202297727266947,
      "backward_entropy": 0.01152101308107376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2377605546353152e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.142022967338562,
      "backward_entropy": 0.012391383945941924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0306734072050858e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202292760213217,
      "backward_entropy": 0.011520980298519135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.977469293341528e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420229176680247,
      "backward_entropy": 0.01152096912264824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0767004116351018e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202292760213217,
      "backward_entropy": 0.01152096912264824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7089661241698195e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1420229176680247,
      "backward_entropy": 0.009961557388305665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.116112878842614e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202290773391724,
      "backward_entropy": 0.011520951986312866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.097203915558566e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202290773391724,
      "backward_entropy": 0.01239122897386551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.418373590273859e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420228878657023,
      "backward_entropy": 0.012391210347414017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5095110939000733e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202287793159485,
      "backward_entropy": 0.00996161624789238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2376887070786324e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420228878657023,
      "backward_entropy": 0.012391176819801331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1400524019554723e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1420228679974874,
      "backward_entropy": 0.011520934104919434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8031377280181005e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202285806337991,
      "backward_entropy": 0.011520931124687194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.843452857031025e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202284812927246,
      "backward_entropy": 0.011520926654338837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6139694025696372e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202282826105753,
      "backward_entropy": 0.012391097843647003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4709485185449012e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202279845873514,
      "backward_entropy": 0.012391090393066406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3920896435593022e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202277859052023,
      "backward_entropy": 0.009961726516485215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0088911039929371e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202276865641275,
      "backward_entropy": 0.011520916968584061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2801407933693554e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202273885409036,
      "backward_entropy": 0.011520913243293763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5045621637455042e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202274878819784,
      "backward_entropy": 0.012391019612550735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2002722371562413e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202274878819784,
      "backward_entropy": 0.011520910263061523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2178823283193196e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202273885409036,
      "backward_entropy": 0.011520906537771224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.419721891390509e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202273885409036,
      "backward_entropy": 0.011520906537771224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0690186513784283e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202273885409036,
      "backward_entropy": 0.012390962988138198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.794121069717221e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202273885409036,
      "backward_entropy": 0.01152087226510048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.393605810397275e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202274878819784,
      "backward_entropy": 0.009961833059787751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.579231464660552e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202274878819784,
      "backward_entropy": 0.012390902638435364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.782187256249017e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202276865641275,
      "backward_entropy": 0.012390895187854767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.132022972200502e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202277859052023,
      "backward_entropy": 0.009961853921413421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471204182569636e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202278852462769,
      "backward_entropy": 0.00996185690164566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.36559968572692e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202280839284262,
      "backward_entropy": 0.01152084767818451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.043809091555886e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202279845873514,
      "backward_entropy": 0.012390849739313125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.252470706793247e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202280839284262,
      "backward_entropy": 0.01239081472158432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.512148794015957e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14202281832695007,
      "backward_entropy": 0.009961911290884019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.258911528471799e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202282826105753,
      "backward_entropy": 0.011520830541849136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.551999831572175e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202281832695007,
      "backward_entropy": 0.011520826816558838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.998735564891831e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202282826105753,
      "backward_entropy": 0.011520826816558838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.042739476517454e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202282826105753,
      "backward_entropy": 0.011520823091268539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.644160528892826e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202281832695007,
      "backward_entropy": 0.012390758097171783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.083222731627757e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202279845873514,
      "backward_entropy": 0.011520820111036301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.200270436489518e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202281832695007,
      "backward_entropy": 0.011520820111036301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.236010570617509e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202278852462769,
      "backward_entropy": 0.011520820111036301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.637978807091713e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202278852462769,
      "backward_entropy": 0.011520815640687942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6656473412222113e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14202278852462769,
      "backward_entropy": 0.011520815640687942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3277097461214e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202276865641275,
      "backward_entropy": 0.012390699237585068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.78534190051505e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026328932493925095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14202276865641275,
      "backward_entropy": 0.012390688061714172,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.0724761603242428e-07,
    "avg_log_Z": 0.0263288869895041,
    "success_rate": 1.0,
    "avg_reward": 46.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.29,
      "2": 0.56
    },
    "avg_forward_entropy": 0.14202302674452463,
    "avg_backward_entropy": 0.011539813734591004,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}