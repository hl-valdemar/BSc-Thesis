{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298291683197021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.0630055611783808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.405712127685547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913251241048177,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.403956413269043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913227101167043,
      "backward_entropy": 0.06300434199246494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824587821960449,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0001999997184611857,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132025639216106,
      "backward_entropy": 0.06298278136686845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.071332931518555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00029986959998495877,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131868680318196,
      "backward_entropy": 0.0630016489462419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.069633483886719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0003997405292466283,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131726622581482,
      "backward_entropy": 0.06297762827439742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.898777484893799,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004996127681806684,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913159151871999,
      "backward_entropy": 0.0629748756235296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.395383834838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005994495004415512,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131467342376709,
      "backward_entropy": 0.06299689683047208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.393648147583008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006993944407440722,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131310383478801,
      "backward_entropy": 0.0629625753922896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983433723449707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007994167390279472,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131129582722981,
      "backward_entropy": 0.06299317966807973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.311118125915527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008993637748062611,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130971630414327,
      "backward_entropy": 0.06299114227294922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.230803489685059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000999357784166932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130798776944478,
      "backward_entropy": 0.06295180320739746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.308122634887695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010993561008945107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130626916885376,
      "backward_entropy": 0.06294782595200972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.714069366455078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011993898078799248,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130441149075826,
      "backward_entropy": 0.06295184655623003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30508041381836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012995917350053787,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130213658014934,
      "backward_entropy": 0.06294786388223822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.632430076599121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013997857458889484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912998119990031,
      "backward_entropy": 0.06293477795340797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.224267959594727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015000848798081279,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129721919695537,
      "backward_entropy": 0.0629299445585771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.049169540405273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001600320334546268,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09129472573598225,
      "backward_entropy": 0.06297292492606422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878684043884277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017004527617245913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912923812866211,
      "backward_entropy": 0.06291953000155362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625584602355957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018007832113653421,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128951032956441,
      "backward_entropy": 0.06291395967656915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.623760223388672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019011955009773374,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09128636121749878,
      "backward_entropy": 0.06291990930383856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.026497840881348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002001675311475992,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09128301342328389,
      "backward_entropy": 0.06291451237418434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.871395111083984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021023673471063375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912792980670929,
      "backward_entropy": 0.06289580735293301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770221710205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00220316625200212,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127537409464519,
      "backward_entropy": 0.06295107169584795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.346309661865234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002304038731381297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912712315718333,
      "backward_entropy": 0.0628824071450667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.713860511779785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024051826912909746,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126674135526021,
      "backward_entropy": 0.06289065967906605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.013803482055664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025062852073460817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09126238028208415,
      "backward_entropy": 0.06286790154196999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.935921669006348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026074969209730625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125783046086629,
      "backward_entropy": 0.06286018544977362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.206587791442871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00270876195281744,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125328063964844,
      "backward_entropy": 0.0629279071634466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10706901550293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028097699396312237,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09124902884165446,
      "backward_entropy": 0.06292262944308194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630193710327148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029109090100973845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.091244637966156,
      "backward_entropy": 0.06283520568500865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.702807426452637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003011950757354498,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124045570691426,
      "backward_entropy": 0.06284720247442072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42424488067627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031129433773458004,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123637278874715,
      "backward_entropy": 0.06290531700307672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.421225547790527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032141960691660643,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123201171557109,
      "backward_entropy": 0.06283036145296964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27069091796875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003315672045573592,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912274420261383,
      "backward_entropy": 0.06282120401209051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.194986343383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034168732818216085,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09122308095296223,
      "backward_entropy": 0.0628857829354026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589946746826172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003517790697515011,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09121902783711751,
      "backward_entropy": 0.06280189210718329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.264847755432129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003618636168539524,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121503432591756,
      "backward_entropy": 0.06287145072763617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.907753944396973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037192755844444036,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121128916740417,
      "backward_entropy": 0.0628640814261003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.154014587402344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003820013254880905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120732545852661,
      "backward_entropy": 0.06274053183468906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.326835632324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003920935094356537,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120312333106995,
      "backward_entropy": 0.06284863298589533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972164154052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0040220762602984905,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119872252146403,
      "backward_entropy": 0.0628404834053733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.860455513000488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004123285412788391,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119413296381633,
      "backward_entropy": 0.0627348856492476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.317391395568848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004224038682878017,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119012951850891,
      "backward_entropy": 0.06282336061651056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.249678611755371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004325026646256447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118592739105225,
      "backward_entropy": 0.06267304853959517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.175127983093262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004425764083862305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118194381395976,
      "backward_entropy": 0.06265821240165016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.699642181396484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004526237025856972,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09117826819419861,
      "backward_entropy": 0.06264295361258766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.160597801208496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004627159330993891,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911741058031718,
      "backward_entropy": 0.06266801465641368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.447426795959473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0047282082960009575,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09116997321446736,
      "backward_entropy": 0.06265328147194603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.659978866577148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004829031880944967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116633733113606,
      "backward_entropy": 0.06259405612945557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.235307693481445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004929778631776571,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911628007888794,
      "backward_entropy": 0.06275199218229814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65418815612793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00503028417006135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115954240163167,
      "backward_entropy": 0.06255916031924161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.111873626708984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005130746401846409,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115638335545857,
      "backward_entropy": 0.06258998133919456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.790966033935547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005231400951743126,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115290641784668,
      "backward_entropy": 0.06257286938753995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.613265991210938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005332074128091335,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114933013916016,
      "backward_entropy": 0.06250253048810092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.855490684509277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005432696547359228,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114563465118408,
      "backward_entropy": 0.062482443722811615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.219257354736328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005533379502594471,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09114176034927368,
      "backward_entropy": 0.06251815774224022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26744270324707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005633811932057142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113810459772746,
      "backward_entropy": 0.062440254471518776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.915325164794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005734496749937534,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113419055938721,
      "backward_entropy": 0.0626450397751548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.819038391113281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005835270509123802,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911300281683604,
      "backward_entropy": 0.06245821172540838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.939787864685059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0059365094639360905,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112544854482015,
      "backward_entropy": 0.0624369274486195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.344417572021484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006037748418748379,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112087885538737,
      "backward_entropy": 0.06234700571406971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.270419120788574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006138741038739681,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111640850702922,
      "backward_entropy": 0.06239248405803333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.997466087341309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00623946962878108,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111211697260539,
      "backward_entropy": 0.062369335781444206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.716422080993652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0063402908854186535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09110771616299947,
      "backward_entropy": 0.062269731001420456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.85767936706543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006441099103540182,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09110310673713684,
      "backward_entropy": 0.06251434846357866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74091625213623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006542398128658533,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109802047411601,
      "backward_entropy": 0.06229555606842041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35465145111084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00664360448718071,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09109298388163249,
      "backward_entropy": 0.06247088042172519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.66238021850586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006744529120624065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09108829498291016,
      "backward_entropy": 0.06215548515319824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.242788314819336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006845354568213224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09108372529347737,
      "backward_entropy": 0.06212488087740811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.517284393310547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00694590900093317,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09107943375905354,
      "backward_entropy": 0.06218722733584317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.338825225830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007046817801892757,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09107502301534016,
      "backward_entropy": 0.062374906106428665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.195375442504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007147969212383032,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09107032418251038,
      "backward_entropy": 0.06234894015572288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.671957015991211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007249247282743454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106550614039104,
      "backward_entropy": 0.06199350140311501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.011452674865723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007350855506956577,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09106045961380005,
      "backward_entropy": 0.062065688046542083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.491268157958984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007452461868524551,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910553236802419,
      "backward_entropy": 0.06192153150385076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279305458068848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007553779520094395,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0910505751768748,
      "backward_entropy": 0.06223539872602983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.541650772094727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007654784247279167,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09104596575101216,
      "backward_entropy": 0.06184611537239768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.304155349731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0077561079524457455,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09104095896085103,
      "backward_entropy": 0.06217355077916926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.562993049621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007857092656195164,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09103632966677348,
      "backward_entropy": 0.062141228805888786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14595890045166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007958374917507172,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103151162465413,
      "backward_entropy": 0.06185718016190962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.83284854888916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008059736341238022,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09102659424146016,
      "backward_entropy": 0.06207342581315474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.214667320251465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008161009289324284,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09102174639701843,
      "backward_entropy": 0.0617803768678145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.106654167175293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008261888287961483,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09101735552151997,
      "backward_entropy": 0.06159695712002841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.118371963500977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008362386375665665,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09101323286692302,
      "backward_entropy": 0.06170001896944913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.858182907104492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008463035337626934,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100888172785442,
      "backward_entropy": 0.06150551275773482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.679780006408691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00856320746243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100494782129924,
      "backward_entropy": 0.061458045786077324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.33313274383545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008663810789585114,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09100090463956197,
      "backward_entropy": 0.061571885238994255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.695732116699219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008764654397964478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0909965733687083,
      "backward_entropy": 0.06135874444788152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.306676864624023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008865904994308949,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09099169572194417,
      "backward_entropy": 0.06130685047669844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.274313926696777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008966822177171707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098708629608154,
      "backward_entropy": 0.06125386194749312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93062973022461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009067947044968605,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09098200003306071,
      "backward_entropy": 0.0613836483521895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.285629272460938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009169037453830242,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09097700317700703,
      "backward_entropy": 0.061333401636643844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646196365356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00926979724317789,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09097228447596233,
      "backward_entropy": 0.06157765063372525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.805216789245605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009370457381010056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096749623616536,
      "backward_entropy": 0.06102825294841419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.896912574768066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00947109330445528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096255898475647,
      "backward_entropy": 0.060968469489704476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621362686157227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00957173015922308,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095724423726399,
      "backward_entropy": 0.06090715798464688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91183090209961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00967226643115282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095182021458943,
      "backward_entropy": 0.06084439971230247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73637866973877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009772864170372486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090946098168691,
      "backward_entropy": 0.061003706671974876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.356780052185059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009873442351818085,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09094009796778361,
      "backward_entropy": 0.06126596169038252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.148341178894043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009974292479455471,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0909336507320404,
      "backward_entropy": 0.06120980327779597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.510003089904785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010075250640511513,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09092709422111511,
      "backward_entropy": 0.061152013865384186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.819687843322754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010176003910601139,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09092066685358684,
      "backward_entropy": 0.060506224632263184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42512035369873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010277201421558857,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09091384212176006,
      "backward_entropy": 0.06043329564007846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.514426231384277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010378113947808743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0909072756767273,
      "backward_entropy": 0.06035896864804355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.453420639038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0104787927120924,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09090107679367065,
      "backward_entropy": 0.060904454101215706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.146839141845703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01057976670563221,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09089439113934834,
      "backward_entropy": 0.06048498370430686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38442325592041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010680842213332653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09088748693466187,
      "backward_entropy": 0.06012542681260542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.764496803283691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010781620629131794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09088085095087688,
      "backward_entropy": 0.060340285301208496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.687734603881836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010882311500608921,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09087429443995158,
      "backward_entropy": 0.059961037202314896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.060025215148926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010982874780893326,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09086795647939046,
      "backward_entropy": 0.06018972396850586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.084057807922363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011083022691309452,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09086210529009502,
      "backward_entropy": 0.060481689193032005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.45773696899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011183329857885838,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09085586667060852,
      "backward_entropy": 0.06040633808482777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.186469078063965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011283952742815018,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09084918101628621,
      "backward_entropy": 0.05995177138935436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.818735122680664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011384755373001099,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09084206819534302,
      "backward_entropy": 0.059517990459095345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.427164077758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011485513299703598,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09083483616511027,
      "backward_entropy": 0.05978348038413308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.238702774047852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01158549077808857,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09082874655723572,
      "backward_entropy": 0.05932739647951993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.872162818908691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011685722507536411,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09082219998041789,
      "backward_entropy": 0.05960879000750455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.956068992614746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011785975657403469,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09081558386484782,
      "backward_entropy": 0.05912895094264637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.133514404296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011886343359947205,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09080843130747478,
      "backward_entropy": 0.05942618305032903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.814337730407715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011986934579908848,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09080052375793457,
      "backward_entropy": 0.05973827838897705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.958481788635254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012086953036487103,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09079350034395854,
      "backward_entropy": 0.05923406644300981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.895092010498047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012186522595584393,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09078725179036458,
      "backward_entropy": 0.05870729684829712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.475058555603027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012286249548196793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09078044692675273,
      "backward_entropy": 0.05859697948802601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.145512580871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012386399321258068,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09077282746632893,
      "backward_entropy": 0.05936026573181152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.282085418701172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012486781924962997,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09076454242070515,
      "backward_entropy": 0.05836711146614768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512362480163574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012586901895701885,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09075642625490825,
      "backward_entropy": 0.058717933568087494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.405035972595215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012687401846051216,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09074768424034119,
      "backward_entropy": 0.058608477765863594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.052402973175049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012787677347660065,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09073910117149353,
      "backward_entropy": 0.0589483922178095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.083602905273438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012887016870081425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073197841644287,
      "backward_entropy": 0.05787896026264538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.786171913146973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012986613437533379,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09072381258010864,
      "backward_entropy": 0.057750951160084114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.303084373474121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013086277060210705,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09071529905001323,
      "backward_entropy": 0.05861493674191562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.996635437011719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013185711577534676,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.090707262357076,
      "backward_entropy": 0.057486859234896576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.962397575378418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013285381719470024,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09069859981536865,
      "backward_entropy": 0.05790939114310525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.405455589294434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013384667225182056,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09069047371546428,
      "backward_entropy": 0.05825795910575173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.537384033203125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013483880087733269,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09068210919698079,
      "backward_entropy": 0.057657837867736816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5451555252075195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013583085499703884,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0906734565893809,
      "backward_entropy": 0.05752801353281194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.466392517089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013681747950613499,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09066555897394817,
      "backward_entropy": 0.05787981640208851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.264896869659424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013780966401100159,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09065664807955424,
      "backward_entropy": 0.056631272489374336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.848191261291504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013879450969398022,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09064911802609761,
      "backward_entropy": 0.05712365562265569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00239372253418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013978201895952225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09064070383707683,
      "backward_entropy": 0.056325115940787575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262269020080566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014077230356633663,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0906316339969635,
      "backward_entropy": 0.05616629123687744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.778131484985352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014176140539348125,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09062234560648601,
      "backward_entropy": 0.0571961294520985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.405492782592773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01427523698657751,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09061233202616374,
      "backward_entropy": 0.0558396577835083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.428994178771973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014374799095094204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09060136477152507,
      "backward_entropy": 0.055670066313310104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.132685661315918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014474243856966496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0905903975168864,
      "backward_entropy": 0.055497505448081276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.821676254272461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014572856947779655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09058092037836711,
      "backward_entropy": 0.05532342195510864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.883825302124023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014671143144369125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09057173132896423,
      "backward_entropy": 0.055917962030930954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329023361206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014769711531698704,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09056174755096436,
      "backward_entropy": 0.05627917701547796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.785542011260986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014868217520415783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09055161476135254,
      "backward_entropy": 0.054778873920440674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.132343292236328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014965791255235672,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905432899792989,
      "backward_entropy": 0.05542337894439697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.164851188659668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015063315629959106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09053470691045125,
      "backward_entropy": 0.05440189621665261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.474914073944092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015160824172198772,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09052578608194987,
      "backward_entropy": 0.055604956366799095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5083770751953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015257937833666801,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09051733215649922,
      "backward_entropy": 0.05490529537200928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824655532836914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015354727394878864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09050915638605754,
      "backward_entropy": 0.053812753070484505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.312345504760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015451389364898205,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09050088127454121,
      "backward_entropy": 0.055066991936076774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.423540115356445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015548222698271275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09049185117085774,
      "backward_entropy": 0.05340400609103116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.881387710571289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015645261853933334,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09048202633857727,
      "backward_entropy": 0.05417235331101851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.163858413696289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015742169693112373,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09047199289004008,
      "backward_entropy": 0.05297846685756336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.961023807525635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015839137136936188,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09046130379041036,
      "backward_entropy": 0.054301559925079346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606019020080566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015936018899083138,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09045050541559856,
      "backward_entropy": 0.05410068143497814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.098804473876953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016033228486776352,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09043855468432109,
      "backward_entropy": 0.05338188193061135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.533590316772461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016130993142724037,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09042499462763469,
      "backward_entropy": 0.05317579074339433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.252537250518799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016228364780545235,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0904112458229065,
      "backward_entropy": 0.05185168439691717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.541890144348145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016325218603014946,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09039836128552754,
      "backward_entropy": 0.0532594539902427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.312768936157227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01642235741019249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09038432439168294,
      "backward_entropy": 0.05137380144812844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.213458061218262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01651962473988533,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09036944309870402,
      "backward_entropy": 0.05112846331162886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8804521560668945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016616374254226685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09035525719324748,
      "backward_entropy": 0.052100907672535286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.656357765197754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016712455078959465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09034234285354614,
      "backward_entropy": 0.050634801387786865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.807175636291504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01680838316679001,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09032933910687764,
      "backward_entropy": 0.050383892926302826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9896016120910645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016904260963201523,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09031600753466289,
      "backward_entropy": 0.05189047618345781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100574493408203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017000241205096245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09030171235402425,
      "backward_entropy": 0.049869786609302864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.745785713195801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01709633693099022,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09028671185175578,
      "backward_entropy": 0.05140483921224421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.230552673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01719234697520733,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09027134378751119,
      "backward_entropy": 0.05115593563426624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010007858276367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01728796772658825,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09025648236274719,
      "backward_entropy": 0.05048551884564487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.846803665161133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017383737489581108,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09024017055829366,
      "backward_entropy": 0.048793911933898926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.918342590332031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017478933557868004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09022477269172668,
      "backward_entropy": 0.048518272963437165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.988922119140625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017573678866028786,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0902098814646403,
      "backward_entropy": 0.049747618761929596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.449372291564941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01766808331012726,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09019515911738078,
      "backward_entropy": 0.049495377323844215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.278754234313965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017761806026101112,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09018194675445557,
      "backward_entropy": 0.04924187876961448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519164085388184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017855435609817505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09016825755437215,
      "backward_entropy": 0.04898530786687678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8765788078308105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017949147149920464,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09015350540479024,
      "backward_entropy": 0.049059916626323356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.25690221786499,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018043152987957,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09013705452283223,
      "backward_entropy": 0.048460017551075325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.727604866027832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018137052655220032,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09012006719907124,
      "backward_entropy": 0.0485017787326466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.166697978973389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018231136724352837,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09010170896848042,
      "backward_entropy": 0.0482168739492243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4479546546936035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01832505688071251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09008293350537618,
      "backward_entropy": 0.047644615173339844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3053412437438965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01841903105378151,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09006306529045105,
      "backward_entropy": 0.04736509648236362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.120279312133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018512919545173645,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09004261096318562,
      "backward_entropy": 0.04734418067065152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.496798038482666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018606694415211678,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09002157052357991,
      "backward_entropy": 0.04704913226040927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.540043830871582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018699301406741142,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090003768603007,
      "backward_entropy": 0.04651347615502097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.504501819610596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018791550770401955,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08998624483744304,
      "backward_entropy": 0.04645722020756115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.742897987365723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01888342760503292,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08996906876564026,
      "backward_entropy": 0.045935224403034554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.20005464553833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01897507905960083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0899518330891927,
      "backward_entropy": 0.04373303868553855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.78338098526001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019066225737333298,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08993545174598694,
      "backward_entropy": 0.04554634202610363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.518645286560059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019156651571393013,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08992079893747966,
      "backward_entropy": 0.04523781212893399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.737080097198486,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01924695260822773,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.089905579884847,
      "backward_entropy": 0.04475245692513206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.321518898010254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01933727040886879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08988914887110393,
      "backward_entropy": 0.0424543944272128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.401374340057373,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019427334889769554,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08987229069073994,
      "backward_entropy": 0.04414290731603449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.436543941497803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019516540691256523,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08985819419225057,
      "backward_entropy": 0.04180476882240989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5301737785339355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019605666399002075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08984312415122986,
      "backward_entropy": 0.043528331951661545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.719360828399658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019694814458489418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08982670307159424,
      "backward_entropy": 0.04115061055530201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.88145637512207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01978343352675438,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0898112157980601,
      "backward_entropy": 0.040822438218376854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.17211389541626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01987166330218315,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08979615569114685,
      "backward_entropy": 0.042588553645394066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3637285232543945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01995977759361267,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08978019158045451,
      "backward_entropy": 0.042271402749148285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.158900260925293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020047936588525772,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08976270755132039,
      "backward_entropy": 0.042025539008053864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.549898624420166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02013600431382656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0897442897160848,
      "backward_entropy": 0.03948674418709495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.968230724334717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020224252715706825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0897237757841746,
      "backward_entropy": 0.03914414481683211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3835649490356445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02031223103404045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08970279494921367,
      "backward_entropy": 0.03879971937699751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.003178119659424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020399557426571846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08968345324198405,
      "backward_entropy": 0.038456163623116234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.613396167755127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02048674039542675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0896630088488261,
      "backward_entropy": 0.03811003403230147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.371603012084961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02057352289557457,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08964283267656963,
      "backward_entropy": 0.039980882948095146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4857258796691895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02065977267920971,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08962356050809224,
      "backward_entropy": 0.03965080326253718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.227076530456543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020746352151036263,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08960129817326863,
      "backward_entropy": 0.037064633586189964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.563713550567627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020833075046539307,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08957678079605103,
      "backward_entropy": 0.038982207124883476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.695450782775879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02091946266591549,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08955210447311401,
      "backward_entropy": 0.036353100429881706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.413161754608154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021005624905228615,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0895267128944397,
      "backward_entropy": 0.03830621459267356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.906554222106934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021091369912028313,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08950161933898926,
      "backward_entropy": 0.035638765855269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.040637493133545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021176375448703766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08947845300038655,
      "backward_entropy": 0.03528396649794145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1032586097717285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021261587738990784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08945257465044658,
      "backward_entropy": 0.034925284710797394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.38346529006958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02134626917541027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08942738175392151,
      "backward_entropy": 0.03456765413284302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6696672439575195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02143073081970215,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08940136432647705,
      "backward_entropy": 0.0366100397976962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.43450403213501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021515196189284325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08937340974807739,
      "backward_entropy": 0.03384901447729631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.24298095703125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021599488332867622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0893442730108897,
      "backward_entropy": 0.0334874228997664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.179400444030762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02168348990380764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08931449055671692,
      "backward_entropy": 0.03557852723381736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.567219257354736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021767189726233482,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08928410212198894,
      "backward_entropy": 0.03523364121263677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.849308967590332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021850932389497757,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08925140897432964,
      "backward_entropy": 0.034887126900933006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2283935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021934138610959053,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08921920259793599,
      "backward_entropy": 0.03426250544461337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.317224979400635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02201717533171177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08918556571006775,
      "backward_entropy": 0.03167517889629711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.738876819610596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0221001747995615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08914995193481445,
      "backward_entropy": 0.03131117062135176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.325897216796875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022182662039995193,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08911462624867757,
      "backward_entropy": 0.03350116177038713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.191114902496338,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022264404222369194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08908130725224812,
      "backward_entropy": 0.03315411914478649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.77604341506958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022345319390296936,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0890501340230306,
      "backward_entropy": 0.03244373744184321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.336435317993164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022425975650548935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08901781837145488,
      "backward_entropy": 0.029884815216064453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.460050106048584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022506045177578926,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08898624777793884,
      "backward_entropy": 0.03171975504268299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.105212211608887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022585712373256683,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08895434935887654,
      "backward_entropy": 0.02918267250061035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.079863548278809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022664744406938553,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08892364303270976,
      "backward_entropy": 0.031001519073139538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.984807252883911,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022743133828043938,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08889393011728923,
      "backward_entropy": 0.030643809925426136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.207638740539551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022820891812443733,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08886530001958211,
      "backward_entropy": 0.028148951855572788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.736730575561523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022898290306329727,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08883604407310486,
      "backward_entropy": 0.027808086438612503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8058383464813232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02297583781182766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08880309263865153,
      "backward_entropy": 0.027464576742865822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.221729278564453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023052694275975227,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08877148230870564,
      "backward_entropy": 0.02712462165138938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.586082935333252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023129310458898544,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08873833219210307,
      "backward_entropy": 0.026784913106398148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9653146266937256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023205146193504333,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08870719869931538,
      "backward_entropy": 0.029065142978321423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.091500282287598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023279717192053795,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08868165810902913,
      "backward_entropy": 0.028735084967179733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7363226413726807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023354174569249153,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08865358432133992,
      "backward_entropy": 0.028404533863067627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.644655466079712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023428218439221382,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08862503369649251,
      "backward_entropy": 0.02748521620577032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.864398956298828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023501835763454437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.088596244653066,
      "backward_entropy": 0.02514386718923395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3025922775268555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02357523888349533,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08856536944707234,
      "backward_entropy": 0.024819449944929642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3681814670562744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023647930473089218,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08853587508201599,
      "backward_entropy": 0.026462955908341843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.708280086517334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02372005581855774,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08850679794947307,
      "backward_entropy": 0.026775029572573574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6105496883392334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023792071267962456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08847558498382568,
      "backward_entropy": 0.02645270120013844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6623377799987793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023863857612013817,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08844249447186787,
      "backward_entropy": 0.025459999387914486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2488133907318115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0239354707300663,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08840679128964742,
      "backward_entropy": 0.025126652284102005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.701237916946411,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024006538093090057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08837116758028667,
      "backward_entropy": 0.02291768247430975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0476057529449463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024076560512185097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08833933869997661,
      "backward_entropy": 0.022610970518805763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.098691463470459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02414604090154171,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08830805619557698,
      "backward_entropy": 0.022307805039665916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7874488830566406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02421506494283676,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0882762869199117,
      "backward_entropy": 0.022007060321894558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.248971700668335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02428329735994339,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0882458786169688,
      "backward_entropy": 0.021710314533927223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.444509744644165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024351337924599648,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08821263909339905,
      "backward_entropy": 0.023189422759142788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7562978267669678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024418406188488007,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0881831447283427,
      "backward_entropy": 0.023657118732278996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.596433162689209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024484876543283463,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08815369009971619,
      "backward_entropy": 0.02336212992668152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.725599765777588,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024550627917051315,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08812510967254639,
      "backward_entropy": 0.02307134595784274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4372522830963135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024615922942757607,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08809590339660645,
      "backward_entropy": 0.022782845930619675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3931479454040527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024680422618985176,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08806819717089336,
      "backward_entropy": 0.022499362176114864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1012468338012695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02474423497915268,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08804234862327576,
      "backward_entropy": 0.019724243066527626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.363088846206665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024808259680867195,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08801104625066121,
      "backward_entropy": 0.021060921929099342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5733964443206787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02487161196768284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08798073728879292,
      "backward_entropy": 0.01918052543293346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7264022827148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024934623390436172,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08794897794723511,
      "backward_entropy": 0.020481402223760433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.321213722229004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02499750815331936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08791426817576091,
      "backward_entropy": 0.021101169965483925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.134321451187134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0250597782433033,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0878799060980479,
      "backward_entropy": 0.018381842158057472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.952713131904602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025121277198195457,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0878469447294871,
      "backward_entropy": 0.019634368744763462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1845555305480957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025181865319609642,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08781663576761882,
      "backward_entropy": 0.01936074820431796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8783018589019775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02524188533425331,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08778568108876546,
      "backward_entropy": 0.020025219429622997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7473294734954834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025301020592451096,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08775683244069417,
      "backward_entropy": 0.018822073936462402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7659239768981934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025359181687235832,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08773070573806763,
      "backward_entropy": 0.01951212774623524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7275055646896362,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025416484102606773,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08770636717478435,
      "backward_entropy": 0.019262382929975338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8479914665222168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025473004207015038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08768388628959656,
      "backward_entropy": 0.01666936684738506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5409355163574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025529000908136368,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08766140540440877,
      "backward_entropy": 0.017795100808143616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3685842752456665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025584066286683083,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08764154712359111,
      "backward_entropy": 0.018531922589648853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.118408203125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025638088583946228,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08762578169504802,
      "backward_entropy": 0.018296060237017544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6698641777038574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025692204013466835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08760470151901245,
      "backward_entropy": 0.015789198604497044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7233892679214478,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025745751336216927,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08758316437403361,
      "backward_entropy": 0.01683592660860582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.699928879737854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025798892602324486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0875602662563324,
      "backward_entropy": 0.017601399259133774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6917451620101929,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025851652026176453,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08753599723180135,
      "backward_entropy": 0.015154662457379427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5428053140640259,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025904042646288872,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08750992019971211,
      "backward_entropy": 0.017150938510894775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.498981237411499,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025955887511372566,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08748348553975423,
      "backward_entropy": 0.016929458488117565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4923089742660522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02600712887942791,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08745643496513367,
      "backward_entropy": 0.014540882273153826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3371882438659668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02605780027806759,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08742823203404744,
      "backward_entropy": 0.01649628444151445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5645982027053833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026107756420969963,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08740067481994629,
      "backward_entropy": 0.014146571809595282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.329267978668213,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026157431304454803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08737033605575562,
      "backward_entropy": 0.016076568852771412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0657448768615723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02620648965239525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08733997742335002,
      "backward_entropy": 0.013761869885704735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.302921175956726,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02625448815524578,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08731216192245483,
      "backward_entropy": 0.015670842745087364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1886494159698486,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026301993057131767,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0872834324836731,
      "backward_entropy": 0.015473363074389372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0514962673187256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634883113205433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08725470304489136,
      "backward_entropy": 0.013214558362960815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2872166633605957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02639487385749817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08722772200902303,
      "backward_entropy": 0.015088932080702349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1192944049835205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02644064649939537,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08719858527183533,
      "backward_entropy": 0.012866182760758833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0718884468078613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026485834270715714,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08716893196105957,
      "backward_entropy": 0.014714032411575317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0276507139205933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026530394330620766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08713900049527486,
      "backward_entropy": 0.012528410012071783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0094820261001587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02657434530556202,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08710932731628418,
      "backward_entropy": 0.012364317070354115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1683262586593628,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02661767415702343,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08707934617996216,
      "backward_entropy": 0.012202914465557445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9762424230575562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026660826057195663,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08704681197802226,
      "backward_entropy": 0.012042279947887768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0747802257537842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026703407987952232,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08701403935750325,
      "backward_entropy": 0.013822762803597883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0048514604568481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02674567885696888,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08697909116744995,
      "backward_entropy": 0.011728029359470715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0231654644012451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026787539944052696,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08694273233413696,
      "backward_entropy": 0.01249146190556613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8832905888557434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026829088106751442,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08690443634986877,
      "backward_entropy": 0.012330813841386274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7138468027114868,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026870017871260643,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08686575293540955,
      "backward_entropy": 0.011270785196260973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7473036050796509,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026910044252872467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08682931462923686,
      "backward_entropy": 0.011125339703126387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7336242198944092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02694929949939251,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08679360151290894,
      "backward_entropy": 0.011870599605820396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6230430603027344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026987846940755844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08675849437713623,
      "backward_entropy": 0.012673704461617903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6005845069885254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027025409042835236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08672472834587097,
      "backward_entropy": 0.01071069592779333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8120486736297607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02706208825111389,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08669268091519673,
      "backward_entropy": 0.010579999874938618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.712966799736023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027098456397652626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08665770292282104,
      "backward_entropy": 0.01044962690635161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7502015233039856,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02713436633348465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08662185072898865,
      "backward_entropy": 0.012094247070225802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.589172899723053,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02716994844377041,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08658398191134135,
      "backward_entropy": 0.0119551189921119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6995299458503723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027204809710383415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08654673894246419,
      "backward_entropy": 0.010069821368564259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5574318170547485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027239397168159485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08650817473729451,
      "backward_entropy": 0.009946989742192354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6257296800613403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027273299172520638,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08647024631500244,
      "backward_entropy": 0.009827176278287714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5535850524902344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02730684168636799,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0864316721757253,
      "backward_entropy": 0.009709087962454016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5528573393821716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339806780219078,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08639306823412578,
      "backward_entropy": 0.009593517942862078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7166850566864014,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027372224256396294,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08635381857554118,
      "backward_entropy": 0.010305875404314562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5785052180290222,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027404677122831345,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0863105555375417,
      "backward_entropy": 0.010190828957340935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48915940523147583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027436746284365654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08626591165860494,
      "backward_entropy": 0.009254675697196613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43043991923332214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027468152344226837,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08622107903162639,
      "backward_entropy": 0.009145454926924272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30969172716140747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027498815208673477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08617723981539409,
      "backward_entropy": 0.009039454162120819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38735219836235046,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02752840332686901,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0861365795135498,
      "backward_entropy": 0.010579370639540932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44473281502723694,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027557240799069405,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08609642585118611,
      "backward_entropy": 0.010471138087185946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3596154749393463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027585595846176147,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0860550304253896,
      "backward_entropy": 0.010365326296199451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.460790753364563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02761322446167469,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0860141118367513,
      "backward_entropy": 0.008649327538230202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3337278664112091,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02764066867530346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08597170313199361,
      "backward_entropy": 0.010160880332643335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30172863602638245,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02766738086938858,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08592980106671651,
      "backward_entropy": 0.00846631554040042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30979251861572266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02769332379102707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08588890234629314,
      "backward_entropy": 0.008379244668917223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2236485630273819,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027718590572476387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08584830164909363,
      "backward_entropy": 0.008294748989018526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41567081212997437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02774294652044773,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0858101745446523,
      "backward_entropy": 0.008213891901753166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18860580027103424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027767391875386238,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08577000101407369,
      "backward_entropy": 0.00813280858776786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3451099097728729,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0277908593416214,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08573268850644429,
      "backward_entropy": 0.00960894064469771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3462391197681427,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814200147986412,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08569420377413432,
      "backward_entropy": 0.009523612531748686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3141692280769348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02783740684390068,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08565404017766316,
      "backward_entropy": 0.00871979987079447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29366785287857056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02786034345626831,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08561281363169353,
      "backward_entropy": 0.007827551527456804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19245630502700806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02788287028670311,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08557032545407613,
      "backward_entropy": 0.007753765041177923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3364383578300476,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027904650196433067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08552987376848857,
      "backward_entropy": 0.007682889699935913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13549672067165375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027926338836550713,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0854862133661906,
      "backward_entropy": 0.008435127410021696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22999337315559387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02794696018099785,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08544511596361797,
      "backward_entropy": 0.007545226676897569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20548877120018005,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027967188507318497,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0854039192199707,
      "backward_entropy": 0.008972345428033308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23669591546058655,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0279869232326746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0853630006313324,
      "backward_entropy": 0.007416137240149758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2188715636730194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02800632081925869,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08532077074050903,
      "backward_entropy": 0.007353548299182545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21873870491981506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028025392442941666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08527803421020508,
      "backward_entropy": 0.007292099297046661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18773150444030762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028044074773788452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08523402611414592,
      "backward_entropy": 0.007231853902339935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21450360119342804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02806228958070278,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0851898988087972,
      "backward_entropy": 0.007173213091763583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15223543345928192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028080148622393608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08514405290285747,
      "backward_entropy": 0.0071156004613096065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16710986196994781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028097469359636307,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08509924014409383,
      "backward_entropy": 0.008513399145819923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1975671648979187,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028114311397075653,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08505422870318095,
      "backward_entropy": 0.008454832841049541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16906298696994781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813097834587097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08500806490580241,
      "backward_entropy": 0.0069523182782259855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1733432412147522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028147336095571518,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08496171236038208,
      "backward_entropy": 0.006899862126870589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18796539306640625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02816343866288662,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08491477370262146,
      "backward_entropy": 0.008285130966793407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1517399400472641,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028179431334137917,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08486659328142802,
      "backward_entropy": 0.007664152167060159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1431323140859604,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02819511666893959,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08481856187184651,
      "backward_entropy": 0.007618233561515808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09199412167072296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028210273012518883,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0847698450088501,
      "backward_entropy": 0.00669824399731376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14410580694675446,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028224604204297066,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08472238977750142,
      "backward_entropy": 0.008076025681062178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13899503648281097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02823871560394764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0846744974454244,
      "backward_entropy": 0.008028027686205778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14155425131320953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028252599760890007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0846261978149414,
      "backward_entropy": 0.006562945517626676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15372905135154724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028266092762351036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08457628885904948,
      "backward_entropy": 0.006519640033895319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10891452431678772,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028279663994908333,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08452560504277547,
      "backward_entropy": 0.0078897164626555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08228728175163269,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02829289622604847,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08447570602099101,
      "backward_entropy": 0.007340168411081488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08000646531581879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028305597603321075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08442750573158264,
      "backward_entropy": 0.006393401460214095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07664844393730164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02831762470304966,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08438008030255635,
      "backward_entropy": 0.007762045345523141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10910061001777649,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0283291544765234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08433393637339275,
      "backward_entropy": 0.00631843168627132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10472194850444794,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340378776192665,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08428668975830078,
      "backward_entropy": 0.007210190323266116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07444658130407333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028351403772830963,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0842389166355133,
      "backward_entropy": 0.006247370080514388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07927504181861877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028362112119793892,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08419253428777058,
      "backward_entropy": 0.007152026349847967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08181030303239822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028372468426823616,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08414658904075623,
      "backward_entropy": 0.007124552672559565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08590420335531235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028382599353790283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08410102128982544,
      "backward_entropy": 0.0061480159109289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08206940442323685,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028392493724822998,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08405513564745586,
      "backward_entropy": 0.007511160590431907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0652276873588562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028402214869856834,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08400927980740865,
      "backward_entropy": 0.007478789849714799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08203963190317154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02841148152947426,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08396380146344502,
      "backward_entropy": 0.007447907870466059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09986267983913422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028420643880963326,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08391801516215007,
      "backward_entropy": 0.007417479021982713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05457138642668724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028429890051484108,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08387070894241333,
      "backward_entropy": 0.005996865305033597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051671192049980164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028438623994588852,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0838241974512736,
      "backward_entropy": 0.005968796935948459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09111334383487701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028446676209568977,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08377788464228313,
      "backward_entropy": 0.00594272329048677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08141792565584183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028454827144742012,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08373004198074341,
      "backward_entropy": 0.007304417138749903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051876820623874664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028462860733270645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0836809476216634,
      "backward_entropy": 0.005890040912411429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06995730847120285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028470735996961594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08363335331281026,
      "backward_entropy": 0.005864458327943628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059579793363809586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028478523716330528,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08358532190322876,
      "backward_entropy": 0.0068544108759273185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08036244660615921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02848612144589424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08353745937347412,
      "backward_entropy": 0.005814351141452789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0549432709813118,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028493836522102356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08348827560742696,
      "backward_entropy": 0.005789187821474942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05757841095328331,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0285013597458601,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08343956867853801,
      "backward_entropy": 0.007152241739359769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05556236207485199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028508711606264114,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08339087168375652,
      "backward_entropy": 0.007128422233191403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04541989043354988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028515733778476715,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08334181706110637,
      "backward_entropy": 0.006763379682194103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04973253235220909,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02852240949869156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08329327901204427,
      "backward_entropy": 0.007084000517021526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05623029172420502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02852887660264969,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08324490984280904,
      "backward_entropy": 0.005674005232074044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030168788507580757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02853517234325409,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08319583535194397,
      "backward_entropy": 0.005653026767752387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037349168211221695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02854122593998909,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08314886689186096,
      "backward_entropy": 0.006704383953051133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04305843263864517,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028546933084726334,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0831025242805481,
      "backward_entropy": 0.0066916041753508826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03880445286631584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028552494943141937,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0830563207467397,
      "backward_entropy": 0.006986628879200329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04936695843935013,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028557633981108665,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0830100029706955,
      "backward_entropy": 0.006668390198187394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0384344756603241,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02856287732720375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08296331266562144,
      "backward_entropy": 0.005559942600401965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04218798875808716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02856801077723503,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08291706442832947,
      "backward_entropy": 0.0055425099351189356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04258522018790245,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028573114424943924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08287077645460765,
      "backward_entropy": 0.005525196817788211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028950927779078484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028578130528330803,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08282414575417836,
      "backward_entropy": 0.005508105185898868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035958413034677505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028582876548171043,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0827785034974416,
      "backward_entropy": 0.006888684223998676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0328889898955822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028587354347109795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08273264765739441,
      "backward_entropy": 0.005476322363723408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022860102355480194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028591739013791084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08268725375334422,
      "backward_entropy": 0.00546111369674856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03180307894945145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0285957008600235,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0826428880294164,
      "backward_entropy": 0.005447126924991608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03119216486811638,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028599578887224197,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0825987160205841,
      "backward_entropy": 0.006580858745358207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027087433263659477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028603455051779747,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08255486190319061,
      "backward_entropy": 0.006822444498538971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032978691160678864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028607139363884926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08251143495241801,
      "backward_entropy": 0.005406643856655468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02325991541147232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028610896319150925,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08246789872646332,
      "backward_entropy": 0.006798608059232885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021441157907247543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028614522889256477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08242528637250264,
      "backward_entropy": 0.005380464548414404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0302028376609087,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028617804870009422,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0823832501967748,
      "backward_entropy": 0.006776536730202762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028285222128033638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286212507635355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08234122395515442,
      "backward_entropy": 0.005356275561180982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027539819478988647,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02862454019486904,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08229882021745046,
      "backward_entropy": 0.006533162837678736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02309248596429825,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028627760708332062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08225623766581218,
      "backward_entropy": 0.006744876503944397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023129381239414215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028630705550312996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08221377432346344,
      "backward_entropy": 0.005321695723316886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02719816565513611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028633607551455498,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08217168847719829,
      "backward_entropy": 0.006517565385861831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019938809797167778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028636695817112923,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0821295827627182,
      "backward_entropy": 0.00529960881580006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0244317427277565,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028639549389481544,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08208791414896648,
      "backward_entropy": 0.00670732015913183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022040965035557747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864239551126957,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08204612632592519,
      "backward_entropy": 0.005278401076793671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02423916384577751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028645068407058716,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0820042888323466,
      "backward_entropy": 0.006497728553685275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02118426188826561,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864743024110794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08196167647838593,
      "backward_entropy": 0.005258949642831629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017846764996647835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864978089928627,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0819192926088969,
      "backward_entropy": 0.005249673669988459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02228580042719841,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028651999309659004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08187746008237202,
      "backward_entropy": 0.005240803753787821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020854126662015915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028654204681515694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0818353941043218,
      "backward_entropy": 0.006660181013020602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016531717032194138,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028656478971242905,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08179343740145366,
      "backward_entropy": 0.006652859124270352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021375807002186775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028658552095294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0817519227663676,
      "backward_entropy": 0.00664613734592091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01918196491897106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866082265973091,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0817103882630666,
      "backward_entropy": 0.006638879125768488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016813108697533607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028663072735071182,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08166886369387309,
      "backward_entropy": 0.005196685140783136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016068940982222557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866506204009056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08162738879521687,
      "backward_entropy": 0.005188514563170346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012914326041936874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02866705320775509,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08158641060193379,
      "backward_entropy": 0.006470151245594025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014689094386994839,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286688432097435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08154620726903279,
      "backward_entropy": 0.0051728382029316644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019201243296265602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02867049351334572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08150629202524821,
      "backward_entropy": 0.00516570427201011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011697888374328613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028672397136688232,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08146617809931438,
      "backward_entropy": 0.0051578777757557955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01617157645523548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02867426909506321,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08142710725466411,
      "backward_entropy": 0.005150234157388861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016584137454628944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02867615595459938,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08138793210188548,
      "backward_entropy": 0.005142547867514871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012872091494500637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02867802046239376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08134841918945312,
      "backward_entropy": 0.005134903571822427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01269901916384697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02867976762354374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08130929867426555,
      "backward_entropy": 0.005127606405453248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012089722789824009,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028681447729468346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08127057055632274,
      "backward_entropy": 0.005120531740513715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01070322748273611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028683120384812355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08123235901196797,
      "backward_entropy": 0.00511351769620722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01332719437777996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028684578835964203,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08119459946950276,
      "backward_entropy": 0.006562536413019354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012329714372754097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02868606708943844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08115684986114502,
      "backward_entropy": 0.006557728756557812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011760755442082882,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028687551617622375,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08111923933029175,
      "backward_entropy": 0.006552929905327884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011016113683581352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02868899144232273,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08108180264631908,
      "backward_entropy": 0.0050878507847135716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008052057586610317,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028690403327345848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08104467391967773,
      "backward_entropy": 0.005081625147299333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00829355139285326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02869175188243389,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08100856343905131,
      "backward_entropy": 0.0050756558775901794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009466126561164856,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0286930650472641,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08097330232461293,
      "backward_entropy": 0.0064436976205218925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00922241061925888,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02869441546499729,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08093849817911784,
      "backward_entropy": 0.006530931050127203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010140114463865757,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028695711866021156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08090399205684662,
      "backward_entropy": 0.006526837294751947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007173831108957529,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02869698964059353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08086946606636047,
      "backward_entropy": 0.005052580074830489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008678080514073372,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028698192909359932,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08083571493625641,
      "backward_entropy": 0.006438735533844341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007130044512450695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02869933657348156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0808021326859792,
      "backward_entropy": 0.006515326825055209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00903517846018076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028700439259409904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076919118563335,
      "backward_entropy": 0.005036853931166909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007883485406637192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028701679781079292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08073640366395314,
      "backward_entropy": 0.005031434988433664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008078541606664658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02870285138487816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08070379495620728,
      "backward_entropy": 0.005026204680854624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007032003719359636,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02870401367545128,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08067130049069722,
      "backward_entropy": 0.006433335217562589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006698928773403168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02870519831776619,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08063928286234538,
      "backward_entropy": 0.0064320110461928625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00727055175229907,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028706474229693413,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08060787618160248,
      "backward_entropy": 0.006492947990244085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007198031526058912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028707584366202354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08057639002799988,
      "backward_entropy": 0.005005455152554946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005945178214460611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028708741068840027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08054508765538533,
      "backward_entropy": 0.005000389773737301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005240210331976414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028709815815091133,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08051420251528423,
      "backward_entropy": 0.006482441994276914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005406487267464399,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028710806742310524,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08048392335573833,
      "backward_entropy": 0.0049909986555576324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006236252374947071,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02871163934469223,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08045395215352376,
      "backward_entropy": 0.004986888305707412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006317386869341135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028712378814816475,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08042395611604054,
      "backward_entropy": 0.0064255263317715035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005320664960891008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028713203966617584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08039408922195435,
      "backward_entropy": 0.004978931085629897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005289851687848568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028714021667838097,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08036460479100545,
      "backward_entropy": 0.0064249377359043465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00488267932087183,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028714792802929878,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08033536871274312,
      "backward_entropy": 0.006424769081852653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004936752375215292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028715502470731735,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0803064654270808,
      "backward_entropy": 0.006464117629961534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004382156301289797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028716174885630608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08027782539526622,
      "backward_entropy": 0.004963700744238767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036935354582965374,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028716804459691048,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08024961749712627,
      "backward_entropy": 0.0064251321283253756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005043678916990757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028717396780848503,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08022210995356242,
      "backward_entropy": 0.004956945776939392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036749951541423798,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02871801145374775,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08019460240999858,
      "backward_entropy": 0.00645582987503572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004519272595643997,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028718631714582443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08016772071520488,
      "backward_entropy": 0.004950265992771496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003895670408383012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028719253838062286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08014092842737834,
      "backward_entropy": 0.004946938969872214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029987154994159937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02871987596154213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08011449873447418,
      "backward_entropy": 0.004943644458597357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034977500326931477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028720490634441376,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08008882403373718,
      "backward_entropy": 0.006447790698571639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004148280248045921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02872111275792122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08006354173024495,
      "backward_entropy": 0.004937191578474912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025177670177072287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028721792623400688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08003830909729004,
      "backward_entropy": 0.004933830011974682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029198224656283855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02872241847217083,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08001384139060974,
      "backward_entropy": 0.0064246640963987875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030151614919304848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028722964227199554,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0799897313117981,
      "backward_entropy": 0.006439964879642834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035641680005937815,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028723496943712234,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07996596892674764,
      "backward_entropy": 0.006424548951062289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027011330239474773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02872416190803051,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07994236548741658,
      "backward_entropy": 0.004921615801074288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002458171686157584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028724806383252144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0799191842476527,
      "backward_entropy": 0.004918493330478668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028874478302896023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02872539684176445,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07989645997683208,
      "backward_entropy": 0.006432378833944147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027493038214743137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028726013377308846,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0798739492893219,
      "backward_entropy": 0.006422495977445083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002310684183612466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02872661128640175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0798516074816386,
      "backward_entropy": 0.004909570244225589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024981051683425903,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028727151453495026,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07982964317003886,
      "backward_entropy": 0.0064217529513619165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021974146366119385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02872772514820099,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07980796694755554,
      "backward_entropy": 0.004903961989012631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00260162353515625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0287283007055521,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07978670299053192,
      "backward_entropy": 0.00490114533088424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022145297843962908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028728900477290154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07976552347342174,
      "backward_entropy": 0.004898272116075863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022185032721608877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028729485347867012,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07974459230899811,
      "backward_entropy": 0.0064196722073988485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019304733723402023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02873004786670208,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07972385485967,
      "backward_entropy": 0.006419124928387729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002140191849321127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02873050980269909,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07970336079597473,
      "backward_entropy": 0.006418994881890037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020878068171441555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028730953112244606,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07968299090862274,
      "backward_entropy": 0.0064189373092217875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018994275014847517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02873143181204796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07966283460458119,
      "backward_entropy": 0.004885368726470254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016972188604995608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02873186208307743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07964285214742024,
      "backward_entropy": 0.0048830316148021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001843795063905418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02873227559030056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07962322731812795,
      "backward_entropy": 0.004880760881033811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015673692105337977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028732672333717346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07960375150044759,
      "backward_entropy": 0.004878535189411857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016732624499127269,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028733039274811745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07958459854125977,
      "backward_entropy": 0.004876416176557541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016577126225456595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02873346395790577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07956575850645702,
      "backward_entropy": 0.004874171181158586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016004816861823201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02873390167951584,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07954711218674977,
      "backward_entropy": 0.006405402990904721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013306977925822139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028734365478157997,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07952869931856792,
      "backward_entropy": 0.00641822950406508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014167435001581907,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02873474545776844,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07951053977012634,
      "backward_entropy": 0.006418215957554904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014705926878377795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028735129162669182,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07949263354142506,
      "backward_entropy": 0.006401403383775191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012186468811705709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02873552031815052,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07947488625844319,
      "backward_entropy": 0.006400115110657432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013735898537561297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028735952451825142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07945755124092102,
      "backward_entropy": 0.004861155694181269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011482312111184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02873644232749939,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07944042483965556,
      "backward_entropy": 0.004858858544718136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010776177514344454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02873685583472252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07942352692286174,
      "backward_entropy": 0.0063958317041397095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00115382787771523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028737302869558334,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07940701643625896,
      "backward_entropy": 0.006416544318199158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001240801764652133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028737695887684822,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07939064502716064,
      "backward_entropy": 0.0064163167368281974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012393079232424498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028738079592585564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07937430342038472,
      "backward_entropy": 0.004850646988912063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000986398896202445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02873852662742138,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07935809095700581,
      "backward_entropy": 0.004848518832163377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010219784453511238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028738949447870255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07934212684631348,
      "backward_entropy": 0.006389045579866929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009074173285625875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028739377856254578,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0793263812859853,
      "backward_entropy": 0.006414956667206504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009049210930243134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028739770874381065,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07931086917718251,
      "backward_entropy": 0.006386343051086773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009335046052001417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02874012477695942,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07929554084936778,
      "backward_entropy": 0.006385160440748388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007971742306835949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028740448877215385,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07928032676378886,
      "backward_entropy": 0.0063840564001690255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007387855439446867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874080277979374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0792654554049174,
      "backward_entropy": 0.004837117073210803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007065334939397871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028741084039211273,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07925080259641011,
      "backward_entropy": 0.006414399905638261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006210155552253127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028741324320435524,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07923640807469685,
      "backward_entropy": 0.006381045010956851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000620857288595289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028741534799337387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07922235131263733,
      "backward_entropy": 0.004832670092582703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006706159329041839,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028741735965013504,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07920862237612407,
      "backward_entropy": 0.006379583342508836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005945313023403287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028741948306560516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07919510205586751,
      "backward_entropy": 0.004829990592869845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005464335554279387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874215692281723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07918186485767365,
      "backward_entropy": 0.004828663034872575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000501903472468257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028742317110300064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07916887104511261,
      "backward_entropy": 0.004827483133836226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005429840530268848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874247543513775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07915619512399037,
      "backward_entropy": 0.004826328632506457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005628328071907163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874259278178215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07914368808269501,
      "backward_entropy": 0.00482528724453666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000399476703023538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028742715716362,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07913132508595784,
      "backward_entropy": 0.004824239760637283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043966982048004866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028742801398038864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07911929488182068,
      "backward_entropy": 0.004823307422074405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004549616714939475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028742872178554535,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07910752296447754,
      "backward_entropy": 0.006375368345867504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038642267463728786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028742924332618713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0790959099928538,
      "backward_entropy": 0.004821616140278903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038746220525354147,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028742969036102295,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07908457517623901,
      "backward_entropy": 0.006374889476732774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004442843492142856,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028743013739585876,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07907348871231079,
      "backward_entropy": 0.006420299410820007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036371691385284066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028743097558617592,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07906257112820943,
      "backward_entropy": 0.0063743388110941105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034342717844992876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874320186674595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0790519118309021,
      "backward_entropy": 0.004818327724933624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003663606767076999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028743308037519455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07904150088628133,
      "backward_entropy": 0.0048174434764818716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032734317937865853,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028743410483002663,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07903122405211131,
      "backward_entropy": 0.004816570065238259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035956251667812467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874351292848587,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.079021155834198,
      "backward_entropy": 0.004815715280446139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002665066858753562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028743639588356018,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07901122172673543,
      "backward_entropy": 0.004814807325601578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000291272095637396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028743740171194077,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0790015161037445,
      "backward_entropy": 0.006422671404751864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030456663807854056,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028743823990225792,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07899196942647298,
      "backward_entropy": 0.006371631541035392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002796452317852527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874392829835415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0789825866619746,
      "backward_entropy": 0.004812391305511648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002662631741259247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874404564499855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07897338767846425,
      "backward_entropy": 0.004811557179147547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002276912855450064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874418906867504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07896439731121063,
      "backward_entropy": 0.004810665141452442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026782762142829597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028744356706738472,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07895568013191223,
      "backward_entropy": 0.004809719256379388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001912949956022203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028744537383317947,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0789471020301183,
      "backward_entropy": 0.00480876084078442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002224130294052884,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028744684532284737,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07893870274225871,
      "backward_entropy": 0.004807888106866317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021226124954409897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028744831681251526,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07893045743306477,
      "backward_entropy": 0.0048070302741094065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002247573429485783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874499373137951,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07892239093780518,
      "backward_entropy": 0.004806145009669391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001889115374069661,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02874518185853958,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07891446848710378,
      "backward_entropy": 0.0064232931895689535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001728627539705485,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028745368123054504,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07890671988328297,
      "backward_entropy": 0.006366435777057301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018161808839067817,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028745535761117935,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07889910538991292,
      "backward_entropy": 0.0064230046489022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016543718811590225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874569222331047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07889161010583241,
      "backward_entropy": 0.004802561957727779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001308529026573524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028745848685503006,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07888426880041759,
      "backward_entropy": 0.006422847509384155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014727661618962884,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028745995834469795,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07887715597947438,
      "backward_entropy": 0.006422772326252677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001496283948654309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746120631694794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07887015740076701,
      "backward_entropy": 0.004800220443443818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001365060597890988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746245428919792,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07886328299840291,
      "backward_entropy": 0.004799496382474899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011601757432799786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746379539370537,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07885656754175822,
      "backward_entropy": 0.004798770289529453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012905875337310135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746508061885834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07885004083315532,
      "backward_entropy": 0.0047980540178038855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012152826820965856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746619820594788,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07884360353151958,
      "backward_entropy": 0.0047974014146761465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013145174307283014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746724128723145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07883726557095845,
      "backward_entropy": 0.004796761342070319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011482548143249005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746847063302994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07883103688557942,
      "backward_entropy": 0.004796091128479351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.95867740130052e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028746969997882843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07882493734359741,
      "backward_entropy": 0.00479541922157461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.52143527683802e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028747085481882095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07881895701090495,
      "backward_entropy": 0.004794774746352976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.387192065129057e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0287471953779459,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07881313562393188,
      "backward_entropy": 0.006422581997784701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.441379370400682e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028747308999300003,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07880748311678569,
      "backward_entropy": 0.006422529843720523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.868013537721708e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874741703271866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07880193988482158,
      "backward_entropy": 0.0047929415648633785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.634944242658094e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028747517615556717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07879647612571716,
      "backward_entropy": 0.004792372611435977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.165391045622528e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028747616335749626,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07879111170768738,
      "backward_entropy": 0.006422455337914554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420262747677043e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028747716918587685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07878586649894714,
      "backward_entropy": 0.006358630955219269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.048349991440773e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874782122671604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0787807007630666,
      "backward_entropy": 0.0047906921668486166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.532953218789771e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028747927397489548,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07877562443415324,
      "backward_entropy": 0.004790119826793671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.093876774888486e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028748026117682457,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0787706971168518,
      "backward_entropy": 0.004789589819583026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.782890704926103e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028748132288455963,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07876589894294739,
      "backward_entropy": 0.00642220675945282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.232858140720055e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028748245909810066,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0787612001101176,
      "backward_entropy": 0.0063568949699401855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.300093809841201e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874835953116417,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07875660061836243,
      "backward_entropy": 0.004787921228192069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.573545397259295e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028748469427227974,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07875206073125203,
      "backward_entropy": 0.00642182474786585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.803160820505582e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028748581185936928,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07874757051467896,
      "backward_entropy": 0.004786825315518813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.630213490803726e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02874869853258133,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0787431796391805,
      "backward_entropy": 0.004786280745809729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7994144551921636e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028748810291290283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07873884340127309,
      "backward_entropy": 0.0047857388854026794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.899424675386399e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028748922049999237,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0787346214056015,
      "backward_entropy": 0.00478522005406293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.973866841988638e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02874903753399849,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0787304937839508,
      "backward_entropy": 0.006421121006662195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.744988837046549e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028749143704771996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07872647047042847,
      "backward_entropy": 0.004784181375395168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6186065699439496e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028749248012900352,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0787225067615509,
      "backward_entropy": 0.004783688282424753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.202525087748654e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028749343007802963,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07871865232785542,
      "backward_entropy": 0.0063533457842740145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2225939978379756e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028749438002705574,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07871485749880473,
      "backward_entropy": 0.00478275255723433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.158105730311945e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028749531134963036,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07871111234029134,
      "backward_entropy": 0.0064205344427715645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.246212509111501e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028749627992510796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07870741685231526,
      "backward_entropy": 0.004781842570413242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6499168345471844e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028749726712703705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07870383063952129,
      "backward_entropy": 0.00478138571435755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1768497137818485e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028749823570251465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07870028416315715,
      "backward_entropy": 0.006351783871650696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.128798198304139e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028749922290444374,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07869683702786763,
      "backward_entropy": 0.006351470269940116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.021725387952756e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875002659857273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0786934643983841,
      "backward_entropy": 0.006351141767068343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9183558581280522e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028750138357281685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07869019110997517,
      "backward_entropy": 0.004779551516879688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1637617464875802e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875024639070034,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07868695259094238,
      "backward_entropy": 0.004779081791639328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.67909617832629e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875034511089325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07868382334709167,
      "backward_entropy": 0.00477865609255704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4434384613414295e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875044196844101,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07868073383967082,
      "backward_entropy": 0.0063498297875577755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5444518541917205e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028750544413924217,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07867773373921712,
      "backward_entropy": 0.004777789115905762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8174843717133626e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028750652447342873,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07867478330930074,
      "backward_entropy": 0.006418660283088684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8300546798855066e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028750749304890633,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07867191235224406,
      "backward_entropy": 0.004776933992450888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8405668015475385e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028750842437148094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07866912086804707,
      "backward_entropy": 0.004776533354412426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8624155927682295e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028750933706760406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07866639892260234,
      "backward_entropy": 0.004776143214919351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6976206097751856e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751017525792122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0786637266476949,
      "backward_entropy": 0.004775783216411417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8380935216555372e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751099482178688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07866111397743225,
      "backward_entropy": 0.004775427281856537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7213264072779566e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751177713274956,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07865853110949199,
      "backward_entropy": 0.0047750771045684814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5524685295531526e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751257807016373,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07865599791208903,
      "backward_entropy": 0.004774726927280426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.308813807554543e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875133417546749,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07865350941816966,
      "backward_entropy": 0.004774393683130091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4382138033397496e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028751403093338013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07865108052889506,
      "backward_entropy": 0.006346848877993497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3375303751672618e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751475736498833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07864871621131897,
      "backward_entropy": 0.004773750901222229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3652722373080906e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751546517014503,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07864639163017273,
      "backward_entropy": 0.004773441024801948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1211812307010405e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028751619160175323,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0786441167195638,
      "backward_entropy": 0.006416910751299424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0945968824671581e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751688078045845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07864189147949219,
      "backward_entropy": 0.004772816869345578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2350778888503555e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875174768269062,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07863969604174297,
      "backward_entropy": 0.004772543229840018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.096958112611901e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751812875270844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07863755027453105,
      "backward_entropy": 0.004772252657196738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0376674254075624e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751874342560768,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07863543430964152,
      "backward_entropy": 0.004771971905773336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988242370833177e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028751935809850693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07863335808118184,
      "backward_entropy": 0.0047717067328366366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.548750090791145e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875198796391487,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07863133152325948,
      "backward_entropy": 0.004771453074433587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983228897501249e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0287520382553339,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07862935960292816,
      "backward_entropy": 0.006344854154370048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372278898605146e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02875208668410778,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07862742741902669,
      "backward_entropy": 0.006416204978119244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.590578206873033e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875213325023651,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07862554490566254,
      "backward_entropy": 0.004770752719857476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.565579496964347e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875218167901039,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07862370212872823,
      "backward_entropy": 0.006344399668953635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.511860192404129e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752226382493973,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07862190405527751,
      "backward_entropy": 0.0047703107649629765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.173846031742869e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752267360687256,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07862015565236409,
      "backward_entropy": 0.006415959786285053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3607200243277475e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875230461359024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07861843705177307,
      "backward_entropy": 0.0047699074176224794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.606159447779646e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752340003848076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07861677805582683,
      "backward_entropy": 0.004769718443805521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.912974418402882e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752371668815613,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0786151538292567,
      "backward_entropy": 0.004769538275220178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.937304882128956e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875239960849285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07861355940500896,
      "backward_entropy": 0.006343710151585666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.051318112236913e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875242382287979,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07861202955245972,
      "backward_entropy": 0.004769225350835107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9323230086883996e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875244989991188,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0786105344692866,
      "backward_entropy": 0.004769078371199695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.717609160958091e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875247411429882,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07860905925432841,
      "backward_entropy": 0.006343471733006564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9732176446705125e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875249832868576,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07860763370990753,
      "backward_entropy": 0.006343392485922033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.948695848521311e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02875252440571785,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0786062479019165,
      "backward_entropy": 0.006415789777582342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4543857054813998e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875254862010479,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07860488692919414,
      "backward_entropy": 0.006343233314427463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3196811273228377e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875257097184658,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07860355575879414,
      "backward_entropy": 0.0063431682911786165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2749749152571894e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875259332358837,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07860227425893147,
      "backward_entropy": 0.004768232730301944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8600445602933178e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752615675330162,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07860101759433746,
      "backward_entropy": 0.004768098619851199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.742868900895701e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752636164426804,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07859978079795837,
      "backward_entropy": 0.004767983135851947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.709814907575492e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752656653523445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07859858870506287,
      "backward_entropy": 0.004767867990515449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.042093567273696e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752673417329788,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07859743138154347,
      "backward_entropy": 0.006342858076095581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3303728085011244e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875269018113613,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07859628399213155,
      "backward_entropy": 0.004767650230364366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8323624974291306e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752705082297325,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07859516143798828,
      "backward_entropy": 0.006342758509245786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.044204165940755e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875271998345852,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07859405378500621,
      "backward_entropy": 0.00634271041913466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9478034118947107e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752734884619713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07859298586845398,
      "backward_entropy": 0.004767344417897138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7884726730699185e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752751648426056,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0785919576883316,
      "backward_entropy": 0.006415708498521285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8245531236971146e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752770274877548,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07859094937642415,
      "backward_entropy": 0.006342560730197213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1174112134758616e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875279076397419,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785899708668391,
      "backward_entropy": 0.0047670291228727865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7367508462484693e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752809390425682,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858901222546895,
      "backward_entropy": 0.004766929894685745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6413280263805063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752824291586876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858805855115254,
      "backward_entropy": 0.004766832698475231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6218093605857575e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875283733010292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858713964621226,
      "backward_entropy": 0.004766743968833576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2991663425054867e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752850368618965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07858624557654063,
      "backward_entropy": 0.006342312829060988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3677986316906754e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875286340713501,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07858538130919139,
      "backward_entropy": 0.006342268802902915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2892413678855519e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752874583005905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858452200889587,
      "backward_entropy": 0.004766494713046334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.177196168100636e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875288389623165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858368754386902,
      "backward_entropy": 0.0047664317217740145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0827599226104212e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752891346812248,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07858288288116455,
      "backward_entropy": 0.006342180073261261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0977114470733795e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752900660037994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078582098086675,
      "backward_entropy": 0.004766296256672253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.045363319462922e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875290997326374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858132819334666,
      "backward_entropy": 0.004766232926737179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.403443641531339e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752919286489487,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785805881023407,
      "backward_entropy": 0.004766158759593964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.802888942227582e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752930462360382,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07857986291249593,
      "backward_entropy": 0.00634206086397171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0539067716308637e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752941638231277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07857915262381236,
      "backward_entropy": 0.004766026003794236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.561599654261954e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752950951457024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785784622033437,
      "backward_entropy": 0.004765957932580601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.490126219840022e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02875295840203762,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07857777674992879,
      "backward_entropy": 0.006415710530497811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.013856020421372e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752963989973068,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07857709626356761,
      "backward_entropy": 0.006341965361074967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.886737994842406e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752969577908516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07857644557952881,
      "backward_entropy": 0.006341939622705633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.368173330884019e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752973303198814,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0785758246978124,
      "backward_entropy": 0.00634193014014851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.140838308965613e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752975165843964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07857521375020345,
      "backward_entropy": 0.004765712063420902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.675396437254676e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07857461770375569,
      "backward_entropy": 0.00476567650383169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.950930130893539e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02875298261642456,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07857404152552287,
      "backward_entropy": 0.00641583651304245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.62159073069779e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875298634171486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0785734752813975,
      "backward_entropy": 0.006341888145966964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6075703608039476e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752988204360008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785729189713796,
      "backward_entropy": 0.004765550521287051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.098463020658528e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752990067005157,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07857238749663036,
      "backward_entropy": 0.006415890699083155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.565758899843786e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752990067005157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785718560218811,
      "backward_entropy": 0.004765484482049942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6428002658794867e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752991929650307,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07857134938240051,
      "backward_entropy": 0.004765449261123484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.716913283824397e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752993792295456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07857085267702739,
      "backward_entropy": 0.004765412346883254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7706669786530256e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752995654940605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07857037087281545,
      "backward_entropy": 0.004765387285839428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1812214729143307e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752995654940605,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856990893681844,
      "backward_entropy": 0.006416001103141091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.358297533395671e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752995654940605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856944700082143,
      "backward_entropy": 0.004765336486426267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2658104487381934e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752995654940605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785690148671468,
      "backward_entropy": 0.004765307361429388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0441830745076004e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752993792295456,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856857776641846,
      "backward_entropy": 0.006416090510108254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1368816166832403e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752991929650307,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856816053390503,
      "backward_entropy": 0.006416121667081659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.671429797374003e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752990067005157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785677433013916,
      "backward_entropy": 0.004765255884690719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1079047485272895e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298634171486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856734097003937,
      "backward_entropy": 0.004765244370157068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.722267140597978e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298447906971,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856695353984833,
      "backward_entropy": 0.0047652304849841376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8758562703169446e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298261642456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856657107671101,
      "backward_entropy": 0.004765210503881628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1881798772938055e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298075377941,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856619854768117,
      "backward_entropy": 0.004765200343998996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.903972730588066e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856584588686626,
      "backward_entropy": 0.004765186797488819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6866815144567227e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785655031601588,
      "backward_entropy": 0.0047651583498174496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6211350839512306e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856516043345134,
      "backward_entropy": 0.004765145141970028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6010159242796362e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785648375749588,
      "backward_entropy": 0.004765131934122605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5894417515482928e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856452465057373,
      "backward_entropy": 0.006416379728100516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3933666309640103e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856421669324239,
      "backward_entropy": 0.006416393274610693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.451524127560333e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856391867001851,
      "backward_entropy": 0.0047650770707563924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2024148077216523e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856362064679463,
      "backward_entropy": 0.0047650601376186714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2821796246953454e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856333752473195,
      "backward_entropy": 0.0064164386554197836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0662772353953187e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752978891134262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856306433677673,
      "backward_entropy": 0.004765030673959039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0263624261597215e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02875298075377941,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856280108292897,
      "backward_entropy": 0.006416453556580977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1759045293047166e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298075377941,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856253782908122,
      "backward_entropy": 0.004764994437044317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.339043233718257e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298075377941,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856228947639465,
      "backward_entropy": 0.004764982245185159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471864276771157e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875298075377941,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07856204112370808,
      "backward_entropy": 0.00634187866340984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.609123287011244e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298075377941,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856181263923645,
      "backward_entropy": 0.004764948378909718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.567796783154336e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298075377941,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856157422065735,
      "backward_entropy": 0.004764937880364331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854863153828774e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875298261642456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07856135070323944,
      "backward_entropy": 0.006341862407597629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.924659518541375e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875298447906971,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078561137119929,
      "backward_entropy": 0.004764902659437873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.408670572000119e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02875298634171486,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856092353661855,
      "backward_entropy": 0.006416538899595087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.364262361557849e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752988204360008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856071988741557,
      "backward_entropy": 0.004764865745197643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.877321823139937e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752990067005157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856052120526631,
      "backward_entropy": 0.004764850844036449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0164011611286696e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028752991929650307,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07856033245722453,
      "backward_entropy": 0.0063418366692282934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.061972885300747e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752993792295456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856013377507527,
      "backward_entropy": 0.004764813929796219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.512355999963802e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752995654940605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855995496114095,
      "backward_entropy": 0.004764798012646762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6264737818546564e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028752997517585754,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07855977614720662,
      "backward_entropy": 0.006416550414128737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.140269993513357e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028752999380230904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855961223443349,
      "backward_entropy": 0.004764765162359585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.725081126366604e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753001242876053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855944832166036,
      "backward_entropy": 0.00476475330916318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1396698574326365e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753003105521202,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855927447477977,
      "backward_entropy": 0.004764744503931565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0977930382268823e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875300496816635,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855912049611409,
      "backward_entropy": 0.004764735360037197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.22171374023128e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0287530068308115,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785589615503947,
      "backward_entropy": 0.004764715040271933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.750031041249713e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875300869345665,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855881253878276,
      "backward_entropy": 0.004764704541726546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5256547075969138e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0287530105561018,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855867346127827,
      "backward_entropy": 0.004764695736494931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.75786753434204e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753012418746948,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855852941672008,
      "backward_entropy": 0.004764689640565352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.12670493940459e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753014281392097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855839530626933,
      "backward_entropy": 0.0047646811739964915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8795970052897246e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028753016144037247,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07855825622876485,
      "backward_entropy": 0.0063417567448182536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.604106974501974e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028753018006682396,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07855813205242157,
      "backward_entropy": 0.006416612728075547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4552178956582793e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753018006682396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855799794197083,
      "backward_entropy": 0.004764647646383805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7129341500776718e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028753018006682396,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07855787376562755,
      "backward_entropy": 0.006416624919934707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1651032966474304e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753018006682396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855774958928426,
      "backward_entropy": 0.004764635454524647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.884589551082172e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753018006682396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855764031410217,
      "backward_entropy": 0.004764616150747646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6728135321386617e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028753018006682396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855752110481262,
      "backward_entropy": 0.004764610732143576,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 9.739746468895305e-07,
    "avg_log_Z": 0.028752893917262556,
    "success_rate": 1.0,
    "avg_reward": 49.9,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.16,
      "1": 0.21,
      "2": 0.63
    },
    "avg_forward_entropy": 0.07857513616482417,
    "avg_backward_entropy": 0.005360933752222495,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}