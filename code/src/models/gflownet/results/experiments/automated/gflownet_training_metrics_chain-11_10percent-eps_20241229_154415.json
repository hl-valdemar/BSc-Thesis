{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06288840553977272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06288840553977272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06288840553977272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06288840553977272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06288840553977272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06289680437608199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.179902076721191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913434624671936,
      "backward_entropy": 0.06283928047526967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.177228927612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09134918451309204,
      "backward_entropy": 0.06283412196419456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.079148292541504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019999928190372884,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135480721791585,
      "backward_entropy": 0.06288897449320013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2673115730285645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00029996983357705176,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136033058166504,
      "backward_entropy": 0.06288497014479204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.701395511627197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00039998680585995317,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136562546094258,
      "backward_entropy": 0.06281809915195812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.932234764099121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004998705117031932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913708508014679,
      "backward_entropy": 0.06286840005354448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.259398460388184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005997360567562282,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137583772341411,
      "backward_entropy": 0.0628070289438421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4920878410339355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006996917654760182,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138056635856628,
      "backward_entropy": 0.0628013014793396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.489958763122559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007997772190719843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138503670692444,
      "backward_entropy": 0.06279540061950684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.392572402954102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008999576093629003,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913893183072408,
      "backward_entropy": 0.06285083293914795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.153982162475586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010001694317907095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139342109362285,
      "backward_entropy": 0.06284606998616998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.151553153991699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011003296822309494,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139744440714519,
      "backward_entropy": 0.0627767877145247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.386406898498535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012004469754174352,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140142798423767,
      "backward_entropy": 0.06277035583149303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.813819408416748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013006057124584913,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914052426815033,
      "backward_entropy": 0.06284006075425581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.477572917938232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014005911070853472,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140913685162862,
      "backward_entropy": 0.06282621622085571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.808239459991455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015006853500381112,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141285220781963,
      "backward_entropy": 0.06282999840649692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1876091957092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016006105579435825,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141663710276286,
      "backward_entropy": 0.06274339285763827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.707313060760498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017005172558128834,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142036239306132,
      "backward_entropy": 0.06273638118397105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.51808500289917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018002325668931007,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914241373538971,
      "backward_entropy": 0.06281444159421054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7071614265441895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019000967731699347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142771363258362,
      "backward_entropy": 0.06280105764215643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.843430042266846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020001810044050217,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143103162447612,
      "backward_entropy": 0.0628036694093184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.119986534118652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021000762935727835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143439928690593,
      "backward_entropy": 0.06279815327037465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.278989791870117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002199525013566017,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914379358291626,
      "backward_entropy": 0.06278491562063043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.594962120056152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002299488987773657,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144081672032674,
      "backward_entropy": 0.06278689341111617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.698817729949951,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023991777561604977,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144373734792073,
      "backward_entropy": 0.06278111717917702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.601263999938965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002499119844287634,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144644935925801,
      "backward_entropy": 0.06276776573874733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.020461559295654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002599228173494339,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144909183184306,
      "backward_entropy": 0.06276912038976495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.548119068145752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026992338243871927,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914517343044281,
      "backward_entropy": 0.06265873258764093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.40034818649292,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027994057163596153,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914542277654012,
      "backward_entropy": 0.06265005740252408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.594295024871826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002899676328524947,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145661195119222,
      "backward_entropy": 0.06274277513677423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.123509407043457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003000065917149186,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145887692769368,
      "backward_entropy": 0.06263217600909146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.17251205444336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031008163932710886,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146083394686381,
      "backward_entropy": 0.06273664669557051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4423747062683105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003201869083568454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146253267923991,
      "backward_entropy": 0.06272191892970692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.830582141876221,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003302882192656398,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146421154340108,
      "backward_entropy": 0.06260460073297675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.342426776885986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003404004732146859,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914657711982727,
      "backward_entropy": 0.06259502064098012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.648152351379395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035050148144364357,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146738052368164,
      "backward_entropy": 0.06258526715365323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11445426940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036065622698515654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146842360496521,
      "backward_entropy": 0.06269137425856157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.336916446685791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003708308096975088,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146929780642192,
      "backward_entropy": 0.06269264221191406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.527279853820801,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038098455406725407,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147027134895325,
      "backward_entropy": 0.06268478523601186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.57730770111084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0039113108068704605,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147124489148457,
      "backward_entropy": 0.06267677653919566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715365409851074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004012698773294687,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147223830223083,
      "backward_entropy": 0.06266863779588179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.669814586639404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004114140290766954,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147315224011739,
      "backward_entropy": 0.0626603364944458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7638702392578125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004215557593852282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147404630978902,
      "backward_entropy": 0.06264012510126288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198287010192871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004317007958889008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147489070892334,
      "backward_entropy": 0.06263098391619595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7600626945495605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0044187079183757305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147552649180095,
      "backward_entropy": 0.06263451142744585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.493437767028809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004520398564636707,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914761225382487,
      "backward_entropy": 0.06262555447491733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.447630882263184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004622402135282755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147649010022481,
      "backward_entropy": 0.06260243329134854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.626824378967285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004723655991256237,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147728482882182,
      "backward_entropy": 0.0625928369435397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.752377033233643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004825396928936243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147774179776509,
      "backward_entropy": 0.06258293715390292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7504072189331055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0049271052703261375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147817889849345,
      "backward_entropy": 0.06257284771312367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.239899635314941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005028781481087208,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147859613100688,
      "backward_entropy": 0.0625786239450628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76931095123291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005130648147314787,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147887428601582,
      "backward_entropy": 0.06256872415542603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052301406860352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005232968833297491,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147882461547852,
      "backward_entropy": 0.06239785389466719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.401462078094482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005335862748324871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147838751475017,
      "backward_entropy": 0.0625295639038086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.008706092834473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005438387859612703,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147811929384868,
      "backward_entropy": 0.06253793022849342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.230274200439453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00554138608276844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147754311561584,
      "backward_entropy": 0.0625273043459112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.265608787536621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005644391756504774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147693713506062,
      "backward_entropy": 0.062493373047221794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.503148078918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005747465882450342,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147621194521587,
      "backward_entropy": 0.06232684850692749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.506595611572266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005849720910191536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147584438323975,
      "backward_entropy": 0.06249427795410156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.142496109008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005952236242592335,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914752980073293,
      "backward_entropy": 0.0622965856031938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.428498268127441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006054271012544632,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147496024767558,
      "backward_entropy": 0.0624419396573847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.13771915435791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0061570461839437485,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147419532140096,
      "backward_entropy": 0.062265081839127975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.062253952026367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006259297952055931,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147362907727559,
      "backward_entropy": 0.062414602799849075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6594367027282715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006361554376780987,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147298336029053,
      "backward_entropy": 0.06243395805358887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.996399879455566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006463638041168451,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147235751152039,
      "backward_entropy": 0.06242099675265225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.208782196044922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006565742660313845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147163232167561,
      "backward_entropy": 0.0623717416416515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.372269630432129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006667912472039461,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147085746129353,
      "backward_entropy": 0.06235680796883323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.647137641906738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006769719533622265,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147028128306071,
      "backward_entropy": 0.062380563129078255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002799987792969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006871385499835014,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146970510482788,
      "backward_entropy": 0.06236655061895197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.209041118621826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006973640061914921,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146868189175923,
      "backward_entropy": 0.06231051141565496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.903685569763184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007075449917465448,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914678970972697,
      "backward_entropy": 0.06233765862204812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56069278717041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007177763618528843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146678447723389,
      "backward_entropy": 0.0622781135819175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870552062988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007280339486896992,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146543343861897,
      "backward_entropy": 0.06206843527880582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.949004650115967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007383259478956461,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146387378374736,
      "backward_entropy": 0.062048359350724655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.137147903442383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007485514972358942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146265188852946,
      "backward_entropy": 0.062226598913019356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.035841941833496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007588324137032032,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146104256312053,
      "backward_entropy": 0.062208706682378594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.255801200866699,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007692032027989626,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145895640055339,
      "backward_entropy": 0.06224432316693393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0953168869018555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007795088458806276,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145726760228474,
      "backward_entropy": 0.061964230103926224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.197163581848145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007897499017417431,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145594636599223,
      "backward_entropy": 0.06194215471094305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9243550300598145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00799994170665741,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145451585451762,
      "backward_entropy": 0.062136509201743385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.755949974060059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00810222513973713,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145317475001018,
      "backward_entropy": 0.06217683445323597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.00784969329834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008204787969589233,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145168463389079,
      "backward_entropy": 0.06209862232208252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.272536277770996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008307229727506638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145024418830872,
      "backward_entropy": 0.0621414834802801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.268738746643066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008409741334617138,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144862492879231,
      "backward_entropy": 0.06182297793301669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.897643566131592,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008512310683727264,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914468268553416,
      "backward_entropy": 0.06210463697260076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.165383338928223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008614128455519676,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144558509190877,
      "backward_entropy": 0.06208576939322732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.505369186401367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008716501295566559,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144399563471477,
      "backward_entropy": 0.061746066266840156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.253113746643066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008819055743515491,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144216775894165,
      "backward_entropy": 0.06197606433521618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.640813827514648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00892164371907711,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144020080566406,
      "backward_entropy": 0.061954292384060944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.140915870666504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009024384431540966,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143823385238647,
      "backward_entropy": 0.06200641935521906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.985090255737305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009127008728682995,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143635630607605,
      "backward_entropy": 0.061985590241172096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.491750717163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009230013005435467,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914342204729716,
      "backward_entropy": 0.06160839037461714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.882167339324951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009333651512861252,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143153826395671,
      "backward_entropy": 0.06157940084284002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.543437480926514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009436935186386108,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142911434173584,
      "backward_entropy": 0.06183771111748435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.209556579589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009539712220430374,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914270281791687,
      "backward_entropy": 0.06151959570971402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.365680694580078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009642403572797775,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142499168713887,
      "backward_entropy": 0.06186918236992576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.277022361755371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009745076298713684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914229949315389,
      "backward_entropy": 0.061762365427884186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.530869483947754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009848218411207199,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142068028450012,
      "backward_entropy": 0.06181897900321267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13401985168457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009951402433216572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141823649406433,
      "backward_entropy": 0.06170906803824685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.188138961791992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01005448866635561,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141554435094197,
      "backward_entropy": 0.06168186664581299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183647155761719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010157428681850433,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141294161478679,
      "backward_entropy": 0.061739645221016624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930749893188477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010260232724249363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141037861506145,
      "backward_entropy": 0.06162594123320146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.274113655090332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010363339446485043,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140751759211223,
      "backward_entropy": 0.061596978794444694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.846396446228027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010466398671269417,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140451749165852,
      "backward_entropy": 0.06120818853378296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919318675994873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010569716803729534,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09140116969744365,
      "backward_entropy": 0.061169987375086006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.503188133239746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01067271176725626,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091398020585378,
      "backward_entropy": 0.06159618225964633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.147666931152344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010775777511298656,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139464298884074,
      "backward_entropy": 0.0615666237744418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.896371841430664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0108792120590806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913909375667572,
      "backward_entropy": 0.06144443425265225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.729743003845215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010982844978570938,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138699372609456,
      "backward_entropy": 0.061505929990248245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.905238628387451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011085977777838707,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138349692026775,
      "backward_entropy": 0.06147491931915283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.621420860290527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01118883304297924,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138001998265584,
      "backward_entropy": 0.06144330176440152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.471345901489258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011292356997728348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913759171962738,
      "backward_entropy": 0.06131097403439609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.109407424926758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01139525044709444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137235085169475,
      "backward_entropy": 0.06137837063182484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.354982376098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011498495936393738,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136845668156941,
      "backward_entropy": 0.06079012697393244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.061427593231201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01160222478210926,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136402606964111,
      "backward_entropy": 0.060743662444027985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85236930847168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011705146171152592,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136004249254863,
      "backward_entropy": 0.060696639797904274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.697164058685303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011808325536549091,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913556416829427,
      "backward_entropy": 0.06124136664650657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.324057579040527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011911059729754925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913515289624532,
      "backward_entropy": 0.06107953461733731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.067523956298828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012014307081699371,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134686986605327,
      "backward_entropy": 0.061169039119373665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.674590587615967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012117831036448479,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134197235107422,
      "backward_entropy": 0.06099633737043901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.080561637878418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012220802716910839,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133764108022054,
      "backward_entropy": 0.0610943924296986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.641512870788574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012323569506406784,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913332998752594,
      "backward_entropy": 0.0603951865976507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7421064376831055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012426454573869705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132873018582661,
      "backward_entropy": 0.06086569482629949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.705897331237793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012528947554528713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132434924443562,
      "backward_entropy": 0.0608207800171592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.243252277374268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012631585821509361,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131984909375508,
      "backward_entropy": 0.0609335790980946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.639715194702148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01273359451442957,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131570657094319,
      "backward_entropy": 0.06017444350502708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.522256851196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012835181318223476,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131205081939697,
      "backward_entropy": 0.06011647527868098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.725165367126465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012936879880726337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130845467249553,
      "backward_entropy": 0.06080119176344438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.312952041625977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013039390556514263,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130406379699707,
      "backward_entropy": 0.06075457009402188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.980262756347656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013142380863428116,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129920601844788,
      "backward_entropy": 0.06070724400607022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.13446044921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013245655223727226,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09129384160041809,
      "backward_entropy": 0.05987201495604082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.560591697692871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013349197804927826,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128833810488383,
      "backward_entropy": 0.060425503687425094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.953986167907715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013452710583806038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128264586130778,
      "backward_entropy": 0.060370716181668366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.304462432861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013556383550167084,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127677480379741,
      "backward_entropy": 0.05967587774450129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295693397521973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013659827411174774,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127108256022136,
      "backward_entropy": 0.05960785258900036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52346420288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013763060793280602,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912655492623647,
      "backward_entropy": 0.05953846736387773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.641104698181152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01386626809835434,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125980734825134,
      "backward_entropy": 0.05946791172027588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429353713989258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01396891102194786,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125462174415588,
      "backward_entropy": 0.060080295259302315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.098718643188477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014071475714445114,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09124960501988728,
      "backward_entropy": 0.05932244929400357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.328078269958496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01417382713407278,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091244637966156,
      "backward_entropy": 0.06016114625063809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.634672164916992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014276104979217052,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123963117599487,
      "backward_entropy": 0.06009965593164617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.542135238647461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014378492720425129,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123437603314717,
      "backward_entropy": 0.06003685431046919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.06492805480957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014480957761406898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09122871359189351,
      "backward_entropy": 0.059972622177817604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.365474700927734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014583148062229156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122345844904582,
      "backward_entropy": 0.059695644812150436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4117817878723145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014685309492051601,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912175178527832,
      "backward_entropy": 0.05884518406607888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7212324142456055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01478689443320036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121206402778625,
      "backward_entropy": 0.05955823985013095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.877880096435547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014888095669448376,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120730559031169,
      "backward_entropy": 0.059704688462344085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.834423542022705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014989701099693775,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120150407155354,
      "backward_entropy": 0.05963442542336204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.921745300292969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015090460889041424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09119659662246704,
      "backward_entropy": 0.059344237500971016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.299626350402832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015191072598099709,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119172890981038,
      "backward_entropy": 0.05949070236899636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.276884078979492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015291782096028328,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09118643403053284,
      "backward_entropy": 0.059416705911809746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.352548599243164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015391971915960312,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09118179480234782,
      "backward_entropy": 0.059341658245433464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.87044095993042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01549234613776207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09117656946182251,
      "backward_entropy": 0.059042919765819206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.396755695343018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015592627227306366,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09117104609807332,
      "backward_entropy": 0.058027039874683724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.921239376068115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01569252461194992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116582075754802,
      "backward_entropy": 0.05888482657345859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.917963027954102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015792420133948326,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09116014838218689,
      "backward_entropy": 0.05902304974469272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.436406135559082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01589226722717285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115445613861084,
      "backward_entropy": 0.05872162905606357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.904726505279541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015991808846592903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114891290664673,
      "backward_entropy": 0.058638204227794304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.571438789367676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01609128527343273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09114377697308858,
      "backward_entropy": 0.05876715616746382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5724897384643555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01619115099310875,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113776683807373,
      "backward_entropy": 0.05741120468486439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.336414337158203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01629072241485119,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113250176111858,
      "backward_entropy": 0.05858668955889615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.606991291046143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01639045774936676,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09112748503684998,
      "backward_entropy": 0.05719029361551458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.294848442077637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016489988192915916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112242857615153,
      "backward_entropy": 0.05819581313566728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.653022766113281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016589708626270294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111704428990682,
      "backward_entropy": 0.05830430442636663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.329061508178711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01668926328420639,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911114513874054,
      "backward_entropy": 0.05800759792327881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.785064220428467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016789637506008148,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09110440810521443,
      "backward_entropy": 0.05672440745613792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.058855056762695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01688983291387558,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109741449356079,
      "backward_entropy": 0.05800365859811956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.203099250793457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016990074887871742,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108968575795491,
      "backward_entropy": 0.05789910663257946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.597217559814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01709042116999626,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09108139077822368,
      "backward_entropy": 0.05634860558943315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.652803897857666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01719101518392563,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09107309579849243,
      "backward_entropy": 0.057683988050981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.637146472930908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017291316762566566,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09106515844662984,
      "backward_entropy": 0.056086182594299316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.574131488800049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017391346395015717,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09105752905209859,
      "backward_entropy": 0.05595148693431507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.84183931350708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01749047264456749,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09105163812637329,
      "backward_entropy": 0.055814575065266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.428572654724121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017588995397090912,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09104641278584798,
      "backward_entropy": 0.05723473700610074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.712698936462402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01768733188509941,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09104114770889282,
      "backward_entropy": 0.05694565989754417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.334317207336426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01778567023575306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103551506996155,
      "backward_entropy": 0.05699923905459317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.037955284118652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01788320206105709,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103075663248698,
      "backward_entropy": 0.05687869678844105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7987236976623535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017981598153710365,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09102442860603333,
      "backward_entropy": 0.05675538019700484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.251067638397217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01808006502687931,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09101739525794983,
      "backward_entropy": 0.054949467832391914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.691794395446777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01817827858030796,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09101015329360962,
      "backward_entropy": 0.05479766563935713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.858802318572998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018276508897542953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910024642944336,
      "backward_entropy": 0.05622189695184881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.193863868713379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018374789506196976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09099509318669637,
      "backward_entropy": 0.05609295584938743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.711871147155762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01847280003130436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098748366038005,
      "backward_entropy": 0.055962475863370026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.63990592956543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0185714028775692,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09097921848297119,
      "backward_entropy": 0.05582844127308239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869658470153809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01866990700364113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09097119172414143,
      "backward_entropy": 0.05569213628768921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.666097164154053,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01876908354461193,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0909618337949117,
      "backward_entropy": 0.05568329854445024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.138381958007812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018868129700422287,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09095257520675659,
      "backward_entropy": 0.055538849397139115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.210686683654785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01896738074719906,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09094237287839253,
      "backward_entropy": 0.05539097027345137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.444378852844238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0190668273717165,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0909316639105479,
      "backward_entropy": 0.055240224708210335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.448148250579834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01916653662919998,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09092104434967041,
      "backward_entropy": 0.05313224684108387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.43016529083252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019265905022621155,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090911070505778,
      "backward_entropy": 0.05493321202018044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.726946830749512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019365593791007996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09090018272399902,
      "backward_entropy": 0.05466089465401389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53882122039795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019464531913399696,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09089030822118123,
      "backward_entropy": 0.05461652712388472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.973083972930908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019563883543014526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09087962905565898,
      "backward_entropy": 0.05445444583892822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.662455081939697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01966267079114914,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09086955587069194,
      "backward_entropy": 0.052196621894836426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.245152473449707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01976075768470764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09086044629414876,
      "backward_entropy": 0.054124078967354515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.413400650024414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01985853910446167,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09085212151209514,
      "backward_entropy": 0.05395613475279375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.847726821899414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019956184551119804,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09084369738896687,
      "backward_entropy": 0.05378559502688321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.414577007293701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020054558292031288,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09083403150240581,
      "backward_entropy": 0.05140000039880926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.200434684753418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020152142271399498,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09082515041033427,
      "backward_entropy": 0.05119368163022128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.65891695022583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02024884894490242,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09081784884134929,
      "backward_entropy": 0.05098502202467485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.158738136291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020345699042081833,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09080968300501506,
      "backward_entropy": 0.05077374523336237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0401434898376465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020442333072423935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09080194433530171,
      "backward_entropy": 0.05283077196641402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.42195463180542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020538730546832085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09079416592915852,
      "backward_entropy": 0.05265229940414429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.95819616317749,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020634567365050316,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09078649679819743,
      "backward_entropy": 0.05012449893084439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.834783554077148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020730245858430862,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09077813227971394,
      "backward_entropy": 0.04990439523350109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.30462646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020825637504458427,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09077033400535583,
      "backward_entropy": 0.04968154430389404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.967391014099121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02092106267809868,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09076247612635295,
      "backward_entropy": 0.05192188241265037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.50659704208374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021016348153352737,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09075427055358887,
      "backward_entropy": 0.05173297361894087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.601491928100586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02111123502254486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09074608484903972,
      "backward_entropy": 0.05154184319756248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.881335258483887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02120574750006199,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073917071024577,
      "backward_entropy": 0.05134929310191761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.869202613830566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021300163120031357,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09073188900947571,
      "backward_entropy": 0.0511329553344033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.35275936126709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021393856033682823,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09072539210319519,
      "backward_entropy": 0.05092488093809648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.885322093963623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021486474201083183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09072190523147583,
      "backward_entropy": 0.05071689323945479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.724233150482178,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021579166874289513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09071811040242513,
      "backward_entropy": 0.050506179982965645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.035426139831543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02167120762169361,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0907150109608968,
      "backward_entropy": 0.05036319927735762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.153763294219971,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021763574331998825,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907097856203715,
      "backward_entropy": 0.047324402765794235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.09664249420166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02185559831559658,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09070480863253276,
      "backward_entropy": 0.04985621842471036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4587602615356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021947914734482765,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0906989077727,
      "backward_entropy": 0.046826297586614433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.481781482696533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02204006351530552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09069331487019856,
      "backward_entropy": 0.0495253476229581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.69326114654541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022132787853479385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09068561593691508,
      "backward_entropy": 0.04930613257668235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.174272537231445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022226115688681602,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09067656596501668,
      "backward_entropy": 0.04894628849896518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.92712926864624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022319654002785683,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09066683053970337,
      "backward_entropy": 0.0488521781834689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.160166263580322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0224132277071476,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.090656578540802,
      "backward_entropy": 0.04553089358589866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.412148475646973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022506993263959885,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09064545234044392,
      "backward_entropy": 0.04526353424245661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.132289409637451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022600393742322922,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09063520034154256,
      "backward_entropy": 0.04499323801560835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.341087818145752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022693336009979248,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09062519669532776,
      "backward_entropy": 0.047902215610850944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.158164024353027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022785954177379608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09061596790949504,
      "backward_entropy": 0.047658362171866676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.497354507446289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022878851741552353,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09060583511988322,
      "backward_entropy": 0.047246049750934944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.287716388702393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022971585392951965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09059526522954305,
      "backward_entropy": 0.04699235612695867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.945286273956299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02306399494409561,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090585192044576,
      "backward_entropy": 0.046736733479933304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.949934959411621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023156605660915375,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09057377775510152,
      "backward_entropy": 0.04647743160074407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.398926258087158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02324867434799671,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09056339661280315,
      "backward_entropy": 0.04302107475020669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.325602054595947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0233406163752079,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09055224061012268,
      "backward_entropy": 0.04613267291675915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3841328620910645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023432444781064987,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09053975343704224,
      "backward_entropy": 0.04587058045647361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.818822383880615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023524820804595947,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.090525617202123,
      "backward_entropy": 0.04214139147238298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.723370552062988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023616651073098183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09051169951756795,
      "backward_entropy": 0.045330166816711426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.481063365936279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023707913234829903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09049826860427856,
      "backward_entropy": 0.04505846446210688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.238818645477295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02379915863275528,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09048455953598022,
      "backward_entropy": 0.04458909684961492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.626428127288818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023890230804681778,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09047073125839233,
      "backward_entropy": 0.04431003873998469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.064737796783447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023979978635907173,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09046024084091187,
      "backward_entropy": 0.04422963749278675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.054492473602295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02406962402164936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09044893582661946,
      "backward_entropy": 0.043751150369644165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.263167858123779,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024159124121069908,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09043760101000468,
      "backward_entropy": 0.04346851327202537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.214637279510498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024247922003269196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0904277761777242,
      "backward_entropy": 0.04338843443176963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.342094421386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024336785078048706,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09041722615559895,
      "backward_entropy": 0.039401097731156784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.514182090759277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02442510612308979,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09040717283884685,
      "backward_entropy": 0.042817300016229805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.417218208312988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024513117969036102,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09039632479349773,
      "backward_entropy": 0.0423135215585882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.182637691497803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024600770324468613,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09038508931795756,
      "backward_entropy": 0.042242367159236564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.226456165313721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024687940254807472,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09037371476491292,
      "backward_entropy": 0.041720699180256234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.610415935516357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024775372818112373,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09036115805308025,
      "backward_entropy": 0.04166129502383145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.88885498046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02486261911690235,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09034816424051921,
      "backward_entropy": 0.037515523758801544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5172119140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024949876591563225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09033462405204773,
      "backward_entropy": 0.041069713505831634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.180740833282471,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025036901235580444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09032070636749268,
      "backward_entropy": 0.04051083326339722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.524661540985107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02512345090508461,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09030729532241821,
      "backward_entropy": 0.04020511291243813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.534224033355713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025209877640008926,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09029285113016765,
      "backward_entropy": 0.03989701921289617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.193371772766113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025295430794358253,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09027971824010213,
      "backward_entropy": 0.039588781920346344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.912622451782227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025380713865160942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09026604890823364,
      "backward_entropy": 0.039567985317923805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5845489501953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02546553499996662,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09025246898333232,
      "backward_entropy": 0.03926648876883767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.182613849639893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025549672544002533,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09023984273274739,
      "backward_entropy": 0.03865676034580578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.266355037689209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025633659213781357,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09022667010625203,
      "backward_entropy": 0.03463121977719394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.351691246032715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02571755275130272,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0902130405108134,
      "backward_entropy": 0.03803118521516973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.119760990142822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025800645351409912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09020103017489116,
      "backward_entropy": 0.03805335272442211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1780242919921875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025883613154292107,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09018860260645549,
      "backward_entropy": 0.03740610859610818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.079224109649658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025965772569179535,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09017741680145264,
      "backward_entropy": 0.037093520164489746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.288590431213379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026047956198453903,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0901643435160319,
      "backward_entropy": 0.03677852587266402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7917160987854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02613028511404991,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09014966090520223,
      "backward_entropy": 0.03682564063505693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.312804698944092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026212336495518684,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09013476967811584,
      "backward_entropy": 0.03237152099609375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.06993293762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02629455178976059,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09011854728062947,
      "backward_entropy": 0.03204715522852811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.249837398529053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026375848799943924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09010503689448039,
      "backward_entropy": 0.035887869921597565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.286480903625488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026456540450453758,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09009214242299397,
      "backward_entropy": 0.0355764085596258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.718255996704102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026537571102380753,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09007664521535237,
      "backward_entropy": 0.03107584606517445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.149005889892578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02661846950650215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09005960822105408,
      "backward_entropy": 0.03494550694118847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.656569480895996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026698734611272812,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09004310766855876,
      "backward_entropy": 0.030432310971346768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.808665752410889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026778915897011757,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09002482891082764,
      "backward_entropy": 0.03431570529937744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.259015083312988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026859087869524956,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09000529845555623,
      "backward_entropy": 0.033592516725713555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.243889331817627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02693968266248703,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08998287717501323,
      "backward_entropy": 0.029473293911327015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7755422592163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027019795030355453,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08996010820070903,
      "backward_entropy": 0.02915553884072737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.09770393371582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027098989114165306,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08993937571843465,
      "backward_entropy": 0.028838937932794743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.841566324234009,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027177704498171806,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08991847435633342,
      "backward_entropy": 0.03229993310841647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.124260902404785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02725568786263466,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08989912271499634,
      "backward_entropy": 0.031981181014667855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.383114337921143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733415924012661,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08987740675608318,
      "backward_entropy": 0.027894469824704258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4538018703460693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02741251140832901,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08985398213068645,
      "backward_entropy": 0.027579107067801735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.075578689575195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02748987264931202,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08983221650123596,
      "backward_entropy": 0.027264576066624035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8250157833099365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027566879987716675,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08981035153071086,
      "backward_entropy": 0.030706446279178966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9278626441955566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027643412351608276,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08978798985481262,
      "backward_entropy": 0.03039004315029491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2232513427734375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771960385143757,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0897648533185323,
      "backward_entropy": 0.03050349246371876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8984365463256836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027795687317848206,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08974102139472961,
      "backward_entropy": 0.029759133403951473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5409352779388428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02787141129374504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08971681197484334,
      "backward_entropy": 0.02986791188066656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7171571254730225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02794649824500084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08969293038050334,
      "backward_entropy": 0.02955258705399253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1400692462921143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028021130710840225,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0896692971388499,
      "backward_entropy": 0.028823782097209583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2445411682128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02809487283229828,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0896466573079427,
      "backward_entropy": 0.024787130680951206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7411656379699707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028167828917503357,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08962556719779968,
      "backward_entropy": 0.028211674906990745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9371581077575684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028240583837032318,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08960370222727458,
      "backward_entropy": 0.027908634055744518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2010369300842285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028313392773270607,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08957977096239726,
      "backward_entropy": 0.027605522762645374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6550228595733643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02838551625609398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08955637613932292,
      "backward_entropy": 0.027695330706509678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0680429935455322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028456471860408783,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08953535556793213,
      "backward_entropy": 0.023296537724408237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.100139141082764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028526777401566505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08951507012049358,
      "backward_entropy": 0.02670862999829379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6662466526031494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028597531840205193,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08949173490206401,
      "backward_entropy": 0.022715503519231624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1896474361419678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028667164966464043,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08947127064069112,
      "backward_entropy": 0.022427607666362415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.177600622177124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02873646840453148,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08944987257321675,
      "backward_entropy": 0.02582115747711875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.452986717224121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028805401176214218,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08942902088165283,
      "backward_entropy": 0.025904053991491146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.531327486038208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028874391689896584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08940521876017253,
      "backward_entropy": 0.02560857751152732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.217832088470459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028943516314029694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08937837680180867,
      "backward_entropy": 0.02494210817597129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.002817392349243,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029012367129325867,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08935040235519409,
      "backward_entropy": 0.024650002067739315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6322474479675293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02908073365688324,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08932208021481831,
      "backward_entropy": 0.02075102925300598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.870542287826538,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029148241505026817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08929490049680074,
      "backward_entropy": 0.0240742103620009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.69397234916687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029215240851044655,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08926757176717122,
      "backward_entropy": 0.023790866136550903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.366516590118408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029281597584486008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08924049139022827,
      "backward_entropy": 0.023864326151934536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3794188499450684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029347004368901253,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08921484152475993,
      "backward_entropy": 0.019687305797230114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.362945795059204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02941160649061203,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08918984731038411,
      "backward_entropy": 0.023310265757820824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1943256855010986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029475484043359756,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08916513125101726,
      "backward_entropy": 0.022688780318606983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4584524631500244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029539629817008972,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08913724621136983,
      "backward_entropy": 0.022417984225533226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8218369483947754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029603147879242897,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08910952011744182,
      "backward_entropy": 0.022496124560182743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8448376655578613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029666544869542122,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08907998601595561,
      "backward_entropy": 0.01842811568216844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6264712810516357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02972864732146263,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08905324339866638,
      "backward_entropy": 0.018185408277945084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3289270401000977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02978936955332756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08902947107950847,
      "backward_entropy": 0.021705191243778576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8055860996246338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029849691316485405,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08900482455889384,
      "backward_entropy": 0.021450072526931763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.142045021057129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02990901842713356,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08898163835207622,
      "backward_entropy": 0.01748430864377455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.125016212463379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029967764392495155,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0889586607615153,
      "backward_entropy": 0.0206139399246736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6199676990509033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030025986954569817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08893553415934245,
      "backward_entropy": 0.020706642757762562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5017430782318115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030083101242780685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08891452352205913,
      "backward_entropy": 0.02013003419746052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7872085571289062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03014032542705536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08889088034629822,
      "backward_entropy": 0.02022127400745045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.665855884552002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030196746811270714,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08886802196502686,
      "backward_entropy": 0.016373997384851628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5467149019241333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03025231324136257,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08884606758753459,
      "backward_entropy": 0.01942555064504797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9063314199447632,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030306972563266754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08882518609364827,
      "backward_entropy": 0.01951600746674971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.691060781478882,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0303612370043993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08880324165026347,
      "backward_entropy": 0.019287152723832565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9900294542312622,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030416149646043777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08877638975779216,
      "backward_entropy": 0.019053991545330395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.648519515991211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03047069162130356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08874857425689697,
      "backward_entropy": 0.018822227012027393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5539811849594116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030524447560310364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08872132500012715,
      "backward_entropy": 0.018594376065514305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.008988380432129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030577411875128746,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08869458238283794,
      "backward_entropy": 0.01809016141024503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2748568058013916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03063039854168892,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08866496880849202,
      "backward_entropy": 0.01787516881119121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6018530130386353,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030683664605021477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08863176902135213,
      "backward_entropy": 0.017661119049245663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7528750896453857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030736178159713745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08859890699386597,
      "backward_entropy": 0.017700989137996326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5669916868209839,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030788352712988853,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08856462438901265,
      "backward_entropy": 0.01748179712078788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8038376569747925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03083987534046173,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08853021264076233,
      "backward_entropy": 0.017266056754372337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5311133861541748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030891146510839462,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08849406242370605,
      "backward_entropy": 0.016834348440170288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5493512153625488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03094184771180153,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08845744530359904,
      "backward_entropy": 0.016840268265117298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4774858951568604,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03099200315773487,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08842022220293681,
      "backward_entropy": 0.01343132961880077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3081616163253784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031041640788316727,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08838236331939697,
      "backward_entropy": 0.016426511786200783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5807321071624756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031090466305613518,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08834501107533772,
      "backward_entropy": 0.016225439581004055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6858464479446411,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031138915568590164,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08830629785855611,
      "backward_entropy": 0.012915860522877087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2959169149398804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031187444925308228,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08826470375061035,
      "backward_entropy": 0.015826786106283016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2438697814941406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031235232949256897,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08822325865427653,
      "backward_entropy": 0.015631446784192867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3410955667495728,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03128238022327423,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08818185329437256,
      "backward_entropy": 0.012423290447755293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.104274034500122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031329043209552765,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08813963333765666,
      "backward_entropy": 0.012265254150737415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.367026448249817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03137461096048355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08809862534205119,
      "backward_entropy": 0.015066679228435863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5855374336242676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03141992166638374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08805596828460693,
      "backward_entropy": 0.014884000474756414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9337137937545776,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031465429812669754,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08800987402598064,
      "backward_entropy": 0.011806763031265953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9895745515823364,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03150993958115578,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0879654586315155,
      "backward_entropy": 0.011659562587738037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9274078011512756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0315534844994545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08792207638422649,
      "backward_entropy": 0.014349690892479637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9516419768333435,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031595949083566666,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08787993590037028,
      "backward_entropy": 0.011376222426241095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7445611953735352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03163759782910347,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08783840139706929,
      "backward_entropy": 0.01395567845214497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2644129991531372,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167818486690521,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08779906233151753,
      "backward_entropy": 0.013857577334750782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5488128662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031718768179416656,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08775673309961955,
      "backward_entropy": 0.010975990783084522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7175930738449097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031757939606904984,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08771797021230061,
      "backward_entropy": 0.013501626524058256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0069844722747803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031796108931303024,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08768062790234883,
      "backward_entropy": 0.013357896696437489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6603650450706482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031834084540605545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08764161666234334,
      "backward_entropy": 0.013251250440424139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8871724009513855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031870972365140915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08760408560434978,
      "backward_entropy": 0.013109182769601995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8990437388420105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031907517462968826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08756553133328755,
      "backward_entropy": 0.012940577485344627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7144091725349426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0319436714053154,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08752557635307312,
      "backward_entropy": 0.010259105400605635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6958186626434326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03197915479540825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08748603860537212,
      "backward_entropy": 0.01269413801756772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5363366603851318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03201398625969887,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0874468485514323,
      "backward_entropy": 0.012561455368995667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.046587347984314,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032047778367996216,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08740940690040588,
      "backward_entropy": 0.012420142238790339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5302312970161438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03208174929022789,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08736780285835266,
      "backward_entropy": 0.012304090640761635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6527122855186462,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03211482614278793,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08732786774635315,
      "backward_entropy": 0.012174212119796059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0138667821884155,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03214721754193306,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08728776375452678,
      "backward_entropy": 0.00962998853488402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5067327618598938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03218003734946251,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08724357684453328,
      "backward_entropy": 0.00953049822287126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6711896657943726,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03221181035041809,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.087200661500295,
      "backward_entropy": 0.009434573352336884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44133421778678894,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03224311023950577,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08715691169102986,
      "backward_entropy": 0.011709159070795233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5941246747970581,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03227340057492256,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08711489041646321,
      "backward_entropy": 0.011599920012734154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5566651821136475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03230320289731026,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08707247177759807,
      "backward_entropy": 0.011492748152125965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5598010420799255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032332323491573334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08702955643335979,
      "backward_entropy": 0.011361468244682659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6637181043624878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03236093744635582,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08698615431785583,
      "backward_entropy": 0.011254913427612999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5901936888694763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03238949179649353,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08694105346997578,
      "backward_entropy": 0.011185119097883051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3891828954219818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03241772949695587,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08689509828885396,
      "backward_entropy": 0.01104385270313783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7451069355010986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03244515508413315,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08685074249903361,
      "backward_entropy": 0.010987789793448015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5715615749359131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032472770661115646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0868025819460551,
      "backward_entropy": 0.010840438983657143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.486114501953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03249991312623024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08675249417622884,
      "backward_entropy": 0.01073991439559243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6191385984420776,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03252653777599335,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08670212825139363,
      "backward_entropy": 0.010641582987525246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49706295132637024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032553210854530334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08664992451667786,
      "backward_entropy": 0.010543200102719393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6889671683311462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03257935494184494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08659684658050537,
      "backward_entropy": 0.010446887801993977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5606017708778381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032605983316898346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08654119571050008,
      "backward_entropy": 0.010348959402604536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4356926679611206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032632339745759964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08648378650347392,
      "backward_entropy": 0.010252103886821053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4517156481742859,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03265819326043129,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08642696340878804,
      "backward_entropy": 0.010249840264970606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5986157059669495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03268348425626755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0863695243994395,
      "backward_entropy": 0.010065153241157532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5435962080955505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032708790153265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08630916476249695,
      "backward_entropy": 0.009972673925486479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38539379835128784,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03273390233516693,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0862466295560201,
      "backward_entropy": 0.007938163524324244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5962286591529846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03275838494300842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08618475993474324,
      "backward_entropy": 0.009791833433237944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3938562572002411,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032783087342977524,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08611996968587239,
      "backward_entropy": 0.00982917845249176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4607731103897095,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03280709683895111,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08605486154556274,
      "backward_entropy": 0.009749594059857454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3798691928386688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032830897718667984,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08598872025807698,
      "backward_entropy": 0.009670915928753939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4333334267139435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03285419940948486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08592275778452556,
      "backward_entropy": 0.009444519877433777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29300275444984436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03287719562649727,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08585566282272339,
      "backward_entropy": 0.009361648424105211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28278449177742004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03289937973022461,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08578985929489136,
      "backward_entropy": 0.009446054697036743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33952420949935913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0329207107424736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0857248604297638,
      "backward_entropy": 0.009205847978591919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36230799555778503,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03294159099459648,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08565982182820638,
      "backward_entropy": 0.007390102202242071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35280030965805054,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03296223282814026,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08559435606002808,
      "backward_entropy": 0.007337318902665918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45718446373939514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03298262134194374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0855284035205841,
      "backward_entropy": 0.008984999223188921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36090680956840515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03300318866968155,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08545954028765361,
      "backward_entropy": 0.008911778303709898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43132972717285156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03302346542477608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08538953463236491,
      "backward_entropy": 0.008839657360857183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.395591676235199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03304363787174225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08531582355499268,
      "backward_entropy": 0.00876773622902957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20436620712280273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03306382894515991,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08524040381113689,
      "backward_entropy": 0.008695857091383501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1728384643793106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03308320790529251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0851676066716512,
      "backward_entropy": 0.00885376130992716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36425259709358215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03310146555304527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08509671688079834,
      "backward_entropy": 0.008562800559130583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25953155755996704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03311965614557266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0850231945514679,
      "backward_entropy": 0.008498485115441408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27619415521621704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03313729166984558,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08494946360588074,
      "backward_entropy": 0.008436172523281792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31338411569595337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033154502511024475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08487491806348164,
      "backward_entropy": 0.00837537104433233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19653858244419098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03317171335220337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08479935924212138,
      "backward_entropy": 0.008574639531699095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21139226853847504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033188093453645706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08472439646720886,
      "backward_entropy": 0.0082568959756331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26910802721977234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03320400044322014,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08465033769607544,
      "backward_entropy": 0.008474142713980242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2817087471485138,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03321976214647293,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08457533518473308,
      "backward_entropy": 0.008425337347117338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27593743801116943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033235546201467514,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08449926972389221,
      "backward_entropy": 0.006666797128590671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30835390090942383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03325120359659195,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08442157506942749,
      "backward_entropy": 0.00832873515107415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22425612807273865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03326687589287758,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08434101939201355,
      "backward_entropy": 0.007980051365765658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25309646129608154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03328213840723038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08426027496655782,
      "backward_entropy": 0.00792635435407812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2109544426202774,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03329731523990631,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0841788649559021,
      "backward_entropy": 0.008188859982924028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19103778898715973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033312153071165085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08409763375918071,
      "backward_entropy": 0.008144041354005987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11893712729215622,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0333264134824276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08401622374852498,
      "backward_entropy": 0.007770797745748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29234421253204346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03333970531821251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.083936740954717,
      "backward_entropy": 0.00806113671172749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16267865896224976,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03335341811180115,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08385424812634786,
      "backward_entropy": 0.008020233701575886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2610701322555542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033366430550813675,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0837717354297638,
      "backward_entropy": 0.007981569929556414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2079957127571106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03337973728775978,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08368706703186035,
      "backward_entropy": 0.007583391937342557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1734657883644104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033393003046512604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08360213041305542,
      "backward_entropy": 0.007536851546981118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08826092630624771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03340598940849304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08351780970891316,
      "backward_entropy": 0.00749139352278276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1793573945760727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03341793641448021,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08343607187271118,
      "backward_entropy": 0.006253802640871568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18727003037929535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033429741859436035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08335399627685547,
      "backward_entropy": 0.007408110255544836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13011722266674042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03344152495265007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08327118555704753,
      "backward_entropy": 0.007366832007061352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1548406034708023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033452875912189484,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08318967123826344,
      "backward_entropy": 0.007728173651478507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.197974294424057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03346392512321472,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08310770988464355,
      "backward_entropy": 0.007288357073610479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15696853399276733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03347513824701309,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08302392562230428,
      "backward_entropy": 0.007249108769676902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12556183338165283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03348618000745773,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08293997744719188,
      "backward_entropy": 0.007210407744754444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12667261064052582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033496975898742676,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08285768826802571,
      "backward_entropy": 0.0076011798598549585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15375064313411713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03350739926099777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08277578155199687,
      "backward_entropy": 0.007136231796307998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11267995834350586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03351782262325287,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08269338806470235,
      "backward_entropy": 0.007099837742068551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12773096561431885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03352769464254379,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08261114358901978,
      "backward_entropy": 0.007065215571360154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1175241619348526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03353732079267502,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0825287401676178,
      "backward_entropy": 0.007031413641842929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1301603615283966,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033546533435583115,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08244594931602478,
      "backward_entropy": 0.005980560725385492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1561276614665985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03355564549565315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0823628306388855,
      "backward_entropy": 0.006966825235973705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1709098070859909,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03356489539146423,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08227801819642384,
      "backward_entropy": 0.0059432055462490425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1198885440826416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033574409782886505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08219075202941895,
      "backward_entropy": 0.006900691850618882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10426197946071625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03358374536037445,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08210356533527374,
      "backward_entropy": 0.005904514003883709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11870764940977097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033592600375413895,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08201628923416138,
      "backward_entropy": 0.007333020594987002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12488201260566711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03360147401690483,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08192956447601318,
      "backward_entropy": 0.007308615202253515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11639861762523651,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033610399812459946,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08184259633223216,
      "backward_entropy": 0.007284107533368197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09831629693508148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03361918777227402,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08175514141718547,
      "backward_entropy": 0.007260014387694272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07031938433647156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03362765908241272,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08166806896527608,
      "backward_entropy": 0.005814853716980328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09941914677619934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033635664731264114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08158322175343831,
      "backward_entropy": 0.00668644363229925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08729902654886246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03364350274205208,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0814983497063319,
      "backward_entropy": 0.0066586746410890055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09404797106981277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033651161938905716,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08141444126764934,
      "backward_entropy": 0.005767484957521612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08149635046720505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03365866467356682,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08133034904797871,
      "backward_entropy": 0.0071519884196194735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10783188790082932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03366602212190628,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08124733964602153,
      "backward_entropy": 0.007131976837461645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09933829307556152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033673468977212906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08116304377714793,
      "backward_entropy": 0.006552305411208759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0892305076122284,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033680882304906845,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08107780416806538,
      "backward_entropy": 0.007091709158637307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051381900906562805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03368820995092392,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08099242051442464,
      "backward_entropy": 0.007071948186917739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06761547178030014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033694785088300705,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08090820908546448,
      "backward_entropy": 0.007054286924275485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04580017551779747,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033701103180646896,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08082495133082072,
      "backward_entropy": 0.007037326693534851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07337111979722977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03370705246925354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807446042696635,
      "backward_entropy": 0.00643177330493927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0775272399187088,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033712759613990784,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08066350221633911,
      "backward_entropy": 0.007006198167800903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0667848289012909,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03371848911046982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08058224121729533,
      "backward_entropy": 0.006389873948964206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07244457304477692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03372405469417572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08050118883450826,
      "backward_entropy": 0.006369401785460385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0730535164475441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033729664981365204,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08042017618815105,
      "backward_entropy": 0.005614203824238343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07886087149381638,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033735234290361404,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08033847312132518,
      "backward_entropy": 0.005603767931461334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04449373856186867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033740926533937454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08025591572125752,
      "backward_entropy": 0.006307590414177288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0846424400806427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03374608978629112,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08017427722613017,
      "backward_entropy": 0.006288436326113614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04404519498348236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03375167027115822,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08009204268455505,
      "backward_entropy": 0.00690283558585427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04861916974186897,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03375685587525368,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08001128832499187,
      "backward_entropy": 0.005563342774456198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028509940952062607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03376169502735138,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07993100086847942,
      "backward_entropy": 0.0055547349832274695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060814060270786285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03376604616641998,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07985332111517589,
      "backward_entropy": 0.006865242665464228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06549490243196487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033770568668842316,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.079775666197141,
      "backward_entropy": 0.006198098036375913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04137544333934784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033775392919778824,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07969826459884644,
      "backward_entropy": 0.006180660968477076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0452694334089756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03377995640039444,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07962205012639363,
      "backward_entropy": 0.005522493611682545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04514703527092934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03378429636359215,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0795460691054662,
      "backward_entropy": 0.006816754286939447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.047758813947439194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03378872200846672,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07947186628977458,
      "backward_entropy": 0.006131107156926935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.057952649891376495,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03379309922456741,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07939792672793071,
      "backward_entropy": 0.006792556155811657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05095992609858513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033797699958086014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07932364443937938,
      "backward_entropy": 0.006097757003524087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0336419902741909,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033802349120378494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07924912373224895,
      "backward_entropy": 0.0060808082873171024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04917866364121437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03380676731467247,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07917607327302296,
      "backward_entropy": 0.006064623594284058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03104567714035511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03381119668483734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07910232742627461,
      "backward_entropy": 0.006048379296606237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040648166090250015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033815279603004456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07902943094571431,
      "backward_entropy": 0.006033252586017956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0483715757727623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03381942957639694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07895713051160176,
      "backward_entropy": 0.006018000570210544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03982765972614288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03382376581430435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07888436317443848,
      "backward_entropy": 0.00600221956318075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035985928028821945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03382807970046997,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07881164054075877,
      "backward_entropy": 0.0059866099195046854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03488153964281082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03383231163024902,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07873953382174174,
      "backward_entropy": 0.005971259014172988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03773101419210434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03383646532893181,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07866803805033366,
      "backward_entropy": 0.00541821765628728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.043179936707019806,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03384067118167877,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0785969744126002,
      "backward_entropy": 0.005410142581571232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02670496329665184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033845074474811554,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07852555314699809,
      "backward_entropy": 0.005925105376677079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04003176465630531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03384915739297867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07845472792784373,
      "backward_entropy": 0.0059104859828948975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03399193286895752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03385331854224205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07838327685991923,
      "backward_entropy": 0.00589562478390607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034061796963214874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03385746479034424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07831209897994995,
      "backward_entropy": 0.005880695852366361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03133447468280792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0338616669178009,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07824146747589111,
      "backward_entropy": 0.005865576592358676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016799619421362877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033865850418806076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07817136247952779,
      "backward_entropy": 0.005850473588163202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020393017679452896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03386970981955528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07810360689957936,
      "backward_entropy": 0.0058367645198648625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023746617138385773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03387334197759628,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07803737123807271,
      "backward_entropy": 0.006577646867795424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024353252723813057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03387683629989624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07797200481096904,
      "backward_entropy": 0.005811299790035595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019287200644612312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03388025611639023,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07790743311246236,
      "backward_entropy": 0.006559117951176383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01742394082248211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03388345241546631,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0778439740339915,
      "backward_entropy": 0.005786905911835757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01617860049009323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033886391669511795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07778153320153554,
      "backward_entropy": 0.005775767971168865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02145545557141304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033889126032590866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0777205228805542,
      "backward_entropy": 0.0057652240449732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024919210001826286,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033891841769218445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07766012350718181,
      "backward_entropy": 0.005754860287362879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020633108913898468,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03389466926455498,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07759949564933777,
      "backward_entropy": 0.005744264207103036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02276439405977726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03389754146337509,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07753958304723103,
      "backward_entropy": 0.005733579397201538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019802918657660484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03390052542090416,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07747997840245564,
      "backward_entropy": 0.006503995846618305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01497308723628521,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03390341252088547,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07742032905419667,
      "backward_entropy": 0.006496275013143366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017988942563533783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03390611335635185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773615837097168,
      "backward_entropy": 0.0057017180052670565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01592112146317959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03390876576304436,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07730328540007274,
      "backward_entropy": 0.006482027471065521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016976483166217804,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03391134738922119,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07724578181902568,
      "backward_entropy": 0.006475175646218387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01465827040374279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03391396999359131,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07718902826309204,
      "backward_entropy": 0.005274169147014618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017500458285212517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03391653299331665,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07713304956754048,
      "backward_entropy": 0.005662769756533883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01871897652745247,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033919136971235275,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07707722981770833,
      "backward_entropy": 0.00645487823269584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014533518813550472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033921774476766586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07702101270357768,
      "backward_entropy": 0.005643574351614172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015178929083049297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03392435982823372,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07696563005447388,
      "backward_entropy": 0.005634120580824939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010373746044933796,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033926837146282196,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07691024740537007,
      "backward_entropy": 0.005250766196034171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017277028411626816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033929113298654556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07685601711273193,
      "backward_entropy": 0.005616236478090286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010174725204706192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033931467682123184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07680156330267589,
      "backward_entropy": 0.005607244643298062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014478979632258415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03393368422985077,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0767482320467631,
      "backward_entropy": 0.005239037627523596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018103765323758125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03393599018454552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07669531802336375,
      "backward_entropy": 0.005590247498317199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011772328056395054,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0339384451508522,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.076641450325648,
      "backward_entropy": 0.006402855569666082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013873548246920109,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03394082561135292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07658809423446655,
      "backward_entropy": 0.00557237220081416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01319894753396511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033943209797143936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653444012006123,
      "backward_entropy": 0.005563573065129193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010686979629099369,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03394560515880585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07648074130217235,
      "backward_entropy": 0.005554809827696194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00742120249196887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033947914838790894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0764276534318924,
      "backward_entropy": 0.005546363578601317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010295345447957516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03395010903477669,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07637657721837361,
      "backward_entropy": 0.0055382990024306555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01122167706489563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03395227715373039,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07632636030515035,
      "backward_entropy": 0.005530253052711487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007755545433610678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033954471349716187,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07627655565738678,
      "backward_entropy": 0.005202217196876352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010149730369448662,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0339566171169281,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0762282411257426,
      "backward_entropy": 0.00635389577258717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009646601043641567,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033958800137043,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0761803686618805,
      "backward_entropy": 0.006347927180203525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006529618985950947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03396102413535118,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07613302270571391,
      "backward_entropy": 0.006341919302940369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007860003039240837,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03396308794617653,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07608657081921895,
      "backward_entropy": 0.005186247216029601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008381391875445843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03396514430642128,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07604090372721355,
      "backward_entropy": 0.005483076653697274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006784044671803713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03396725282073021,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0759959618250529,
      "backward_entropy": 0.005475511266426606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0063631488010287285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03396931663155556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07595198353131612,
      "backward_entropy": 0.006320103325627067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006229933816939592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03397129476070404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07590878009796143,
      "backward_entropy": 0.005461143837733703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0070440745912492275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03397318348288536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07586637636025746,
      "backward_entropy": 0.005454344505613501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006873534992337227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03397507965564728,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07582472264766693,
      "backward_entropy": 0.006304913623766465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004966096952557564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0339769683778286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07578353583812714,
      "backward_entropy": 0.005440508438782258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00500442273914814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03397876396775246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07574336230754852,
      "backward_entropy": 0.0054339719089594755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006430657580494881,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033980511128902435,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07570414741834004,
      "backward_entropy": 0.006290127607909116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005783497355878353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0339822843670845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07566521565119426,
      "backward_entropy": 0.005421222272244367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004973741248250008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03398411348462105,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0756271481513977,
      "backward_entropy": 0.006280443207784133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00538851972669363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033985890448093414,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07558960715929668,
      "backward_entropy": 0.006275756115263159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0053298743441700935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033987659960985184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0755524883667628,
      "backward_entropy": 0.00540206174958836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004257215186953545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03398940712213516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07551553348700206,
      "backward_entropy": 0.005136028948155316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043951524421572685,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03399106487631798,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07547901074091594,
      "backward_entropy": 0.00513288751244545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00518342899158597,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03399266302585602,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07544286052385966,
      "backward_entropy": 0.006258042021231217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034421756863594055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033994294703006744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07540695865948994,
      "backward_entropy": 0.005378395996310494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004048929549753666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03399583697319031,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07537184158960979,
      "backward_entropy": 0.005372949283231388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004345807712525129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03399735316634178,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07533734540144603,
      "backward_entropy": 0.005367535759102215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003681331407278776,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03399888426065445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0753033459186554,
      "backward_entropy": 0.005362006412311034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036461069248616695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03400038927793503,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07527004679044087,
      "backward_entropy": 0.006237715482711792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023681677412241697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03400186076760292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07523724436759949,
      "backward_entropy": 0.005351235920732672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003469675313681364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03400321677327156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07520532608032227,
      "backward_entropy": 0.006229997358538888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029764221981167793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034004535526037216,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07517353693644206,
      "backward_entropy": 0.005341474644162438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003169009927660227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034005820751190186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07514231403668721,
      "backward_entropy": 0.005336801436814395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036259416956454515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03400711715221405,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07511162757873535,
      "backward_entropy": 0.0053321275521408425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002725322265177965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034008461982011795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0750811646382014,
      "backward_entropy": 0.005327287384054877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028360283467918634,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03400975838303566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07505110402901967,
      "backward_entropy": 0.0053226277232170105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022178238723427057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03401101380586624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07502123713493347,
      "backward_entropy": 0.005318068645217202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00311444909311831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03401222452521324,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07499211033185323,
      "backward_entropy": 0.005313681946559386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021984712220728397,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034013476222753525,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07496307293574016,
      "backward_entropy": 0.00620270384983583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022953669540584087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03401469439268112,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07493476072947185,
      "backward_entropy": 0.00530486520041119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023803620133548975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03401589021086693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07490698496500652,
      "backward_entropy": 0.005300607532262802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023959861136972904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03401707112789154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07487961153189342,
      "backward_entropy": 0.005296380682425065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024278489872813225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03401828557252884,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0748528242111206,
      "backward_entropy": 0.005081572315909646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001930799102410674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03401953727006912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07482648889223735,
      "backward_entropy": 0.005287677049636841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014594931853935122,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402072563767433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07480037212371826,
      "backward_entropy": 0.005283473228866404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001691179582849145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402185067534447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0747750202814738,
      "backward_entropy": 0.005279475315050645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016470971750095487,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03402296081185341,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07475023468335469,
      "backward_entropy": 0.006177459928122434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020045330747962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402405232191086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07472595075766246,
      "backward_entropy": 0.005271707068790089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012547958176583052,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340251699090004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07470194498697917,
      "backward_entropy": 0.005267793482000177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011536700185388327,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03402622416615486,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07467856009801228,
      "backward_entropy": 0.006168939173221588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015737086068838835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03402720019221306,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07465573151906331,
      "backward_entropy": 0.00506420602852648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001617804984562099,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03402818366885185,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07463270425796509,
      "backward_entropy": 0.006163785403425043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010343148605898023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402920439839363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07460980614026387,
      "backward_entropy": 0.005253586918115616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010924465022981167,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403017297387123,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07458733518918355,
      "backward_entropy": 0.0061584663662043486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012801986886188388,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403109684586525,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07456515232721965,
      "backward_entropy": 0.006156006997281855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001113185309804976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034032005816698074,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07454312841097514,
      "backward_entropy": 0.0052436637607487764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010274422820657492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034032877534627914,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0745212584733963,
      "backward_entropy": 0.006151238625699823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008649323135614395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03403371945023537,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07449967662493388,
      "backward_entropy": 0.0052375353195450525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010873847641050816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03403449058532715,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07447828352451324,
      "backward_entropy": 0.005050050941380588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009916486451402307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03403525426983833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07445714871088664,
      "backward_entropy": 0.005231999876824292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009177871397696435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034036021679639816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07443647583325703,
      "backward_entropy": 0.005229221148924394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009630332351662219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034036774188280106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07441615064938863,
      "backward_entropy": 0.005226490172472867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006985840736888349,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340375155210495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07439598441123962,
      "backward_entropy": 0.005223813382062045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000785311684012413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03403819352388382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07437609632809956,
      "backward_entropy": 0.00522132929075848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008141100406646729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03403884917497635,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07435647646586101,
      "backward_entropy": 0.005218922753225674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006804824224673212,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403950482606888,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07433722416559856,
      "backward_entropy": 0.006133559075268832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007777126156724989,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034040145576000214,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07431843876838684,
      "backward_entropy": 0.005039845000613819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00072222895687446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034040797501802444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07430002093315125,
      "backward_entropy": 0.005211762067946521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007271583308465779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03404146432876587,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07428207496802013,
      "backward_entropy": 0.005037413402037187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006482781609520316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404213488101959,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07426431775093079,
      "backward_entropy": 0.00520695915276354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006433698581531644,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404281660914421,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0742470274368922,
      "backward_entropy": 0.00520456074313684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006047216011211276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404350206255913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07423003514607747,
      "backward_entropy": 0.005202158946882595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005755653255619109,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034044187515974045,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07421339054902394,
      "backward_entropy": 0.005032183433120901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006807398749515414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404487669467926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07419709861278534,
      "backward_entropy": 0.005197385156696493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035087703145109117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034045588225126266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0741809109846751,
      "backward_entropy": 0.005194958976723931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004710929642897099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404625132679939,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07416527966658275,
      "backward_entropy": 0.0051926943388852205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000431730441050604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404690697789192,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07415005067984264,
      "backward_entropy": 0.005190457132729617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037372048245742917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404754400253296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07413521409034729,
      "backward_entropy": 0.0051882588727907705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004567083087749779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404814377427101,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07412068049112956,
      "backward_entropy": 0.0051861700009215965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003248495631851256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404874727129936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07410639524459839,
      "backward_entropy": 0.005184065889228474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034737103851512074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404933586716652,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07409262657165527,
      "backward_entropy": 0.005182042040608146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002633480471558869,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03404990956187248,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07407917579015096,
      "backward_entropy": 0.005020939152349125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024596782168373466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405045345425606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07406619191169739,
      "backward_entropy": 0.0051781690933487634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023416041221935302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034050971269607544,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07405364513397217,
      "backward_entropy": 0.0051763789220289754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003468942304607481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405146673321724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07404155035813649,
      "backward_entropy": 0.005174662579189648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000197785600903444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034051962196826935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07402954995632172,
      "backward_entropy": 0.005172939463095231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030437891837209463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405243158340454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0740179717540741,
      "backward_entropy": 0.00517131049524654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020281488832551986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03405289351940155,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07400645812352498,
      "backward_entropy": 0.0050151619044217196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027555148699320853,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03405333310365677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07399530212084453,
      "backward_entropy": 0.006096304817633195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002684998617041856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034053780138492584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07398439447085063,
      "backward_entropy": 0.0051666203547607766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024377094814553857,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0340542308986187,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07397363086541493,
      "backward_entropy": 0.0060938014225526286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020144220616202801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405468165874481,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07396302620569865,
      "backward_entropy": 0.005163502286780964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000139165815198794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405512124300003,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07395268479983012,
      "backward_entropy": 0.005161991512233561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000169610750162974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034055523574352264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07394261161486308,
      "backward_entropy": 0.005160586739128286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018041291332338005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0340559147298336,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07393280665079753,
      "backward_entropy": 0.005009343339638276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013989272702019662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405630588531494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07392325003941853,
      "backward_entropy": 0.005157862197269093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001976386847672984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034056685864925385,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07391401628653209,
      "backward_entropy": 0.006087114187804135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016355088155250996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034057073295116425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07390489180882771,
      "backward_entropy": 0.005155230449004607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015355504001490772,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405746445059776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07389605045318604,
      "backward_entropy": 0.0051538937471129675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001585257996339351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340578593313694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07388749718666077,
      "backward_entropy": 0.0051525634798136625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001274447567993775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034058257937431335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0738791028658549,
      "backward_entropy": 0.006082830103960904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017594195378478616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034058645367622375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07387089729309082,
      "backward_entropy": 0.005149936811490493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001242068683495745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03405904769897461,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07386274139086406,
      "backward_entropy": 0.006080700592561202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010245934390695766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034059446305036545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07385481397310893,
      "backward_entropy": 0.005147293210029602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011401196388760582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405982628464699,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07384708523750305,
      "backward_entropy": 0.00514602932063016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012645327660720795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406020253896713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07383955021699269,
      "backward_entropy": 0.005144778977740894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011204974725842476,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406057506799698,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07383205989996593,
      "backward_entropy": 0.006076601418581876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.457321382593364e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034060943871736526,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0738246738910675,
      "backward_entropy": 0.004999217661944303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.43285529804416e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406129404902458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07381747166315715,
      "backward_entropy": 0.005141185427253897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19385313661769e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406161442399025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07381050288677216,
      "backward_entropy": 0.005140105770392852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.454093429259956e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406193107366562,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07380373279253642,
      "backward_entropy": 0.005139036273414438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.052982255117968e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406223654747009,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07379712661107381,
      "backward_entropy": 0.0051380145278843966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.359189087059349e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406253084540367,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07379067937533061,
      "backward_entropy": 0.0060712762854316015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.380718696163967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406283259391785,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07378441095352173,
      "backward_entropy": 0.005136014385656877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.27882473054342e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034063130617141724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07377832134564717,
      "backward_entropy": 0.005135031925006347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.310050957836211e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034063421189785004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07377240061759949,
      "backward_entropy": 0.005134071816097607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.740959047921933e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406370431184769,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07376658419768016,
      "backward_entropy": 0.005133139477534728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.67946262890473e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034063976258039474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07376097639401753,
      "backward_entropy": 0.0051322315226901664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9133516111178324e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406424820423126,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07375552256902058,
      "backward_entropy": 0.005131331357088956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.197422822471708e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034064508974552155,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07375029226144154,
      "backward_entropy": 0.0060659050941467285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.287462434149347e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406475856900215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07374518116315205,
      "backward_entropy": 0.005129648880525069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6837852753233165e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034064993262290955,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07374013463656108,
      "backward_entropy": 0.0060646073384718465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.487790672807023e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406522795557976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07373509804407756,
      "backward_entropy": 0.00512808391993696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.898208524333313e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034065451472997665,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0737302303314209,
      "backward_entropy": 0.005127322944727811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5591782105038874e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406567499041557,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07372548182805379,
      "backward_entropy": 0.0051265863532369785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.249137807870284e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034065887331962585,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0737209568421046,
      "backward_entropy": 0.0049892413345250216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6707699362304993e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340660884976387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07371652126312256,
      "backward_entropy": 0.005125211382454092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8317375836195424e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034066278487443924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07371220986048381,
      "backward_entropy": 0.005124572664499283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.442076220177114e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034066468477249146,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07370806733767192,
      "backward_entropy": 0.005123926157301123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.569519347161986e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406665101647377,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07370405395825703,
      "backward_entropy": 0.005123309791088104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.068910154979676e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034066829830408096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07370016972223918,
      "backward_entropy": 0.005122707987373526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.746671270870138e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406701236963272,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07369634509086609,
      "backward_entropy": 0.006059074943715876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.374032737861853e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034067194908857346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0736925999323527,
      "backward_entropy": 0.006058581173419952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8383667338639498e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406737372279167,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07368894418080647,
      "backward_entropy": 0.006058091467077082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1428006220958196e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340675450861454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07368539273738861,
      "backward_entropy": 0.005120328881523826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9933590010623448e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406770899891853,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07368189096450806,
      "backward_entropy": 0.0051197714426300745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5165350305323955e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034067872911691666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07367846369743347,
      "backward_entropy": 0.005119232630187815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6142437743837945e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340680256485939,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07367513080437978,
      "backward_entropy": 0.005118727684020996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9202288967790082e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406817466020584,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07367192208766937,
      "backward_entropy": 0.0060559125109152364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6674504877300933e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406832739710808,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07366878787676494,
      "backward_entropy": 0.006055492569099773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1104004443041049e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034068480134010315,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07366574803988139,
      "backward_entropy": 0.004983996803110296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.44446739795967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034068625420331955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07366281747817993,
      "backward_entropy": 0.0051167390563271265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2339181012066547e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034068766981363297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07365993658701579,
      "backward_entropy": 0.005116280845620416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.168731614598073e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406889736652374,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07365708549817403,
      "backward_entropy": 0.006053932688452981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2268281352589838e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03406902402639389,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07365430394808452,
      "backward_entropy": 0.00498290630904111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1374590030754916e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406914696097374,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07365156213442485,
      "backward_entropy": 0.006053261458873749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.850669135223143e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406926617026329,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07364887992540996,
      "backward_entropy": 0.006052933633327484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02537885849597e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406938165426254,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07364631692568462,
      "backward_entropy": 0.006052614613012834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1189948054379784e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034069497138261795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0736438383658727,
      "backward_entropy": 0.005113823170011694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.50480989558855e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406961262226105,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07364140450954437,
      "backward_entropy": 0.005113447931679812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.306507086468628e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0340697281062603,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07363903025786082,
      "backward_entropy": 0.006051684645089236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.203722477948759e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034069836139678955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0736367255449295,
      "backward_entropy": 0.00511269440705126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456690920866095e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406994417309761,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07363452017307281,
      "backward_entropy": 0.006051092662594535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.66598623158643e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034070052206516266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07363236447175343,
      "backward_entropy": 0.005111989649859342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.21156425747904e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407016023993492,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07363024353981018,
      "backward_entropy": 0.005111631683327935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0172156988992356e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407026082277298,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0736281822125117,
      "backward_entropy": 0.00605024668303403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8276319830620196e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407035395503044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07362618048985799,
      "backward_entropy": 0.006049988622015173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.130709607532481e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034070443361997604,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07362424333890279,
      "backward_entropy": 0.006049749526110562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.291335583024193e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03407053276896477,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07362234592437744,
      "backward_entropy": 0.004979870536110618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.530404112301767e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407062217593193,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07362049321333568,
      "backward_entropy": 0.006049257787791165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.655457021523034e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034070707857608795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07361868520577748,
      "backward_entropy": 0.005109821530905637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4505867461120943e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407078981399536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07361694673697154,
      "backward_entropy": 0.006048814139582894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.377151642780518e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407086804509163,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0736152579387029,
      "backward_entropy": 0.00510930134491487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8943597953912104e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0340709425508976,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07361362377802531,
      "backward_entropy": 0.004979074678637765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9097618607920595e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407101333141327,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07361204425493877,
      "backward_entropy": 0.005108823491768403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9415032258839346e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407108038663864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.073610524336497,
      "backward_entropy": 0.006048036569898779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6077506138099125e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034071143716573715,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07360903422037761,
      "backward_entropy": 0.005108379166234623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8490371732914355e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407121077179909,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0736075888077418,
      "backward_entropy": 0.005108152600851926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.32292973123549e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407127410173416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07360617319742839,
      "backward_entropy": 0.005107947032560001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7743324153561844e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407133370637894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07360480229059856,
      "backward_entropy": 0.005107732659036463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.31891044677468e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407139331102371,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07360347112019856,
      "backward_entropy": 0.005107524720105258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.343074356758734e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407145291566849,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07360217968622844,
      "backward_entropy": 0.00604700432582335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.069739821308758e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407151252031326,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07360091805458069,
      "backward_entropy": 0.006046836349097165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9952844922954682e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407156839966774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07359967629114787,
      "backward_entropy": 0.0051069320602850484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0673930976045085e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407162427902222,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07359846929709117,
      "backward_entropy": 0.005106749859723178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5622983937646495e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034071680158376694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07359729707241058,
      "backward_entropy": 0.0060463777997277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6309078318954562e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407173231244087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07359613974889119,
      "backward_entropy": 0.00510639257051728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6019951090129325e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407178074121475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07359500726064046,
      "backward_entropy": 0.005106219852512533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1757127822420443e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407182916998863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07359391450881958,
      "backward_entropy": 0.005106056955727664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.193594698634115e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034071873873472214,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07359285155932109,
      "backward_entropy": 0.006045850840481845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.98294922283094e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034071918576955795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07359182834625244,
      "backward_entropy": 0.0051057538525624705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3329538433026755e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407195955514908,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07359083990255992,
      "backward_entropy": 0.006045615808530288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.196091147903644e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407200053334236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358987132708232,
      "backward_entropy": 0.005105474455790086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.039143383735791e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034072041511535645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358892261981964,
      "backward_entropy": 0.005105333910747008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0146382010134403e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407207876443863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358801364898682,
      "backward_entropy": 0.005105209621516141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0170499535888666e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034072116017341614,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0735871394475301,
      "backward_entropy": 0.006045168773694472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.535284112236695e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0340721532702446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0735862801472346,
      "backward_entropy": 0.006045064465566115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.505393912448199e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034072186797857285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358544071515401,
      "backward_entropy": 0.005104827948591926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.713470384056563e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407222032546997,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.073584645986557,
      "backward_entropy": 0.00510470298203555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.432904177065211e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407225385308266,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07358386119206746,
      "backward_entropy": 0.0060447826981544495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.069036544431583e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034072283655405045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358313103516896,
      "backward_entropy": 0.005104487592523748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9931654782776604e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03407231345772743,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07358240087827046,
      "backward_entropy": 0.0049763531847433614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.233646902524924e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407233953475952,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358170549074809,
      "backward_entropy": 0.005104297264055772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.21036270129116e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407236188650131,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358102003733318,
      "backward_entropy": 0.005104211921041662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.006301648791123e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340723842382431,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07358034451802571,
      "backward_entropy": 0.00510413876988671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.346624677964428e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034072406589984894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07357968886693318,
      "backward_entropy": 0.005104052072221582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.742122203220788e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034072428941726685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07357905308405559,
      "backward_entropy": 0.006044286895882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.419669951654214e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407244756817818,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0735784371693929,
      "backward_entropy": 0.006044229323213751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.766248314856057e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03407246619462967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07357783615589142,
      "backward_entropy": 0.005103829909454693,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.6541599759184464e-05,
    "avg_log_Z": 0.03406815584748983,
    "success_rate": 1.0,
    "avg_reward": 49.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.07,
      "1": 0.33,
      "2": 0.6
    },
    "avg_forward_entropy": 0.07367185314496356,
    "avg_backward_entropy": 0.005418497202071276,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}