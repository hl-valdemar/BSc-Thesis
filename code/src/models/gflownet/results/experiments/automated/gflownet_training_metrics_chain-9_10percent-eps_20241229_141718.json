{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07697430584165785,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07697430584165785,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07697430584165785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07697430584165785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07697430584165785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07697430584165785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07684872547785442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07697430584165785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.777043342590332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951464176177979,
      "backward_entropy": 0.07682162523269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.685184955596924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952301025390625,
      "backward_entropy": 0.07681571112738715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.681406021118164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019997973868157715,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10953096151351929,
      "backward_entropy": 0.07696916659673055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.549174785614014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00029995251679793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10953869819641113,
      "backward_entropy": 0.07696647114223903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.85356330871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003999100299552083,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10954573154449462,
      "backward_entropy": 0.07679707474178737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.760578632354736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004999333759769797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10955286026000977,
      "backward_entropy": 0.07696058352788289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.542453289031982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005999643472023308,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955994129180908,
      "backward_entropy": 0.07681402232911852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.845173358917236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006999513716436923,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095665454864502,
      "backward_entropy": 0.07677694161732991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.055424690246582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007999923545867205,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10957311391830445,
      "backward_entropy": 0.07676992151472303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.836511135101318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009001208236441016,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957984924316407,
      "backward_entropy": 0.07694753011067708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4146528244018555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009999388130381703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958532094955445,
      "backward_entropy": 0.07694392734103733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.01944637298584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010997417848557234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958998203277588,
      "backward_entropy": 0.07694009939829509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.227297782897949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011997214751318097,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959476232528687,
      "backward_entropy": 0.07693613237804836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.132716178894043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012995621655136347,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959904193878174,
      "backward_entropy": 0.07673365539974636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.827391147613525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013992433669045568,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960294008255005,
      "backward_entropy": 0.07692770825492011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.035290241241455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014990429626777768,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096070647239685,
      "backward_entropy": 0.07671750916375054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.521772861480713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015986390644684434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961087942123413,
      "backward_entropy": 0.07691881391737196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.614056587219238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016982675297185779,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961463451385497,
      "backward_entropy": 0.07670063442654079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.807040214538574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017979713156819344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961828231811524,
      "backward_entropy": 0.07690931028789944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.521940231323242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018974632257595658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962055921554566,
      "backward_entropy": 0.07690420415666369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.704343795776367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001996619626879692,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962194204330444,
      "backward_entropy": 0.07689890596601698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.199770927429199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00209598196670413,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962340831756592,
      "backward_entropy": 0.07666419612036811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.191781044006348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021953503601253033,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962419509887696,
      "backward_entropy": 0.0768877002927992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.305760383605957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022951101418584585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962542295455932,
      "backward_entropy": 0.07668080594804552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.31227445602417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023948252201080322,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962648391723633,
      "backward_entropy": 0.07687575287289089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5824613571167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002494093729183078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962638854980469,
      "backward_entropy": 0.07666145430670844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67679500579834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025939426850527525,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962705612182617,
      "backward_entropy": 0.0766143004099528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.790507793426514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002694344148039818,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962830781936646,
      "backward_entropy": 0.0766412549548679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.298977851867676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027948329225182533,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962960720062256,
      "backward_entropy": 0.07659296194712321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.575516700744629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028951673302799463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963072776794433,
      "backward_entropy": 0.07662014166514079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.806590557098389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029959389939904213,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963238477706909,
      "backward_entropy": 0.07683580451541477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.188276290893555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003096275497227907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963363647460937,
      "backward_entropy": 0.07682851288053724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8890767097473145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031964594963937998,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963420867919922,
      "backward_entropy": 0.0765474107530382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.472123146057129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032967617735266685,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963536500930786,
      "backward_entropy": 0.07653541035122341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.992757797241211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033974568359553814,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963711738586426,
      "backward_entropy": 0.07680482334560818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.598303318023682,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003497827798128128,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963830947875977,
      "backward_entropy": 0.0767964522043864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75296688079834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035977258812636137,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963873863220215,
      "backward_entropy": 0.07649781968858507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.500121593475342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003698243759572506,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109639573097229,
      "backward_entropy": 0.07648481925328572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.891445636749268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003798200748860836,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963976383209229,
      "backward_entropy": 0.07647151417202419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.497248649597168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003897853195667267,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963963270187378,
      "backward_entropy": 0.07676119274563259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.98362922668457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003997044172137976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096389651298523,
      "backward_entropy": 0.07675166924794515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.576501846313477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004096082877367735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963797569274902,
      "backward_entropy": 0.0764742030037774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4794721603393555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004195250570774078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963737964630127,
      "backward_entropy": 0.07646087143156263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.681184768676758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004294471349567175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963723659515381,
      "backward_entropy": 0.07644720872243245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.451990127563477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004393401090055704,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963637828826904,
      "backward_entropy": 0.07638441191779242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.974911212921143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004492923617362976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963633060455322,
      "backward_entropy": 0.07641906208462185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.068426609039307,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004592251498252153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963590145111084,
      "backward_entropy": 0.07668858104281956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.673894882202148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004691469948738813,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963504314422608,
      "backward_entropy": 0.07638973659939235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.873997688293457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004790391772985458,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963354110717774,
      "backward_entropy": 0.07637470960617065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5864105224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004889124073088169,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963188409805298,
      "backward_entropy": 0.07630189259847005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.477155685424805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004987495951354504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963035821914673,
      "backward_entropy": 0.07664065890842015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.249136924743652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005085539072751999,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962842702865601,
      "backward_entropy": 0.07662800947825114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.949489116668701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005184178706258535,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962761640548706,
      "backward_entropy": 0.07624904314676921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721869468688965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005283208563923836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096274733543396,
      "backward_entropy": 0.07660184966193305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42198371887207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005383039824664593,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096278190612793,
      "backward_entropy": 0.07627618975109524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.430977821350098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005483441054821014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962824821472168,
      "backward_entropy": 0.07625799708896214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.143592357635498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0055842893198132515,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962934494018554,
      "backward_entropy": 0.07617474926842584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.425761222839355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005684911739081144,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962977409362792,
      "backward_entropy": 0.07615531815422906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.15127420425415,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005785952787846327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963085889816285,
      "backward_entropy": 0.07653039031558567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.218188285827637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005886683240532875,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963189601898193,
      "backward_entropy": 0.07611521747377184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.241960048675537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0059877424500882626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963308811187744,
      "backward_entropy": 0.07649953497780694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.616727828979492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006088547874242067,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963410139083862,
      "backward_entropy": 0.07648358080122206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.332219123840332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00618981895968318,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963606834411621,
      "backward_entropy": 0.07605192396375868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.515754699707031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006290871649980545,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096376895904541,
      "backward_entropy": 0.07602994971805149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1381516456604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006392292212694883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964030027389526,
      "backward_entropy": 0.07643406920962864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.011720657348633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006493337452411652,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964270830154418,
      "backward_entropy": 0.07606973912980822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.819366931915283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006594529841095209,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964528322219849,
      "backward_entropy": 0.07639949851565891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89180850982666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006695718038827181,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964820384979249,
      "backward_entropy": 0.07602773110071818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.517996311187744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006797454785555601,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965207815170289,
      "backward_entropy": 0.07600605487823486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.799663066864014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006898974999785423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965576171875,
      "backward_entropy": 0.07598400115966797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.163481712341309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0070004998706281185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965902805328369,
      "backward_entropy": 0.0759615765677558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.025385856628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007102723233401775,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966291427612304,
      "backward_entropy": 0.07583418157365587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.894386291503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0072043840773403645,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966653823852539,
      "backward_entropy": 0.07580695549647014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5822649002075195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007306030485779047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967022180557251,
      "backward_entropy": 0.07589185900158352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.430900573730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007407635450363159,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967246294021607,
      "backward_entropy": 0.0757510397169325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366499900817871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007510116323828697,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967508554458619,
      "backward_entropy": 0.07572272088792589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.370258331298828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007612753659486771,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096779465675354,
      "backward_entropy": 0.07620316081576878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.096492290496826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007715465966612101,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968151092529296,
      "backward_entropy": 0.07618118657006158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449115753173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00781765952706337,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968416929244995,
      "backward_entropy": 0.07563396957185534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.617860794067383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007920094765722752,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968693494796752,
      "backward_entropy": 0.07560321357515123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.826414108276367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008021690882742405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096893310546875,
      "backward_entropy": 0.07571522394816081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.720358848571777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008123798295855522,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096920371055603,
      "backward_entropy": 0.0756881766849094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.799100875854492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008226347155869007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109694504737854,
      "backward_entropy": 0.07566064596176147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.067142486572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008328165858983994,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969642400741578,
      "backward_entropy": 0.07547496424780951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.750036716461182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008431090973317623,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096994161605835,
      "backward_entropy": 0.07544179757436116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.463772296905518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008533795364201069,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970194339752197,
      "backward_entropy": 0.07557508680555555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.703763008117676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008636094629764557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970437526702881,
      "backward_entropy": 0.07596027851104736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.885861396789551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008738730102777481,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097070574760437,
      "backward_entropy": 0.0753380921151903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.506038665771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008840608410537243,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970972776412964,
      "backward_entropy": 0.07530206441879272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.035109519958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008942726999521255,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971283912658691,
      "backward_entropy": 0.07545361916224162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.727163791656494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009045831859111786,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971726179122925,
      "backward_entropy": 0.07522845268249512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.87124252319336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009148666635155678,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972104072570801,
      "backward_entropy": 0.07538912031385633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.483449935913086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009251829236745834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972515344619752,
      "backward_entropy": 0.07535576820373535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.097814559936523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009353996254503727,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972833633422852,
      "backward_entropy": 0.07511385944154528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.756218910217285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009457188658416271,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973255634307862,
      "backward_entropy": 0.07507469256718953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.656271934509277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009560644626617432,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973660945892334,
      "backward_entropy": 0.07569897174835205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.367613792419434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009664260782301426,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974055528640747,
      "backward_entropy": 0.07499432563781738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.510002613067627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009767808951437473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974469184875488,
      "backward_entropy": 0.07563353909386529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73327922821045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00987086072564125,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974838733673095,
      "backward_entropy": 0.07491078641679552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312809944152832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009974105283617973,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097523808479309,
      "backward_entropy": 0.07510485251744588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.909163475036621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010076801292598248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975556373596192,
      "backward_entropy": 0.07506643401251899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.304710865020752,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0101798539981246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975875854492187,
      "backward_entropy": 0.07549397150675456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61501693725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010282368399202824,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976132154464721,
      "backward_entropy": 0.07473385334014893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.451903343200684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01038510724902153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976388454437255,
      "backward_entropy": 0.07541886965433757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.602703094482422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010488464497029781,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976696014404297,
      "backward_entropy": 0.0753804710176256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.658430099487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010591940954327583,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976994037628174,
      "backward_entropy": 0.07459240489535862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.936381816864014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010694957338273525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977283716201783,
      "backward_entropy": 0.0748190614912245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.047033309936523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010797766037285328,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977541208267212,
      "backward_entropy": 0.07449155383639866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.755806922912598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0109009500592947,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977833271026612,
      "backward_entropy": 0.07443869113922119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.380692481994629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011004255153238773,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978174209594727,
      "backward_entropy": 0.0743842257393731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.18423080444336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01110751647502184,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978512763977051,
      "backward_entropy": 0.07432852851019965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.022232055664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011210593394935131,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978860855102539,
      "backward_entropy": 0.07427151997884114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.358959197998047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011314057745039463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979187488555908,
      "backward_entropy": 0.07504491011301677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.223476886749268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011417442001402378,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10979509353637695,
      "backward_entropy": 0.07415440347459581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5889506340026855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011519542895257473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979777574539185,
      "backward_entropy": 0.0749523573451572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.073533058166504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011620706878602505,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980005264282226,
      "backward_entropy": 0.07403118080563015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.673654079437256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011721951887011528,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980188846588135,
      "backward_entropy": 0.07485532760620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.394319534301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01182241179049015,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980339050292968,
      "backward_entropy": 0.07390293810102674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50644302368164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011922523379325867,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098050594329834,
      "backward_entropy": 0.07475401295555963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.035316467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012023028917610645,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980666875839233,
      "backward_entropy": 0.07376935746934679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.396239280700684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012123598717153072,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980826616287231,
      "backward_entropy": 0.07370062006844415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.299745082855225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01222443301230669,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980995893478393,
      "backward_entropy": 0.07459394137064616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8289213180542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012324932962656021,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981123447418213,
      "backward_entropy": 0.07453787326812744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.915587425231934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012425906024873257,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098129391670227,
      "backward_entropy": 0.0734865731663174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902328968048096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01252736710011959,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098149299621582,
      "backward_entropy": 0.07386158572302924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0831990242004395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012628692202270031,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981690883636475,
      "backward_entropy": 0.07333695888519287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.963322162628174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012729465961456299,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981853008270263,
      "backward_entropy": 0.07325988345675999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8780364990234375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012829595245420933,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982022285461426,
      "backward_entropy": 0.07366369830237494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.254950046539307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01292914617806673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982170104980468,
      "backward_entropy": 0.07359601391686334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.844125270843506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013028467074036598,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982275009155273,
      "backward_entropy": 0.07301873630947536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142044067382812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013127208687365055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982396602630615,
      "backward_entropy": 0.07406779792573717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941207408905029,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01322629489004612,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982509851455688,
      "backward_entropy": 0.07284990946451823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.284322738647461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013325539417564869,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982623100280761,
      "backward_entropy": 0.07330874601999919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.293005466461182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013423912227153778,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982730388641357,
      "backward_entropy": 0.07267418834898207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.728236675262451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013522154651582241,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982824563980102,
      "backward_entropy": 0.07379982868830363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.542792797088623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01361991185694933,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098291277885437,
      "backward_entropy": 0.07249115573035346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.896761894226074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01371773611754179,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982999801635743,
      "backward_entropy": 0.07365815507041083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.009332656860352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013815832324326038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983092784881592,
      "backward_entropy": 0.07290553384357029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6936798095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013914322480559349,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983155965805054,
      "backward_entropy": 0.07220128509733412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.613664150238037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01401227992027998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983216762542725,
      "backward_entropy": 0.07343293560875787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.663913249969482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01410976517945528,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098325490951538,
      "backward_entropy": 0.07199811935424805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.608374118804932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014207389205694199,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098331332206726,
      "backward_entropy": 0.07327534092797174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.559455871582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01430398691445589,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983326435089111,
      "backward_entropy": 0.07178678777482775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5638275146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01440015621483326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098334550857544,
      "backward_entropy": 0.07167802916632758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.206782817840576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014496599324047565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983368158340454,
      "backward_entropy": 0.07302963733673096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.850246906280518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014592486433684826,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983364582061768,
      "backward_entropy": 0.07145449850294325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.435841083526611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01468831766396761,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983328819274903,
      "backward_entropy": 0.07134019666247898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.146562576293945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014784370549023151,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983304977416992,
      "backward_entropy": 0.07277191347546047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.316991806030273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014881052076816559,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983304977416992,
      "backward_entropy": 0.07268231444888645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.237726211547852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014977778308093548,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983319282531738,
      "backward_entropy": 0.07098322444491917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.654453754425049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015074549242854118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098332405090332,
      "backward_entropy": 0.07165327999326918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.807483196258545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015171563252806664,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983350276947021,
      "backward_entropy": 0.0707356333732605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.446239471435547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01526885386556387,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983409881591796,
      "backward_entropy": 0.07142980231179132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.930383205413818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015366831794381142,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983489751815796,
      "backward_entropy": 0.07220425870683458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.440835475921631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015464555472135544,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983542203903199,
      "backward_entropy": 0.07034256723192003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.883643627166748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015562329441308975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983595848083497,
      "backward_entropy": 0.0702056090037028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.577949047088623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01566043682396412,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983648300170898,
      "backward_entropy": 0.07006625334421794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.32975435256958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015758603811264038,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983717441558838,
      "backward_entropy": 0.06992398367987739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.388143539428711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015856092795729637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983765125274658,
      "backward_entropy": 0.07166824738184611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.179768085479736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015953626483678818,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983811616897583,
      "backward_entropy": 0.0715548661020067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.360490322113037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0160510390996933,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983866453170776,
      "backward_entropy": 0.07044719325171576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.701931953430176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016148488968610764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983918905258179,
      "backward_entropy": 0.07031381792492336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.523878574371338,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016246184706687927,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983976125717163,
      "backward_entropy": 0.0691724353366428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.799030303955078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01634335331618786,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098402500152588,
      "backward_entropy": 0.0710801813337538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8156657218933105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016441423445940018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984108448028565,
      "backward_entropy": 0.06989785035451253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.773486137390137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016539711505174637,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984203815460206,
      "backward_entropy": 0.0697523554166158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.136967658996582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016637617722153664,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984272956848144,
      "backward_entropy": 0.0706999037000868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.254547595977783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01673528552055359,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984363555908203,
      "backward_entropy": 0.06945567660861546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.178465366363525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016832901164889336,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984447002410888,
      "backward_entropy": 0.07043610678778754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.590240478515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01693047769367695,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984503030776978,
      "backward_entropy": 0.06800061464309692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.399613857269287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017028776928782463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984592437744141,
      "backward_entropy": 0.07016134262084961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.700577259063721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017127087339758873,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984662771224976,
      "backward_entropy": 0.07001492712232801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27657699584961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017224842682480812,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984749794006347,
      "backward_entropy": 0.06866657733917236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.460093975067139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017323128879070282,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984851121902466,
      "backward_entropy": 0.06726340452829997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.687135696411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017421359196305275,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984961986541748,
      "backward_entropy": 0.06706990136040582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7122273445129395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01751910336315632,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985060930252075,
      "backward_entropy": 0.06687201393975152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.344552993774414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017617063596844673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985156297683715,
      "backward_entropy": 0.06797953446706136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.187587261199951,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017714984714984894,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985243320465088,
      "backward_entropy": 0.06779960791269939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.958111763000488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01781211607158184,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985321998596191,
      "backward_entropy": 0.06625794039832221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.840301513671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01790904998779297,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985395908355713,
      "backward_entropy": 0.06743401951260036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.968726634979248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01800571382045746,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985465049743652,
      "backward_entropy": 0.06583102544148763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.584395885467529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01810218207538128,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098554015159607,
      "backward_entropy": 0.06561174657609728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.777661323547363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018198926001787186,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985609292984008,
      "backward_entropy": 0.0653891298505995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.196470260620117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018295379355549812,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985676050186158,
      "backward_entropy": 0.06802795992957221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.028263568878174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018391862511634827,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985734462738037,
      "backward_entropy": 0.06784125169118245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2489471435546875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01848830282688141,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985779762268066,
      "backward_entropy": 0.06765056980980767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1274614334106445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018584828823804855,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985817909240722,
      "backward_entropy": 0.0674559473991394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.926148891448975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01868133619427681,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985851287841797,
      "backward_entropy": 0.06422566043006049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.597762584686279,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018778309226036072,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985884666442872,
      "backward_entropy": 0.06705500019921197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.476490497589111,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018874909728765488,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098590612411499,
      "backward_entropy": 0.06373594204584758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.40951681137085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018971076235175133,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985920429229737,
      "backward_entropy": 0.0651902887556288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.960819721221924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019066868349909782,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098591923713684,
      "backward_entropy": 0.06496681107415093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.026035785675049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019162669777870178,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985909700393677,
      "backward_entropy": 0.0629789498117235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.384336471557617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019257880747318268,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985887050628662,
      "backward_entropy": 0.06597578525543213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8805036544799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019353406503796577,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985862016677857,
      "backward_entropy": 0.062459468841552734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.802082538604736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019448254257440567,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985829830169677,
      "backward_entropy": 0.06551361083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.96824836730957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019543033093214035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985798835754394,
      "backward_entropy": 0.06527770227856106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.223313808441162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019637901335954666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985764265060424,
      "backward_entropy": 0.06503776046964857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.292694568634033,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019732274115085602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985741615295411,
      "backward_entropy": 0.0647960172759162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.691529750823975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019826268777251244,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985727310180664,
      "backward_entropy": 0.06109383371141222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.44059944152832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019920213147997856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985713005065918,
      "backward_entropy": 0.06281469265619914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.892736434936523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02001328393816948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985707044601441,
      "backward_entropy": 0.06405393282572429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9324564933776855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020105978474020958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985684394836426,
      "backward_entropy": 0.06230019860797458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3425822257995605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020198926329612732,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985664129257203,
      "backward_entropy": 0.06353904141320123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.366640090942383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02029171958565712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985641479492188,
      "backward_entropy": 0.061769591437445745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.49531888961792,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020384471863508224,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985606908798218,
      "backward_entropy": 0.06300344069798787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.832727432250977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02047654613852501,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985572338104248,
      "backward_entropy": 0.06272980239656237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5985107421875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020568188279867172,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985546112060547,
      "backward_entropy": 0.06095424625608656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1899333000183105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020660072565078735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985503196716309,
      "backward_entropy": 0.06067593892415365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.260603427886963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020751813426613808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098546028137207,
      "backward_entropy": 0.06039259168836805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.803569316864014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02084413170814514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098541259765625,
      "backward_entropy": 0.060101330280303955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.957202434539795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020935991778969765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985366106033326,
      "backward_entropy": 0.06128741635216607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.191981315612793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021027589216828346,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985313653945923,
      "backward_entropy": 0.0570979118347168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.023094654083252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02111903764307499,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985267162322998,
      "backward_entropy": 0.060674680603875056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.444240093231201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02121027372777462,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985219478607178,
      "backward_entropy": 0.05640799469417996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.451396465301514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02130092866718769,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985175371170045,
      "backward_entropy": 0.05605718824598524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.008070468902588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02139100432395935,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985146760940552,
      "backward_entropy": 0.05570210350884332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.523885726928711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021481022238731384,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985109806060792,
      "backward_entropy": 0.057949993345472545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.660768508911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021570682525634766,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985062122344971,
      "backward_entropy": 0.05498164892196655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.341445446014404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02166001684963703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985027551651001,
      "backward_entropy": 0.05730424324671427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.220638751983643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021749574691057205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984984636306763,
      "backward_entropy": 0.05697361628214518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.351568698883057,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02183937281370163,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984911918640136,
      "backward_entropy": 0.05387361844380697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.719027519226074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021929379552602768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984827280044555,
      "backward_entropy": 0.05771495236290826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.667089939117432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022018438205122948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984747409820557,
      "backward_entropy": 0.05736260281668769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.597714900970459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022108040750026703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984646081924439,
      "backward_entropy": 0.055613411797417536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.136180400848389,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022196555510163307,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984575748443604,
      "backward_entropy": 0.05526807573106554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.358066082000732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022285176441073418,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984508991241455,
      "backward_entropy": 0.05628463294770983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.137192249298096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022374125197529793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984430313110352,
      "backward_entropy": 0.05591917037963867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.320716381072998,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022463161498308182,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984346866607667,
      "backward_entropy": 0.05555093950695462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.617990493774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02255099080502987,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984278917312622,
      "backward_entropy": 0.05077455441157023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.447758197784424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022638676688075066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984207391738891,
      "backward_entropy": 0.05346826712290446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1048502922058105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0227261520922184,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984125137329101,
      "backward_entropy": 0.04996971951590644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.407857418060303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02281317301094532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984032154083252,
      "backward_entropy": 0.0527260767088996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.683627128601074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022900111973285675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983911752700806,
      "backward_entropy": 0.053661088148752846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.309966564178467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02298639342188835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983788967132568,
      "backward_entropy": 0.05327017108599345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.349571704864502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023072436451911926,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098366618156433,
      "backward_entropy": 0.04834041330549452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.718874931335449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023158321157097816,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983535051345825,
      "backward_entropy": 0.047927008734809026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.926040172576904,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023244312033057213,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098339319229126,
      "backward_entropy": 0.05208290285534329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.375461578369141,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02332988567650318,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098323941230774,
      "backward_entropy": 0.04709433847003513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.500586986541748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023415422067046165,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983064174652099,
      "backward_entropy": 0.04668011930253771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.380578994750977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02350015379488468,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982908010482788,
      "backward_entropy": 0.05086930592854818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.778656005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02358420379459858,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982751846313477,
      "backward_entropy": 0.04584913783603244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.530327320098877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023667847737669945,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098259449005127,
      "backward_entropy": 0.0454321371184455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.640624046325684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023750947788357735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982444286346435,
      "backward_entropy": 0.049639367394977145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.475070476531982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02383353002369404,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982308387756348,
      "backward_entropy": 0.04459366533491346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5864787101745605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023915555328130722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982179641723633,
      "backward_entropy": 0.04754939675331116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.898069858551025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023998109623789787,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981998443603516,
      "backward_entropy": 0.04713271723853217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4272658824920654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024080540984869003,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981792211532593,
      "backward_entropy": 0.04332214262750414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8524763584136963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024161512032151222,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981640815734864,
      "backward_entropy": 0.04757245381673177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.009411334991455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024241505190730095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981514453887939,
      "backward_entropy": 0.04588585760858324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.965713977813721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024320902302861214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981391668319702,
      "backward_entropy": 0.04547353254424201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9951980113983154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02440056763589382,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098122239112854,
      "backward_entropy": 0.04633294873767429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.504495620727539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024479679763317108,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981049537658691,
      "backward_entropy": 0.04591383536656698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.745434522628784,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024559520184993744,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980803966522217,
      "backward_entropy": 0.040760040283203125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.257264614105225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02463851310312748,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980565547943115,
      "backward_entropy": 0.04033219814300537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.066195964813232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024717122316360474,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980291366577148,
      "backward_entropy": 0.03990381293826633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.275780200958252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024795345962047577,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980002880096436,
      "backward_entropy": 0.039476745658450656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.769826889038086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024873415008187294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979685783386231,
      "backward_entropy": 0.04251870181825426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.126513957977295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024951720610260963,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10979305505752564,
      "backward_entropy": 0.03861936926841736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.057544231414795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02502962201833725,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978901386260986,
      "backward_entropy": 0.03818979859352112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6705322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025108110159635544,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978409051895141,
      "backward_entropy": 0.03775894641876221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7600717544555664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025186745449900627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097785234451294,
      "backward_entropy": 0.04078300131691827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3883209228515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025264712050557137,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977295637130738,
      "backward_entropy": 0.03689908650186327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.542003870010376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025341693311929703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976762771606445,
      "backward_entropy": 0.03991505834791395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8767526149749756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02541782520711422,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976228713989258,
      "backward_entropy": 0.0407188336054484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2416398525238037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025493573397397995,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975663661956787,
      "backward_entropy": 0.040282636880874634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1767802238464355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025568410754203796,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975120067596436,
      "backward_entropy": 0.03863306840260824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.661282539367676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02564327046275139,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974502563476562,
      "backward_entropy": 0.034787515799204506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5922510623931885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02571866661310196,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097377061843872,
      "backward_entropy": 0.038975268602371216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.013067245483398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025793449953198433,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973010063171387,
      "backward_entropy": 0.03394823604159885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1310172080993652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025868313387036324,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972199440002442,
      "backward_entropy": 0.03353193402290344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5918991565704346,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02594229206442833,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971415042877197,
      "backward_entropy": 0.033120042747921415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1893868446350098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02601577714085579,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970579385757447,
      "backward_entropy": 0.03722704781426324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.546677350997925,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026088545098900795,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969748497009277,
      "backward_entropy": 0.03230270412233141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7468535900115967,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02616092935204506,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968860387802123,
      "backward_entropy": 0.036362654632992215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9403467178344727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026233308017253876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096790075302124,
      "backward_entropy": 0.0347763564851549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4413607120513916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026306016370654106,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966861248016357,
      "backward_entropy": 0.035492665237850614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3806450366973877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026378275826573372,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965763330459595,
      "backward_entropy": 0.03506194551785787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7888734340667725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026448993012309074,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964748859405518,
      "backward_entropy": 0.030289861891004775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.63079833984375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026518894359469414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096376657485962,
      "backward_entropy": 0.03421784109539456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8063435554504395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02658882923424244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962661504745483,
      "backward_entropy": 0.03268201814757453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4253671169281006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026657892391085625,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096154808998108,
      "backward_entropy": 0.029116372267405193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5623250007629395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026726916432380676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960334539413452,
      "backward_entropy": 0.032968650261561074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.229377508163452,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026794904842972755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959146022796631,
      "backward_entropy": 0.031473484304216176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5531952381134033,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026861628517508507,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095804214477539,
      "backward_entropy": 0.03215568926599291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9736669063568115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026927467435598373,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10956926345825195,
      "backward_entropy": 0.030697219901614718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0045318603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026993179693818092,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955746173858642,
      "backward_entropy": 0.027227318949169584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.381195068359375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027058757841587067,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954476594924926,
      "backward_entropy": 0.029926733838187322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.115807294845581,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02712344564497471,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953218936920166,
      "backward_entropy": 0.026496665345297918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.473761558532715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027187099680304527,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952036380767823,
      "backward_entropy": 0.030171636078092787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3256547451019287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027250170707702637,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950822830200195,
      "backward_entropy": 0.02578725086318122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.444565534591675,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02731246128678322,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10949583053588867,
      "backward_entropy": 0.025438643164104886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5102529525756836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027374442666769028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948328971862793,
      "backward_entropy": 0.028080648846096463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5899887084960938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027436060830950737,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947002172470092,
      "backward_entropy": 0.028637905915578205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8443766832351685,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02749742940068245,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945570468902588,
      "backward_entropy": 0.024407510956128437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4504088163375854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02755756676197052,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944190025329589,
      "backward_entropy": 0.027890198760562472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4877705574035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027615904808044434,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942915678024293,
      "backward_entropy": 0.023744116226832073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.60646915435791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027674231678247452,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941517353057861,
      "backward_entropy": 0.026329073641035292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6879395246505737,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027732722461223602,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939962863922119,
      "backward_entropy": 0.023094003399213154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.096078395843506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027790021151304245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938463211059571,
      "backward_entropy": 0.0256517231464386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4928793907165527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027846794575452805,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936892032623291,
      "backward_entropy": 0.02531971534093221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.12722110748291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027903640642762184,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093514084815979,
      "backward_entropy": 0.025776432620154485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.554938793182373,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027960017323493958,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933289527893067,
      "backward_entropy": 0.02543646925025516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.191364049911499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028016922995448112,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093127965927124,
      "backward_entropy": 0.024321619007322524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1070594787597656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02807345986366272,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10929139852523803,
      "backward_entropy": 0.023990175790256925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7265410423278809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028129655867815018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10926904678344726,
      "backward_entropy": 0.02366133365366194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.978613257408142,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028184913098812103,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10924662351608276,
      "backward_entropy": 0.023338970210817125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4654490947723389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02823972888290882,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10922328233718873,
      "backward_entropy": 0.023758055435286626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3529021739959717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028293438255786896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10920069217681885,
      "backward_entropy": 0.02343574497434828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7757748365402222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028347371146082878,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10917553901672364,
      "backward_entropy": 0.0231153451734119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.148606538772583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028400756418704987,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914984941482545,
      "backward_entropy": 0.019498649570677016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6533827781677246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0284541267901659,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10912206172943115,
      "backward_entropy": 0.019222554233339097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4257842302322388,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850693091750145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10909425020217896,
      "backward_entropy": 0.022172265582614474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3821055889129639,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028558578342199326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10906647443771363,
      "backward_entropy": 0.021177162726720173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9756017923355103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028609272092580795,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090391755104065,
      "backward_entropy": 0.021569652689827815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7543463706970215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028658192604780197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10901316404342651,
      "backward_entropy": 0.02061061726676093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0135438442230225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028707033023238182,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1089855670928955,
      "backward_entropy": 0.020995676517486572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4049450159072876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028756389394402504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10895557403564453,
      "backward_entropy": 0.020054217841890123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1603668928146362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02880493365228176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10892506837844848,
      "backward_entropy": 0.0197800530327691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5922428369522095,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028852317482233047,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10889499187469483,
      "backward_entropy": 0.01721045540438758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.617630124092102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028899507597088814,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10886343717575073,
      "backward_entropy": 0.016977386342154607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5146080255508423,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028946498408913612,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1088300108909607,
      "backward_entropy": 0.016746812396579318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2588074207305908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02899320237338543,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10879526138305665,
      "backward_entropy": 0.016519306434525385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7374995946884155,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02903912588953972,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1087601661682129,
      "backward_entropy": 0.01629690660370721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9213413596153259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029083332046866417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1087272047996521,
      "backward_entropy": 0.01821873750951555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9398097991943359,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029126139357686043,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10869452953338624,
      "backward_entropy": 0.01858529117372301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4154878854751587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029168054461479187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10866273641586303,
      "backward_entropy": 0.01774809095594618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9281806349754333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920999377965927,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10862866640090943,
      "backward_entropy": 0.015478284822569953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8216671347618103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02925094962120056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10859491825103759,
      "backward_entropy": 0.01728894313176473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1793417930603027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0292910635471344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10856268405914307,
      "backward_entropy": 0.017069053318765428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8548654317855835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029331019148230553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10852909088134766,
      "backward_entropy": 0.016850206587049697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9798097610473633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029370004311203957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10849565267562866,
      "backward_entropy": 0.01720051301850213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.131851315498352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029408320784568787,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10846122503280639,
      "backward_entropy": 0.016428305043114558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1632715463638306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029446419328451157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842485427856445,
      "backward_entropy": 0.016220202048619587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.919913113117218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029484622180461884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1083868145942688,
      "backward_entropy": 0.01601188712649875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.65987628698349,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029522143304347992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10834808349609375,
      "backward_entropy": 0.015807756119304232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0885828733444214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029558727517724037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1083111047744751,
      "backward_entropy": 0.015610489580366347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5738788843154907,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029595155268907547,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10827168226242065,
      "backward_entropy": 0.013714197609159682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7186675667762756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029629971832036972,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10823280811309814,
      "backward_entropy": 0.013560890323585935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1381382942199707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029664115980267525,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10819437503814697,
      "backward_entropy": 0.015566532810529074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9730098843574524,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029698429629206657,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10815236568450928,
      "backward_entropy": 0.015380099415779114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7101686000823975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029732488095760345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10810799598693847,
      "backward_entropy": 0.015196815133094788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9563205242156982,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029765820130705833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10806365013122558,
      "backward_entropy": 0.01501774787902832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45612290501594543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029798753559589386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10801626443862915,
      "backward_entropy": 0.014318837059868706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8022437691688538,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02983022667467594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10797048807144165,
      "backward_entropy": 0.014676060941484239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6265435814857483,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029861198738217354,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10792280435562134,
      "backward_entropy": 0.01257181167602539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6506807208061218,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029891444370150566,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10787516832351685,
      "backward_entropy": 0.01435387134552002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6483766436576843,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029920944944024086,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10782678127288818,
      "backward_entropy": 0.012325466507010989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8402734994888306,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029949890449643135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10777783393859863,
      "backward_entropy": 0.012207510570685068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.614654004573822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029978718608617783,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10772591829299927,
      "backward_entropy": 0.012090893255339729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5350700616836548,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030006956309080124,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10767360925674438,
      "backward_entropy": 0.013753515978654226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5158527493476868,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030034322291612625,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10762125253677368,
      "backward_entropy": 0.013612684276368883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5575789213180542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030060773715376854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10756868124008179,
      "backward_entropy": 0.013476942148473527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7954806685447693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030086562037467957,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10751539468765259,
      "backward_entropy": 0.011664066877630021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5947253704071045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030112501233816147,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10745869874954224,
      "backward_entropy": 0.012647801803217994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4619910418987274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030138181522488594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10740135908126831,
      "backward_entropy": 0.012511788970894284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46175146102905273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030162855982780457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10734384059906006,
      "backward_entropy": 0.012960006793340048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5251309871673584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030186818912625313,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10728647708892822,
      "backward_entropy": 0.011279855337407853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3548809289932251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030210033059120178,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1072275161743164,
      "backward_entropy": 0.012131916152106391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4192597270011902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030232423916459084,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10717010498046875,
      "backward_entropy": 0.011110691560639275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7546085715293884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030253974720835686,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10711232423782349,
      "backward_entropy": 0.012503390510876974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41108790040016174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030276091769337654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10705002546310424,
      "backward_entropy": 0.01178362468878428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3942711055278778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030297698453068733,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10698832273483276,
      "backward_entropy": 0.011669836110538907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5451558828353882,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03031858056783676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10692671537399293,
      "backward_entropy": 0.01218419935968187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38122549653053284,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030339479446411133,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10686311721801758,
      "backward_entropy": 0.010723964207702212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4412705600261688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030359946191310883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1068002462387085,
      "backward_entropy": 0.0119808672202958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39199307560920715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030380001291632652,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10673633813858033,
      "backward_entropy": 0.010580678780873617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34731483459472656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03039938397705555,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10667170286178589,
      "backward_entropy": 0.011136319074365828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2658858597278595,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03041800856590271,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10660699605941773,
      "backward_entropy": 0.010449761317835914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30028173327445984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03043525107204914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10654247999191284,
      "backward_entropy": 0.010947795377837287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3597027063369751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030452121049165726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10647940635681152,
      "backward_entropy": 0.010859333806567721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3169998824596405,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030468998476862907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10641667842864991,
      "backward_entropy": 0.011447378330760531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40483877062797546,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03048531338572502,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.106353759765625,
      "backward_entropy": 0.011367308596769968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2714320421218872,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03050137311220169,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10628851652145385,
      "backward_entropy": 0.011289056804445054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41649606823921204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030516983941197395,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10622435808181763,
      "backward_entropy": 0.010126147005293105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3758179843425751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030532734468579292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10615795850753784,
      "backward_entropy": 0.01043717728720771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39809325337409973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030548667535185814,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10609062910079955,
      "backward_entropy": 0.010023712284035154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35844850540161133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0305644441395998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10602071285247802,
      "backward_entropy": 0.010983669095569186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24048882722854614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03058013506233692,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10594971179962158,
      "backward_entropy": 0.010187251700295342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28765618801116943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03059513494372368,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10587970018386841,
      "backward_entropy": 0.009874722195996178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20648743212223053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030609775334596634,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10580946207046509,
      "backward_entropy": 0.009828680091434054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2513454258441925,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030623409897089005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1057399868965149,
      "backward_entropy": 0.010700637267695533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3427443206310272,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030636463314294815,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1056703805923462,
      "backward_entropy": 0.010637718770239089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23771478235721588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030649598687887192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1055985450744629,
      "backward_entropy": 0.009816264940632714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.278734028339386,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030662283301353455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10552710294723511,
      "backward_entropy": 0.010513963798681894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1864904910326004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03067481517791748,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1054547905921936,
      "backward_entropy": 0.009680092334747314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2428935468196869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03068639151751995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10538303852081299,
      "backward_entropy": 0.00961692382891973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2832467257976532,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030697772279381752,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10531096458435059,
      "backward_entropy": 0.010343795021375021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19381698966026306,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070910833775997,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10523688793182373,
      "backward_entropy": 0.00953946676519182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28856775164604187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030719785019755363,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10516316890716552,
      "backward_entropy": 0.009433872169918485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19998793303966522,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03073066473007202,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10508766174316406,
      "backward_entropy": 0.009480971429083083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17185966670513153,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03074122965335846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10501278638839721,
      "backward_entropy": 0.009315578473938836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2104927897453308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03075149841606617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10493943691253663,
      "backward_entropy": 0.009259136186705695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20397497713565826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030761579051613808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10486574172973633,
      "backward_entropy": 0.009203680687480502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19590702652931213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0307715255767107,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10479193925857544,
      "backward_entropy": 0.0093704867694113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22478002309799194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030781438574194908,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10471842288970948,
      "backward_entropy": 0.009094703528616164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21600762009620667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03079161047935486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1046442985534668,
      "backward_entropy": 0.009039454989963107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14579319953918457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03080141916871071,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.104568350315094,
      "backward_entropy": 0.008985653519630432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13258934020996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03081032633781433,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1044926404953003,
      "backward_entropy": 0.009265227450264825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20163632929325104,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030818717554211617,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10441840887069702,
      "backward_entropy": 0.00976646774344974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28187295794487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0308274794369936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10434397459030151,
      "backward_entropy": 0.008840425146950616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06489800661802292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03083694726228714,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1042658805847168,
      "backward_entropy": 0.009680370489756266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12246470153331757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030845265835523605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10419131517410278,
      "backward_entropy": 0.008742017878426446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11805122345685959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030853023752570152,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10411791801452637,
      "backward_entropy": 0.008698392245504592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17159110307693481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030860314145684242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1040457010269165,
      "backward_entropy": 0.008657078776094649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14193901419639587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030867651104927063,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10397250652313232,
      "backward_entropy": 0.008615555034743415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12288858741521835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03087473101913929,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10389919281005859,
      "backward_entropy": 0.009105410840776231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15691839158535004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030881520360708237,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10382661819458008,
      "backward_entropy": 0.009466717640558878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1869739443063736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030888453125953674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10375347137451171,
      "backward_entropy": 0.008496991462177701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13118791580200195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03089551255106926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10367794036865234,
      "backward_entropy": 0.008456819587283664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10227964073419571,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030902255326509476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1036023736000061,
      "backward_entropy": 0.008418040143118964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1696186363697052,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03090851940214634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10352797508239746,
      "backward_entropy": 0.008381531470351748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14866000413894653,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030915062874555588,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10345193147659301,
      "backward_entropy": 0.009013395342561934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14056354761123657,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03092145547270775,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10337438583374023,
      "backward_entropy": 0.008999202814367082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13566435873508453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03092782385647297,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10329607725143433,
      "backward_entropy": 0.008984941575262282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16826516389846802,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030934199690818787,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10321727991104127,
      "backward_entropy": 0.009216588404443529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048409100621938705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030940797179937363,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10313608646392822,
      "backward_entropy": 0.008954845368862152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14406849443912506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030946414917707443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1030582308769226,
      "backward_entropy": 0.008160918123192258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14557041227817535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03095197305083275,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10297820568084717,
      "backward_entropy": 0.008932574755615659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09760940819978714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03095770999789238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10289649963378907,
      "backward_entropy": 0.008093235393365225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09789331257343292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03096332773566246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10281599760055542,
      "backward_entropy": 0.00907930400636461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10534930229187012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03096875362098217,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10273621082305909,
      "backward_entropy": 0.009053672353426615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09441890567541122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03097408451139927,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10265653133392334,
      "backward_entropy": 0.008886747062206268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0809832289814949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030979201197624207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10257734060287475,
      "backward_entropy": 0.007964171469211578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11612587422132492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03098374232649803,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10249847173690796,
      "backward_entropy": 0.008869030409389071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1067352369427681,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03098841942846775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10241844654083251,
      "backward_entropy": 0.007906648019949595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06321512907743454,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030993061140179634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10233755111694336,
      "backward_entropy": 0.007877757979763879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11395838856697083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0309975054115057,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10225926637649536,
      "backward_entropy": 0.008916786975330777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09334618598222733,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031002216041088104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10217978954315185,
      "backward_entropy": 0.00889460328552458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10126881301403046,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031007030978798866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10210058689117432,
      "backward_entropy": 0.00887207355764177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.062427617609500885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031011944636702538,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10202056169509888,
      "backward_entropy": 0.007762844363848369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0926605686545372,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031016454100608826,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10194201469421386,
      "backward_entropy": 0.008828183015187582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09574298560619354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03102087788283825,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10186257362365722,
      "backward_entropy": 0.008796739081541697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06703007221221924,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03102535381913185,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10178217887878419,
      "backward_entropy": 0.008786501155959235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08047939091920853,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03102947771549225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10170245170593262,
      "backward_entropy": 0.008767030305332608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07967943698167801,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031033404171466827,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10162221193313599,
      "backward_entropy": 0.00874834010998408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09202613681554794,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03103739582002163,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10154209136962891,
      "backward_entropy": 0.008766554296016693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0886765792965889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03104155883193016,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10146074295043946,
      "backward_entropy": 0.008709837992986044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056815970689058304,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03104589693248272,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10137864351272582,
      "backward_entropy": 0.008749528063668145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0731227919459343,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03104993887245655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10129795074462891,
      "backward_entropy": 0.008670537008179558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0832475945353508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031053954735398293,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10121705532073974,
      "backward_entropy": 0.007501691579818726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05500144883990288,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031058084219694138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10113515853881835,
      "backward_entropy": 0.008632471164067587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05156528577208519,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03106210008263588,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10105488300323487,
      "backward_entropy": 0.008613833122783236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03308974206447601,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031065816059708595,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10097572803497315,
      "backward_entropy": 0.008596482376257578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06553742289543152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031069310382008553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10090000629425049,
      "backward_entropy": 0.007405981421470642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06978161633014679,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031072990968823433,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10082433223724366,
      "backward_entropy": 0.008563407593303256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0544787161052227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03107687644660473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10074789524078369,
      "backward_entropy": 0.00735982424683041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.057334158569574356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031080668792128563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10067191123962402,
      "backward_entropy": 0.00733684500058492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04374471679329872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031084459275007248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10059607028961182,
      "backward_entropy": 0.007313953505622016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06842655688524246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031087957322597504,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10052111148834228,
      "backward_entropy": 0.00866198374165429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0784597098827362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03109166771173477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10044482946395875,
      "backward_entropy": 0.007269899050394694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06778481602668762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03109581582248211,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10036650896072388,
      "backward_entropy": 0.0086429077717993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027489209547638893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0311001967638731,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10028694868087769,
      "backward_entropy": 0.0072204288509156965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04035872593522072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031104188412427902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10021042823791504,
      "backward_entropy": 0.007197144130865733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04914387688040733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03110797144472599,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1001349687576294,
      "backward_entropy": 0.007174860272142623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027905432507395744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03111182525753975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10005985498428345,
      "backward_entropy": 0.007152424090438419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052224062383174896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031115233898162842,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09998672008514405,
      "backward_entropy": 0.008374601602554321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041136033833026886,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031118718907237053,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09991276860237122,
      "backward_entropy": 0.00858457303709454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03339302912354469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031122030690312386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09983898401260376,
      "backward_entropy": 0.007090722521146138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03830327093601227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031125232577323914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09976671934127808,
      "backward_entropy": 0.008329913020133972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03335272893309593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031128300353884697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09969469308853149,
      "backward_entropy": 0.0070519960588879054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02718074433505535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031131204217672348,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09962306022644044,
      "backward_entropy": 0.008302984966172112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031461749225854874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03113379143178463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0995525062084198,
      "backward_entropy": 0.00829108390543196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03676201030611992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03113625757396221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09948259592056274,
      "backward_entropy": 0.0070002443260616725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03530304133892059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031138723716139793,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09941250085830688,
      "backward_entropy": 0.00854145156012641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03466707095503807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03114120475947857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09934245347976685,
      "backward_entropy": 0.006967410445213318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039337966591119766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031143678352236748,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09927237033843994,
      "backward_entropy": 0.008245452410644956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04740612208843231,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031146250665187836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09920151829719544,
      "backward_entropy": 0.008233641584714254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02229367382824421,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03114919550716877,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09912909269332885,
      "backward_entropy": 0.008220406042204963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03154180198907852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03115181066095829,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09905810356140136,
      "backward_entropy": 0.00820846524503496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027791548520326614,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031154515221714973,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09898765087127685,
      "backward_entropy": 0.008506796426243253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039339859038591385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031157096847891808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0989176332950592,
      "backward_entropy": 0.006865512993600633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026038575917482376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031159961596131325,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0988466501235962,
      "backward_entropy": 0.008171715670161776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02490133047103882,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031162681058049202,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09877628684043885,
      "backward_entropy": 0.008159490095244514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02738294191658497,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03116527944803238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09870665073394776,
      "backward_entropy": 0.006814443402820163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01957230642437935,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03116791509091854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09863747954368592,
      "backward_entropy": 0.00813590238491694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024349063634872437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03117046132683754,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09857008457183838,
      "backward_entropy": 0.00846804016166263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014593848027288914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03117295540869236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985029935836792,
      "backward_entropy": 0.006766468286514282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017736362293362617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031175119802355766,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09843757748603821,
      "backward_entropy": 0.008457144101460775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02283656597137451,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031177090480923653,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0983731508255005,
      "backward_entropy": 0.006738953706290986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014576819725334644,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031179161742329597,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09830920696258545,
      "backward_entropy": 0.008448700110117594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019601531326770782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03118101693689823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09824674129486084,
      "backward_entropy": 0.0067126986881097155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0257436390966177,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031182801350951195,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09818454980850219,
      "backward_entropy": 0.008441708154148526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020532818511128426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031184833496809006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09812192916870117,
      "backward_entropy": 0.006687097251415253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018083635717630386,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031186923384666443,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0980596661567688,
      "backward_entropy": 0.008049960765573714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01647159270942211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031189030036330223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09799820184707642,
      "backward_entropy": 0.006660294615560108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021776335313916206,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031191077083349228,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09793756008148194,
      "backward_entropy": 0.008031535479757521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017336435616016388,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031193241477012634,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09787654876708984,
      "backward_entropy": 0.008416271871990628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018779713660478592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031195472925901413,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0978163480758667,
      "backward_entropy": 0.006620141367117564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020839838311076164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031197762116789818,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0977562665939331,
      "backward_entropy": 0.006606351584196091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014454018324613571,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03120017610490322,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09769574403762818,
      "backward_entropy": 0.006592077513535817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014641007408499718,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031202450394630432,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09763587713241577,
      "backward_entropy": 0.006578406939903895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012109928764402866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031204666942358017,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09757670164108276,
      "backward_entropy": 0.007972439957989587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013502172194421291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031206728890538216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09751852750778198,
      "backward_entropy": 0.006552368402481079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012278759852051735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031208757311105728,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09746110439300537,
      "backward_entropy": 0.0065398915774292415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01740236021578312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03121069073677063,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09740444421768188,
      "backward_entropy": 0.006527874618768692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015036206692457199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031212707981467247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09734708070755005,
      "backward_entropy": 0.006515519486533271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013583972118794918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03121480904519558,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09728978276252746,
      "backward_entropy": 0.00650291062063641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009413165040314198,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031216934323310852,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09723283052444458,
      "backward_entropy": 0.00835052298174964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012697123922407627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03121892735362053,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09717723727226257,
      "backward_entropy": 0.007910182906521691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009924953803420067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031220940873026848,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09712196588516235,
      "backward_entropy": 0.006466252936257256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007644289638847113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031222838908433914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09706753492355347,
      "backward_entropy": 0.00645474385884073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010129697620868683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031224580481648445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09701457023620605,
      "backward_entropy": 0.006443945897950066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009842277504503727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031226258724927902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09696201682090759,
      "backward_entropy": 0.006433412846591737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009678885340690613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031227869912981987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0969098687171936,
      "backward_entropy": 0.006423185269037883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0061466083861887455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031229494139552116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09685834050178528,
      "backward_entropy": 0.006412985010279549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010572724975645542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031230932101607323,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0968082070350647,
      "backward_entropy": 0.007857480810748206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010596218518912792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031232444569468498,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09675804376602173,
      "backward_entropy": 0.0063939156631628675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011461333371698856,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031234072521328926,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09670796394348144,
      "backward_entropy": 0.008304943641026815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0056425039656460285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031235862523317337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09665764570236206,
      "backward_entropy": 0.00637322540084521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00769829424098134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03123750165104866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09660878181457519,
      "backward_entropy": 0.006363266458113988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0065126363188028336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031239133328199387,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09656060934066772,
      "backward_entropy": 0.00782174203130934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009382911026477814,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0312406737357378,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09651326537132263,
      "backward_entropy": 0.007815030713876089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0053109521977603436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03124232031404972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09646575450897217,
      "backward_entropy": 0.006334149175220066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006147719454020262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031243856996297836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09641948938369752,
      "backward_entropy": 0.006324835121631622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004857878666371107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03124534897506237,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09637398719787597,
      "backward_entropy": 0.008272599014970992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007033489178866148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031246749684214592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09632967710494995,
      "backward_entropy": 0.006307143718004227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004203020129352808,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031248196959495544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09628558158874512,
      "backward_entropy": 0.007782697677612305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005734787788242102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03124951384961605,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09624264240264893,
      "backward_entropy": 0.007777017851670583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043098595924675465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125081956386566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0962000846862793,
      "backward_entropy": 0.006282131291098065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024982525501400232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03125203028321266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09615845680236816,
      "backward_entropy": 0.0077661532494756914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004997885320335627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031253062188625336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09611842036247253,
      "backward_entropy": 0.006267610937356949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004746111109852791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312541127204895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09607884883880616,
      "backward_entropy": 0.006260729912254546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035610245540738106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125518932938576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09603985548019409,
      "backward_entropy": 0.0062537843154536355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038749300874769688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031256210058927536,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.096001797914505,
      "backward_entropy": 0.006247149987353219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033587419893592596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03125718981027603,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09596437215805054,
      "backward_entropy": 0.007743828826480442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004502229392528534,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03125811368227005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0959277629852295,
      "backward_entropy": 0.007739826209015316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003008707659319043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03125908225774765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09589135646820068,
      "backward_entropy": 0.007735678719149696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004411241505295038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126000985503197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09585590362548828,
      "backward_entropy": 0.006222152047687107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037707423325628042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031261004507541656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09582061171531678,
      "backward_entropy": 0.006215857962767283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031232843175530434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031262002885341644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09578565359115601,
      "backward_entropy": 0.008227465881241692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003869501408189535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03126295283436775,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09575124979019164,
      "backward_entropy": 0.007719231148560842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002561426954343915,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03126396983861923,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09571714997291565,
      "backward_entropy": 0.008221796817249723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043794456869363785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03126492723822594,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09568386673927307,
      "backward_entropy": 0.008219012783633338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016517769545316696,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031265996396541595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09565038681030273,
      "backward_entropy": 0.006184859408272637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002905759960412979,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031266938894987106,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09561812877655029,
      "backward_entropy": 0.007702531086073982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028590860310941935,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03126789256930351,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09558632969856262,
      "backward_entropy": 0.008209990130530464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031313954386860132,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03126884251832962,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09555487632751465,
      "backward_entropy": 0.008207099305258857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018663258524611592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126982972025871,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09552358388900757,
      "backward_entropy": 0.006161504321628147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022600414231419563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03127072751522064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0954931139945984,
      "backward_entropy": 0.006155980130036672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002444760873913765,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031271617859601974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09546324014663696,
      "backward_entropy": 0.007683023810386658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00175633211620152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03127250075340271,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09543370008468628,
      "backward_entropy": 0.007679329150252872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001876095193438232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031273335218429565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09540492296218872,
      "backward_entropy": 0.006140013535817464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002469761064276099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031274136155843735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09537670612335206,
      "backward_entropy": 0.006135037375821007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001415163860656321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03127497434616089,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09534862637519836,
      "backward_entropy": 0.006129940350850423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002256296342238784,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03127574548125267,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09532135725021362,
      "backward_entropy": 0.00766577488846249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001844604965299368,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031276557594537735,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0952942430973053,
      "backward_entropy": 0.008183698687288497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012610406847670674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312773771584034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09526760578155517,
      "backward_entropy": 0.0061153388685650295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001866258797235787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031278129667043686,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09524171948432922,
      "backward_entropy": 0.008178790410359701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013920613564550877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03127890080213547,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09521608352661133,
      "backward_entropy": 0.0076527587241596645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000876480364240706,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03127964213490486,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09519104361534118,
      "backward_entropy": 0.008174054324626923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016926745884120464,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128029406070709,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09516686201095581,
      "backward_entropy": 0.007647017637888591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010353251127526164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128096088767052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09514279961585999,
      "backward_entropy": 0.006093352205223507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015962511533871293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031281571835279465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0951193928718567,
      "backward_entropy": 0.0060894497566752965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014514971990138292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128223121166229,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09509618282318115,
      "backward_entropy": 0.006085391673776839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016086130635812879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128291293978691,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09507321119308472,
      "backward_entropy": 0.006081296337975396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013283160515129566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128363564610481,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09505031108856202,
      "backward_entropy": 0.006077053232325448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017575313104316592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128436952829361,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09502770900726318,
      "backward_entropy": 0.006072803503937191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008841019589453936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128517419099808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0950049877166748,
      "backward_entropy": 0.006068278517987993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008125599124468863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128592297434807,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09498289823532105,
      "backward_entropy": 0.006064006023936802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015238862251862884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031286630779504776,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0949614942073822,
      "backward_entropy": 0.007621114452679952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010132757015526295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128740191459656,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09493999481201172,
      "backward_entropy": 0.0076180075605710345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010284847812727094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128815442323685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0949188232421875,
      "backward_entropy": 0.007614982624848683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009289663285017014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128889948129654,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09489791989326476,
      "backward_entropy": 0.007611997425556183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005884677520953119,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128962218761444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09487736821174622,
      "backward_entropy": 0.007609085904227363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008948292816057801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03129028528928757,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09485752582550049,
      "backward_entropy": 0.008139027489556206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007875848677940667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03129094839096069,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0948379635810852,
      "backward_entropy": 0.007603755427731408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006543081835843623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031291596591472626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09481878280639648,
      "backward_entropy": 0.006032064143154357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008318605250678957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031292207539081573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09480001926422119,
      "backward_entropy": 0.006028569820854399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005973521037958562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129282593727112,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.094781494140625,
      "backward_entropy": 0.006025052318970363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008934316574595869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129340708255768,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09476338624954224,
      "backward_entropy": 0.0060216983159383135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033407079172320664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03129402920603752,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09474535584449768,
      "backward_entropy": 0.007591357661618127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005891264299862087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031294580549001694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09472806453704834,
      "backward_entropy": 0.006015026321013768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006618071929551661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129512444138527,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09471113085746766,
      "backward_entropy": 0.006011899146768782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005041426629759371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03129567205905914,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09469434022903442,
      "backward_entropy": 0.008120668431123098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005151662044227123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031296197324991226,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09467794895172119,
      "backward_entropy": 0.008118857112195756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005519111291505396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031296711415052414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0946618676185608,
      "backward_entropy": 0.006002788328462177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007218969985842705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031297218054533005,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09464596509933472,
      "backward_entropy": 0.008115367756949531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004489089478738606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129776939749718,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09463001489639282,
      "backward_entropy": 0.005996794750293096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046010108781047165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129830211400986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09461439847946167,
      "backward_entropy": 0.005993797961208556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003495231212582439,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129882737994194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09459908008575439,
      "backward_entropy": 0.005990857051478492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004863936628680676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03129931539297104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09458414316177369,
      "backward_entropy": 0.00757027914126714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004698120173998177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031299807131290436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09456934928894042,
      "backward_entropy": 0.005985280291901695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037852165405638516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130031377077103,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09455472230911255,
      "backward_entropy": 0.005982452796565162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003092358529102057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031300805509090424,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09454036355018616,
      "backward_entropy": 0.005979692356454002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003652045561466366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130127117037773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09452638030052185,
      "backward_entropy": 0.005977045330736373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023665247135795653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130173310637474,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09451260566711425,
      "backward_entropy": 0.0059744492173194885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034627062268555164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130215406417847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09449926614761353,
      "backward_entropy": 0.005972016188833449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003645482356660068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130257874727249,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09448609352111817,
      "backward_entropy": 0.005969588541322284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002964679151773453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130302205681801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09447302818298339,
      "backward_entropy": 0.007555399503972795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002789259306155145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130345419049263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09446016550064087,
      "backward_entropy": 0.005964685645368364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001856107119238004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031303878873586655,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09444754123687744,
      "backward_entropy": 0.005962291111548741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022047101811040193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031304266303777695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09443531036376954,
      "backward_entropy": 0.005960080772638321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019411035464145243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130463510751724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09442335367202759,
      "backward_entropy": 0.005957945353455014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021818386449012905,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031304981559515,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09441171884536743,
      "backward_entropy": 0.00808845791551802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015147071098908782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031305328011512756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09440032243728638,
      "backward_entropy": 0.005953906310929192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018836230447050184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130564093589783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09438926577568055,
      "backward_entropy": 0.005952032075987922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002077253593597561,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313059464097023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09437842965126038,
      "backward_entropy": 0.005950206269820531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018092402024194598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031306251883506775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0943677544593811,
      "backward_entropy": 0.00594838625854916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017291821131948382,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130655363202095,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09435727000236512,
      "backward_entropy": 0.0075413402583864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001827076484914869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130685165524483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09434698224067688,
      "backward_entropy": 0.00594481701652209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001315954577876255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0313071571290493,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09433683753013611,
      "backward_entropy": 0.007538946138487922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016839145973790437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130744770169258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09432697296142578,
      "backward_entropy": 0.005941332214408451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014007130812387913,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130774945020676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09431725740432739,
      "backward_entropy": 0.007536604172653622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011512343917274848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130804002285004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09430772662162781,
      "backward_entropy": 0.005937902463807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512050746707246e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130831569433212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09429845213890076,
      "backward_entropy": 0.00593629562192493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011727876699296758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130856901407242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09428944587707519,
      "backward_entropy": 0.0059347798426946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012430148490238935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130881488323212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09428062438964843,
      "backward_entropy": 0.005933291382259793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.597481792094186e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031309064477682114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09427192211151122,
      "backward_entropy": 0.005931813683774736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.325264257611707e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130929544568062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09426348209381104,
      "backward_entropy": 0.00593041545814938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930866897571832e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130949288606644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09425532221794128,
      "backward_entropy": 0.005929149687290192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.206109098158777e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130968287587166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09424735307693481,
      "backward_entropy": 0.007528901100158691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.806243229424581e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03130987659096718,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09423952102661133,
      "backward_entropy": 0.008072000410821702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.258388020796701e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0313100628554821,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09423189163208008,
      "backward_entropy": 0.008071404364373948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.634712917730212e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131023421883583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09422447681427001,
      "backward_entropy": 0.005924395389027066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.035055023152381e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031310394406318665,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09421725273132324,
      "backward_entropy": 0.007526050839159224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.458729330915958e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0313105545938015,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09421018362045289,
      "backward_entropy": 0.008069886101616753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.80426780693233e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131070360541344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09420325756072997,
      "backward_entropy": 0.005921258694595761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.73896138323471e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131086379289627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09419641494750977,
      "backward_entropy": 0.0059202296866310965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.944695683661848e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313110277056694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09418968558311462,
      "backward_entropy": 0.005919186605347527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.542003782466054e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131118044257164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09418315291404725,
      "backward_entropy": 0.005918196505970425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0902461478253826e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031311336904764175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0941767692565918,
      "backward_entropy": 0.005917203923066457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.279500353732146e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131147846579552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09417058229446411,
      "backward_entropy": 0.007521638439761268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.918810762115754e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031311605125665665,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09416454434394836,
      "backward_entropy": 0.007521115243434906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.951178198098205e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131172060966492,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09415866136550903,
      "backward_entropy": 0.005914592494567235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.088906669290736e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131183981895447,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09415286779403687,
      "backward_entropy": 0.005913780795203315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1400330044562e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131194785237312,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09414728879928588,
      "backward_entropy": 0.007519653273953332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.857414619938936e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131204843521118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09414186477661132,
      "backward_entropy": 0.005912270810869005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0517767552519217e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131214156746864,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09413660764694214,
      "backward_entropy": 0.008065348698033227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.027536488138139e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131221979856491,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09413156509399415,
      "backward_entropy": 0.005910949574576484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7727246560971253e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031312305480241776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09412657618522643,
      "backward_entropy": 0.00591029640701082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4486782422172837e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131238743662834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09412171244621277,
      "backward_entropy": 0.005909668074713813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5216582798748277e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131246566772461,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09411699175834656,
      "backward_entropy": 0.005909069544739193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4502231099177152e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131254389882088,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09411239624023438,
      "backward_entropy": 0.008064410752720304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.253410821140278e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031312618404626846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09410791397094727,
      "backward_entropy": 0.005907909737692939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1543428374570794e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031312692910432816,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09410355091094971,
      "backward_entropy": 0.008064082927174039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2049258404877037e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031312763690948486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09409929513931274,
      "backward_entropy": 0.005906795461972554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6047017197706737e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131283447146416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09409513473510742,
      "backward_entropy": 0.007515837748845418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.006151589739602e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131289780139923,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09409110546112061,
      "backward_entropy": 0.005905762314796448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6606467397650704e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313129648566246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09408718347549438,
      "backward_entropy": 0.005905256089237001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1226662283879705e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131302818655968,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09408335685729981,
      "backward_entropy": 0.005904760625627305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3550365110859275e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131309524178505,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09407958984375,
      "backward_entropy": 0.007514686220222049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1711753359122667e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131315857172012,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09407593607902527,
      "backward_entropy": 0.007514398131105635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4573675798601471e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313132144510746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09407242536544799,
      "backward_entropy": 0.005903323491414388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3080786629871e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031313274055719376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09406898021697999,
      "backward_entropy": 0.007513861689302657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3796686289424542e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131333366036415,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09406564235687256,
      "backward_entropy": 0.005902431077427334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0588069017103408e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031313396990299225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09406238794326782,
      "backward_entropy": 0.005901988181802962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.071193406067323e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031313456594944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09405921697616577,
      "backward_entropy": 0.005901561015182071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.75028547650436e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131350874900818,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09405617713928223,
      "backward_entropy": 0.005901152888933818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.79029846348567e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131355717778206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09405325651168824,
      "backward_entropy": 0.005900786568721135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0001452210417483e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131360560655594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09405040144920349,
      "backward_entropy": 0.005900419006745021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0022939022746868e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131365776062012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09404762983322143,
      "backward_entropy": 0.0059000419245825875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.448500011581928e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031313713639974594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09404491186141968,
      "backward_entropy": 0.007511918743451436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.716124284546822e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131376579403877,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09404226541519164,
      "backward_entropy": 0.007511672046449449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.407752946164692e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131382167339325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0940396785736084,
      "backward_entropy": 0.005898909436331855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.914189725648612e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031313877552747726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09403716325759888,
      "backward_entropy": 0.0058985381490654415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.891097084211651e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313139334321022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09403471946716309,
      "backward_entropy": 0.005898172656695048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6931007798557403e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131398931145668,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09403233528137207,
      "backward_entropy": 0.007510700159602695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.626263711950742e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131404146552086,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09403004646301269,
      "backward_entropy": 0.00751047498650021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.180150987551315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131409361958504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09402782917022705,
      "backward_entropy": 0.005897127919726902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.671408078138484e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031314149498939514,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09402563571929931,
      "backward_entropy": 0.008060615923669603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.587920102494536e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131420537829399,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09402352571487427,
      "backward_entropy": 0.007509777115450965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.49028993898537e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131426125764847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.094021475315094,
      "backward_entropy": 0.007509530418448978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.736598839372164e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031314313411712646,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0940194845199585,
      "backward_entropy": 0.007509309384557936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.228616035106825e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031314365565776825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09401754140853882,
      "backward_entropy": 0.0058954498834080165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.772107331518782e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031314417719841,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09401564598083496,
      "backward_entropy": 0.005895138614707523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.447930794209242e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131447359919548,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09401379823684693,
      "backward_entropy": 0.005894818653662999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.049123051823699e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131452575325966,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09401199817657471,
      "backward_entropy": 0.0075084252489937674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.514192258080584e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131457418203354,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09401025176048279,
      "backward_entropy": 0.00805931786696116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2111636301124236e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131462261080742,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09400855302810669,
      "backward_entropy": 0.005893930378887389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2726317183696665e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0313146710395813,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09400690197944642,
      "backward_entropy": 0.007507810162173377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8156086955277715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131471574306488,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09400529861450195,
      "backward_entropy": 0.008058903945816888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1138370104599744e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131475672125816,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09400373697280884,
      "backward_entropy": 0.0080587656961547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2256509712169645e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031314801424741745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09400221109390258,
      "backward_entropy": 0.005892856667439143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0911118099320447e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031314849853515625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09400070905685425,
      "backward_entropy": 0.0058925872047742205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4482503704348346e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131489455699921,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09399924278259278,
      "backward_entropy": 0.005892318569951587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.072355528071057e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131493926048279,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09399782419204712,
      "backward_entropy": 0.00750664621591568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.948251338035334e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131498396396637,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09399644136428834,
      "backward_entropy": 0.0058917999267578125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5556536254734965e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131502866744995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0939950942993164,
      "backward_entropy": 0.005891549504465527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5635611134712235e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131507337093353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0939937949180603,
      "backward_entropy": 0.005891304463148117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4114003761278582e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031315114349126816,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09399253726005555,
      "backward_entropy": 0.008057588504420387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.057484837474476e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313151553273201,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09399131536483765,
      "backward_entropy": 0.005890843354993396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.865548236120958e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315192580223083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09399014115333557,
      "backward_entropy": 0.005890638050105836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.156231064669555e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131522610783577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09398900270462036,
      "backward_entropy": 0.0058904364705085754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.049560733525141e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131525591015816,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09398791193962097,
      "backward_entropy": 0.008057121601369645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1176102816534694e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131528198719025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09398685693740845,
      "backward_entropy": 0.0075051916970147025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.726719554237206e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031315308064222336,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09398583173751832,
      "backward_entropy": 0.007505078282621171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.819910254307615e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315334141254425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09398481845855713,
      "backward_entropy": 0.005889749361409081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.106031259558222e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031315356492996216,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09398386478424073,
      "backward_entropy": 0.0075048597322569955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.879518537061813e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131537884473801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09398293495178223,
      "backward_entropy": 0.007504773636658986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.287104952207301e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0313154011964798,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09398202300071716,
      "backward_entropy": 0.0075046759512689375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.324399350887688e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131542354822159,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09398115277290345,
      "backward_entropy": 0.005889190153943168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.576251058097114e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131544217467308,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09398030042648316,
      "backward_entropy": 0.005889067219363319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.532074851544166e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031315457075834274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09397948384284974,
      "backward_entropy": 0.007504439188374413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.747092473029625e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131547197699547,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09397870302200317,
      "backward_entropy": 0.008056494096914927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1901105873876077e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131548687815666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09397793412208558,
      "backward_entropy": 0.007504297627343072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.108551022203756e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031315501779317856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09397718906402588,
      "backward_entropy": 0.007504238022698296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.326870512410096e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131551668047905,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09397647380828858,
      "backward_entropy": 0.007504178418053521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.042909438339848e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315527856349945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397578239440918,
      "backward_entropy": 0.005888434333933724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.003955555413995e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131553903222084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397510290145875,
      "backward_entropy": 0.005888351135783725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.287060224010929e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315550208091736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397444725036622,
      "backward_entropy": 0.005888276629977756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0069489298512053e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131556138396263,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09397382736206054,
      "backward_entropy": 0.007503988014327155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7752801656788506e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131556883454323,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397321939468384,
      "backward_entropy": 0.005888117684258355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1304381309382734e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315576285123825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397262930870057,
      "backward_entropy": 0.005888054354323281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1293828328671225e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131558373570442,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0939720630645752,
      "backward_entropy": 0.008056267268127866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.865932060558407e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131559118628502,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09397149682044983,
      "backward_entropy": 0.007503835691346062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3602920862231258e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315598636865616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397094845771789,
      "backward_entropy": 0.005887866848044925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8098413079314923e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131560608744621,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397042393684388,
      "backward_entropy": 0.005887798964977264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.332015469619364e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131561353802681,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396991729736329,
      "backward_entropy": 0.005887739360332489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5122139984669047e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131562098860741,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09396942853927612,
      "backward_entropy": 0.007503702408737606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5636102546068287e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031315624713897705,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09396893978118896,
      "backward_entropy": 0.007503670122888353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3600026704807533e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031315628439188004,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09396848678588868,
      "backward_entropy": 0.007503651910358005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6537229896584904e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313156321644783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396803975105286,
      "backward_entropy": 0.005887532399760352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5758034521695663e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313156358897686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396761655807495,
      "backward_entropy": 0.0058874959746996565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3571239776410948e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313156396150589,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396719932556152,
      "backward_entropy": 0.005887450443373786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3123514008839265e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313156433403492,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396678805351258,
      "backward_entropy": 0.005887403256363339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.30327677538844e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315647065639496,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396640062332154,
      "backward_entropy": 0.005887372212277519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.836569437813523e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031315650790929794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09396601915359497,
      "backward_entropy": 0.00750351283285353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.707596859698242e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131565451622009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396565556526185,
      "backward_entropy": 0.005887276182572047,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 9.328636305880878e-06,
    "avg_log_Z": 0.0313142316788435,
    "success_rate": 1.0,
    "avg_reward": 47.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.11,
      "1": 0.32,
      "2": 0.57
    },
    "avg_forward_entropy": 0.09403131473064422,
    "avg_backward_entropy": 0.006651114655865565,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}